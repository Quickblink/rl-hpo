{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "lz4 not available, disabling sample compression. This will significantly impact RLlib performance. To install lz4, run `pip install lz4`.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.preprocessors import get_preprocessor\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.annotations import override\n",
    "from ray.rllib.utils import try_import_torch\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from gym.spaces import Box\n",
    "import ray\n",
    "import gym\n",
    "import numpy as np\n",
    "import ray.rllib.agents.ppo as ppo\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "\n",
    "torch, nn = try_import_torch()\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "class MyModel(TorchModelV2, nn.Module):\n",
    "    \"\"\"The default RNN model for QMIX.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config,\n",
    "                 name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs,\n",
    "                              model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        model_config =  model_config['custom_options']#print('HELLO', model_config)\n",
    "        self.obs_size = _get_size(obs_space)\n",
    "        self.prelstm = nn.ModuleList()\n",
    "        lstminp = self.obs_size\n",
    "        if model_config['prelstm']:\n",
    "            self.prelstm.append(nn.Linear(self.obs_size, model_config['prelstm'][0], bias=True))\n",
    "            lstminp = model_config['prelstm'][-1]\n",
    "            for i in range(0,len(model_config['prelstm'])-1):\n",
    "                self.prelstm.append(nn.Linear(model_config['prelstm'][i], model_config['prelstm'][i+1], bias=True))\n",
    "        self.rnn_hidden_dim = model_config[\"lstm_cell_size\"]\n",
    "        #self.fc1 = nn.Linear(self.obs_size, self.rnn_hidden_dim)\n",
    "        #self.rnn = nn.GRUCell(self.rnn_hidden_dim, self.rnn_hidden_dim)\n",
    "        self.lstm = nn.LSTM(lstminp, self.rnn_hidden_dim)\n",
    "        \n",
    "        self.postlstm = nn.ModuleList()\n",
    "        lstmout = self.rnn_hidden_dim\n",
    "        if model_config['postlstm']:\n",
    "            self.postlstm.append(nn.Linear(self.rnn_hidden_dim, model_config['postlstm'][0], bias=True))\n",
    "            lstmout = model_config['postlstm'][-1]\n",
    "            for i in range(0,len(model_config['postlstm'])-1):\n",
    "                self.postlstm.append(nn.Linear(model_config['postlstm'][i], model_config['postlstm'][i+1], bias=True))\n",
    "        \n",
    "        self.fcout = nn.Linear(lstmout, num_outputs)\n",
    "        self.valuef = nn.Linear(lstmout, 1)\n",
    "        self.v = 0\n",
    "\n",
    "    @override(TorchModelV2)\n",
    "    def get_initial_state(self):\n",
    "        # make hidden states on same device as model\n",
    "        #return [self.fcout.weight.new(1, self.rnn_hidden_dim).zero_().squeeze(0)]\n",
    "        return torch.zeros((2,1,self.rnn_hidden_dim))\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, hidden_state, seq_lens):\n",
    "        x = input_dict[\"obs_flat\"].float()\n",
    "        bsz = x.shape[0]\n",
    "        #x = nn.functional.relu(self.fc1(input_dict[\"obs_flat\"].float()))\n",
    "        for layer in self.prelstm:\n",
    "            x = F.relu(layer(x))\n",
    "        \n",
    "        #print(input_dict, hidden_state)\n",
    "        hidden_state[0] = hidden_state[0].reshape(1, bsz, self.rnn_hidden_dim)# if hidden_state else torch.zeros((1,1,1,self.rnn_hidden_dim))\n",
    "        hidden_state[1] = hidden_state[1].reshape(1, bsz, self.rnn_hidden_dim)\n",
    "        x, h = self.lstm(x.view(1,bsz,self.rnn_hidden_dim), hidden_state)\n",
    "        for layer in self.postlstm:\n",
    "            x = F.relu(layer(x.view(bsz,-1)))\n",
    "        # no ReLu activation in the output layer\n",
    "        a = self.fcout(x)\n",
    "        self.v = self.valuef(x)\n",
    "        return a, list(h)\n",
    "    \n",
    "    @override(TorchModelV2)\n",
    "    def value_function(self):\n",
    "        return self.v[0]\n",
    "\n",
    "\n",
    "def _get_size(obs_space):\n",
    "    return get_preprocessor(obs_space)(obs_space).size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "class GPEnv(gym.Env):\n",
    "    \"\"\"Example of a custom env in which you have to walk down a corridor.\n",
    "    You can configure the length of the corridor via the env config.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.kernel = RBF()\n",
    "        self.gp = GaussianProcessRegressor(kernel=self.kernel,\n",
    "        random_state=None, optimizer=None) #random?\n",
    "        self.observation_space = Box(\n",
    "            -np.inf, np.inf, shape=(2, ), dtype=np.float32)\n",
    "        self.action_space = Box(0,1,shape=(1, ), dtype=np.float32)\n",
    "        self.best = 0\n",
    "        self.nstep = 0\n",
    "        \n",
    "\n",
    "    def reset(self):\n",
    "        self.nstep = 0\n",
    "        self.gp = GaussianProcessRegressor(kernel=self.kernel, optimizer=None) #random?\n",
    "        y = self.gp.sample_y([[0.5]], random_state=np.random.randint(100000))\n",
    "        self.gp.fit([[0.5]], y)\n",
    "        y = y[0,0]\n",
    "        self.best = y\n",
    "        return [0.5, y]\n",
    "\n",
    "    def step(self, action):\n",
    "        #assert 0 <= action <= 1, action\n",
    "        y = self.gp.sample_y([action], random_state=np.random.randint(100000))[0]\n",
    "        #print(y)\n",
    "        self.gp.fit([action], y)\n",
    "        y = y[0,0]\n",
    "        reward = 0\n",
    "        if y > self.best:\n",
    "            reward = y-self.best\n",
    "            self.best = y\n",
    "        done = self.nstep >= 20\n",
    "        self.nstep = self.nstep + 1\n",
    "        return [action[0], y], reward, done, {} #never done\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "2020-02-25 15:25:43,285\tINFO resource_spec.py:212 -- Starting Ray with 8.94 GiB memory available for workers and up to 4.47 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-02-25 15:25:43,798\tINFO services.py:1083 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "{'node_ip_address': '192.168.178.57',\n 'redis_address': '192.168.178.57:42130',\n 'object_store_address': '/tmp/ray/session_2020-02-25_15-25-43_251116_491/sockets/plasma_store',\n 'raylet_socket_name': '/tmp/ray/session_2020-02-25_15-25-43_251116_491/sockets/raylet',\n 'webui_url': 'localhost:8265',\n 'session_dir': '/tmp/ray/session_2020-02-25_15-25-43_251116_491'}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "ray.init()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"my_model\", MyModel)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "2020-02-25 16:47:02,067\tERROR logger.py:184 -- pip install 'ray[tune]' to see TensorBoard files.\n",
      "2020-02-25 16:47:02,068\tWARNING logger.py:286 -- Could not instantiate TBXLogger: No module named 'tensorboardX'.\n",
      "2020-02-25 16:47:02,069\tERROR syncer.py:39 -- Log sync requires rsync to be installed.\n",
      "2020-02-25 16:47:20,089\tERROR trial_runner.py:513 -- Trial PPO_GPEnv_725a83b4: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 459, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 377, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ray/worker.py\", line 1504, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(KeyError): \u001b[36mray::PPO.train()\u001b[39m (pid=825, ip=192.168.178.57)\n",
      "  File \"python/ray/_raylet.pyx\", line 452, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 430, in ray._raylet.execute_task.function_executor\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\", line 497, in train\n",
      "    raise e\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\", line 483, in train\n",
      "    result = Trainable.train(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ray/tune/trainable.py\", line 254, in train\n",
      "    result = self._train()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ray/rllib/agents/trainer_template.py\", line 133, in _train\n",
      "    fetches = self.optimizer.step()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ray/rllib/optimizers/sync_samples_optimizer.py\", line 71, in step\n",
      "    self.standardize_fields)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ray/rllib/utils/sgd.py\", line 111, in do_minibatch_sgd\n",
      "    }, minibatch.count)))[policy_id]\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 626, in learn_on_batch\n",
      "    info_out[pid] = policy.learn_on_batch(batch)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ray/rllib/policy/torch_policy.py\", line 130, in learn_on_batch\n",
      "    loss_out = self._loss(self, self.model, self.dist_class, train_batch)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ray/rllib/agents/ppo/ppo_torch_policy.py\", line 113, in ppo_surrogate_loss\n",
      "    max_seq_len = torch.max(train_batch[\"seq_lens\"])\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/ray/rllib/utils/tracking_dict.py\", line 22, in __getitem__\n",
      "    value = dict.__getitem__(self, key)\n",
      "KeyError: 'seq_lens'\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 7.0/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/8 CPUs, 0/1 GPUs, 0.0/8.94 GiB heap, 0.0/3.08 GiB objects<br>Result logdir: /home/developer/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name        </th><th>status  </th><th>loc  </th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_GPEnv_725a83b4</td><td>RUNNING </td><td>     </td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "text": [
      "\u001b[2m\u001b[36m(pid=825)\u001b[0m 2020-02-25 16:47:04,100\tWARNING compression.py:16 -- lz4 not available, disabling sample compression. This will significantly impact RLlib performance. To install lz4, run `pip install lz4`.\n",
      "\u001b[2m\u001b[36m(pid=825)\u001b[0m 2020-02-25 16:47:04,543\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=825)\u001b[0m /opt/conda/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=825)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=825)\u001b[0m 2020-02-25 16:47:04,563\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=825)\u001b[0m 2020-02-25 16:47:19,577\tWARNING sgd.py:62 -- Not shuffling RNN data for SGD in simple mode\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 7.3/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/8.94 GiB heap, 0.0/3.08 GiB objects<br>Result logdir: /home/developer/ray_results/PPO<br>Number of trials: 1 (1 ERROR)<br><table>\n<thead>\n<tr><th>Trial name        </th><th>status  </th><th>loc  </th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_GPEnv_725a83b4</td><td>ERROR   </td><td>     </td></tr>\n</tbody>\n</table><br>Number of errored trials: 1<br><table>\n<thead>\n<tr><th>Trial name        </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                </th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_GPEnv_725a83b4</td><td style=\"text-align: right;\">           1</td><td>/home/developer/ray_results/PPO/PPO_GPEnv_725a83b4_0_2020-02-25_16-47-02akft4mzb/error.txt</td></tr>\n</tbody>\n</table><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 7.3/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/8.94 GiB heap, 0.0/3.08 GiB objects<br>Result logdir: /home/developer/ray_results/PPO<br>Number of trials: 1 (1 ERROR)<br><table>\n<thead>\n<tr><th>Trial name        </th><th>status  </th><th>loc  </th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_GPEnv_725a83b4</td><td>ERROR   </td><td>     </td></tr>\n</tbody>\n</table><br>Number of errored trials: 1<br><table>\n<thead>\n<tr><th>Trial name        </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                </th></tr>\n</thead>\n<tbody>\n<tr><td>PPO_GPEnv_725a83b4</td><td style=\"text-align: right;\">           1</td><td>/home/developer/ray_results/PPO/PPO_GPEnv_725a83b4_0_2020-02-25_16-47-02akft4mzb/error.txt</td></tr>\n</tbody>\n</table><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-ce2a4f41f18e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;34m\"num_workers\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;34m\"env_config\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;34m\"use_pytorch\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     },\n\u001b[1;32m     24\u001b[0m )\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, stop, config, resources_per_trial, num_samples, local_dir, upload_dir, trial_name_creator, loggers, sync_to_cloud, sync_to_driver, checkpoint_freq, checkpoint_at_end, sync_on_checkpoint, keep_checkpoints_num, checkpoint_score_attr, global_checkpoint_period, export_formats, max_failures, restore, search_alg, scheduler, with_server, server_port, verbose, progress_reporter, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, return_trials, ray_auto_init, sync_function)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merrored_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrored_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrored_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [PPO_GPEnv_725a83b4])"
     ],
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [PPO_GPEnv_725a83b4])",
     "output_type": "error"
    }
   ],
   "source": [
    "ray.tune.run(\n",
    "    \"PPO\",\n",
    "    stop={\n",
    "        \"timesteps_total\": 10000,\n",
    "    },\n",
    "    config={\n",
    "        \"env\": GPEnv,  # or \"corridor\" if registered above\n",
    "        \"model\": {\n",
    "            \"custom_model\": \"my_model\",\n",
    "            \"custom_options\": {\n",
    "                \"prelstm\": [20],\n",
    "                \"lstm_cell_size\": 20,\n",
    "                \"postlstm\": [20, 10]\n",
    "            },\n",
    "            \"lstm_cell_size\": 20,\n",
    "            #\"use_lstm\" : True\n",
    "        },\n",
    "        #\"vf_share_layers\": True,\n",
    "        \"lr\": 1e-4,  # try different lrs\n",
    "        \"num_workers\": 0,  # parallelism\n",
    "        \"env_config\": {},\n",
    "        \"use_pytorch\": True\n",
    "    },\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 62
    }
   ],
   "source": [
    "torch.zeros((2,3)).shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "model.value_function()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = ppo.DEFAULT_CONFIG.copy()\n",
    "config[\"num_gpus\"] = 0\n",
    "config[\"num_workers\"] = 1\n",
    "config[\"eager\"] = False\n",
    "config[\"model\"]: {\"custom_model\": \"my_model\",}\n",
    "config[\"use_pytorch\"] = True\n",
    "trainer = ppo.PPOTrainer(config=config, env=GPEnv)\n",
    "\n",
    "# Can optionally call trainer.restore(path) to load a checkpoint.\n",
    "\n",
    "for i in range(1000):\n",
    "   # Perform one iteration of training the policy with PPO\n",
    "   result = trainer.train()\n",
    "   print(pretty_print(result))\n",
    "\n",
    "   if i % 100 == 0:\n",
    "       checkpoint = trainer.save()\n",
    "       print(\"checkpoint saved at\", checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}