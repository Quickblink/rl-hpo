{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from GPEnv import GPEnv\n",
    "from train import train, validate\n",
    "from model import MyModel\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#TODO: predict variance\n",
    "model = MyModel(2,1,{\n",
    "    'prelstm' : [128],\n",
    "    'lstm_cell_size' : 128,\n",
    "    'postlstm' : []#[64, 32]\n",
    "}).cuda()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "model = torch.load('hposimple1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=5e-5) #4e-4\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[0.0032]], device='cuda:0', grad_fn=<SigmoidBackward>),\n tensor([[0.9672]], device='cuda:0', grad_fn=<AddmmBackward>),\n (tensor([[[-0.3149,  0.3946,  0.5414, -0.0153,  0.2291, -0.4799,  0.2608,\n             0.5244, -0.1804, -0.4252, -0.4694, -0.5543, -0.1199,  0.1159,\n             0.6361,  0.1772, -0.1424,  0.5044,  0.4748, -0.3647, -0.3612,\n             0.2253,  0.0463, -0.2367,  0.0425, -0.4260, -0.3491, -0.2106,\n             0.1556, -0.3615,  0.1084, -0.3915,  0.2386,  0.2935,  0.4883,\n            -0.1162, -0.4854, -0.4134, -0.3960,  0.0594,  0.1795,  0.5850,\n             0.0534,  0.5141, -0.5588, -0.5560, -0.4066,  0.4371,  0.3165,\n            -0.2182, -0.3429,  0.4248, -0.3054, -0.0986, -0.1397, -0.0681,\n             0.6596,  0.0592, -0.3955,  0.1683, -0.0955, -0.0341, -0.1875,\n            -0.0652,  0.2324,  0.6095, -0.0246,  0.5951, -0.2629, -0.0807,\n             0.4403,  0.4517, -0.3891, -0.2264, -0.4737,  0.1346,  0.2644,\n             0.6044, -0.3757, -0.2937, -0.4118, -0.4184,  0.3407,  0.1639,\n             0.3573, -0.3807, -0.5175, -0.4059,  0.1977,  0.2734,  0.1349,\n             0.3453, -0.2821,  0.4634,  0.5518,  0.0731,  0.0997,  0.2387,\n            -0.3089, -0.3433,  0.1928, -0.0291, -0.2514, -0.4222, -0.1543,\n             0.4829, -0.4339, -0.2802, -0.5199, -0.0816,  0.4587, -0.0937,\n            -0.0207, -0.1192,  0.2399, -0.5930, -0.4144, -0.1989,  0.4660,\n             0.5977, -0.3883,  0.3126, -0.5481,  0.5425,  0.2327,  0.2204,\n             0.0783, -0.2073]]], device='cuda:0', grad_fn=<CudnnRnnBackward>),\n  tensor([[[-0.4136,  0.5303,  0.6640, -0.0193,  0.2849, -0.6467,  0.3000,\n             0.6329, -0.2067, -0.5177, -0.5820, -0.6550, -0.1434,  0.1412,\n             0.7975,  0.2964, -0.1859,  0.6156,  0.6414, -0.5557, -0.5462,\n             0.2632,  0.0531, -0.2737,  0.0455, -0.4700, -0.5149, -0.2645,\n             0.1968, -0.5340,  0.1899, -0.4421,  0.2707,  0.3691,  0.5738,\n            -0.1326, -0.7193, -0.6425, -0.4278,  0.1040,  0.2029,  0.8072,\n             0.0602,  0.5796, -0.6777, -0.7108, -0.4481,  0.5956,  0.5122,\n            -0.2395, -0.5199,  0.5375, -0.4066, -0.1412, -0.2001, -0.0817,\n             0.8289,  0.0858, -0.4489,  0.1742, -0.1258, -0.0383, -0.2163,\n            -0.0771,  0.2675,  0.7938, -0.0327,  0.6903, -0.2977, -0.0909,\n             0.6060,  0.7422, -0.6043, -0.3134, -0.6495,  0.1889,  0.3468,\n             0.7241, -0.5519, -0.3253, -0.4449, -0.5724,  0.4405,  0.1982,\n             0.4059, -0.4939, -0.5993, -0.5851,  0.2448,  0.3136,  0.1428,\n             0.4041, -0.3882,  0.5303,  0.7166,  0.0888,  0.1049,  0.3121,\n            -0.4790, -0.4420,  0.2571, -0.0296, -0.4020, -0.4865, -0.1587,\n             0.6426, -0.5031, -0.3197, -0.7456, -0.0872,  0.7679, -0.1132,\n            -0.0233, -0.1380,  0.3373, -0.7222, -0.4889, -0.2803,  0.5741,\n             0.7026, -0.5468,  0.4599, -0.6354,  0.7150,  0.3177,  0.4394,\n             0.0900, -0.2692]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)))"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    }
   ],
   "source": [
    "model(torch.tensor([[0.5, 0]]).cuda(), None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Bigstep:  0\n",
      "Loss: 0.40104806423187256 -0.018125776201486588\n",
      "Loss: 0.34679555892944336 -0.21017135679721832\n",
      "Loss: 0.36601653695106506 -0.7704151272773743\n",
      "Loss: 0.34952428936958313 -0.5529991984367371\n",
      "Loss: 0.34491682052612305 -0.5640881657600403\n",
      "Loss: 0.257053941488266 -0.35665062069892883\n",
      "Loss: 0.3375386893749237 -0.8207054138183594\n",
      "Policy Reward: tensor(1.0709, device='cuda:0')\n",
      "Trajectory:  ['0.01', '0.99', '0.15', '0.17', '0.24', '0.17', '0.30', '0.30', '0.42', '0.52', '0.53', '0.48', '0.46', '0.48', '0.48', '0.47', '0.41', '0.32', '0.23']\n",
      "Last Action:  tensor([0.2288, 0.0753, 0.0526, 0.6747, 0.0054, 0.3281, 0.0069, 0.3240, 0.0757,\n",
      "        0.0054], device='cuda:0')\n",
      "Loss: 0.33930671215057373 -0.2736586034297943\n",
      "Loss: 0.3165954351425171 -0.8368289470672607\n",
      "Loss: 0.314645379781723 -0.8934194445610046\n",
      "Loss: 0.37905406951904297 -0.7121289372444153\n",
      "Loss: 0.32926830649375916 -0.2754681706428528\n",
      "Loss: 0.3017456829547882 -0.3414854109287262\n",
      "Loss: 0.2810101807117462 -0.7883521318435669\n",
      "Policy Reward: tensor(1.0931, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.47', '0.31', '0.21', '0.14', '0.30', '0.32', '0.19', '0.11', '0.14', '0.08', '0.06', '0.05', '0.05', '0.04', '0.03', '0.05', '0.11']\n",
      "Last Action:  tensor([0.1053, 0.0865, 0.0045, 0.0321, 0.1761, 0.0086, 0.5107, 0.0935, 0.1917,\n",
      "        0.5713], device='cuda:0')\n",
      "Loss: 0.3036974370479584 -0.6503645181655884\n",
      "Loss: 0.2972951829433441 -0.6295887231826782\n",
      "Loss: 0.36625853180885315 -0.8627508282661438\n",
      "Loss: 0.26343613862991333 -0.37160342931747437\n",
      "Loss: 0.33711618185043335 -0.5327722430229187\n",
      "Loss: 0.3087286651134491 -0.47467249631881714\n",
      "Loss: 0.27332431077957153 -0.43634331226348877\n",
      "Policy Reward: tensor(1.1087, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.58', '0.46', '0.29', '0.32', '0.53', '0.56', '0.43', '0.28', '0.33', '0.27', '0.19', '0.15', '0.10', '0.06', '0.04', '0.03', '0.01']\n",
      "Last Action:  tensor([0.0137, 0.5560, 0.0501, 0.0080, 0.6134, 0.0094, 0.0582, 0.0382, 0.0767,\n",
      "        0.6151], device='cuda:0')\n",
      "Loss: 0.30724036693573 -0.4112384021282196\n",
      "Loss: 0.3125077486038208 -0.24843446910381317\n",
      "Loss: 0.29474979639053345 -0.5345962047576904\n",
      "Loss: 0.2607569992542267 -0.4757407307624817\n",
      "Loss: 0.33795374631881714 -0.5239311456680298\n",
      "Loss: 0.29714882373809814 -0.4018462300300598\n",
      "Loss: 0.37862876057624817 -1.0065009593963623\n",
      "Policy Reward: tensor(1.1339, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.47', '0.81', '0.36', '0.41', '0.68', '0.59', '0.70', '0.60', '0.56', '0.56', '0.52', '0.52', '0.52', '0.57', '0.57', '0.62', '0.62']\n",
      "Last Action:  tensor([0.6233, 0.0528, 0.0745, 0.5858, 0.0011, 0.0328, 0.1425, 0.4301, 0.1469,\n",
      "        0.0548], device='cuda:0')\n",
      "Loss: 0.32742851972579956 -0.5758140683174133\n",
      "Loss: 0.3110533654689789 -0.31626826524734497\n",
      "Loss: 0.2802630662918091 -0.42477232217788696\n",
      "Loss: 0.3744073212146759 -0.7359824776649475\n",
      "Loss: 0.2625220715999603 -0.3637891411781311\n",
      "Loss: 0.3902469277381897 -0.9623097777366638\n",
      "Loss: 0.3156887888908386 -0.3525749742984772\n",
      "Policy Reward: tensor(1.0968, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.35', '0.43', '0.22', '0.20', '0.25', '0.14', '0.06', '0.11', '0.05', '0.02', '0.01', '0.02', '0.02', '0.01', '0.00', '0.00', '0.00']\n",
      "Last Action:  tensor([0.0024, 0.0434, 0.0043, 0.8129, 0.0023, 0.0025, 0.0106, 0.5343, 0.4072,\n",
      "        0.3904], device='cuda:0')\n",
      "Loss: 0.36823341250419617 -0.748363733291626\n",
      "Loss: 0.3008771240711212 -0.6049420833587646\n",
      "Loss: 0.2901204526424408 -0.6122339367866516\n",
      "Loss: 0.2907724678516388 -0.49792513251304626\n",
      "Loss: 0.2950959801673889 -0.6106043457984924\n",
      "Loss: 0.4150157868862152 -0.8846440315246582\n",
      "Loss: 0.24083642661571503 -0.6150471568107605\n",
      "Policy Reward: tensor(1.1144, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.76', '0.46', '0.23', '0.20', '0.21', '0.25', '0.29', '0.38', '0.49', '0.56', '0.54', '0.50', '0.49', '0.49', '0.44', '0.42', '0.40', '0.34']\n",
      "Last Action:  tensor([0.3372, 0.0229, 0.1473, 0.7681, 0.7559, 0.0899, 0.0028, 0.0035, 0.7326,\n",
      "        0.5379], device='cuda:0')\n",
      "Loss: 0.2807450294494629 -0.5354142189025879\n",
      "Loss: 0.32835084199905396 -0.7568454742431641\n",
      "Loss: 0.26706787943840027 -0.4076474606990814\n",
      "Loss: 0.3362908959388733 -0.4642152786254883\n",
      "Loss: 0.3191651403903961 -0.6275565028190613\n",
      "Loss: 0.27867016196250916 -0.739702582359314\n",
      "Loss: 0.354389488697052 -0.7989428639411926\n",
      "Policy Reward: tensor(0.9989, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.78', '0.18', '0.14', '0.15', '0.24', '0.39', '0.49', '0.57', '0.53', '0.44', '0.31', '0.31', '0.31', '0.29', '0.25', '0.19', '0.13']\n",
      "Last Action:  tensor([0.1285, 0.0018, 0.0616, 0.0026, 0.0021, 0.0127, 0.0040, 0.0503, 0.4056,\n",
      "        0.0390], device='cuda:0')\n",
      "Loss: 0.31795522570610046 -0.5718385577201843\n",
      "Loss: 0.3005402684211731 -0.607634961605072\n",
      "Loss: 0.25283944606781006 -0.3964952528476715\n",
      "Loss: 0.35262271761894226 -0.9088168144226074\n",
      "Loss: 0.4149809777736664 -1.1238491535186768\n",
      "Loss: 0.29188641905784607 -0.6504585146903992\n",
      "Loss: 0.3190472722053528 -0.842877209186554\n",
      "Policy Reward: tensor(1.1261, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.62', '0.24', '0.17', '0.09', '0.15', '0.25', '0.21', '0.16', '0.12', '0.05', '0.03', '0.02', '0.02', '0.02', '0.01', '0.00', '0.00']\n",
      "Last Action:  tensor([0.0030, 0.6073, 0.2334, 0.0654, 0.0803, 0.1046, 0.3494, 0.0391, 0.6011,\n",
      "        0.0129], device='cuda:0')\n",
      "Bigstep:  1\n",
      "Loss: 0.3876839280128479 -0.13831886649131775\n",
      "Loss: 0.3420555591583252 -0.13896311819553375\n",
      "Loss: 0.3829776346683502 -0.5050103068351746\n",
      "Loss: 0.3333098590373993 -0.08861794322729111\n",
      "Loss: 0.3410338759422302 -0.18829727172851562\n",
      "Loss: 0.28026068210601807 -0.35101625323295593\n",
      "Loss: 0.30652663111686707 -0.3532334566116333\n",
      "Policy Reward: tensor(0.9222, device='cuda:0')\n",
      "Trajectory:  ['0.01', '0.25', '0.25', '0.34', '0.41', '0.60', '0.97', '0.94', '0.92', '0.85', '0.76', '0.73', '0.68', '0.70', '0.73', '0.76', '0.80', '0.87', '0.93']\n",
      "Last Action:  tensor([0.9298, 0.8486, 0.9890, 0.9887, 0.8333, 0.9392, 0.9371, 0.9928, 0.9912,\n",
      "        0.9616], device='cuda:0')\n",
      "Loss: 0.3047098219394684 -0.16807416081428528\n",
      "Loss: 0.30928337574005127 -0.2763574421405792\n",
      "Loss: 0.2997230589389801 -0.3984713554382324\n",
      "Loss: 0.30068913102149963 -0.3135554790496826\n",
      "Loss: 0.36131080985069275 -0.6300563812255859\n",
      "Loss: 0.3705148994922638 -0.46105825901031494\n",
      "Loss: 0.33088019490242004 -0.3902377486228943\n",
      "Policy Reward: tensor(0.9907, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.90', '0.79', '0.71', '0.79', '0.91', '0.95', '0.92', '0.83', '0.73', '0.73', '0.74', '0.77', '0.79', '0.78', '0.80', '0.82', '0.85']\n",
      "Last Action:  tensor([0.8541, 0.8773, 0.9501, 0.8901, 0.9096, 0.9149, 0.9702, 0.6724, 0.9810,\n",
      "        0.9512], device='cuda:0')\n",
      "Loss: 0.40345704555511475 -0.670952558517456\n",
      "Loss: 0.27531760931015015 -0.11167912185192108\n",
      "Loss: 0.34085604548454285 -0.5779424905776978\n",
      "Loss: 0.336494505405426 -0.4772237539291382\n",
      "Loss: 0.3492029011249542 -0.6404991149902344\n",
      "Loss: 0.3507915139198303 -0.30580246448516846\n",
      "Loss: 0.34087812900543213 -0.4391998052597046\n",
      "Policy Reward: tensor(1.0008, device='cuda:0')\n",
      "Trajectory:  ['0.01', '0.18', '0.12', '0.29', '0.31', '0.46', '0.72', '0.89', '0.90', '0.86', '0.78', '0.78', '0.76', '0.71', '0.69', '0.70', '0.69', '0.68', '0.66']\n",
      "Last Action:  tensor([0.6555, 0.9043, 0.6052, 0.8260, 0.7606, 0.9904, 0.6862, 0.6939, 0.6835,\n",
      "        0.7214], device='cuda:0')\n",
      "Loss: 0.3694537580013275 -0.771203875541687\n",
      "Loss: 0.3651334345340729 -0.6219655275344849\n",
      "Loss: 0.3630128502845764 -0.48492172360420227\n",
      "Loss: 0.34542912244796753 -0.5511496067047119\n",
      "Loss: 0.37021443247795105 -0.6285746097564697\n",
      "Loss: 0.31079530715942383 -0.42707791924476624\n",
      "Loss: 0.3480890691280365 -0.236838236451149\n",
      "Policy Reward: tensor(1.0852, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.62', '0.55', '0.46', '0.48', '0.81', '0.94', '0.92', '0.89', '0.78', '0.69', '0.66', '0.68', '0.72', '0.75', '0.76', '0.77', '0.86']\n",
      "Last Action:  tensor([0.8612, 0.9653, 0.9799, 0.9470, 0.8164, 0.7120, 0.9346, 0.6240, 0.7898,\n",
      "        0.8618], device='cuda:0')\n",
      "Loss: 0.38130390644073486 -0.6054353713989258\n",
      "Loss: 0.4108363687992096 -0.65276700258255\n",
      "Loss: 0.2961405813694 -0.4591858386993408\n",
      "Loss: 0.34834983944892883 -0.46276792883872986\n",
      "Loss: 0.25986889004707336 -0.3324631154537201\n",
      "Loss: 0.29675719141960144 -0.3977593183517456\n",
      "Loss: 0.2714667320251465 -0.566536545753479\n",
      "Policy Reward: tensor(0.9591, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.78', '0.68', '0.69', '0.75', '0.83', '0.89', '0.91', '0.90', '0.84', '0.72', '0.59', '0.58', '0.68', '0.69', '0.71', '0.74', '0.79']\n",
      "Last Action:  tensor([0.7942, 0.9607, 0.9185, 0.6717, 0.6926, 0.9934, 0.9560, 0.9453, 0.5573,\n",
      "        0.8590], device='cuda:0')\n",
      "Loss: 0.32056230306625366 -0.5218316316604614\n",
      "Loss: 0.30630606412887573 -0.42970457673072815\n",
      "Loss: 0.33019086718559265 -0.7180495262145996\n",
      "Loss: 0.3444308340549469 -0.5147334337234497\n",
      "Loss: 0.3357038199901581 -0.5490385293960571\n",
      "Loss: 0.29634660482406616 -0.26694655418395996\n",
      "Loss: 0.34420299530029297 -0.4300493597984314\n",
      "Policy Reward: tensor(0.8920, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.72', '0.78', '0.73', '0.79', '0.88', '0.93', '0.93', '0.89', '0.82', '0.77', '0.74', '0.74', '0.75', '0.77', '0.77', '0.75', '0.73']\n",
      "Last Action:  tensor([0.7268, 0.5447, 0.9799, 0.8237, 0.9719, 0.6734, 0.9748, 0.6562, 0.9813,\n",
      "        0.7930], device='cuda:0')\n",
      "Loss: 0.30554431676864624 -0.46332138776779175\n",
      "Loss: 0.3278277814388275 -0.5570127367973328\n",
      "Loss: 0.30313020944595337 -0.3884328007698059\n",
      "Loss: 0.2819434702396393 -0.3777014911174774\n",
      "Loss: 0.3474053740501404 -0.3188566267490387\n",
      "Loss: 0.34218716621398926 -0.43518245220184326\n",
      "Loss: 0.34040567278862 -0.5981453061103821\n",
      "Policy Reward: tensor(0.9895, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.89', '0.84', '0.83', '0.88', '0.92', '0.93', '0.89', '0.83', '0.73', '0.63', '0.67', '0.69', '0.71', '0.72', '0.72', '0.72', '0.73']\n",
      "Last Action:  tensor([0.7329, 0.9148, 0.7897, 0.9706, 0.9553, 0.7681, 0.9801, 0.8646, 0.9500,\n",
      "        0.6693], device='cuda:0')\n",
      "Loss: 0.33563414216041565 -0.8408709168434143\n",
      "Loss: 0.3989790678024292 -0.7700161933898926\n",
      "Loss: 0.29482200741767883 -0.11492690443992615\n",
      "Loss: 0.3014262616634369 -0.1605261266231537\n",
      "Loss: 0.3660593032836914 -0.7765486240386963\n",
      "Loss: 0.35538044571876526 -0.5946805477142334\n",
      "Loss: 0.3166194558143616 -0.518273115158081\n",
      "Policy Reward: tensor(1.0590, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.94', '0.92', '0.94', '0.95', '0.95', '0.94', '0.93', '0.90', '0.84', '0.68', '0.70', '0.72', '0.76', '0.82', '0.86', '0.90', '0.94']\n",
      "Last Action:  tensor([0.9354, 0.8790, 0.9228, 0.8981, 0.9461, 0.8380, 0.7628, 0.7469, 0.7862,\n",
      "        0.7587], device='cuda:0')\n",
      "Bigstep:  2\n",
      "Loss: 0.29039013385772705 1.4927761554718018\n",
      "Loss: 0.24535420536994934 0.5335570573806763\n",
      "Loss: 0.3141775131225586 0.0461014062166214\n",
      "Loss: 0.24499356746673584 0.1877918839454651\n",
      "Loss: 0.31627705693244934 -0.0774521678686142\n",
      "Loss: 0.26015791296958923 -0.006825696676969528\n",
      "Loss: 0.3074570596218109 -0.39834997057914734\n",
      "Policy Reward: tensor(1.0499, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.99', '0.99', '0.99', '0.98', '0.92', '0.69', '0.64', '0.49', '0.32', '0.20', '0.17', '0.27', '0.34', '0.35', '0.39', '0.53', '0.73']\n",
      "Last Action:  tensor([0.7329, 0.0162, 0.0173, 0.4412, 0.2390, 0.0141, 0.2865, 0.0858, 0.8481,\n",
      "        0.2780], device='cuda:0')\n",
      "Loss: 0.23296509683132172 -0.07508759945631027\n",
      "Loss: 0.26546919345855713 0.09117694199085236\n",
      "Loss: 0.30371350049972534 -0.2671019732952118\n",
      "Loss: 0.20347413420677185 0.14923331141471863\n",
      "Loss: 0.2416883409023285 -0.03228025510907173\n",
      "Loss: 0.20917421579360962 -0.004700910300016403\n",
      "Loss: 0.2516707479953766 0.10408540815114975\n",
      "Policy Reward: tensor(0.9695, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.97', '0.99', '1.00', '0.66', '0.34', '0.28', '0.21', '0.10', '0.06', '0.06', '0.08', '0.10', '0.12', '0.15', '0.18', '0.19', '0.18']\n",
      "Last Action:  tensor([0.1760, 0.0909, 0.0423, 0.2051, 0.0621, 0.0878, 0.5187, 0.0747, 0.0676,\n",
      "        0.0387], device='cuda:0')\n",
      "Loss: 0.2588352560997009 -0.18370883166790009\n",
      "Loss: 0.2685549855232239 -0.08383135497570038\n",
      "Loss: 0.2632511854171753 -0.050703853368759155\n",
      "Loss: 0.28743356466293335 -0.0841699168086052\n",
      "Loss: 0.28720182180404663 0.008852161467075348\n",
      "Loss: 0.2798405587673187 -0.1149400919675827\n",
      "Loss: 0.27767425775527954 -0.38462087512016296\n",
      "Policy Reward: tensor(0.9297, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.98', '0.97', '0.99', '0.98', '0.34', '0.12', '0.06', '0.05', '0.03', '0.03', '0.05', '0.09', '0.14', '0.21', '0.30', '0.33', '0.15', '0.04']\n",
      "Last Action:  tensor([0.0378, 0.2761, 0.0339, 0.0672, 0.0272, 0.1428, 0.2610, 0.0149, 0.3081,\n",
      "        0.0523], device='cuda:0')\n",
      "Loss: 0.2581983506679535 0.03976299613714218\n",
      "Loss: 0.23610541224479675 0.1528472602367401\n",
      "Loss: 0.2941991090774536 -0.3029380738735199\n",
      "Loss: 0.27171289920806885 -0.003175344318151474\n",
      "Loss: 0.21356964111328125 -0.11914540827274323\n",
      "Loss: 0.24991503357887268 -0.09579625725746155\n",
      "Loss: 0.27884191274642944 -0.08903238922357559\n",
      "Policy Reward: tensor(1.0332, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.98', '1.00', '1.00', '1.00', '0.61', '0.50', '0.26', '0.29', '0.15', '0.06', '0.16', '0.11', '0.15', '0.20', '0.25', '0.23', '0.25']\n",
      "Last Action:  tensor([0.2515, 0.0127, 0.0009, 0.0456, 0.0910, 0.1316, 0.1535, 0.0816, 0.1575,\n",
      "        0.2088], device='cuda:0')\n",
      "Loss: 0.21614785492420197 -0.024087190628051758\n",
      "Loss: 0.2553764283657074 0.05423452705144882\n",
      "Loss: 0.24687667191028595 -0.23067471385002136\n",
      "Loss: 0.21791328489780426 0.07585102319717407\n",
      "Loss: 0.2746928334236145 0.05212051421403885\n",
      "Loss: 0.23581166565418243 -0.02724795788526535\n",
      "Loss: 0.24677354097366333 -0.08605188131332397\n",
      "Policy Reward: tensor(1.0163, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.98', '1.00', '1.00', '0.99', '0.28', '0.25', '0.13', '0.08', '0.04', '0.04', '0.04', '0.04', '0.03', '0.03', '0.02', '0.02', '0.02']\n",
      "Last Action:  tensor([0.0198, 0.1225, 0.0021, 0.2267, 0.0591, 0.2881, 0.0759, 0.1129, 0.0546,\n",
      "        0.0032], device='cuda:0')\n",
      "Loss: 0.2510588467121124 -0.013474080711603165\n",
      "Loss: 0.25417202711105347 -0.16915908455848694\n",
      "Loss: 0.25756657123565674 0.2042778879404068\n",
      "Loss: 0.2387172281742096 -0.022809606045484543\n",
      "Loss: 0.24606074392795563 -0.1549752950668335\n",
      "Loss: 0.22104378044605255 0.24286097288131714\n",
      "Loss: 0.32864779233932495 -0.17045287787914276\n",
      "Policy Reward: tensor(1.0559, device='cuda:0')\n",
      "Trajectory:  ['0.01', '0.97', '0.99', '1.00', '0.98', '0.25', '0.36', '0.10', '0.16', '0.06', '0.16', '0.09', '0.15', '0.12', '0.13', '0.12', '0.10', '0.07', '0.05']\n",
      "Last Action:  tensor([0.0549, 0.1630, 0.2739, 0.2623, 0.0367, 0.0268, 0.0714, 0.4797, 0.0167,\n",
      "        0.0028], device='cuda:0')\n",
      "Loss: 0.23444700241088867 -0.12801432609558105\n",
      "Loss: 0.2806241810321808 0.06561131775379181\n",
      "Loss: 0.2883346974849701 -0.0045655257999897\n",
      "Loss: 0.2545909881591797 -0.07924747467041016\n",
      "Loss: 0.2507267892360687 -0.016256358474493027\n",
      "Loss: 0.2692945897579193 -0.05480489134788513\n",
      "Loss: 0.21177427470684052 0.10260207951068878\n",
      "Policy Reward: tensor(1.0713, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.99', '1.00', '1.00', '0.99', '0.21', '0.14', '0.09', '0.07', '0.04', '0.02', '0.01', '0.01', '0.00', '0.00', '0.00', '0.00', '0.00']\n",
      "Last Action:  tensor([0.0040, 0.0360, 0.3195, 0.0310, 0.1984, 0.2674, 0.0392, 0.1602, 0.0917,\n",
      "        0.1614], device='cuda:0')\n",
      "Loss: 0.23311559855937958 -0.1012067049741745\n",
      "Loss: 0.2087114453315735 -0.021767042577266693\n",
      "Loss: 0.27690669894218445 -0.28419727087020874\n",
      "Loss: 0.26762932538986206 -0.10991460829973221\n",
      "Loss: 0.2394929826259613 -0.036672066897153854\n",
      "Loss: 0.25149932503700256 -0.12424992024898529\n",
      "Loss: 0.2866028845310211 -0.11621427536010742\n",
      "Policy Reward: tensor(1.0222, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.99', '1.00', '1.00', '1.00', '0.41', '0.21', '0.29', '0.08', '0.04', '0.04', '0.04', '0.10', '0.24', '0.33', '0.14', '0.08', '0.04']\n",
      "Last Action:  tensor([0.0434, 0.0994, 0.2277, 0.1820, 0.0440, 0.5756, 0.0347, 0.7944, 0.1718,\n",
      "        0.0085], device='cuda:0')\n",
      "Bigstep:  3\n",
      "Loss: 0.41217929124832153 1.3426350355148315\n",
      "Loss: 0.41438060998916626 1.3872889280319214\n",
      "Loss: 0.4594801664352417 0.9032362103462219\n",
      "Loss: 0.4022730886936188 1.0056774616241455\n",
      "Loss: 0.3484073579311371 0.9750063419342041\n",
      "Loss: 0.3956654965877533 0.3561371862888336\n",
      "Loss: 0.29515814781188965 1.1596055030822754\n",
      "Policy Reward: tensor(1.0701, device='cuda:0')\n",
      "Trajectory:  ['0.03', '0.75', '0.83', '0.79', '0.72', '0.59', '0.22', '0.14', '0.16', '0.40', '0.76', '0.80', '0.63', '0.44', '0.88', '0.72', '0.74', '0.74', '0.78']\n",
      "Last Action:  tensor([0.7814, 0.1693, 0.1702, 0.1451, 0.2991, 0.3008, 0.1844, 0.1661, 0.1443,\n",
      "        0.1685], device='cuda:0')\n",
      "Loss: 0.41607847809791565 0.6227453947067261\n",
      "Loss: 0.33648601174354553 1.0550495386123657\n",
      "Loss: 0.34765738248825073 0.9641916155815125\n",
      "Loss: 0.40113866329193115 0.6116440296173096\n",
      "Loss: 0.3275473415851593 0.8869240880012512\n",
      "Loss: 0.3448418080806732 0.8676597476005554\n",
      "Loss: 0.3469439446926117 0.6215037107467651\n",
      "Policy Reward: tensor(1.1610, device='cuda:0')\n",
      "Trajectory:  ['0.03', '1.00', '0.99', '0.99', '0.99', '0.90', '0.50', '0.23', '0.18', '0.26', '0.30', '0.33', '0.36', '0.38', '0.39', '0.34', '0.25', '0.19', '0.16']\n",
      "Last Action:  tensor([0.1641, 0.1708, 0.0536, 0.1413, 0.1021, 0.3345, 0.2168, 0.2092, 0.2893,\n",
      "        0.2350], device='cuda:0')\n",
      "Loss: 0.37226712703704834 0.40827757120132446\n",
      "Loss: 0.32379940152168274 1.0159664154052734\n",
      "Loss: 0.4102422893047333 0.7743918895721436\n",
      "Loss: 0.36037206649780273 0.5900630950927734\n",
      "Loss: 0.34213027358055115 0.7865960001945496\n",
      "Loss: 0.3234528601169586 0.6767025589942932\n",
      "Loss: 0.3506426513195038 0.44914013147354126\n",
      "Policy Reward: tensor(1.2863, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.94', '0.94', '0.72', '0.38', '0.28', '0.22', '0.17', '0.22', '0.23', '0.23', '0.23', '0.23', '0.21', '0.17', '0.16', '0.13', '0.10']\n",
      "Last Action:  tensor([0.0974, 0.5891, 0.0912, 0.1069, 0.1557, 0.0706, 0.0886, 0.0716, 0.1988,\n",
      "        0.0680], device='cuda:0')\n",
      "Loss: 0.3645491600036621 -0.043236143887043\n",
      "Loss: 0.3131502866744995 -0.14617353677749634\n",
      "Loss: 0.34277042746543884 -0.4682340919971466\n",
      "Loss: 0.4030761420726776 -0.47501131892204285\n",
      "Loss: 0.3669215142726898 -0.7602062225341797\n",
      "Loss: 0.2727747857570648 -0.30220288038253784\n",
      "Loss: 0.30156436562538147 -0.49264588952064514\n",
      "Policy Reward: tensor(1.1500, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.72', '0.59', '0.57', '0.67', '0.44', '0.10', '0.20', '0.29', '0.38', '0.44', '0.25', '0.28', '0.32', '0.35', '0.25', '0.21', '0.17']\n",
      "Last Action:  tensor([0.1651, 0.1428, 0.2705, 0.1627, 0.1601, 0.1626, 0.1360, 0.1343, 0.2549,\n",
      "        0.2253], device='cuda:0')\n",
      "Loss: 0.4065770208835602 -0.7655767798423767\n",
      "Loss: 0.33910271525382996 -0.7244824171066284\n",
      "Loss: 0.3869962990283966 -0.9797954559326172\n",
      "Loss: 0.2912582755088806 -0.5193122029304504\n",
      "Loss: 0.33364078402519226 -0.48511284589767456\n",
      "Loss: 0.3218626081943512 -0.24756629765033722\n",
      "Loss: 0.3854256868362427 -0.8645830154418945\n",
      "Policy Reward: tensor(1.1941, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.60', '0.69', '0.76', '0.86', '0.45', '0.17', '0.36', '0.23', '0.47', '0.26', '0.40', '0.32', '0.35', '0.34', '0.25', '0.31', '0.22']\n",
      "Last Action:  tensor([0.2182, 0.1600, 0.1558, 0.1522, 0.4165, 0.2205, 0.2508, 0.1954, 0.2135,\n",
      "        0.1972], device='cuda:0')\n",
      "Loss: 0.4573392868041992 -0.9620621800422668\n",
      "Loss: 0.36132165789604187 -0.8040300011634827\n",
      "Loss: 0.37012314796447754 -0.8788427710533142\n",
      "Loss: 0.3396631181240082 -0.7746152281761169\n",
      "Loss: 0.33182579278945923 -0.4437248110771179\n",
      "Loss: 0.33553439378738403 -0.5330067873001099\n",
      "Loss: 0.342260479927063 -0.792741060256958\n",
      "Policy Reward: tensor(1.2984, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.64', '0.77', '0.79', '0.84', '0.33', '0.10', '0.19', '0.26', '0.35', '0.33', '0.35', '0.41', '0.37', '0.31', '0.23', '0.17', '0.14']\n",
      "Last Action:  tensor([0.1381, 0.2654, 0.2019, 0.1441, 0.1369, 0.1939, 0.1672, 0.2662, 0.2509,\n",
      "        0.0792], device='cuda:0')\n",
      "Loss: 0.39609435200691223 -0.6240269541740417\n",
      "Loss: 0.38920214772224426 -0.9316879510879517\n",
      "Loss: 0.3365204930305481 -0.6357230544090271\n",
      "Loss: 0.2601056396961212 -0.42871713638305664\n",
      "Loss: 0.35700076818466187 -0.6425467133522034\n",
      "Loss: 0.30979400873184204 -0.6506810784339905\n",
      "Loss: 0.35736018419265747 -0.8116269111633301\n",
      "Policy Reward: tensor(1.0766, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.50', '0.69', '0.70', '0.62', '0.26', '0.16', '0.22', '0.25', '0.25', '0.27', '0.29', '0.33', '0.29', '0.22', '0.17', '0.15', '0.14']\n",
      "Last Action:  tensor([0.1407, 0.1095, 0.1433, 0.1488, 0.1183, 0.1196, 0.2197, 0.1189, 0.1349,\n",
      "        0.1550], device='cuda:0')\n",
      "Loss: 0.3571697771549225 -0.6708208322525024\n",
      "Loss: 0.3530111610889435 -0.6888278126716614\n",
      "Loss: 0.4582071304321289 -1.1627765893936157\n",
      "Loss: 0.310514360666275 -0.5051229000091553\n",
      "Loss: 0.34289395809173584 -0.504374623298645\n",
      "Loss: 0.38953903317451477 -0.8968649506568909\n",
      "Loss: 0.25608164072036743 -0.4367997348308563\n",
      "Policy Reward: tensor(1.0959, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.74', '0.62', '0.72', '0.78', '0.42', '0.13', '0.29', '0.30', '0.38', '0.36', '0.32', '0.37', '0.37', '0.31', '0.26', '0.23', '0.17']\n",
      "Last Action:  tensor([0.1743, 0.0687, 0.0500, 0.1207, 0.0723, 0.1489, 0.1475, 0.1851, 0.1805,\n",
      "        0.2279], device='cuda:0')\n",
      "Bigstep:  4\n",
      "Loss: 0.5202262997627258 -0.01352033019065857\n",
      "Loss: 0.4995212256908417 0.2009797841310501\n",
      "Loss: 0.48192670941352844 -0.27839329838752747\n",
      "Loss: 0.5287083983421326 -0.344574898481369\n",
      "Loss: 0.47489675879478455 -0.04980741813778877\n",
      "Loss: 0.5149788856506348 -0.24695885181427002\n",
      "Loss: 0.4513695240020752 0.3232623338699341\n",
      "Policy Reward: tensor(1.2018, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.79', '0.29', '0.76', '0.70', '0.19', '0.52', '0.17', '0.42', '0.49', '0.56', '0.39', '0.45', '0.57', '0.46', '0.39', '0.41', '0.35']\n",
      "Last Action:  tensor([0.3457, 0.2110, 0.3372, 0.3515, 0.3029, 0.4878, 0.2222, 0.3088, 0.4659,\n",
      "        0.7385], device='cuda:0')\n",
      "Loss: 0.4897659420967102 -0.2205263376235962\n",
      "Loss: 0.42729735374450684 -0.1938549429178238\n",
      "Loss: 0.44100311398506165 0.2733118534088135\n",
      "Loss: 0.5103235840797424 -0.3388076424598694\n",
      "Loss: 0.43004119396209717 -0.24731017649173737\n",
      "Loss: 0.46374717354774475 0.038422755897045135\n",
      "Loss: 0.5440059900283813 -0.20628884434700012\n",
      "Policy Reward: tensor(1.2692, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.83', '0.54', '0.73', '0.93', '0.58', '0.54', '0.34', '0.53', '0.43', '0.53', '0.40', '0.48', '0.48', '0.43', '0.46', '0.47', '0.44']\n",
      "Last Action:  tensor([0.4383, 0.3309, 0.8735, 0.1474, 0.2465, 0.3541, 0.2088, 0.2186, 0.3226,\n",
      "        0.1802], device='cuda:0')\n",
      "Loss: 0.42325857281684875 -0.3799651265144348\n",
      "Loss: 0.3636864721775055 -0.03611793369054794\n",
      "Loss: 0.4694775938987732 -0.4210769236087799\n",
      "Loss: 0.4642772674560547 -0.4179820716381073\n",
      "Loss: 0.41265562176704407 -0.07831399142742157\n",
      "Loss: 0.485076367855072 -0.1511366367340088\n",
      "Loss: 0.4594428837299347 -0.31181085109710693\n",
      "Policy Reward: tensor(1.1295, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.78', '0.60', '0.72', '0.76', '0.28', '0.35', '0.25', '0.45', '0.51', '0.48', '0.45', '0.44', '0.47', '0.51', '0.46', '0.41', '0.31']\n",
      "Last Action:  tensor([0.3082, 0.3351, 0.1665, 0.2363, 0.1961, 0.3398, 0.2235, 0.3378, 0.3855,\n",
      "        0.1933], device='cuda:0')\n",
      "Loss: 0.4398353695869446 0.11478415131568909\n",
      "Loss: 0.45565366744995117 -0.12766319513320923\n",
      "Loss: 0.5327370166778564 -0.36676788330078125\n",
      "Loss: 0.453678160905838 -0.19060368835926056\n",
      "Loss: 0.46840664744377136 -0.10227145254611969\n",
      "Loss: 0.4362124502658844 -0.05933469906449318\n",
      "Loss: 0.42407092452049255 -0.19474154710769653\n",
      "Policy Reward: tensor(1.1684, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.62', '0.44', '0.61', '0.80', '0.30', '0.22', '0.19', '0.32', '0.44', '0.47', '0.46', '0.49', '0.56', '0.52', '0.39', '0.21', '0.16']\n",
      "Last Action:  tensor([0.1650, 0.1915, 0.1470, 0.1187, 0.2081, 0.2265, 0.1851, 0.3074, 0.3000,\n",
      "        0.2257], device='cuda:0')\n",
      "Loss: 0.44884589314460754 0.1257392168045044\n",
      "Loss: 0.4402090907096863 -0.029573310166597366\n",
      "Loss: 0.44577133655548096 -0.2069232314825058\n",
      "Loss: 0.45019352436065674 -0.32548806071281433\n",
      "Loss: 0.5209099054336548 -0.4514564275741577\n",
      "Loss: 0.4393822252750397 0.023251034319400787\n",
      "Loss: 0.487740159034729 -0.0647110566496849\n",
      "Policy Reward: tensor(1.2132, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.69', '0.40', '0.63', '0.36', '0.21', '0.33', '0.46', '0.46', '0.51', '0.48', '0.47', '0.55', '0.50', '0.45', '0.41', '0.33', '0.23']\n",
      "Last Action:  tensor([0.2256, 0.3571, 0.1438, 0.4208, 0.4601, 0.4185, 0.2992, 0.2524, 0.3792,\n",
      "        0.3840], device='cuda:0')\n",
      "Loss: 0.3634151220321655 0.16990996897220612\n",
      "Loss: 0.436390221118927 -0.04512974992394447\n",
      "Loss: 0.44320788979530334 -0.2629448473453522\n",
      "Loss: 0.37467652559280396 -0.17997831106185913\n",
      "Loss: 0.47127261757850647 -0.28574466705322266\n",
      "Loss: 0.47409793734550476 -0.3058716952800751\n",
      "Loss: 0.4876558184623718 0.06386686861515045\n",
      "Policy Reward: tensor(1.1679, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.56', '0.59', '0.71', '0.62', '0.25', '0.36', '0.39', '0.45', '0.48', '0.49', '0.47', '0.47', '0.51', '0.47', '0.43', '0.38', '0.30']\n",
      "Last Action:  tensor([0.2962, 0.2132, 0.2969, 0.1431, 0.1178, 0.3112, 0.2822, 0.2584, 0.3189,\n",
      "        0.2490], device='cuda:0')\n",
      "Loss: 0.42646247148513794 -0.06942678242921829\n",
      "Loss: 0.448889821767807 -0.14364470541477203\n",
      "Loss: 0.4783194065093994 -0.20730078220367432\n",
      "Loss: 0.4485659599304199 -0.08787824958562851\n",
      "Loss: 0.43327176570892334 -0.35800477862358093\n",
      "Loss: 0.46501848101615906 -0.20709238946437836\n",
      "Loss: 0.39957717061042786 -0.2892540693283081\n",
      "Policy Reward: tensor(1.1907, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.63', '0.55', '0.71', '0.55', '0.24', '0.34', '0.35', '0.44', '0.49', '0.48', '0.48', '0.49', '0.53', '0.49', '0.43', '0.35', '0.26']\n",
      "Last Action:  tensor([0.2619, 0.5505, 0.2377, 0.3708, 0.2073, 0.3661, 0.2258, 0.2235, 0.2723,\n",
      "        0.3218], device='cuda:0')\n",
      "Loss: 0.44291532039642334 -0.04424312710762024\n",
      "Loss: 0.4801068603992462 -0.33201223611831665\n",
      "Loss: 0.45553743839263916 -0.35605159401893616\n",
      "Loss: 0.502042293548584 -0.5072681903839111\n",
      "Loss: 0.4073279798030853 0.14433357119560242\n",
      "Loss: 0.4073856770992279 0.17964239418506622\n",
      "Loss: 0.43167969584465027 -0.2500436007976532\n",
      "Policy Reward: tensor(1.1751, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.88', '0.73', '0.71', '0.57', '0.36', '0.35', '0.43', '0.43', '0.52', '0.46', '0.47', '0.49', '0.50', '0.46', '0.38', '0.34', '0.23']\n",
      "Last Action:  tensor([0.2262, 0.3982, 0.3882, 0.2603, 0.5922, 0.2248, 0.2415, 0.2438, 0.2530,\n",
      "        0.4537], device='cuda:0')\n",
      "Bigstep:  5\n",
      "Loss: 0.49494391679763794 -0.08954793214797974\n",
      "Loss: 0.4642378091812134 0.2680204510688782\n",
      "Loss: 0.4382653832435608 -0.056599173694849014\n",
      "Loss: 0.5066054463386536 0.17180685698986053\n",
      "Loss: 0.4974115192890167 -0.430810809135437\n",
      "Loss: 0.4211091995239258 0.1530415266752243\n",
      "Loss: 0.4327523410320282 -0.3304433822631836\n",
      "Policy Reward: tensor(1.2843, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.63', '0.57', '0.69', '0.85', '0.36', '0.32', '0.54', '0.64', '0.68', '0.67', '0.65', '0.69', '0.71', '0.67', '0.63', '0.59', '0.53']\n",
      "Last Action:  tensor([0.5272, 0.3889, 0.3916, 0.3520, 0.3013, 0.5325, 0.4384, 0.4541, 0.5003,\n",
      "        0.5181], device='cuda:0')\n",
      "Loss: 0.4483518898487091 -0.013128828257322311\n",
      "Loss: 0.4725119173526764 -0.46851903200149536\n",
      "Loss: 0.4700392186641693 -0.2445107251405716\n",
      "Loss: 0.46175655722618103 -0.27677708864212036\n",
      "Loss: 0.43749868869781494 -0.014345478266477585\n",
      "Loss: 0.4440648555755615 -0.14502495527267456\n",
      "Loss: 0.5100560188293457 -0.313164621591568\n",
      "Policy Reward: tensor(1.1907, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.79', '0.77', '0.74', '0.72', '0.52', '0.47', '0.60', '0.65', '0.71', '0.71', '0.70', '0.69', '0.66', '0.67', '0.66', '0.61', '0.52']\n",
      "Last Action:  tensor([0.5212, 0.6270, 0.6206, 0.5543, 0.3643, 0.9236, 0.5588, 0.3778, 0.3897,\n",
      "        0.4201], device='cuda:0')\n",
      "Loss: 0.4469972252845764 -0.10316555202007294\n",
      "Loss: 0.43647146224975586 -0.1239282637834549\n",
      "Loss: 0.48466503620147705 -0.924373209476471\n",
      "Loss: 0.5518335700035095 -0.6166945099830627\n",
      "Loss: 0.5340692400932312 -0.48657917976379395\n",
      "Loss: 0.43754881620407104 -0.17991924285888672\n",
      "Loss: 0.4981383681297302 -0.22772938013076782\n",
      "Policy Reward: tensor(1.2416, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.87', '0.65', '0.72', '0.63', '0.30', '0.60', '0.54', '0.60', '0.72', '0.75', '0.74', '0.70', '0.69', '0.73', '0.71', '0.67', '0.60']\n",
      "Last Action:  tensor([0.5970, 0.4216, 0.2670, 0.6612, 0.5637, 0.3882, 0.6930, 0.4796, 0.6185,\n",
      "        0.5856], device='cuda:0')\n",
      "Loss: 0.4646857976913452 -0.18679216504096985\n",
      "Loss: 0.4840485155582428 -0.44291436672210693\n",
      "Loss: 0.4995279908180237 -0.24980510771274567\n",
      "Loss: 0.43893563747406006 -0.36145687103271484\n",
      "Loss: 0.4970147907733917 -0.26202094554901123\n",
      "Loss: 0.5161934494972229 -0.2680903971195221\n",
      "Loss: 0.48994868993759155 -0.3159434497356415\n",
      "Policy Reward: tensor(1.1665, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.89', '0.67', '0.73', '0.76', '0.35', '0.43', '0.64', '0.58', '0.64', '0.65', '0.64', '0.63', '0.61', '0.63', '0.60', '0.48', '0.39']\n",
      "Last Action:  tensor([0.3919, 0.5870, 0.5477, 0.5362, 0.4413, 0.3904, 0.3925, 0.5031, 0.4701,\n",
      "        0.4015], device='cuda:0')\n",
      "Loss: 0.4924869239330292 -0.42512965202331543\n",
      "Loss: 0.43099233508110046 -0.2628629207611084\n",
      "Loss: 0.37950485944747925 -0.09171079099178314\n",
      "Loss: 0.4981207549571991 -0.47893524169921875\n",
      "Loss: 0.4427441954612732 -0.18319451808929443\n",
      "Loss: 0.45690855383872986 -0.2574857771396637\n",
      "Loss: 0.45318374037742615 -0.24931952357292175\n",
      "Policy Reward: tensor(1.1317, device='cuda:0')\n",
      "Trajectory:  ['0.02', '1.00', '0.77', '0.92', '0.70', '0.92', '0.60', '0.74', '0.89', '0.78', '0.87', '0.70', '0.88', '0.67', '0.82', '0.68', '0.87', '0.69', '0.91']\n",
      "Last Action:  tensor([0.9123, 0.5566, 0.2140, 0.5662, 0.3760, 0.6378, 0.2351, 0.4994, 0.4670,\n",
      "        0.3769], device='cuda:0')\n",
      "Loss: 0.4427843987941742 -0.3033413887023926\n",
      "Loss: 0.4581162631511688 -0.16677871346473694\n",
      "Loss: 0.5262097716331482 -0.42666399478912354\n",
      "Loss: 0.42078661918640137 -0.26584383845329285\n",
      "Loss: 0.4402981400489807 -0.3595030605792999\n",
      "Loss: 0.4579675495624542 -0.3987787961959839\n",
      "Loss: 0.47306689620018005 -0.14081710577011108\n",
      "Policy Reward: tensor(1.1873, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.85', '0.48', '0.77', '0.81', '0.39', '0.30', '0.42', '0.59', '0.68', '0.71', '0.69', '0.66', '0.66', '0.72', '0.73', '0.69', '0.61']\n",
      "Last Action:  tensor([0.6117, 0.2636, 0.3557, 0.5559, 0.4648, 0.5311, 0.4388, 0.4409, 0.6076,\n",
      "        0.5833], device='cuda:0')\n",
      "Loss: 0.48193323612213135 -0.2779156565666199\n",
      "Loss: 0.44857797026634216 -0.4100068509578705\n",
      "Loss: 0.47289803624153137 -0.5138669610023499\n",
      "Loss: 0.440929651260376 -0.17602071166038513\n",
      "Loss: 0.3409007787704468 -0.10029362142086029\n",
      "Loss: 0.471966028213501 -0.2552396357059479\n",
      "Loss: 0.5082066655158997 -0.5805795192718506\n",
      "Policy Reward: tensor(1.2155, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.69', '0.63', '0.75', '0.61', '0.34', '0.48', '0.50', '0.59', '0.72', '0.74', '0.72', '0.68', '0.69', '0.71', '0.67', '0.59', '0.49']\n",
      "Last Action:  tensor([0.4868, 0.5862, 0.5538, 0.5080, 0.8605, 0.5431, 0.3244, 0.5912, 0.4594,\n",
      "        0.5523], device='cuda:0')\n",
      "Loss: 0.5264820456504822 -0.5233771800994873\n",
      "Loss: 0.3816171884536743 0.058348964899778366\n",
      "Loss: 0.3848934471607208 -0.2748509645462036\n",
      "Loss: 0.46746906638145447 -0.382310152053833\n",
      "Loss: 0.42947256565093994 -0.26060399413108826\n",
      "Loss: 0.409760981798172 0.10477391630411148\n",
      "Loss: 0.480232834815979 -0.3382454514503479\n",
      "Policy Reward: tensor(1.1504, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.76', '0.45', '0.70', '0.65', '0.22', '0.54', '0.60', '0.60', '0.74', '0.72', '0.69', '0.67', '0.72', '0.72', '0.66', '0.57', '0.41']\n",
      "Last Action:  tensor([0.4084, 0.4582, 0.4762, 0.3132, 0.8283, 0.2637, 0.5658, 0.4443, 0.4429,\n",
      "        0.3990], device='cuda:0')\n",
      "Bigstep:  6\n",
      "Loss: 0.5329089164733887 -0.8862611651420593\n",
      "Loss: 0.4689904749393463 -0.9858779311180115\n",
      "Loss: 0.4825144410133362 -0.879435658454895\n",
      "Loss: 0.5016346573829651 -0.9474129676818848\n",
      "Loss: 0.3891245424747467 -0.7501645088195801\n",
      "Loss: 0.44443774223327637 -0.7829766869544983\n",
      "Loss: 0.4668801426887512 -0.9839386940002441\n",
      "Policy Reward: tensor(1.2465, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.81', '0.33', '0.78', '0.86', '0.25', '0.11', '0.34', '0.40', '0.40', '0.46', '0.38', '0.58', '0.46', '0.57', '0.52', '0.50', '0.41']\n",
      "Last Action:  tensor([0.4124, 0.1765, 0.1985, 0.2576, 0.2729, 0.3357, 0.3713, 0.2547, 0.1369,\n",
      "        0.1421], device='cuda:0')\n",
      "Loss: 0.4428512752056122 -1.070820927619934\n",
      "Loss: 0.4383552074432373 -0.9327881932258606\n",
      "Loss: 0.3531632125377655 -1.0336835384368896\n",
      "Loss: 0.5135449171066284 -1.5733569860458374\n",
      "Loss: 0.45811107754707336 -1.053593397140503\n",
      "Loss: 0.4609648585319519 -1.316526174545288\n",
      "Loss: 0.45772865414619446 -0.89520663022995\n",
      "Policy Reward: tensor(1.2854, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.87', '0.79', '0.77', '0.63', '0.35', '0.43', '0.57', '0.51', '0.67', '0.53', '0.60', '0.45', '0.61', '0.55', '0.54', '0.47', '0.33']\n",
      "Last Action:  tensor([0.3321, 0.1825, 0.4502, 0.4520, 0.3616, 0.4482, 0.3166, 0.3709, 0.1406,\n",
      "        0.2904], device='cuda:0')\n",
      "Loss: 0.41977718472480774 -0.9702843427658081\n",
      "Loss: 0.4168033003807068 -0.6479630470275879\n",
      "Loss: 0.4168393015861511 -0.8096803426742554\n",
      "Loss: 0.4684683680534363 -1.13206148147583\n",
      "Loss: 0.40310996770858765 -0.8858208656311035\n",
      "Loss: 0.4447917938232422 -1.119070291519165\n",
      "Loss: 0.38758203387260437 -0.6180212497711182\n",
      "Policy Reward: tensor(1.2864, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.68', '0.61', '0.71', '0.89', '0.41', '0.12', '0.30', '0.44', '0.53', '0.48', '0.48', '0.55', '0.66', '0.64', '0.62', '0.59', '0.50']\n",
      "Last Action:  tensor([0.4964, 0.1784, 0.2017, 0.3033, 0.4104, 0.1926, 0.3279, 0.2247, 0.4128,\n",
      "        0.2336], device='cuda:0')\n",
      "Loss: 0.43824082612991333 -0.9253333806991577\n",
      "Loss: 0.45088058710098267 -0.9693645238876343\n",
      "Loss: 0.4408653974533081 -1.1268301010131836\n",
      "Loss: 0.49773815274238586 -1.3343031406402588\n",
      "Loss: 0.35682743787765503 -0.7542724609375\n",
      "Loss: 0.40006524324417114 -0.8923807144165039\n",
      "Loss: 0.5217065811157227 -1.259434700012207\n",
      "Policy Reward: tensor(1.2912, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.78', '0.46', '0.58', '0.46', '0.30', '0.43', '0.51', '0.49', '0.57', '0.47', '0.54', '0.53', '0.59', '0.58', '0.56', '0.47', '0.28']\n",
      "Last Action:  tensor([0.2770, 0.3588, 0.6098, 0.4436, 0.3921, 0.3765, 0.1764, 0.4113, 0.2194,\n",
      "        0.2974], device='cuda:0')\n",
      "Loss: 0.38039690256118774 -0.7025060653686523\n",
      "Loss: 0.39701518416404724 -1.0014324188232422\n",
      "Loss: 0.4848427474498749 -1.156046986579895\n",
      "Loss: 0.48951321840286255 -1.185587763786316\n",
      "Loss: 0.4565533995628357 -1.3456733226776123\n",
      "Loss: 0.41073501110076904 -1.0689165592193604\n",
      "Loss: 0.5034815073013306 -1.6042027473449707\n",
      "Policy Reward: tensor(1.2040, device='cuda:0')\n",
      "Trajectory:  ['0.02', '1.00', '0.69', '0.48', '0.69', '0.66', '0.16', '0.16', '0.37', '0.57', '0.56', '0.60', '0.64', '0.49', '0.37', '0.44', '0.39', '0.25', '0.12']\n",
      "Last Action:  tensor([0.1200, 0.3952, 0.1963, 0.3319, 0.5007, 0.4579, 0.2312, 0.2846, 0.5300,\n",
      "        0.2154], device='cuda:0')\n",
      "Loss: 0.4936275780200958 -1.3710887432098389\n",
      "Loss: 0.40992921590805054 -1.1027281284332275\n",
      "Loss: 0.5602002739906311 -1.4515557289123535\n",
      "Loss: 0.4443899989128113 -1.2852051258087158\n",
      "Loss: 0.512627899646759 -1.02236807346344\n",
      "Loss: 0.38778063654899597 -0.666422963142395\n",
      "Loss: 0.4013015329837799 -0.6866000890731812\n",
      "Policy Reward: tensor(1.1223, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.70', '0.58', '0.65', '0.82', '0.32', '0.16', '0.27', '0.34', '0.43', '0.46', '0.48', '0.63', '0.66', '0.58', '0.52', '0.36', '0.19']\n",
      "Last Action:  tensor([0.1902, 0.2892, 0.2188, 0.1804, 0.2305, 0.3516, 0.2190, 0.2625, 0.1271,\n",
      "        0.6326], device='cuda:0')\n",
      "Loss: 0.4855472445487976 -1.0380022525787354\n",
      "Loss: 0.39023807644844055 -0.8430533409118652\n",
      "Loss: 0.4998389780521393 -1.351173758506775\n",
      "Loss: 0.45513713359832764 -1.0778828859329224\n",
      "Loss: 0.3950146436691284 -0.9279245734214783\n",
      "Loss: 0.4515882134437561 -0.8105925917625427\n",
      "Loss: 0.45959869027137756 -1.2197905778884888\n",
      "Policy Reward: tensor(1.2519, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.73', '0.90', '0.75', '0.87', '0.43', '0.25', '0.38', '0.41', '0.45', '0.49', '0.50', '0.49', '0.55', '0.56', '0.46', '0.32', '0.20']\n",
      "Last Action:  tensor([0.1979, 0.4128, 0.3839, 0.4438, 0.3893, 0.0969, 0.2678, 0.2071, 0.1472,\n",
      "        0.0881], device='cuda:0')\n",
      "Loss: 0.44701215624809265 -1.0103437900543213\n",
      "Loss: 0.5043188333511353 -1.4954215288162231\n",
      "Loss: 0.3710261881351471 -0.6759388446807861\n",
      "Loss: 0.4597228169441223 -1.3277404308319092\n",
      "Loss: 0.34803855419158936 -0.8211695551872253\n",
      "Loss: 0.4889281392097473 -0.979984700679779\n",
      "Loss: 0.41685429215431213 -1.1761927604675293\n",
      "Policy Reward: tensor(1.1875, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.73', '0.43', '0.82', '0.82', '0.32', '0.14', '0.29', '0.47', '0.49', '0.59', '0.50', '0.60', '0.43', '0.54', '0.48', '0.46', '0.38']\n",
      "Last Action:  tensor([0.3834, 0.3250, 0.2967, 0.7250, 0.2822, 0.3061, 0.5127, 0.3178, 0.3076,\n",
      "        0.1401], device='cuda:0')\n",
      "Bigstep:  7\n",
      "Loss: 0.3663637340068817 -0.25479361414909363\n",
      "Loss: 0.4367362856864929 -0.5821576714515686\n",
      "Loss: 0.44058921933174133 -1.0897940397262573\n",
      "Loss: 0.45379528403282166 -0.7529476881027222\n",
      "Loss: 0.420544296503067 -0.7263136506080627\n",
      "Loss: 0.45359355211257935 -1.3123451471328735\n",
      "Loss: 0.3935416340827942 -0.7461246252059937\n",
      "Policy Reward: tensor(1.1000, device='cuda:0')\n",
      "Trajectory:  ['0.07', '1.00', '0.85', '0.86', '0.84', '0.81', '0.79', '0.79', '0.78', '0.78', '0.78', '0.79', '0.79', '0.79', '0.79', '0.79', '0.79', '0.79', '0.79']\n",
      "Last Action:  tensor([0.7898, 0.5161, 0.5275, 0.4575, 0.6506, 0.5493, 0.6278, 0.6505, 0.7752,\n",
      "        0.4703], device='cuda:0')\n",
      "Loss: 0.38694679737091064 -0.6618485450744629\n",
      "Loss: 0.4814877510070801 -0.9467228651046753\n",
      "Loss: 0.3816872835159302 -0.9283745288848877\n",
      "Loss: 0.47403082251548767 -1.1128348112106323\n",
      "Loss: 0.4409734606742859 -0.8787437677383423\n",
      "Loss: 0.39636486768722534 -0.8445566892623901\n",
      "Loss: 0.40119701623916626 -0.8293124437332153\n",
      "Policy Reward: tensor(1.2242, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.77', '0.33', '0.73', '0.82', '0.26', '0.51', '0.68', '0.64', '0.67', '0.71', '0.70', '0.66', '0.70', '0.75', '0.74', '0.72', '0.70']\n",
      "Last Action:  tensor([0.6990, 0.7462, 0.7082, 0.2016, 0.6148, 0.5847, 0.4049, 0.2657, 0.7136,\n",
      "        0.6796], device='cuda:0')\n",
      "Loss: 0.39945918321609497 -0.4967811107635498\n",
      "Loss: 0.3938927948474884 -0.698066771030426\n",
      "Loss: 0.504615306854248 -0.9124642610549927\n",
      "Loss: 0.4259876310825348 -0.748374342918396\n",
      "Loss: 0.35439053177833557 -0.37875276803970337\n",
      "Loss: 0.4008791148662567 -0.7861034870147705\n",
      "Loss: 0.38481584191322327 -1.171293020248413\n",
      "Policy Reward: tensor(1.1587, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.70', '0.48', '0.68', '0.85', '0.37', '0.33', '0.69', '0.74', '0.69', '0.64', '0.63', '0.73', '0.79', '0.77', '0.71', '0.55', '0.45']\n",
      "Last Action:  tensor([0.4483, 0.3476, 0.6903, 0.6272, 0.6115, 0.5411, 0.7697, 0.6712, 0.6609,\n",
      "        0.4932], device='cuda:0')\n",
      "Loss: 0.43031659722328186 -0.722324550151825\n",
      "Loss: 0.48092299699783325 -1.0465021133422852\n",
      "Loss: 0.4213586151599884 -1.1341632604599\n",
      "Loss: 0.45160746574401855 -0.8664346933364868\n",
      "Loss: 0.4778295159339905 -1.0867995023727417\n",
      "Loss: 0.47928640246391296 -1.1179877519607544\n",
      "Loss: 0.38448643684387207 -0.7697904109954834\n",
      "Policy Reward: tensor(1.1464, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.72', '0.55', '0.67', '0.84', '0.35', '0.37', '0.71', '0.68', '0.69', '0.65', '0.66', '0.72', '0.78', '0.78', '0.74', '0.60', '0.47']\n",
      "Last Action:  tensor([0.4719, 0.5199, 0.6926, 0.4678, 0.6835, 0.3887, 0.6116, 0.3651, 0.6661,\n",
      "        0.6678], device='cuda:0')\n",
      "Loss: 0.4085145592689514 -0.5602314472198486\n",
      "Loss: 0.44708266854286194 -0.8117929100990295\n",
      "Loss: 0.36924269795417786 -0.6475015878677368\n",
      "Loss: 0.35914379358291626 -0.597586452960968\n",
      "Loss: 0.4927726984024048 -1.1239395141601562\n",
      "Loss: 0.42946696281433105 -0.9501208066940308\n",
      "Loss: 0.4510018229484558 -0.8668434619903564\n",
      "Policy Reward: tensor(1.1255, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.46', '0.71', '0.95', '0.73', '0.76', '0.61', '0.52', '0.66', '0.75', '0.72', '0.78', '0.62', '0.57', '0.46', '0.56', '0.61', '0.54']\n",
      "Last Action:  tensor([0.5391, 0.5559, 0.1607, 0.6252, 0.5504, 0.6198, 0.3643, 0.6350, 0.5164,\n",
      "        0.5218], device='cuda:0')\n",
      "Loss: 0.4425254166126251 -0.727733850479126\n",
      "Loss: 0.41119372844696045 -0.7296335101127625\n",
      "Loss: 0.453933447599411 -0.5874558091163635\n",
      "Loss: 0.3318629860877991 -0.7313624024391174\n",
      "Loss: 0.42420488595962524 -0.9517207145690918\n",
      "Loss: 0.4857940375804901 -1.1139495372772217\n",
      "Loss: 0.37189099192619324 -0.931879997253418\n",
      "Policy Reward: tensor(1.1898, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.99', '0.76', '0.55', '0.72', '0.66', '0.45', '0.64', '0.68', '0.70', '0.71', '0.69', '0.66', '0.73', '0.76', '0.74', '0.70', '0.61', '0.52']\n",
      "Last Action:  tensor([0.5210, 0.6238, 0.6854, 0.6146, 0.6716, 0.4131, 0.3792, 0.2313, 0.7853,\n",
      "        0.7133], device='cuda:0')\n",
      "Loss: 0.4366130828857422 -0.9281275272369385\n",
      "Loss: 0.4032403528690338 -0.7073955535888672\n",
      "Loss: 0.37569743394851685 -0.8713126182556152\n",
      "Loss: 0.3772737681865692 -0.9784484505653381\n",
      "Loss: 0.46816980838775635 -0.9939479231834412\n",
      "Loss: 0.46147194504737854 -0.8288881778717041\n",
      "Loss: 0.3987356126308441 -0.8803910613059998\n",
      "Policy Reward: tensor(1.1335, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.63', '0.25', '0.74', '0.78', '0.14', '0.55', '0.63', '0.65', '0.62', '0.64', '0.58', '0.69', '0.71', '0.73', '0.75', '0.75', '0.75']\n",
      "Last Action:  tensor([0.7454, 0.2395, 0.7084, 0.9185, 0.6148, 0.7149, 0.6204, 0.3127, 0.3734,\n",
      "        0.5573], device='cuda:0')\n",
      "Loss: 0.41565391421318054 -0.804258406162262\n",
      "Loss: 0.4313831627368927 -1.0028457641601562\n",
      "Loss: 0.46082380414009094 -0.7318210601806641\n",
      "Loss: 0.38794124126434326 -0.768608570098877\n",
      "Loss: 0.3566341698169708 -0.6398322582244873\n",
      "Loss: 0.353723406791687 -0.48402535915374756\n",
      "Loss: 0.3619273900985718 -0.7190918922424316\n",
      "Policy Reward: tensor(1.1749, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.60', '0.79', '0.90', '0.80', '0.72', '0.57', '0.59', '0.61', '0.63', '0.67', '0.64', '0.64', '0.66', '0.68', '0.63', '0.53', '0.44']\n",
      "Last Action:  tensor([0.4423, 0.3481, 0.6119, 0.5503, 0.5122, 0.4981, 0.8330, 0.5787, 0.3775,\n",
      "        0.5736], device='cuda:0')\n",
      "Bigstep:  8\n",
      "Loss: 0.3377276659011841 -0.24629250168800354\n",
      "Loss: 0.3592406213283539 -0.7617244124412537\n",
      "Loss: 0.4014165997505188 -0.8547738790512085\n",
      "Loss: 0.4464283287525177 -0.9798779487609863\n",
      "Loss: 0.3608161509037018 -0.6210129857063293\n",
      "Loss: 0.46702080965042114 -1.2544996738433838\n",
      "Loss: 0.3653382658958435 -0.7428476810455322\n",
      "Policy Reward: tensor(1.2206, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.46', '0.42', '0.74', '0.77', '0.06', '0.09', '0.29', '0.55', '0.31', '0.53', '0.31', '0.69', '0.53', '0.60', '0.63', '0.58', '0.57']\n",
      "Last Action:  tensor([0.5708, 0.5412, 0.2704, 0.5699, 0.4358, 0.4223, 0.4155, 0.3564, 0.4615,\n",
      "        0.3907], device='cuda:0')\n",
      "Loss: 0.34514567255973816 -0.601264476776123\n",
      "Loss: 0.4630592167377472 -0.871203601360321\n",
      "Loss: 0.4724721312522888 -1.3171790838241577\n",
      "Loss: 0.45130792260169983 -0.9659430384635925\n",
      "Loss: 0.4111177325248718 -0.9146296381950378\n",
      "Loss: 0.33051666617393494 -0.6330186128616333\n",
      "Loss: 0.3903677463531494 -1.0019574165344238\n",
      "Policy Reward: tensor(1.1306, device='cuda:0')\n",
      "Trajectory:  ['0.02', '1.00', '0.77', '0.49', '0.68', '0.80', '0.24', '0.18', '0.42', '0.36', '0.57', '0.41', '0.39', '0.48', '0.49', '0.49', '0.51', '0.39', '0.28']\n",
      "Last Action:  tensor([0.2797, 0.2591, 0.4660, 0.3794, 0.4245, 0.2355, 0.3005, 0.4161, 0.3285,\n",
      "        0.4005], device='cuda:0')\n",
      "Loss: 0.3337649703025818 -0.508745551109314\n",
      "Loss: 0.45170342922210693 -1.0904312133789062\n",
      "Loss: 0.38189053535461426 -0.7993219494819641\n",
      "Loss: 0.40980803966522217 -0.988655686378479\n",
      "Loss: 0.41988617181777954 -1.0217852592468262\n",
      "Loss: 0.38602644205093384 -0.6805558204650879\n",
      "Loss: 0.38164958357810974 -1.1290377378463745\n",
      "Policy Reward: tensor(1.2149, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.65', '0.76', '0.78', '0.68', '0.31', '0.65', '0.59', '0.52', '0.38', '0.54', '0.38', '0.51', '0.35', '0.72', '0.65', '0.76', '0.55']\n",
      "Last Action:  tensor([0.5523, 0.5137, 0.5144, 0.1769, 0.2434, 0.3138, 0.3775, 0.4313, 0.6655,\n",
      "        0.4168], device='cuda:0')\n",
      "Loss: 0.37346556782722473 -0.5970979332923889\n",
      "Loss: 0.3603202998638153 -0.554409921169281\n",
      "Loss: 0.40190181136131287 -0.8959411382675171\n",
      "Loss: 0.36648982763290405 -0.792563796043396\n",
      "Loss: 0.4603898525238037 -1.1148053407669067\n",
      "Loss: 0.43883246183395386 -0.9586849212646484\n",
      "Loss: 0.42549529671669006 -1.2161461114883423\n",
      "Policy Reward: tensor(1.2163, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.80', '0.33', '0.73', '0.70', '0.04', '0.13', '0.34', '0.38', '0.47', '0.47', '0.42', '0.46', '0.58', '0.60', '0.51', '0.33', '0.17']\n",
      "Last Action:  tensor([0.1680, 0.6069, 0.5469, 0.4430, 0.3696, 0.3007, 0.4790, 0.5264, 0.4391,\n",
      "        0.5278], device='cuda:0')\n",
      "Loss: 0.3948036730289459 -0.6990251541137695\n",
      "Loss: 0.41143447160720825 -0.6510105729103088\n",
      "Loss: 0.33969560265541077 -0.910834789276123\n",
      "Loss: 0.3917131721973419 -0.7193771600723267\n",
      "Loss: 0.3058006465435028 -0.5634998679161072\n",
      "Loss: 0.3467956781387329 -0.7532643675804138\n",
      "Loss: 0.3745267391204834 -1.028159737586975\n",
      "Policy Reward: tensor(1.2004, device='cuda:0')\n",
      "Trajectory:  ['0.03', '1.00', '0.81', '0.46', '0.74', '0.70', '0.27', '0.20', '0.43', '0.54', '0.46', '0.50', '0.46', '0.51', '0.61', '0.54', '0.50', '0.46', '0.33']\n",
      "Last Action:  tensor([0.3334, 0.2774, 0.4547, 0.4540, 0.5575, 0.2296, 0.4984, 0.3264, 0.4790,\n",
      "        0.5388], device='cuda:0')\n",
      "Loss: 0.327915757894516 -0.657856285572052\n",
      "Loss: 0.361307293176651 -0.8434842228889465\n",
      "Loss: 0.34048181772232056 -0.9764041900634766\n",
      "Loss: 0.43338167667388916 -1.0226178169250488\n",
      "Loss: 0.39000919461250305 -0.9431774020195007\n",
      "Loss: 0.42600908875465393 -0.9463179111480713\n",
      "Loss: 0.38308584690093994 -0.8388131856918335\n",
      "Policy Reward: tensor(1.1919, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.54', '0.49', '0.84', '0.78', '0.20', '0.38', '0.25', '0.52', '0.48', '0.59', '0.39', '0.41', '0.44', '0.58', '0.40', '0.28', '0.20']\n",
      "Last Action:  tensor([0.1976, 0.2900, 0.4403, 0.2742, 0.3172, 0.8732, 0.5832, 0.2037, 0.2825,\n",
      "        0.4961], device='cuda:0')\n",
      "Loss: 0.35848578810691833 -0.7907476425170898\n",
      "Loss: 0.4026950001716614 -0.917167603969574\n",
      "Loss: 0.47345393896102905 -0.8580782413482666\n",
      "Loss: 0.37620317935943604 -0.8183344602584839\n",
      "Loss: 0.3832918107509613 -0.9122169613838196\n",
      "Loss: 0.4197913110256195 -1.0970232486724854\n",
      "Loss: 0.36818987131118774 -1.0817196369171143\n",
      "Policy Reward: tensor(1.1411, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.76', '0.52', '0.91', '0.67', '0.24', '0.30', '0.33', '0.35', '0.43', '0.59', '0.72', '0.42', '0.50', '0.66', '0.40', '0.25', '0.18']\n",
      "Last Action:  tensor([0.1808, 0.3991, 0.1426, 0.3200, 0.3485, 0.1716, 0.5741, 0.6212, 0.2866,\n",
      "        0.4700], device='cuda:0')\n",
      "Loss: 0.3381558954715729 -0.8556991815567017\n",
      "Loss: 0.39066240191459656 -0.8118590712547302\n",
      "Loss: 0.34484007954597473 -0.7888906002044678\n",
      "Loss: 0.42395317554473877 -0.8916257619857788\n",
      "Loss: 0.3963557779788971 -0.7780563235282898\n",
      "Loss: 0.4308258593082428 -1.1245911121368408\n",
      "Loss: 0.36312317848205566 -1.2074817419052124\n",
      "Policy Reward: tensor(1.2071, device='cuda:0')\n",
      "Trajectory:  ['0.02', '0.99', '0.77', '0.35', '0.60', '0.93', '0.35', '0.10', '0.32', '0.61', '0.53', '0.73', '0.48', '0.62', '0.54', '0.67', '0.56', '0.69', '0.54']\n",
      "Last Action:  tensor([0.5413, 0.4082, 0.2548, 0.4144, 0.5699, 0.3755, 0.6345, 0.5488, 0.5550,\n",
      "        0.4904], device='cuda:0')\n",
      "Bigstep:  9\n",
      "Loss: 0.3840329945087433 -0.27441880106925964\n",
      "Loss: 0.4343056082725525 -0.21358172595500946\n",
      "Loss: 0.42265066504478455 -0.6153731346130371\n",
      "Loss: 0.35580500960350037 -0.6993265748023987\n",
      "Loss: 0.36382317543029785 -0.8051347732543945\n",
      "Loss: 0.3904231786727905 -0.8622165322303772\n",
      "Loss: 0.44532129168510437 -0.723432183265686\n",
      "Policy Reward: tensor(1.1726, device='cuda:0')\n",
      "Trajectory:  ['0.02', '1.00', '0.81', '0.57', '0.87', '0.90', '0.52', '0.27', '0.37', '0.39', '0.49', '0.59', '0.67', '0.69', '0.68', '0.67', '0.66', '0.63', '0.62']\n",
      "Last Action:  tensor([0.6175, 0.7410, 0.8066, 0.7659, 0.6257, 0.7054, 0.7752, 0.7750, 0.6228,\n",
      "        0.7594], device='cuda:0')\n",
      "Loss: 0.5225995182991028 -0.6241066455841064\n",
      "Loss: 0.36063140630722046 -0.6620342135429382\n",
      "Loss: 0.37776434421539307 -0.7003128528594971\n",
      "Loss: 0.37501269578933716 -0.5913376212120056\n",
      "Loss: 0.34656086564064026 -0.35124218463897705\n",
      "Loss: 0.35820600390434265 -0.7750013470649719\n",
      "Loss: 0.4298708736896515 -1.051797866821289\n",
      "Policy Reward: tensor(1.1655, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.62', '0.72', '0.98', '0.90', '0.59', '0.34', '0.46', '0.59', '0.52', '0.58', '0.56', '0.50', '0.68', '0.85', '0.73', '0.76', '0.73']\n",
      "Last Action:  tensor([0.7262, 0.3287, 0.5911, 0.5875, 0.7781, 0.7785, 0.7679, 0.6835, 0.6612,\n",
      "        0.7192], device='cuda:0')\n",
      "Loss: 0.354184627532959 -0.730144739151001\n",
      "Loss: 0.30344516038894653 -0.5304551124572754\n",
      "Loss: 0.38552019000053406 -0.3752334713935852\n",
      "Loss: 0.38382789492607117 -0.8848671317100525\n",
      "Loss: 0.3840305805206299 -0.5822351574897766\n",
      "Loss: 0.3975867033004761 -0.6170956492424011\n",
      "Loss: 0.3724692463874817 -0.6052327752113342\n",
      "Policy Reward: tensor(1.2357, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.91', '0.85', '0.81', '0.79', '0.58', '0.44', '0.32', '0.47', '0.56', '0.72', '0.68', '0.69', '0.68', '0.73', '0.77', '0.77', '0.71']\n",
      "Last Action:  tensor([0.7134, 0.2529, 0.5413, 0.7730, 0.7788, 0.6289, 0.6455, 0.7234, 0.3896,\n",
      "        0.5900], device='cuda:0')\n",
      "Loss: 0.39988404512405396 -0.8411528468132019\n",
      "Loss: 0.37130266427993774 -1.0121707916259766\n",
      "Loss: 0.36939963698387146 -0.7968327403068542\n",
      "Loss: 0.33157163858413696 -0.32765448093414307\n",
      "Loss: 0.3134600818157196 -0.3614768087863922\n",
      "Loss: 0.46212688088417053 -0.9939207434654236\n",
      "Loss: 0.3786163628101349 -0.7871386408805847\n",
      "Policy Reward: tensor(1.1690, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.73', '0.53', '0.88', '0.85', '0.26', '0.37', '0.60', '0.54', '0.68', '0.63', '0.70', '0.62', '0.69', '0.77', '0.81', '0.82', '0.83']\n",
      "Last Action:  tensor([0.8314, 0.8503, 0.5790, 0.6267, 0.8240, 0.7238, 0.8832, 0.5700, 0.8177,\n",
      "        0.6739], device='cuda:0')\n",
      "Loss: 0.3601852059364319 -0.7602842450141907\n",
      "Loss: 0.4004175066947937 -0.7078490257263184\n",
      "Loss: 0.39957961440086365 -0.8373329043388367\n",
      "Loss: 0.3223586082458496 -0.3990117609500885\n",
      "Loss: 0.3682880699634552 -0.8788421750068665\n",
      "Loss: 0.3538394272327423 -0.7153988480567932\n",
      "Loss: 0.41105443239212036 -0.8479548692703247\n",
      "Policy Reward: tensor(1.2217, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.62', '0.63', '0.91', '0.75', '0.25', '0.30', '0.38', '0.54', '0.71', '0.68', '0.70', '0.68', '0.69', '0.77', '0.80', '0.78', '0.72']\n",
      "Last Action:  tensor([0.7194, 0.7013, 0.7138, 0.6434, 0.3167, 0.5281, 0.7632, 0.7008, 0.8007,\n",
      "        0.3328], device='cuda:0')\n",
      "Loss: 0.3797266185283661 -0.6364977359771729\n",
      "Loss: 0.3698834180831909 -0.5767987370491028\n",
      "Loss: 0.4178277254104614 -1.0380879640579224\n",
      "Loss: 0.41670286655426025 -1.3975656032562256\n",
      "Loss: 0.45350179076194763 -0.8647330403327942\n",
      "Loss: 0.3799068033695221 -0.6584721207618713\n",
      "Loss: 0.3638990819454193 -0.48671066761016846\n",
      "Policy Reward: tensor(1.1385, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.37', '0.31', '0.86', '0.98', '0.44', '0.13', '0.30', '0.46', '0.65', '0.63', '0.55', '0.60', '0.80', '0.83', '0.76', '0.77', '0.71']\n",
      "Last Action:  tensor([0.7135, 0.5316, 0.5633, 0.1813, 0.7913, 0.2787, 0.7719, 0.7764, 0.4691,\n",
      "        0.7576], device='cuda:0')\n",
      "Loss: 0.42843231558799744 -0.7491264343261719\n",
      "Loss: 0.3524027168750763 -0.6924984455108643\n",
      "Loss: 0.3396405577659607 -0.815520167350769\n",
      "Loss: 0.42605897784233093 -0.9302475452423096\n",
      "Loss: 0.36286383867263794 -0.6894614100456238\n",
      "Loss: 0.3994680345058441 -0.719423770904541\n",
      "Loss: 0.3700955808162689 -0.8206809163093567\n",
      "Policy Reward: tensor(1.3231, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.76', '0.89', '0.89', '0.83', '0.80', '0.84', '0.87', '0.77', '0.84', '0.86', '0.83', '0.91', '0.84', '0.93', '0.84', '0.93', '0.81']\n",
      "Last Action:  tensor([0.8095, 0.8427, 0.5782, 0.8089, 0.6501, 0.7949, 0.7047, 0.7938, 0.7347,\n",
      "        0.7702], device='cuda:0')\n",
      "Loss: 0.45573508739471436 -1.2047780752182007\n",
      "Loss: 0.2788693904876709 -0.47811195254325867\n",
      "Loss: 0.36167171597480774 -0.621369481086731\n",
      "Loss: 0.382419615983963 -0.5824834108352661\n",
      "Loss: 0.38235706090927124 -0.7048302292823792\n",
      "Loss: 0.40247073769569397 -0.8779845833778381\n",
      "Loss: 0.4242016077041626 -0.7314068078994751\n",
      "Policy Reward: tensor(1.0841, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.70', '0.69', '0.92', '0.86', '0.33', '0.36', '0.44', '0.54', '0.67', '0.72', '0.73', '0.71', '0.68', '0.80', '0.84', '0.85', '0.86']\n",
      "Last Action:  tensor([0.8580, 0.8472, 0.7960, 0.5963, 0.6365, 0.5397, 0.8044, 0.7537, 0.8030,\n",
      "        0.7848], device='cuda:0')\n",
      "Bigstep:  10\n",
      "Loss: 0.3726850152015686 0.49310824275016785\n",
      "Loss: 0.3728048503398895 -0.054194387048482895\n",
      "Loss: 0.4489906132221222 -0.49101752042770386\n",
      "Loss: 0.43921011686325073 -0.3269711136817932\n",
      "Loss: 0.40753260254859924 -0.7186601161956787\n",
      "Loss: 0.3446965217590332 -0.3660155236721039\n",
      "Loss: 0.3671272397041321 -0.007306305691599846\n",
      "Policy Reward: tensor(1.2639, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.55', '0.23', '0.72', '0.78', '0.29', '0.20', '0.32', '0.31', '0.40', '0.51', '0.53', '0.47', '0.39', '0.38', '0.32', '0.12', '0.05']\n",
      "Last Action:  tensor([0.0525, 0.1879, 0.5371, 0.6195, 0.3228, 0.4464, 0.1545, 0.4935, 0.5151,\n",
      "        0.3629], device='cuda:0')\n",
      "Loss: 0.40866127610206604 -0.6495074033737183\n",
      "Loss: 0.4134819805622101 -0.7162510752677917\n",
      "Loss: 0.44163960218429565 -0.6033159494400024\n",
      "Loss: 0.37474313378334045 -0.5009204149246216\n",
      "Loss: 0.347307950258255 -0.24662257730960846\n",
      "Loss: 0.34782111644744873 -0.47616907954216003\n",
      "Loss: 0.36508268117904663 -0.7425970435142517\n",
      "Policy Reward: tensor(1.2512, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.71', '0.30', '0.82', '0.70', '0.41', '0.64', '0.36', '0.71', '0.65', '0.49', '0.41', '0.65', '0.58', '0.47', '0.50', '0.41', '0.67']\n",
      "Last Action:  tensor([0.6734, 0.5023, 0.4543, 0.3652, 0.4268, 0.5312, 0.4714, 0.4307, 0.5306,\n",
      "        0.1402], device='cuda:0')\n",
      "Loss: 0.3532567024230957 -0.2676432430744171\n",
      "Loss: 0.3520788550376892 -0.34299299120903015\n",
      "Loss: 0.44299906492233276 -0.9988549947738647\n",
      "Loss: 0.33635130524635315 -0.30252090096473694\n",
      "Loss: 0.41482383012771606 -0.6344931125640869\n",
      "Loss: 0.4232209622859955 -0.6550112366676331\n",
      "Loss: 0.32745543122291565 -0.420157790184021\n",
      "Policy Reward: tensor(1.3089, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.85', '0.54', '0.65', '0.61', '0.41', '0.39', '0.41', '0.45', '0.57', '0.49', '0.39', '0.42', '0.76', '0.64', '0.61', '0.54', '0.42']\n",
      "Last Action:  tensor([0.4229, 0.4862, 0.6269, 0.2373, 0.5792, 0.2120, 0.4492, 0.4494, 0.5262,\n",
      "        0.4923], device='cuda:0')\n",
      "Loss: 0.41171586513519287 -0.5401482582092285\n",
      "Loss: 0.36324143409729004 -0.5200386047363281\n",
      "Loss: 0.3458625376224518 -0.2685354948043823\n",
      "Loss: 0.40078306198120117 -0.667875349521637\n",
      "Loss: 0.34364837408065796 -0.8524882793426514\n",
      "Loss: 0.3962121605873108 -0.5703073143959045\n",
      "Loss: 0.36322730779647827 -0.4341285228729248\n",
      "Policy Reward: tensor(1.1417, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.66', '0.36', '0.57', '0.82', '0.42', '0.15', '0.21', '0.25', '0.41', '0.56', '0.49', '0.54', '0.72', '0.75', '0.67', '0.61', '0.48']\n",
      "Last Action:  tensor([0.4838, 0.6187, 0.3030, 0.4382, 0.4286, 0.6488, 0.4345, 0.3360, 0.3976,\n",
      "        0.3779], device='cuda:0')\n",
      "Loss: 0.3808455765247345 -0.27565592527389526\n",
      "Loss: 0.35801786184310913 -0.7688750624656677\n",
      "Loss: 0.37811362743377686 -0.47120797634124756\n",
      "Loss: 0.44242528080940247 -0.6998854875564575\n",
      "Loss: 0.39037007093429565 -0.5056936144828796\n",
      "Loss: 0.36413121223449707 -0.6084772944450378\n",
      "Loss: 0.33715376257896423 -0.6484346985816956\n",
      "Policy Reward: tensor(1.3207, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.60', '0.65', '0.61', '0.63', '0.56', '0.37', '0.30', '0.38', '0.38', '0.36', '0.39', '0.43', '0.45', '0.46', '0.39', '0.30', '0.33']\n",
      "Last Action:  tensor([0.3330, 0.5019, 0.3938, 0.2885, 0.3884, 0.4761, 0.4402, 0.2738, 0.4707,\n",
      "        0.0836], device='cuda:0')\n",
      "Loss: 0.3795590400695801 -0.4254305064678192\n",
      "Loss: 0.3665725290775299 -0.7876301407814026\n",
      "Loss: 0.40155544877052307 -0.8880714774131775\n",
      "Loss: 0.3974631130695343 -0.7891935706138611\n",
      "Loss: 0.3377276062965393 -0.4926038384437561\n",
      "Loss: 0.39841604232788086 -0.5978487133979797\n",
      "Loss: 0.34201183915138245 -0.4252130687236786\n",
      "Policy Reward: tensor(1.2926, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.58', '0.83', '0.56', '0.83', '0.57', '0.62', '0.51', '0.50', '0.53', '0.63', '0.69', '0.66', '0.62', '0.67', '0.61', '0.72', '0.60']\n",
      "Last Action:  tensor([0.5968, 0.3830, 0.5429, 0.3683, 0.4431, 0.5242, 0.3308, 0.2873, 0.7256,\n",
      "        0.6451], device='cuda:0')\n",
      "Loss: 0.4327434003353119 -0.7246427536010742\n",
      "Loss: 0.4078722596168518 -0.8532566428184509\n",
      "Loss: 0.3844200074672699 -0.580981433391571\n",
      "Loss: 0.4086223542690277 -0.48236867785453796\n",
      "Loss: 0.4047415554523468 -0.7174332737922668\n",
      "Loss: 0.38374337553977966 -0.6880179047584534\n",
      "Loss: 0.3890761733055115 -1.0258938074111938\n",
      "Policy Reward: tensor(1.1338, device='cuda:0')\n",
      "Trajectory:  ['0.03', '1.00', '0.85', '0.78', '0.68', '0.61', '0.61', '0.48', '0.34', '0.44', '0.47', '0.44', '0.46', '0.47', '0.48', '0.49', '0.43', '0.41', '0.45']\n",
      "Last Action:  tensor([0.4508, 0.7482, 0.7882, 0.2215, 0.3375, 0.6664, 0.2608, 0.6099, 0.5665,\n",
      "        0.4790], device='cuda:0')\n",
      "Loss: 0.3854779601097107 -0.5489274263381958\n",
      "Loss: 0.3657965064048767 -0.4092998802661896\n",
      "Loss: 0.41031911969184875 -0.9594866633415222\n",
      "Loss: 0.41628745198249817 -0.7482758164405823\n",
      "Loss: 0.3807165026664734 -0.6396251320838928\n",
      "Loss: 0.40037447214126587 -0.7793864011764526\n",
      "Loss: 0.36683985590934753 -0.36832481622695923\n",
      "Policy Reward: tensor(1.1747, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.78', '0.59', '0.56', '0.66', '0.33', '0.23', '0.37', '0.37', '0.44', '0.59', '0.61', '0.60', '0.69', '0.69', '0.70', '0.66', '0.51']\n",
      "Last Action:  tensor([0.5134, 0.4003, 0.1793, 0.4795, 0.5545, 0.6907, 0.4255, 0.4113, 0.4864,\n",
      "        0.5133], device='cuda:0')\n",
      "Bigstep:  11\n",
      "Loss: 0.34139981865882874 0.4685465693473816\n",
      "Loss: 0.39377814531326294 0.13190147280693054\n",
      "Loss: 0.377192884683609 -0.1654115468263626\n",
      "Loss: 0.32562971115112305 -0.1339300125837326\n",
      "Loss: 0.42418619990348816 -0.0405493825674057\n",
      "Loss: 0.3748289942741394 -0.15851083397865295\n",
      "Loss: 0.35582926869392395 -0.02194533497095108\n",
      "Policy Reward: tensor(1.0651, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.99', '0.36', '0.22', '0.31', '0.49', '0.26', '0.08', '0.08', '0.11', '0.14', '0.14', '0.13', '0.16', '0.23', '0.19', '0.10', '0.07', '0.03']\n",
      "Last Action:  tensor([0.0331, 0.0171, 0.1926, 0.2739, 0.1164, 0.1032, 0.0274, 0.0268, 0.2022,\n",
      "        0.0539], device='cuda:0')\n",
      "Loss: 0.33662155270576477 -0.014389888383448124\n",
      "Loss: 0.31995174288749695 -0.12665753066539764\n",
      "Loss: 0.36480653285980225 -0.20326557755470276\n",
      "Loss: 0.4312727451324463 -0.33645081520080566\n",
      "Loss: 0.4483184218406677 -0.2964417338371277\n",
      "Loss: 0.4124299883842468 -0.3170183598995209\n",
      "Loss: 0.4015699028968811 -0.19141235947608948\n",
      "Policy Reward: tensor(1.1411, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.68', '0.15', '0.21', '0.33', '0.09', '0.00', '0.02', '0.09', '0.16', '0.20', '0.24', '0.29', '0.33', '0.36', '0.33', '0.18', '0.07']\n",
      "Last Action:  tensor([0.0746, 0.0765, 0.0736, 0.0721, 0.0874, 0.0683, 0.0483, 0.1472, 0.2899,\n",
      "        0.0476], device='cuda:0')\n",
      "Loss: 0.34373003244400024 -0.011941338889300823\n",
      "Loss: 0.3149641156196594 0.23296484351158142\n",
      "Loss: 0.4034610092639923 -0.19785888493061066\n",
      "Loss: 0.4401032328605652 -0.2696954011917114\n",
      "Loss: 0.4009436368942261 -0.3278349041938782\n",
      "Loss: 0.3461679220199585 -0.2016623616218567\n",
      "Loss: 0.3191215991973877 0.017537806183099747\n",
      "Policy Reward: tensor(1.1638, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.51', '0.23', '0.20', '0.29', '0.26', '0.05', '0.04', '0.10', '0.18', '0.16', '0.20', '0.27', '0.29', '0.31', '0.29', '0.15', '0.06']\n",
      "Last Action:  tensor([0.0594, 0.0307, 0.1191, 0.2493, 0.0471, 0.0502, 0.3441, 0.0708, 0.0248,\n",
      "        0.0280], device='cuda:0')\n",
      "Loss: 0.36599430441856384 -0.2661735415458679\n",
      "Loss: 0.39014875888824463 -0.05788541957736015\n",
      "Loss: 0.3605562150478363 -0.18991456925868988\n",
      "Loss: 0.40679043531417847 -0.36460715532302856\n",
      "Loss: 0.2827133238315582 -0.2870745360851288\n",
      "Loss: 0.3824136555194855 0.030767520889639854\n",
      "Loss: 0.4042060971260071 -0.18018092215061188\n",
      "Policy Reward: tensor(1.0763, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.48', '0.20', '0.17', '0.31', '0.66', '0.28', '0.12', '0.11', '0.14', '0.15', '0.18', '0.25', '0.29', '0.24', '0.08', '0.04', '0.03']\n",
      "Last Action:  tensor([0.0301, 0.0996, 0.0991, 0.3887, 0.3419, 0.3249, 0.1031, 0.0794, 0.3299,\n",
      "        0.0267], device='cuda:0')\n",
      "Loss: 0.3676592707633972 -0.1228051632642746\n",
      "Loss: 0.4289124310016632 -0.3578812777996063\n",
      "Loss: 0.3382551670074463 -0.3337101340293884\n",
      "Loss: 0.42096734046936035 -0.36164775490760803\n",
      "Loss: 0.3677771985530853 0.11629072576761246\n",
      "Loss: 0.3401404321193695 -0.301118403673172\n",
      "Loss: 0.35621899366378784 -0.34418436884880066\n",
      "Policy Reward: tensor(1.0823, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.49', '0.19', '0.27', '0.55', '0.42', '0.12', '0.10', '0.13', '0.18', '0.20', '0.23', '0.35', '0.52', '0.64', '0.58', '0.44', '0.29']\n",
      "Last Action:  tensor([0.2888, 0.4580, 0.0692, 0.5538, 0.3319, 0.3218, 0.4260, 0.5997, 0.3561,\n",
      "        0.1139], device='cuda:0')\n",
      "Loss: 0.3892647325992584 -0.07020416110754013\n",
      "Loss: 0.36971214413642883 -0.26851144433021545\n",
      "Loss: 0.432157963514328 -0.1814495027065277\n",
      "Loss: 0.3091048300266266 -0.09843721240758896\n",
      "Loss: 0.41867244243621826 -0.2246924340724945\n",
      "Loss: 0.35704678297042847 -0.076572947204113\n",
      "Loss: 0.38291630148887634 -0.3988918364048004\n",
      "Policy Reward: tensor(1.1255, device='cuda:0')\n",
      "Trajectory:  ['0.02', '0.79', '0.70', '0.24', '0.09', '0.31', '0.65', '0.28', '0.07', '0.09', '0.14', '0.23', '0.28', '0.33', '0.32', '0.36', '0.41', '0.33', '0.12']\n",
      "Last Action:  tensor([0.1158, 0.3995, 0.0335, 0.1035, 0.5376, 0.1394, 0.0614, 0.4507, 0.0392,\n",
      "        0.3049], device='cuda:0')\n",
      "Loss: 0.3669081926345825 -0.37785136699676514\n",
      "Loss: 0.3129105269908905 -0.2343491017818451\n",
      "Loss: 0.43767356872558594 -0.16628891229629517\n",
      "Loss: 0.3613485097885132 -0.2485659271478653\n",
      "Loss: 0.4035479724407196 -0.5891311764717102\n",
      "Loss: 0.3407246768474579 -0.21410693228244781\n",
      "Loss: 0.3877134323120117 -0.3872707188129425\n",
      "Policy Reward: tensor(1.1148, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.94', '0.57', '0.13', '0.08', '0.45', '0.52', '0.22', '0.07', '0.10', '0.09', '0.16', '0.37', '0.58', '0.48', '0.40', '0.36', '0.22', '0.09']\n",
      "Last Action:  tensor([0.0924, 0.0431, 0.4679, 0.4791, 0.2351, 0.2128, 0.2438, 0.1864, 0.4111,\n",
      "        0.6534], device='cuda:0')\n",
      "Loss: 0.32535508275032043 0.07228471338748932\n",
      "Loss: 0.3839672803878784 -0.15401452779769897\n",
      "Loss: 0.4270673990249634 -0.592035174369812\n",
      "Loss: 0.3693195581436157 -0.27674296498298645\n",
      "Loss: 0.4240865111351013 -0.5950382947921753\n",
      "Loss: 0.3470112681388855 -0.24315118789672852\n",
      "Loss: 0.3609921634197235 -0.2779337167739868\n",
      "Policy Reward: tensor(1.0891, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.61', '0.14', '0.14', '0.39', '0.32', '0.05', '0.02', '0.05', '0.14', '0.22', '0.33', '0.37', '0.39', '0.47', '0.57', '0.49', '0.19']\n",
      "Last Action:  tensor([0.1945, 0.3520, 0.5378, 0.4985, 0.3687, 0.0733, 0.4564, 0.2388, 0.0702,\n",
      "        0.3434], device='cuda:0')\n",
      "Bigstep:  12\n",
      "Loss: 0.3763808608055115 0.6106318831443787\n",
      "Loss: 0.34504470229148865 0.44305741786956787\n",
      "Loss: 0.36360132694244385 0.0388726182281971\n",
      "Loss: 0.3448474407196045 -0.14909233152866364\n",
      "Loss: 0.29294151067733765 0.03867868334054947\n",
      "Loss: 0.4245450794696808 -0.1990412026643753\n",
      "Loss: 0.34925374388694763 -0.11547590047121048\n",
      "Policy Reward: tensor(1.0020, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.81', '0.65', '0.60', '0.79', '0.72', '0.64', '0.57', '0.58', '0.58', '0.61', '0.62', '0.61', '0.71', '0.79', '0.87', '0.92', '0.93']\n",
      "Last Action:  tensor([0.9315, 0.8814, 0.7980, 0.7430, 0.9203, 0.7058, 0.9546, 0.8840, 0.8700,\n",
      "        0.7809], device='cuda:0')\n",
      "Loss: 0.3616262376308441 0.07248565554618835\n",
      "Loss: 0.2671895921230316 0.06506437808275223\n",
      "Loss: 0.3747453987598419 -0.3989544212818146\n",
      "Loss: 0.33268821239471436 -0.21780769526958466\n",
      "Loss: 0.28990352153778076 -0.1531228870153427\n",
      "Loss: 0.3517868220806122 -0.3423554599285126\n",
      "Loss: 0.34211957454681396 -0.148576021194458\n",
      "Policy Reward: tensor(1.0434, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.92', '0.76', '0.65', '0.79', '0.71', '0.68', '0.59', '0.49', '0.45', '0.50', '0.55', '0.62', '0.73', '0.79', '0.87', '0.93', '0.94']\n",
      "Last Action:  tensor([0.9377, 0.8097, 0.6652, 0.5615, 0.9253, 0.8242, 0.8663, 0.8281, 0.9060,\n",
      "        0.8258], device='cuda:0')\n",
      "Loss: 0.32601699233055115 -0.19991406798362732\n",
      "Loss: 0.36982816457748413 -0.02016780525445938\n",
      "Loss: 0.3266923129558563 -0.2341693639755249\n",
      "Loss: 0.4053449332714081 -0.19892708957195282\n",
      "Loss: 0.3259848356246948 -0.14555801451206207\n",
      "Loss: 0.3430331349372864 -0.21787817776203156\n",
      "Loss: 0.3226796090602875 -0.27809932827949524\n",
      "Policy Reward: tensor(1.1119, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.81', '0.66', '0.67', '0.84', '0.86', '0.74', '0.55', '0.48', '0.47', '0.42', '0.38', '0.37', '0.41', '0.49', '0.61', '0.61', '0.52']\n",
      "Last Action:  tensor([0.5195, 0.7811, 0.7071, 0.8809, 0.8230, 0.8954, 0.7595, 0.5297, 0.8384,\n",
      "        0.7480], device='cuda:0')\n",
      "Loss: 0.27048593759536743 0.15390534698963165\n",
      "Loss: 0.3253841698169708 -0.29519686102867126\n",
      "Loss: 0.3064011335372925 -0.06576193124055862\n",
      "Loss: 0.31944262981414795 0.18630367517471313\n",
      "Loss: 0.29645389318466187 -0.14874869585037231\n",
      "Loss: 0.353390634059906 -0.29710879921913147\n",
      "Loss: 0.3984455466270447 -0.23526304960250854\n",
      "Policy Reward: tensor(1.1015, device='cuda:0')\n",
      "Trajectory:  ['0.04', '1.00', '0.94', '0.75', '0.72', '0.78', '0.81', '0.76', '0.68', '0.55', '0.54', '0.54', '0.45', '0.39', '0.42', '0.49', '0.62', '0.70', '0.70']\n",
      "Last Action:  tensor([0.6961, 0.8801, 0.7596, 0.8627, 0.8796, 0.4359, 0.6615, 0.8138, 0.8815,\n",
      "        0.3893], device='cuda:0')\n",
      "Loss: 0.37710896134376526 -0.14303553104400635\n",
      "Loss: 0.3145872950553894 -0.40097033977508545\n",
      "Loss: 0.3216770887374878 -0.08846233040094376\n",
      "Loss: 0.3119252026081085 -0.04418812319636345\n",
      "Loss: 0.36496126651763916 -0.13672159612178802\n",
      "Loss: 0.3550035357475281 -0.1958017647266388\n",
      "Loss: 0.3851730525493622 -0.15453341603279114\n",
      "Policy Reward: tensor(1.0156, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.94', '0.76', '0.70', '0.87', '0.85', '0.74', '0.66', '0.60', '0.57', '0.54', '0.51', '0.54', '0.66', '0.78', '0.84', '0.84', '0.82']\n",
      "Last Action:  tensor([0.8167, 0.6979, 0.8334, 0.8031, 0.6461, 0.7025, 0.5916, 0.8408, 0.7056,\n",
      "        0.6760], device='cuda:0')\n",
      "Loss: 0.31812235713005066 0.0053019835613667965\n",
      "Loss: 0.41867795586586 -0.17321288585662842\n",
      "Loss: 0.30894798040390015 -0.287733793258667\n",
      "Loss: 0.31433266401290894 -0.17209994792938232\n",
      "Loss: 0.4595062732696533 -0.46615070104599\n",
      "Loss: 0.34702926874160767 -0.22732828557491302\n",
      "Loss: 0.3166233003139496 -0.33692488074302673\n",
      "Policy Reward: tensor(1.0896, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.96', '0.72', '0.65', '0.81', '0.85', '0.75', '0.60', '0.51', '0.54', '0.49', '0.42', '0.39', '0.46', '0.58', '0.71', '0.74', '0.68']\n",
      "Last Action:  tensor([0.6772, 0.4664, 0.8220, 0.5987, 0.8576, 0.8754, 0.5577, 0.4750, 0.4461,\n",
      "        0.4540], device='cuda:0')\n",
      "Loss: 0.3776842951774597 -0.07973772287368774\n",
      "Loss: 0.31730136275291443 -0.5459126234054565\n",
      "Loss: 0.35820457339286804 -0.39673712849617004\n",
      "Loss: 0.40195217728614807 -0.3499937951564789\n",
      "Loss: 0.3120180666446686 -0.17966601252555847\n",
      "Loss: 0.345387727022171 -0.280184268951416\n",
      "Loss: 0.2964877486228943 -0.32705360651016235\n",
      "Policy Reward: tensor(0.9665, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.80', '0.69', '0.80', '0.86', '0.84', '0.73', '0.64', '0.58', '0.52', '0.48', '0.45', '0.45', '0.54', '0.69', '0.76', '0.73', '0.65']\n",
      "Last Action:  tensor([0.6502, 0.5961, 0.8978, 0.4137, 0.7109, 0.7456, 0.6714, 0.8423, 0.7721,\n",
      "        0.7141], device='cuda:0')\n",
      "Loss: 0.29050830006599426 -0.09017649292945862\n",
      "Loss: 0.3486345410346985 -0.16761688888072968\n",
      "Loss: 0.3892555832862854 -0.09631440788507462\n",
      "Loss: 0.34660428762435913 -0.2789020240306854\n",
      "Loss: 0.387104868888855 -0.3586824834346771\n",
      "Loss: 0.32379189133644104 0.05051236227154732\n",
      "Loss: 0.33628907799720764 -0.10650806128978729\n",
      "Policy Reward: tensor(1.1603, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.85', '0.57', '0.73', '0.82', '0.76', '0.65', '0.51', '0.47', '0.40', '0.42', '0.48', '0.60', '0.75', '0.80', '0.83', '0.86', '0.85']\n",
      "Last Action:  tensor([0.8504, 0.8476, 0.3884, 0.7859, 0.8917, 0.7744, 0.7506, 0.8273, 0.4066,\n",
      "        0.6014], device='cuda:0')\n",
      "Bigstep:  13\n",
      "Loss: 0.33634498715400696 0.9724887013435364\n",
      "Loss: 0.3135763108730316 0.33527010679244995\n",
      "Loss: 0.38261422514915466 -0.5298637747764587\n",
      "Loss: 0.39653509855270386 -0.3292970657348633\n",
      "Loss: 0.2702796161174774 0.32803773880004883\n",
      "Loss: 0.30490943789482117 -0.2256239652633667\n",
      "Loss: 0.3712179362773895 -0.31886202096939087\n",
      "Policy Reward: tensor(1.1481, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.52', '0.28', '0.78', '0.62', '0.56', '0.45', '0.36', '0.27', '0.23', '0.20', '0.21', '0.34', '0.48', '0.62', '0.67', '0.62', '0.52']\n",
      "Last Action:  tensor([0.5195, 0.6118, 0.7297, 0.7402, 0.4878, 0.4487, 0.8447, 0.4748, 0.4551,\n",
      "        0.5291], device='cuda:0')\n",
      "Loss: 0.3225826621055603 0.003636963665485382\n",
      "Loss: 0.33336979150772095 -0.19004176557064056\n",
      "Loss: 0.3604319393634796 -0.02560862898826599\n",
      "Loss: 0.29340341687202454 -0.10969804972410202\n",
      "Loss: 0.2501167058944702 -0.26192066073417664\n",
      "Loss: 0.2721754312515259 -0.23938952386379242\n",
      "Loss: 0.35603275895118713 -0.3645106852054596\n",
      "Policy Reward: tensor(1.1326, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.86', '0.69', '0.64', '0.76', '0.69', '0.55', '0.42', '0.35', '0.34', '0.38', '0.41', '0.46', '0.63', '0.73', '0.74', '0.77', '0.73']\n",
      "Last Action:  tensor([0.7316, 0.7987, 0.1776, 0.6714, 0.8438, 0.7428, 0.4159, 0.6868, 0.6283,\n",
      "        0.6823], device='cuda:0')\n",
      "Loss: 0.2911442220211029 -0.17937025427818298\n",
      "Loss: 0.31901833415031433 -0.35494735836982727\n",
      "Loss: 0.3500591814517975 -0.17446991801261902\n",
      "Loss: 0.2520882785320282 -0.18060201406478882\n",
      "Loss: 0.3400455713272095 -0.3354089558124542\n",
      "Loss: 0.3034186065196991 -0.11638064682483673\n",
      "Loss: 0.3094410300254822 -0.2405412495136261\n",
      "Policy Reward: tensor(1.1047, device='cuda:0')\n",
      "Trajectory:  ['0.04', '0.61', '0.58', '0.37', '0.38', '0.66', '0.84', '0.78', '0.74', '0.61', '0.41', '0.31', '0.29', '0.35', '0.46', '0.52', '0.48', '0.43', '0.40']\n",
      "Last Action:  tensor([0.3996, 0.5869, 0.7640, 0.5418, 0.3464, 0.3139, 0.7763, 0.6518, 0.4179,\n",
      "        0.3230], device='cuda:0')\n",
      "Loss: 0.33781829476356506 -0.29602545499801636\n",
      "Loss: 0.3520030081272125 -0.3327440321445465\n",
      "Loss: 0.34216445684432983 -0.36503732204437256\n",
      "Loss: 0.34604009985923767 -0.366577684879303\n",
      "Loss: 0.30171674489974976 -0.07731972634792328\n",
      "Loss: 0.3064134120941162 -0.23296421766281128\n",
      "Loss: 0.320068359375 -0.16692209243774414\n",
      "Policy Reward: tensor(1.1182, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.50', '0.22', '0.39', '0.53', '0.46', '0.24', '0.31', '0.21', '0.21', '0.20', '0.24', '0.33', '0.52', '0.68', '0.61', '0.54', '0.55']\n",
      "Last Action:  tensor([0.5507, 0.7592, 0.6628, 0.4695, 0.7399, 0.7124, 0.4360, 0.4739, 0.6921,\n",
      "        0.7810], device='cuda:0')\n",
      "Loss: 0.3175569474697113 -0.2855089604854584\n",
      "Loss: 0.317439466714859 -0.05701643228530884\n",
      "Loss: 0.3832647204399109 -0.7441561222076416\n",
      "Loss: 0.3710406422615051 -0.4183550477027893\n",
      "Loss: 0.38545170426368713 -0.5204388499259949\n",
      "Loss: 0.3369962275028229 -0.2970130741596222\n",
      "Loss: 0.256960928440094 -0.30273184180259705\n",
      "Policy Reward: tensor(1.0837, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.99', '0.19', '0.14', '0.22', '0.43', '0.27', '0.11', '0.17', '0.24', '0.26', '0.19', '0.15', '0.19', '0.32', '0.46', '0.55', '0.55', '0.58']\n",
      "Last Action:  tensor([0.5754, 0.7943, 0.6644, 0.7128, 0.1675, 0.6402, 0.6562, 0.7297, 0.3748,\n",
      "        0.5931], device='cuda:0')\n",
      "Loss: 0.3407650887966156 -0.29151198267936707\n",
      "Loss: 0.3896894156932831 -0.6441644430160522\n",
      "Loss: 0.2994008958339691 -0.5331475138664246\n",
      "Loss: 0.28673824667930603 -0.32641902565956116\n",
      "Loss: 0.4021807909011841 -0.6328375935554504\n",
      "Loss: 0.34350115060806274 -0.4053365886211395\n",
      "Loss: 0.31204965710639954 -0.6972115635871887\n",
      "Policy Reward: tensor(1.0723, device='cuda:0')\n",
      "Trajectory:  ['0.02', '0.77', '0.29', '0.14', '0.22', '0.48', '0.60', '0.40', '0.22', '0.21', '0.22', '0.21', '0.20', '0.30', '0.47', '0.53', '0.46', '0.44', '0.40']\n",
      "Last Action:  tensor([0.3964, 0.7440, 0.6348, 0.2936, 0.4592, 0.7708, 0.6958, 0.7175, 0.5512,\n",
      "        0.6491], device='cuda:0')\n",
      "Loss: 0.3050273060798645 -0.418864905834198\n",
      "Loss: 0.2922552525997162 -0.4629517197608948\n",
      "Loss: 0.3229386806488037 -0.29294922947883606\n",
      "Loss: 0.32682177424430847 -0.2625264525413513\n",
      "Loss: 0.24695467948913574 -0.18663933873176575\n",
      "Loss: 0.34080490469932556 -0.4926983118057251\n",
      "Loss: 0.34895503520965576 -0.5630428791046143\n",
      "Policy Reward: tensor(1.0588, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.83', '0.21', '0.10', '0.24', '0.45', '0.50', '0.20', '0.16', '0.19', '0.22', '0.24', '0.28', '0.35', '0.44', '0.51', '0.61', '0.69', '0.71']\n",
      "Last Action:  tensor([0.7128, 0.4751, 0.5927, 0.6575, 0.7075, 0.7390, 0.4316, 0.5021, 0.4524,\n",
      "        0.5582], device='cuda:0')\n",
      "Loss: 0.3463500440120697 -0.45266905426979065\n",
      "Loss: 0.2945077121257782 -0.6490441560745239\n",
      "Loss: 0.37331363558769226 -0.5895649194717407\n",
      "Loss: 0.2977482080459595 -0.44115912914276123\n",
      "Loss: 0.2920601963996887 -0.35706308484077454\n",
      "Loss: 0.37208959460258484 -0.5415271520614624\n",
      "Loss: 0.3042682707309723 -0.5365914106369019\n",
      "Policy Reward: tensor(1.0314, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.54', '0.13', '0.17', '0.30', '0.50', '0.52', '0.26', '0.36', '0.31', '0.29', '0.27', '0.28', '0.32', '0.45', '0.65', '0.72', '0.73', '0.73']\n",
      "Last Action:  tensor([0.7293, 0.6568, 0.4596, 0.6739, 0.6419, 0.4638, 0.4429, 0.7174, 0.6040,\n",
      "        0.4847], device='cuda:0')\n",
      "Bigstep:  14\n",
      "Loss: 0.32234352827072144 1.6080114841461182\n",
      "Loss: 0.303188294172287 0.28634411096572876\n",
      "Loss: 0.4015759825706482 -0.20571014285087585\n",
      "Loss: 0.3093711733818054 -0.011159420944750309\n",
      "Loss: 0.32268157601356506 -0.44805991649627686\n",
      "Loss: 0.38396671414375305 -0.06929972767829895\n",
      "Loss: 0.3506312668323517 -0.541628360748291\n",
      "Policy Reward: tensor(1.0543, device='cuda:0')\n",
      "Trajectory:  ['0.02', '0.52', '0.66', '0.63', '0.70', '0.68', '0.70', '0.69', '0.65', '0.57', '0.51', '0.53', '0.63', '0.71', '0.72', '0.75', '0.83', '0.90', '0.94']\n",
      "Last Action:  tensor([0.9421, 0.9317, 0.8950, 0.9605, 0.9556, 0.9680, 0.9699, 0.9700, 0.9556,\n",
      "        0.9511], device='cuda:0')\n",
      "Loss: 0.31383171677589417 -0.4944542944431305\n",
      "Loss: 0.29297980666160583 -0.3512377142906189\n",
      "Loss: 0.33322909474372864 -0.4818178117275238\n",
      "Loss: 0.3375653624534607 -0.27601706981658936\n",
      "Loss: 0.3325396180152893 -0.4079328775405884\n",
      "Loss: 0.3317234218120575 -0.48599034547805786\n",
      "Loss: 0.27659890055656433 -0.21354088187217712\n",
      "Policy Reward: tensor(1.1180, device='cuda:0')\n",
      "Trajectory:  ['0.01', '0.95', '0.77', '0.63', '0.64', '0.70', '0.66', '0.63', '0.59', '0.52', '0.44', '0.44', '0.56', '0.61', '0.59', '0.63', '0.76', '0.88', '0.93']\n",
      "Last Action:  tensor([0.9275, 0.9160, 0.9427, 0.9282, 0.9463, 0.9266, 0.8850, 0.9588, 0.8923,\n",
      "        0.9188], device='cuda:0')\n",
      "Loss: 0.2922098934650421 -0.39608603715896606\n",
      "Loss: 0.3491150438785553 -0.5537265539169312\n",
      "Loss: 0.3074921667575836 -0.38780397176742554\n",
      "Loss: 0.2971220314502716 -0.29156696796417236\n",
      "Loss: 0.35998502373695374 -0.4747723639011383\n",
      "Loss: 0.4430292844772339 -0.49821120500564575\n",
      "Loss: 0.2808712422847748 -0.5006889700889587\n",
      "Policy Reward: tensor(0.9489, device='cuda:0')\n",
      "Trajectory:  ['0.01', '0.86', '0.83', '0.79', '0.79', '0.73', '0.75', '0.77', '0.74', '0.69', '0.65', '0.67', '0.74', '0.79', '0.78', '0.79', '0.86', '0.91', '0.94']\n",
      "Last Action:  tensor([0.9378, 0.9276, 0.9408, 0.9448, 0.9728, 0.9453, 0.9594, 0.9532, 0.9158,\n",
      "        0.9262], device='cuda:0')\n",
      "Loss: 0.27452927827835083 -0.32735395431518555\n",
      "Loss: 0.42062702775001526 -0.38796189427375793\n",
      "Loss: 0.3691554665565491 -0.47786247730255127\n",
      "Loss: 0.3440975546836853 -0.5053198337554932\n",
      "Loss: 0.3125763535499573 -0.6270239949226379\n",
      "Loss: 0.304533988237381 -0.6614091396331787\n",
      "Loss: 0.40429794788360596 -0.5693046450614929\n",
      "Policy Reward: tensor(1.1242, device='cuda:0')\n",
      "Trajectory:  ['0.24', '1.00', '0.86', '0.77', '0.72', '0.77', '0.78', '0.76', '0.71', '0.68', '0.65', '0.65', '0.68', '0.68', '0.65', '0.72', '0.85', '0.90', '0.92']\n",
      "Last Action:  tensor([0.9235, 0.9382, 0.9631, 0.9474, 0.9329, 0.9023, 0.9569, 0.9374, 0.9505,\n",
      "        0.9224], device='cuda:0')\n",
      "Loss: 0.4003840982913971 -0.8687060475349426\n",
      "Loss: 0.35192903876304626 -0.3814244568347931\n",
      "Loss: 0.2870478332042694 -0.4970402717590332\n",
      "Loss: 0.2295728474855423 -0.3940586447715759\n",
      "Loss: 0.3152056336402893 -0.5479030013084412\n",
      "Loss: 0.32182401418685913 -0.5890516042709351\n",
      "Loss: 0.32870250940322876 -0.3129791021347046\n",
      "Policy Reward: tensor(0.9560, device='cuda:0')\n",
      "Trajectory:  ['0.31', '1.00', '0.74', '0.63', '0.61', '0.71', '0.65', '0.63', '0.68', '0.67', '0.61', '0.62', '0.68', '0.66', '0.67', '0.75', '0.86', '0.94', '0.96']\n",
      "Last Action:  tensor([0.9613, 0.9377, 0.9497, 0.9484, 0.8906, 0.9621, 0.9365, 0.9716, 0.9465,\n",
      "        0.9734], device='cuda:0')\n",
      "Loss: 0.3003411293029785 -0.49661386013031006\n",
      "Loss: 0.33114397525787354 -0.6049837470054626\n",
      "Loss: 0.2862582504749298 -0.4701378643512726\n",
      "Loss: 0.3469548523426056 -0.46014726161956787\n",
      "Loss: 0.3082703948020935 -0.6608604192733765\n",
      "Loss: 0.3673497438430786 -0.7562878131866455\n",
      "Loss: 0.34567517042160034 -0.579947292804718\n",
      "Policy Reward: tensor(1.0878, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.94', '0.86', '0.85', '0.78', '0.76', '0.80', '0.81', '0.78', '0.75', '0.74', '0.76', '0.82', '0.83', '0.79', '0.82', '0.90', '0.94', '0.96']\n",
      "Last Action:  tensor([0.9575, 0.9622, 0.9786, 0.9617, 0.8510, 0.9680, 0.9403, 0.9591, 0.9733,\n",
      "        0.9747], device='cuda:0')\n",
      "Loss: 0.30495715141296387 -0.37705451250076294\n",
      "Loss: 0.3532297909259796 -0.42653897404670715\n",
      "Loss: 0.35349369049072266 -0.4951546788215637\n",
      "Loss: 0.30781084299087524 -0.5077651739120483\n",
      "Loss: 0.3288288712501526 -0.5745481252670288\n",
      "Loss: 0.36796143651008606 -0.7396367788314819\n",
      "Loss: 0.3931291401386261 -0.6605090498924255\n",
      "Policy Reward: tensor(0.8947, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.89', '0.67', '0.78', '0.86', '0.77', '0.79', '0.83', '0.80', '0.74', '0.75', '0.81', '0.85', '0.85', '0.87', '0.92', '0.95', '0.97', '0.97']\n",
      "Last Action:  tensor([0.9745, 0.9141, 0.9795, 0.9500, 0.9624, 0.9403, 0.9795, 0.9411, 0.9275,\n",
      "        0.9708], device='cuda:0')\n",
      "Loss: 0.38516858220100403 -0.7500340342521667\n",
      "Loss: 0.27394944429397583 -0.5248185992240906\n",
      "Loss: 0.29062387347221375 -0.5069226622581482\n",
      "Loss: 0.375336229801178 -0.5333314538002014\n",
      "Loss: 0.2930973172187805 -0.542948842048645\n",
      "Loss: 0.3205881714820862 -0.5699922442436218\n",
      "Loss: 0.3720857799053192 -0.3790997564792633\n",
      "Policy Reward: tensor(0.9170, device='cuda:0')\n",
      "Trajectory:  ['0.50', '1.00', '0.77', '0.68', '0.72', '0.70', '0.69', '0.67', '0.69', '0.68', '0.63', '0.63', '0.64', '0.62', '0.68', '0.81', '0.91', '0.93', '0.91']\n",
      "Last Action:  tensor([0.9094, 0.9315, 0.9369, 0.9270, 0.9511, 0.9237, 0.9477, 0.9479, 0.7917,\n",
      "        0.9644], device='cuda:0')\n",
      "Bigstep:  15\n",
      "Loss: 0.2796923816204071 1.1542243957519531\n",
      "Loss: 0.3048100471496582 0.5639458894729614\n",
      "Loss: 0.28085535764694214 0.25860798358917236\n",
      "Loss: 0.25662726163864136 -0.18198738992214203\n",
      "Loss: 0.2982748746871948 -0.2976314425468445\n",
      "Loss: 0.2444005310535431 -0.00426909327507019\n",
      "Loss: 0.2904628813266754 -0.25784945487976074\n",
      "Policy Reward: tensor(1.0342, device='cuda:0')\n",
      "Trajectory:  ['0.01', '0.44', '0.44', '0.28', '0.26', '0.36', '0.51', '0.58', '0.46', '0.32', '0.31', '0.33', '0.44', '0.64', '0.73', '0.68', '0.66', '0.73', '0.83']\n",
      "Last Action:  tensor([0.8301, 0.7983, 0.8254, 0.9056, 0.8283, 0.9072, 0.8524, 0.8798, 0.9113,\n",
      "        0.8966], device='cuda:0')\n",
      "Loss: 0.3069659173488617 -0.2978251576423645\n",
      "Loss: 0.3494134247303009 -0.403836190700531\n",
      "Loss: 0.3202609717845917 -0.4144105315208435\n",
      "Loss: 0.2258794754743576 -0.4399324059486389\n",
      "Loss: 0.3400469124317169 -0.45085227489471436\n",
      "Loss: 0.3104148507118225 -0.1910112500190735\n",
      "Loss: 0.22783249616622925 -0.31639572978019714\n",
      "Policy Reward: tensor(1.0893, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.85', '0.59', '0.52', '0.48', '0.39', '0.41', '0.46', '0.45', '0.41', '0.41', '0.47', '0.57', '0.64', '0.65', '0.70', '0.80', '0.87', '0.92']\n",
      "Last Action:  tensor([0.9203, 0.9205, 0.8776, 0.8794, 0.8822, 0.9001, 0.8484, 0.8594, 0.8793,\n",
      "        0.8559], device='cuda:0')\n",
      "Loss: 0.2589280903339386 -0.23358696699142456\n",
      "Loss: 0.2924604117870331 -0.2603268027305603\n",
      "Loss: 0.27019962668418884 -0.2794899344444275\n",
      "Loss: 0.27212002873420715 -0.4547223448753357\n",
      "Loss: 0.25921231508255005 -0.35181352496147156\n",
      "Loss: 0.28307920694351196 -0.43681296706199646\n",
      "Loss: 0.32123515009880066 -0.5217151641845703\n",
      "Policy Reward: tensor(1.0320, device='cuda:0')\n",
      "Trajectory:  ['0.34', '1.00', '0.60', '0.34', '0.27', '0.33', '0.25', '0.14', '0.24', '0.33', '0.44', '0.44', '0.50', '0.51', '0.50', '0.56', '0.65', '0.73', '0.81']\n",
      "Last Action:  tensor([0.8082, 0.7685, 0.8722, 0.9354, 0.9358, 0.9590, 0.8574, 0.9486, 0.8663,\n",
      "        0.8641], device='cuda:0')\n",
      "Loss: 0.3322248160839081 -0.6790400743484497\n",
      "Loss: 0.31606006622314453 -0.42426469922065735\n",
      "Loss: 0.32119977474212646 -0.4982571005821228\n",
      "Loss: 0.27511003613471985 -0.47378599643707275\n",
      "Loss: 0.3173004984855652 -0.32753926515579224\n",
      "Loss: 0.28018808364868164 -0.3846854567527771\n",
      "Loss: 0.23621630668640137 -0.27017927169799805\n",
      "Policy Reward: tensor(1.0899, device='cuda:0')\n",
      "Trajectory:  ['0.04', '0.88', '0.77', '0.51', '0.38', '0.48', '0.52', '0.48', '0.37', '0.31', '0.31', '0.38', '0.45', '0.52', '0.60', '0.69', '0.77', '0.83', '0.88']\n",
      "Last Action:  tensor([0.8847, 0.8257, 0.7529, 0.8250, 0.7924, 0.8021, 0.8056, 0.7097, 0.8902,\n",
      "        0.9085], device='cuda:0')\n",
      "Loss: 0.3206298053264618 -0.5444595813751221\n",
      "Loss: 0.23058412969112396 -0.421515554189682\n",
      "Loss: 0.25934645533561707 -0.5160238742828369\n",
      "Loss: 0.30403387546539307 -0.36006927490234375\n",
      "Loss: 0.2844163477420807 -0.3988560736179352\n",
      "Loss: 0.3599011301994324 -0.5923318862915039\n",
      "Loss: 0.23218701779842377 -0.28850680589675903\n",
      "Policy Reward: tensor(0.9861, device='cuda:0')\n",
      "Trajectory:  ['0.08', '1.00', '0.38', '0.21', '0.16', '0.20', '0.18', '0.13', '0.17', '0.30', '0.40', '0.33', '0.34', '0.41', '0.42', '0.40', '0.45', '0.61', '0.78']\n",
      "Last Action:  tensor([0.7771, 0.9152, 0.8223, 0.8657, 0.9064, 0.9243, 0.8081, 0.8125, 0.9368,\n",
      "        0.7929], device='cuda:0')\n",
      "Loss: 0.24820837378501892 -0.3173865079879761\n",
      "Loss: 0.25232845544815063 -0.49693071842193604\n",
      "Loss: 0.24646900594234467 -0.3601457476615906\n",
      "Loss: 0.25757139921188354 -0.463796466588974\n",
      "Loss: 0.2551831305027008 -0.3727648854255676\n",
      "Loss: 0.31752297282218933 -0.5884631276130676\n",
      "Loss: 0.2867538630962372 -0.41610217094421387\n",
      "Policy Reward: tensor(1.1154, device='cuda:0')\n",
      "Trajectory:  ['0.04', '0.99', '0.68', '0.29', '0.23', '0.29', '0.19', '0.16', '0.26', '0.36', '0.33', '0.33', '0.43', '0.50', '0.53', '0.62', '0.74', '0.83', '0.89']\n",
      "Last Action:  tensor([0.8925, 0.8392, 0.8602, 0.9113, 0.7852, 0.7514, 0.8727, 0.8200, 0.8719,\n",
      "        0.8881], device='cuda:0')\n",
      "Loss: 0.23674950003623962 -0.5116347670555115\n",
      "Loss: 0.292476624250412 -0.4340437948703766\n",
      "Loss: 0.34550198912620544 -0.5224422216415405\n",
      "Loss: 0.23783442378044128 -0.32424396276474\n",
      "Loss: 0.3305584490299225 -0.6572276949882507\n",
      "Loss: 0.26925545930862427 -0.42222023010253906\n",
      "Loss: 0.23307430744171143 -0.2926710844039917\n",
      "Policy Reward: tensor(1.2169, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.83', '0.77', '0.55', '0.45', '0.51', '0.51', '0.48', '0.41', '0.36', '0.41', '0.53', '0.60', '0.60', '0.60', '0.71', '0.80', '0.81', '0.86']\n",
      "Last Action:  tensor([0.8580, 0.8890, 0.6866, 0.7458, 0.8153, 0.7988, 0.7332, 0.5811, 0.7768,\n",
      "        0.7966], device='cuda:0')\n",
      "Loss: 0.2389512062072754 -0.20693066716194153\n",
      "Loss: 0.2642710208892822 -0.496309757232666\n",
      "Loss: 0.30564191937446594 -0.5631159543991089\n",
      "Loss: 0.21165108680725098 -0.30695199966430664\n",
      "Loss: 0.24902257323265076 -0.03141668438911438\n",
      "Loss: 0.27192920446395874 -0.23245565593242645\n",
      "Loss: 0.3214300572872162 -0.7386831641197205\n",
      "Policy Reward: tensor(1.0979, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.94', '0.79', '0.45', '0.44', '0.51', '0.34', '0.26', '0.31', '0.33', '0.40', '0.53', '0.61', '0.58', '0.56', '0.67', '0.77', '0.82', '0.86']\n",
      "Last Action:  tensor([0.8579, 0.9178, 0.8745, 0.7177, 0.8781, 0.8395, 0.8670, 0.8432, 0.8848,\n",
      "        0.7625], device='cuda:0')\n",
      "Bigstep:  16\n",
      "Loss: 0.40648171305656433 -0.051890093833208084\n",
      "Loss: 0.38219282031059265 -0.22492340207099915\n",
      "Loss: 0.40563035011291504 -0.3948451578617096\n",
      "Loss: 0.3743908107280731 -0.5801813006401062\n",
      "Loss: 0.4570017457008362 -0.35620400309562683\n",
      "Loss: 0.3628709316253662 -0.2217162549495697\n",
      "Loss: 0.4006178379058838 -0.3529835343360901\n",
      "Policy Reward: tensor(1.0819, device='cuda:0')\n",
      "Trajectory:  ['0.02', '0.48', '0.36', '0.20', '0.14', '0.14', '0.23', '0.29', '0.27', '0.23', '0.20', '0.27', '0.29', '0.24', '0.29', '0.39', '0.44', '0.45', '0.38']\n",
      "Last Action:  tensor([0.3815, 0.6310, 0.8634, 0.8022, 0.7646, 0.4855, 0.5574, 0.3532, 0.8415,\n",
      "        0.8513], device='cuda:0')\n",
      "Loss: 0.41265249252319336 -0.7228245735168457\n",
      "Loss: 0.37589550018310547 -0.7501764893531799\n",
      "Loss: 0.4276733100414276 -0.6234586834907532\n",
      "Loss: 0.41398885846138 -0.8446535468101501\n",
      "Loss: 0.4201622009277344 -0.6246950626373291\n",
      "Loss: 0.44793838262557983 -0.6454209685325623\n",
      "Loss: 0.4456523656845093 -0.5759193301200867\n",
      "Policy Reward: tensor(1.1331, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.83', '0.64', '0.42', '0.27', '0.24', '0.30', '0.26', '0.18', '0.26', '0.37', '0.44', '0.51', '0.55', '0.50', '0.42', '0.48', '0.64', '0.67']\n",
      "Last Action:  tensor([0.6660, 0.8272, 0.6973, 0.7755, 0.5552, 0.6750, 0.8251, 0.7798, 0.8408,\n",
      "        0.7088], device='cuda:0')\n",
      "Loss: 0.41002631187438965 -0.6733471155166626\n",
      "Loss: 0.3455635905265808 -0.2971827983856201\n",
      "Loss: 0.4016716778278351 -0.6034224033355713\n",
      "Loss: 0.3774663805961609 -0.810703456401825\n",
      "Loss: 0.40882056951522827 -0.689124345779419\n",
      "Loss: 0.3812315762042999 -0.5553249716758728\n",
      "Loss: 0.3831577003002167 -0.8060259222984314\n",
      "Policy Reward: tensor(1.1206, device='cuda:0')\n",
      "Trajectory:  ['0.28', '0.99', '0.58', '0.29', '0.11', '0.07', '0.01', '0.01', '0.13', '0.48', '0.51', '0.30', '0.26', '0.41', '0.49', '0.41', '0.45', '0.60', '0.67']\n",
      "Last Action:  tensor([0.6681, 0.7546, 0.6154, 0.7633, 0.7824, 0.6302, 0.7684, 0.8236, 0.5867,\n",
      "        0.8142], device='cuda:0')\n",
      "Loss: 0.40639328956604004 -0.6189451217651367\n",
      "Loss: 0.5186325907707214 -1.1217994689941406\n",
      "Loss: 0.43581873178482056 -0.4587264955043793\n",
      "Loss: 0.392648845911026 -0.8410345911979675\n",
      "Loss: 0.38838595151901245 -0.8765023350715637\n",
      "Loss: 0.396225243806839 -0.5989631414413452\n",
      "Loss: 0.36608079075813293 -0.5090769529342651\n",
      "Policy Reward: tensor(1.0904, device='cuda:0')\n",
      "Trajectory:  ['0.06', '0.79', '0.62', '0.37', '0.20', '0.20', '0.25', '0.32', '0.35', '0.30', '0.33', '0.39', '0.43', '0.40', '0.42', '0.49', '0.63', '0.67', '0.65']\n",
      "Last Action:  tensor([0.6479, 0.6886, 0.8100, 0.6988, 0.6888, 0.8652, 0.6600, 0.8702, 0.7956,\n",
      "        0.6367], device='cuda:0')\n",
      "Loss: 0.340007483959198 -0.45556914806365967\n",
      "Loss: 0.3590810000896454 -0.5456410050392151\n",
      "Loss: 0.4134620726108551 -0.8783295154571533\n",
      "Loss: 0.5014044046401978 -0.8772352933883667\n",
      "Loss: 0.34345245361328125 -0.6193536520004272\n",
      "Loss: 0.4832632839679718 -0.4813109338283539\n",
      "Loss: 0.424426794052124 -0.6111452579498291\n",
      "Policy Reward: tensor(1.2103, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.90', '0.67', '0.44', '0.27', '0.16', '0.07', '0.17', '0.31', '0.51', '0.39', '0.42', '0.45', '0.49', '0.58', '0.66', '0.74', '0.83', '0.89']\n",
      "Last Action:  tensor([0.8898, 0.8700, 0.7613, 0.8550, 0.6260, 0.9487, 0.7310, 0.5649, 0.5293,\n",
      "        0.8165], device='cuda:0')\n",
      "Loss: 0.41408342123031616 -0.383384644985199\n",
      "Loss: 0.42704424262046814 -0.5606318116188049\n",
      "Loss: 0.4378681480884552 -0.5957528948783875\n",
      "Loss: 0.3590487837791443 -0.3153921067714691\n",
      "Loss: 0.3839351236820221 -0.31803277134895325\n",
      "Loss: 0.40200135111808777 -0.6532837748527527\n",
      "Loss: 0.33889761567115784 -0.5226249694824219\n",
      "Policy Reward: tensor(1.2599, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.90', '0.73', '0.50', '0.37', '0.29', '0.28', '0.21', '0.26', '0.39', '0.39', '0.41', '0.51', '0.47', '0.37', '0.56', '0.67', '0.80', '0.88']\n",
      "Last Action:  tensor([0.8836, 0.8584, 0.8847, 0.8769, 0.7358, 0.0612, 0.8339, 0.8408, 0.6578,\n",
      "        0.8750], device='cuda:0')\n",
      "Loss: 0.38700640201568604 -0.32395631074905396\n",
      "Loss: 0.42995959520339966 -0.8129074573516846\n",
      "Loss: 0.366705983877182 -0.7102830410003662\n",
      "Loss: 0.44480273127555847 -0.9602271318435669\n",
      "Loss: 0.4355500638484955 -0.6246568560600281\n",
      "Loss: 0.39657139778137207 -0.9526896476745605\n",
      "Loss: 0.39420634508132935 -0.48463404178619385\n",
      "Policy Reward: tensor(1.1572, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.72', '0.54', '0.33', '0.21', '0.22', '0.28', '0.29', '0.38', '0.42', '0.39', '0.43', '0.51', '0.55', '0.58', '0.66', '0.72', '0.74', '0.79']\n",
      "Last Action:  tensor([0.7899, 0.8616, 0.8465, 0.8606, 0.6633, 0.7562, 0.7973, 0.5806, 0.6956,\n",
      "        0.7672], device='cuda:0')\n",
      "Loss: 0.3654426038265228 -0.46101346611976624\n",
      "Loss: 0.3729294538497925 -0.5973013639450073\n",
      "Loss: 0.38653066754341125 -0.730339765548706\n",
      "Loss: 0.490439772605896 -1.1712943315505981\n",
      "Loss: 0.3957621157169342 -0.7732976675033569\n",
      "Loss: 0.35175278782844543 -0.4340067505836487\n",
      "Loss: 0.4033965468406677 -0.6212188005447388\n",
      "Policy Reward: tensor(1.2480, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.91', '0.71', '0.52', '0.39', '0.27', '0.21', '0.17', '0.24', '0.34', '0.36', '0.36', '0.42', '0.50', '0.52', '0.57', '0.68', '0.80', '0.87']\n",
      "Last Action:  tensor([0.8653, 0.5693, 0.9002, 0.5639, 0.7592, 0.9060, 0.8753, 0.7606, 0.6096,\n",
      "        0.7420], device='cuda:0')\n",
      "Bigstep:  17\n",
      "Loss: 0.3868946135044098 -0.06396694481372833\n",
      "Loss: 0.4679982662200928 -0.5721116662025452\n",
      "Loss: 0.4638407826423645 -0.49403834342956543\n",
      "Loss: 0.37750911712646484 -0.527661919593811\n",
      "Loss: 0.397111177444458 -0.2982361614704132\n",
      "Loss: 0.44290193915367126 -0.7435615658760071\n",
      "Loss: 0.4581342935562134 -0.5846507549285889\n",
      "Policy Reward: tensor(1.1175, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.82', '0.54', '0.35', '0.20', '0.10', '0.07', '0.09', '0.18', '0.40', '0.56', '0.61', '0.53', '0.49', '0.58', '0.68', '0.71', '0.75', '0.83']\n",
      "Last Action:  tensor([0.8305, 0.8657, 0.8736, 0.9263, 0.7134, 0.7864, 0.8568, 0.7450, 0.8525,\n",
      "        0.8264], device='cuda:0')\n",
      "Loss: 0.3513718247413635 -0.5474832057952881\n",
      "Loss: 0.3889819383621216 -0.27287012338638306\n",
      "Loss: 0.5227018594741821 -0.8026255369186401\n",
      "Loss: 0.4149412214756012 -0.5936395525932312\n",
      "Loss: 0.43161511421203613 -0.7053862810134888\n",
      "Loss: 0.3910675644874573 -0.7065092325210571\n",
      "Loss: 0.38618749380111694 -0.6312239170074463\n",
      "Policy Reward: tensor(1.2110, device='cuda:0')\n",
      "Trajectory:  ['0.01', '0.88', '0.72', '0.51', '0.32', '0.14', '0.07', '0.05', '0.11', '0.34', '0.53', '0.38', '0.37', '0.37', '0.40', '0.39', '0.40', '0.52', '0.73']\n",
      "Last Action:  tensor([0.7319, 0.7836, 0.8138, 0.8265, 0.8102, 0.6446, 0.8559, 0.7902, 0.7148,\n",
      "        0.7119], device='cuda:0')\n",
      "Loss: 0.45192429423332214 -0.5165913701057434\n",
      "Loss: 0.41794270277023315 -0.7508879899978638\n",
      "Loss: 0.4259665012359619 -0.7102699279785156\n",
      "Loss: 0.40837574005126953 -0.9502328038215637\n",
      "Loss: 0.38124167919158936 -0.5758116245269775\n",
      "Loss: 0.5104863047599792 -0.8062532544136047\n",
      "Loss: 0.49988728761672974 -0.8328387141227722\n",
      "Policy Reward: tensor(1.1033, device='cuda:0')\n",
      "Trajectory:  ['0.32', '0.99', '0.39', '0.09', '0.05', '0.01', '0.01', '0.02', '0.09', '0.48', '0.58', '0.62', '0.58', '0.54', '0.52', '0.53', '0.66', '0.79', '0.84']\n",
      "Last Action:  tensor([0.8403, 0.8738, 0.8009, 0.8257, 0.9038, 0.8883, 0.9154, 0.9316, 0.8451,\n",
      "        0.8370], device='cuda:0')\n",
      "Loss: 0.45308250188827515 -0.5184865593910217\n",
      "Loss: 0.3917175233364105 -0.6827645897865295\n",
      "Loss: 0.4554947316646576 -1.107375979423523\n",
      "Loss: 0.3738049864768982 -0.661361575126648\n",
      "Loss: 0.37656259536743164 -0.5660690069198608\n",
      "Loss: 0.41692471504211426 -0.8197932243347168\n",
      "Loss: 0.4052225351333618 -0.29982972145080566\n",
      "Policy Reward: tensor(1.2416, device='cuda:0')\n",
      "Trajectory:  ['0.15', '0.48', '0.38', '0.32', '0.14', '0.06', '0.05', '0.08', '0.14', '0.37', '0.54', '0.64', '0.71', '0.73', '0.65', '0.53', '0.46', '0.52', '0.63']\n",
      "Last Action:  tensor([0.6293, 0.8181, 0.7394, 0.8119, 0.8475, 0.8192, 0.7811, 0.8143, 0.6730,\n",
      "        0.8917], device='cuda:0')\n",
      "Loss: 0.41205957531929016 -0.6962730288505554\n",
      "Loss: 0.3752864599227905 -0.5068010091781616\n",
      "Loss: 0.3884124159812927 -0.8291101455688477\n",
      "Loss: 0.3939886689186096 -0.5945508480072021\n",
      "Loss: 0.4873695969581604 -0.8523783683776855\n",
      "Loss: 0.3428739607334137 -0.36069566011428833\n",
      "Loss: 0.33200374245643616 -0.3516404330730438\n",
      "Policy Reward: tensor(1.2562, device='cuda:0')\n",
      "Trajectory:  ['0.03', '0.98', '0.77', '0.41', '0.22', '0.05', '0.02', '0.05', '0.25', '0.56', '0.52', '0.39', '0.44', '0.57', '0.66', '0.73', '0.82', '0.87', '0.91']\n",
      "Last Action:  tensor([0.9070, 0.7559, 0.6497, 0.7141, 0.7477, 0.7463, 0.7868, 0.8023, 0.8764,\n",
      "        0.7912], device='cuda:0')\n",
      "Loss: 0.416559636592865 -0.9344809055328369\n",
      "Loss: 0.3946034014225006 -0.4765598177909851\n",
      "Loss: 0.4143543541431427 -0.6630479097366333\n",
      "Loss: 0.4052439332008362 -0.6126701831817627\n",
      "Loss: 0.4366261065006256 -0.7051248550415039\n",
      "Loss: 0.49957275390625 -0.9356205463409424\n",
      "Loss: 0.4158049523830414 -0.6259800791740417\n",
      "Policy Reward: tensor(1.2135, device='cuda:0')\n",
      "Trajectory:  ['0.01', '0.94', '0.69', '0.53', '0.37', '0.19', '0.04', '0.03', '0.19', '0.47', '0.57', '0.45', '0.44', '0.60', '0.72', '0.73', '0.77', '0.83', '0.89']\n",
      "Last Action:  tensor([0.8888, 0.8505, 0.8041, 0.8970, 0.8529, 0.6959, 0.6395, 0.8169, 0.7581,\n",
      "        0.6049], device='cuda:0')\n",
      "Loss: 0.3751393258571625 -0.48320311307907104\n",
      "Loss: 0.3855202794075012 -0.6044974327087402\n",
      "Loss: 0.4975430369377136 -0.8920294642448425\n",
      "Loss: 0.4866141974925995 -0.8621963262557983\n",
      "Loss: 0.412443608045578 -0.9729127883911133\n",
      "Loss: 0.4110487699508667 -0.6200851202011108\n",
      "Loss: 0.39726054668426514 -0.8131934404373169\n",
      "Policy Reward: tensor(1.0968, device='cuda:0')\n",
      "Trajectory:  ['0.43', '1.00', '0.44', '0.10', '0.04', '0.00', '0.00', '0.00', '0.02', '0.25', '0.46', '0.47', '0.36', '0.39', '0.50', '0.53', '0.61', '0.76', '0.84']\n",
      "Last Action:  tensor([0.8366, 0.7770, 0.8071, 0.8870, 0.7733, 0.6587, 0.7339, 0.7604, 0.7974,\n",
      "        0.7726], device='cuda:0')\n",
      "Loss: 0.34820765256881714 -0.4497973620891571\n",
      "Loss: 0.46497538685798645 -0.6921130418777466\n",
      "Loss: 0.44848668575286865 -0.6528065204620361\n",
      "Loss: 0.4099431037902832 -0.6254830360412598\n",
      "Loss: 0.5324883460998535 -1.1704256534576416\n",
      "Loss: 0.4957946538925171 -0.6567791104316711\n",
      "Loss: 0.4518929421901703 -0.8365306258201599\n",
      "Policy Reward: tensor(1.2492, device='cuda:0')\n",
      "Trajectory:  ['0.04', '0.96', '0.83', '0.62', '0.33', '0.13', '0.04', '0.01', '0.10', '0.42', '0.56', '0.47', '0.45', '0.54', '0.60', '0.59', '0.62', '0.71', '0.81']\n",
      "Last Action:  tensor([0.8119, 0.7072, 0.7944, 0.7833, 0.7973, 0.7283, 0.8416, 0.8329, 0.8739,\n",
      "        0.8838], device='cuda:0')\n",
      "Bigstep:  18\n",
      "Loss: 0.4232857823371887 -0.4601783752441406\n",
      "Loss: 0.48115307092666626 -0.3497949242591858\n",
      "Loss: 0.45370569825172424 -0.9503419399261475\n",
      "Loss: 0.45612287521362305 -0.6801851987838745\n",
      "Loss: 0.44149237871170044 -0.5853635668754578\n",
      "Loss: 0.5278836488723755 -0.972160816192627\n",
      "Loss: 0.4198445975780487 -0.8045180439949036\n",
      "Policy Reward: tensor(1.1463, device='cuda:0')\n",
      "Trajectory:  ['0.51', '1.00', '0.84', '0.30', '0.07', '0.01', '0.00', '0.00', '0.01', '0.15', '0.38', '0.37', '0.28', '0.21', '0.22', '0.33', '0.41', '0.57', '0.78']\n",
      "Last Action:  tensor([0.7820, 0.8592, 0.8184, 0.7001, 0.4841, 0.8757, 0.7184, 0.3155, 0.8222,\n",
      "        0.7498], device='cuda:0')\n",
      "Loss: 0.35111477971076965 -0.6038418412208557\n",
      "Loss: 0.42898809909820557 -0.5763819217681885\n",
      "Loss: 0.44658201932907104 -0.9711300730705261\n",
      "Loss: 0.45478320121765137 -0.8703022599220276\n",
      "Loss: 0.45349574089050293 -1.0323693752288818\n",
      "Loss: 0.48381534218788147 -0.9679239988327026\n",
      "Loss: 0.43713417649269104 -0.8206702470779419\n",
      "Policy Reward: tensor(1.2268, device='cuda:0')\n",
      "Trajectory:  ['0.51', '1.00', '0.76', '0.32', '0.04', '0.00', '0.00', '0.00', '0.06', '0.37', '0.60', '0.34', '0.19', '0.24', '0.57', '0.71', '0.50', '0.51', '0.69']\n",
      "Last Action:  tensor([0.6903, 0.7592, 0.8077, 0.5183, 0.8267, 0.6407, 0.4874, 0.7314, 0.4824,\n",
      "        0.7870], device='cuda:0')\n",
      "Loss: 0.45631104707717896 -0.9895954132080078\n",
      "Loss: 0.44000253081321716 -0.7458068132400513\n",
      "Loss: 0.4510197937488556 -0.6240302920341492\n",
      "Loss: 0.48690441250801086 -1.0086805820465088\n",
      "Loss: 0.46596962213516235 -1.2410343885421753\n",
      "Loss: 0.4308921694755554 -0.5732781887054443\n",
      "Loss: 0.512083888053894 -1.0201151371002197\n",
      "Policy Reward: tensor(1.1780, device='cuda:0')\n",
      "Trajectory:  ['0.45', '0.99', '0.71', '0.28', '0.08', '0.02', '0.00', '0.00', '0.01', '0.14', '0.44', '0.44', '0.33', '0.23', '0.17', '0.18', '0.28', '0.41', '0.66']\n",
      "Last Action:  tensor([0.6624, 0.8211, 0.7773, 0.8915, 0.7740, 0.8668, 0.6213, 0.3598, 0.7195,\n",
      "        0.8548], device='cuda:0')\n",
      "Loss: 0.5395334959030151 -1.4037914276123047\n",
      "Loss: 0.442518949508667 -0.9881590008735657\n",
      "Loss: 0.3907996118068695 -0.7674369215965271\n",
      "Loss: 0.40016937255859375 -0.4746360778808594\n",
      "Loss: 0.4194551706314087 -0.8131765127182007\n",
      "Loss: 0.33108627796173096 -0.3657611906528473\n",
      "Loss: 0.5190222263336182 -1.1192396879196167\n",
      "Policy Reward: tensor(1.2129, device='cuda:0')\n",
      "Trajectory:  ['0.51', '0.96', '0.68', '0.21', '0.06', '0.00', '0.00', '0.00', '0.03', '0.23', '0.39', '0.44', '0.41', '0.36', '0.41', '0.58', '0.71', '0.78', '0.80']\n",
      "Last Action:  tensor([0.7959, 0.5830, 0.5300, 0.8224, 0.8463, 0.5195, 0.6421, 0.8076, 0.8658,\n",
      "        0.8350], device='cuda:0')\n",
      "Loss: 0.4206714630126953 -0.8186233639717102\n",
      "Loss: 0.5249605774879456 -0.899427056312561\n",
      "Loss: 0.4130959212779999 -0.8033159375190735\n",
      "Loss: 0.44675636291503906 -1.0066877603530884\n",
      "Loss: 0.4777010679244995 -1.2724545001983643\n",
      "Loss: 0.5605049729347229 -1.0054967403411865\n",
      "Loss: 0.46324342489242554 -1.2479546070098877\n",
      "Policy Reward: tensor(1.1368, device='cuda:0')\n",
      "Trajectory:  ['0.13', '0.52', '0.29', '0.17', '0.01', '0.00', '0.00', '0.01', '0.11', '0.41', '0.47', '0.30', '0.20', '0.17', '0.42', '0.56', '0.54', '0.60', '0.70']\n",
      "Last Action:  tensor([0.6974, 0.8301, 0.7777, 0.7420, 0.7274, 0.9074, 0.8947, 0.0489, 0.9233,\n",
      "        0.5674], device='cuda:0')\n",
      "Loss: 0.5085680484771729 -1.0953596830368042\n",
      "Loss: 0.45320895314216614 -0.7442065477371216\n",
      "Loss: 0.40304312109947205 -1.0000700950622559\n",
      "Loss: 0.44544127583503723 -1.056093692779541\n",
      "Loss: 0.42751461267471313 -0.9458063244819641\n",
      "Loss: 0.47173207998275757 -1.1706633567810059\n",
      "Loss: 0.3829033076763153 -0.7446306943893433\n",
      "Policy Reward: tensor(1.0664, device='cuda:0')\n",
      "Trajectory:  ['0.44', '1.00', '0.77', '0.16', '0.07', '0.00', '0.00', '0.00', '0.02', '0.27', '0.51', '0.42', '0.32', '0.31', '0.41', '0.63', '0.82', '0.86', '0.86']\n",
      "Last Action:  tensor([0.8568, 0.8320, 0.5789, 0.7766, 0.7750, 0.6616, 0.7893, 0.8064, 0.8210,\n",
      "        0.8237], device='cuda:0')\n",
      "Loss: 0.41965872049331665 -0.6871269345283508\n",
      "Loss: 0.49590086936950684 -1.1699832677841187\n",
      "Loss: 0.3839331865310669 -0.5762780904769897\n",
      "Loss: 0.5303189158439636 -0.7750014066696167\n",
      "Loss: 0.40423253178596497 -0.7554495334625244\n",
      "Loss: 0.42665019631385803 -0.8544021844863892\n",
      "Loss: 0.4616619944572449 -0.5089564323425293\n",
      "Policy Reward: tensor(1.2111, device='cuda:0')\n",
      "Trajectory:  ['0.47', '1.00', '0.67', '0.11', '0.03', '0.03', '0.03', '0.04', '0.03', '0.04', '0.11', '0.26', '0.43', '0.66', '0.70', '0.54', '0.48', '0.63', '0.75']\n",
      "Last Action:  tensor([0.7495, 0.8752, 0.7572, 0.8585, 0.9116, 0.7070, 0.8768, 0.8206, 0.7926,\n",
      "        0.8622], device='cuda:0')\n",
      "Loss: 0.5248785018920898 -1.0504883527755737\n",
      "Loss: 0.4237006604671478 -0.6265937089920044\n",
      "Loss: 0.3807452321052551 -0.6764110326766968\n",
      "Loss: 0.4470238983631134 -0.7704069018363953\n",
      "Loss: 0.399759978055954 -0.8277763724327087\n",
      "Loss: 0.35593801736831665 -0.5079535245895386\n",
      "Loss: 0.40216028690338135 -0.5447331666946411\n",
      "Policy Reward: tensor(1.1916, device='cuda:0')\n",
      "Trajectory:  ['0.60', '1.00', '0.95', '0.33', '0.14', '0.01', '0.00', '0.00', '0.02', '0.24', '0.43', '0.43', '0.30', '0.29', '0.45', '0.67', '0.76', '0.77', '0.77']\n",
      "Last Action:  tensor([0.7739, 0.5377, 0.5281, 0.8618, 0.5327, 0.6176, 0.8426, 0.8044, 0.5589,\n",
      "        0.7809], device='cuda:0')\n",
      "Bigstep:  19\n",
      "Loss: 0.5343433022499084 -0.8243168592453003\n",
      "Loss: 0.4385277032852173 -0.35040202736854553\n",
      "Loss: 0.37031838297843933 -0.051895081996917725\n",
      "Loss: 0.4631519317626953 -0.6596758961677551\n",
      "Loss: 0.4586789011955261 -0.38577908277511597\n",
      "Loss: 0.39676231145858765 -0.48902493715286255\n",
      "Loss: 0.5015167593955994 -0.6204318404197693\n",
      "Policy Reward: tensor(1.1476, device='cuda:0')\n",
      "Trajectory:  ['0.42', '1.00', '0.80', '0.13', '0.00', '0.00', '0.00', '0.00', '0.07', '0.33', '0.53', '0.52', '0.33', '0.29', '0.48', '0.78', '0.69', '0.62', '0.65']\n",
      "Last Action:  tensor([0.6491, 0.8438, 0.8411, 0.9182, 0.8805, 0.8561, 0.7549, 0.6817, 0.7312,\n",
      "        0.8917], device='cuda:0')\n",
      "Loss: 0.3581329584121704 -0.24457970261573792\n",
      "Loss: 0.43888744711875916 -0.5853495597839355\n",
      "Loss: 0.4692445993423462 -0.45569300651550293\n",
      "Loss: 0.46341702342033386 -0.6528899073600769\n",
      "Loss: 0.4021267890930176 -0.6228946447372437\n",
      "Loss: 0.3739030659198761 -0.1944931596517563\n",
      "Loss: 0.4061456024646759 -0.20112761855125427\n",
      "Policy Reward: tensor(1.1373, device='cuda:0')\n",
      "Trajectory:  ['0.04', '0.17', '0.08', '0.01', '0.00', '0.00', '0.00', '0.02', '0.21', '0.47', '0.41', '0.37', '0.23', '0.07', '0.13', '0.38', '0.71', '0.67', '0.61']\n",
      "Last Action:  tensor([0.6051, 0.8530, 0.8851, 0.8753, 0.8551, 0.8806, 0.8100, 0.8890, 0.7310,\n",
      "        0.8955], device='cuda:0')\n",
      "Loss: 0.45692065358161926 -0.5907605290412903\n",
      "Loss: 0.40427398681640625 -0.40049827098846436\n",
      "Loss: 0.3738054633140564 -0.13248026371002197\n",
      "Loss: 0.4437240660190582 -0.6158350706100464\n",
      "Loss: 0.352591872215271 -0.2723667025566101\n",
      "Loss: 0.46960487961769104 -0.9620742201805115\n",
      "Loss: 0.3497951030731201 -0.22979481518268585\n",
      "Policy Reward: tensor(1.1132, device='cuda:0')\n",
      "Trajectory:  ['0.01', '0.96', '0.80', '0.50', '0.20', '0.02', '0.01', '0.02', '0.24', '0.50', '0.63', '0.63', '0.52', '0.40', '0.53', '0.82', '0.91', '0.88', '0.83']\n",
      "Last Action:  tensor([0.8294, 0.8529, 0.8780, 0.7685, 0.8894, 0.7449, 0.8628, 0.1111, 0.8748,\n",
      "        0.8678], device='cuda:0')\n",
      "Loss: 0.454121857881546 -0.813727855682373\n",
      "Loss: 0.3408072292804718 -0.33307966589927673\n",
      "Loss: 0.41557106375694275 -0.3929673731327057\n",
      "Loss: 0.4312516748905182 -0.38204193115234375\n",
      "Loss: 0.4189746677875519 -0.5082887411117554\n",
      "Loss: 0.4302172362804413 -0.748670756816864\n",
      "Loss: 0.4156002104282379 -0.6810726523399353\n",
      "Policy Reward: tensor(1.2086, device='cuda:0')\n",
      "Trajectory:  ['0.60', '1.00', '0.86', '0.26', '0.04', '0.00', '0.00', '0.00', '0.04', '0.33', '0.52', '0.56', '0.44', '0.31', '0.41', '0.75', '0.86', '0.79', '0.69']\n",
      "Last Action:  tensor([0.6879, 0.8656, 0.8757, 0.8220, 0.6299, 0.8385, 0.8489, 0.8805, 0.8162,\n",
      "        0.8724], device='cuda:0')\n",
      "Loss: 0.43516841530799866 -0.4217999279499054\n",
      "Loss: 0.3554844260215759 -0.058868587017059326\n",
      "Loss: 0.41445764899253845 -0.5227259993553162\n",
      "Loss: 0.39351680874824524 -0.5552987456321716\n",
      "Loss: 0.4612131714820862 -0.721810519695282\n",
      "Loss: 0.4748231768608093 -0.5364629030227661\n",
      "Loss: 0.44850990176200867 -0.887847363948822\n",
      "Policy Reward: tensor(1.1814, device='cuda:0')\n",
      "Trajectory:  ['0.50', '1.00', '0.76', '0.20', '0.02', '0.00', '0.00', '0.01', '0.03', '0.08', '0.37', '0.65', '0.79', '0.71', '0.67', '0.64', '0.64', '0.68', '0.75']\n",
      "Last Action:  tensor([0.7465, 0.8613, 0.8274, 0.7845, 0.7724, 0.8492, 0.0140, 0.6963, 0.8635,\n",
      "        0.4868], device='cuda:0')\n",
      "Loss: 0.44349205493927 -0.46451181173324585\n",
      "Loss: 0.5056126117706299 -0.8900052905082703\n",
      "Loss: 0.48112496733665466 -0.996984601020813\n",
      "Loss: 0.43949803709983826 -0.4325358271598816\n",
      "Loss: 0.4276661276817322 -0.5064449310302734\n",
      "Loss: 0.4562573730945587 -0.5257890224456787\n",
      "Loss: 0.43974465131759644 -0.5763664841651917\n",
      "Policy Reward: tensor(1.1406, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.77', '0.53', '0.32', '0.15', '0.01', '0.00', '0.00', '0.10', '0.55', '0.49', '0.37', '0.34', '0.28', '0.42', '0.77', '0.90', '0.89', '0.83']\n",
      "Last Action:  tensor([0.8301, 0.8846, 0.8578, 0.8638, 0.8475, 0.5911, 0.5868, 0.8872, 0.6735,\n",
      "        0.8817], device='cuda:0')\n",
      "Loss: 0.42708292603492737 -0.5377106070518494\n",
      "Loss: 0.40683266520500183 -0.5981528162956238\n",
      "Loss: 0.4620158076286316 -0.8902521133422852\n",
      "Loss: 0.3516278862953186 -0.5246539115905762\n",
      "Loss: 0.4712688624858856 -0.5091558694839478\n",
      "Loss: 0.3901403248310089 -0.6412699818611145\n",
      "Loss: 0.3986727297306061 -0.5186275243759155\n",
      "Policy Reward: tensor(1.2353, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.86', '0.52', '0.12', '0.02', '0.02', '0.03', '0.08', '0.15', '0.35', '0.72', '0.85', '0.60', '0.35', '0.28', '0.45', '0.83', '0.83', '0.57']\n",
      "Last Action:  tensor([0.5699, 0.8186, 0.8872, 0.7156, 0.9010, 0.4361, 0.8942, 0.7357, 0.8881,\n",
      "        0.8902], device='cuda:0')\n",
      "Loss: 0.4160600006580353 -0.6150931715965271\n",
      "Loss: 0.41870149970054626 -0.6926310062408447\n",
      "Loss: 0.47209152579307556 -1.0919759273529053\n",
      "Loss: 0.3833983242511749 -0.3048902750015259\n",
      "Loss: 0.453002005815506 -0.46138787269592285\n",
      "Loss: 0.5157540440559387 -0.8769398927688599\n",
      "Loss: 0.42591848969459534 -0.752531111240387\n",
      "Policy Reward: tensor(1.0752, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.95', '0.69', '0.43', '0.28', '0.05', '0.00', '0.01', '0.22', '0.58', '0.66', '0.45', '0.27', '0.29', '0.49', '0.81', '0.92', '0.90', '0.86']\n",
      "Last Action:  tensor([0.8621, 0.8692, 0.7051, 0.8441, 0.8553, 0.8697, 0.7883, 0.8846, 0.5411,\n",
      "        0.8714], device='cuda:0')\n",
      "Bigstep:  20\n",
      "Loss: 0.44481611251831055 -0.12025376409292221\n",
      "Loss: 0.4302842319011688 0.0034240013919770718\n",
      "Loss: 0.4834994077682495 -0.5436559319496155\n",
      "Loss: 0.4587284326553345 -0.6769094467163086\n",
      "Loss: 0.4309428930282593 -0.5056273937225342\n",
      "Loss: 0.3718027174472809 -0.38199231028556824\n",
      "Loss: 0.4139789938926697 -0.12945516407489777\n",
      "Policy Reward: tensor(1.0988, device='cuda:0')\n",
      "Trajectory:  ['0.08', '0.97', '0.81', '0.22', '0.01', '0.00', '0.00', '0.00', '0.16', '0.48', '0.70', '0.78', '0.57', '0.31', '0.36', '0.55', '0.85', '0.97', '0.91']\n",
      "Last Action:  tensor([0.9140, 0.6160, 0.9450, 0.7779, 0.7144, 0.9521, 0.9443, 0.8279, 0.9162,\n",
      "        0.9270], device='cuda:0')\n",
      "Loss: 0.4933212995529175 -0.916538417339325\n",
      "Loss: 0.4142836928367615 -0.5440682172775269\n",
      "Loss: 0.4118601977825165 -0.42368242144584656\n",
      "Loss: 0.4469360113143921 -0.5857974290847778\n",
      "Loss: 0.45609787106513977 -0.6134559512138367\n",
      "Loss: 0.4518267810344696 -0.28592926263809204\n",
      "Loss: 0.45256975293159485 -0.7239066362380981\n",
      "Policy Reward: tensor(1.1983, device='cuda:0')\n",
      "Trajectory:  ['0.48', '1.00', '0.90', '0.19', '0.01', '0.00', '0.00', '0.01', '0.22', '0.59', '0.59', '0.45', '0.22', '0.29', '0.64', '0.87', '0.92', '0.93', '0.93']\n",
      "Last Action:  tensor([0.9282, 0.9392, 0.9271, 0.9099, 0.9210, 0.9429, 0.8308, 0.9387, 0.8960,\n",
      "        0.9540], device='cuda:0')\n",
      "Loss: 0.4680916368961334 -0.6623793840408325\n",
      "Loss: 0.4382660686969757 -0.8673453330993652\n",
      "Loss: 0.38456791639328003 -0.4499265253543854\n",
      "Loss: 0.4063204228878021 -0.5836514234542847\n",
      "Loss: 0.4854922294616699 -0.5752760171890259\n",
      "Loss: 0.4172072410583496 -0.7768210172653198\n",
      "Loss: 0.47775891423225403 -0.8370888829231262\n",
      "Policy Reward: tensor(1.2479, device='cuda:0')\n",
      "Trajectory:  ['0.51', '1.00', '0.93', '0.18', '0.01', '0.00', '0.00', '0.00', '0.02', '0.28', '0.51', '0.55', '0.37', '0.21', '0.22', '0.54', '0.90', '0.96', '0.91']\n",
      "Last Action:  tensor([0.9099, 0.9930, 0.9876, 0.8984, 0.9740, 0.9676, 0.9316, 0.9478, 0.9908,\n",
      "        0.9588], device='cuda:0')\n",
      "Loss: 0.44467341899871826 -0.8022519946098328\n",
      "Loss: 0.49884435534477234 -0.9974711537361145\n",
      "Loss: 0.5331181287765503 -1.2478305101394653\n",
      "Loss: 0.4372568428516388 -0.6997345685958862\n",
      "Loss: 0.3765105903148651 -0.5274091958999634\n",
      "Loss: 0.44676125049591064 -0.6271086931228638\n",
      "Loss: 0.40080180764198303 -0.4562247395515442\n",
      "Policy Reward: tensor(1.1680, device='cuda:0')\n",
      "Trajectory:  ['0.49', '1.00', '0.93', '0.18', '0.01', '0.00', '0.00', '0.00', '0.07', '0.41', '0.49', '0.45', '0.30', '0.34', '0.64', '0.94', '0.99', '0.99', '0.98']\n",
      "Last Action:  tensor([0.9786, 0.9904, 0.9892, 0.9922, 0.9429, 0.9178, 0.9357, 0.9845, 0.9400,\n",
      "        0.9786], device='cuda:0')\n",
      "Loss: 0.4408583343029022 -0.8544845581054688\n",
      "Loss: 0.346848726272583 -0.19543065130710602\n",
      "Loss: 0.44373801350593567 -0.9455140233039856\n",
      "Loss: 0.4586177170276642 -0.4781007766723633\n",
      "Loss: 0.5284695625305176 -1.1623315811157227\n",
      "Loss: 0.44636276364326477 -1.002800703048706\n",
      "Loss: 0.4198262095451355 -0.6412142515182495\n",
      "Policy Reward: tensor(1.1312, device='cuda:0')\n",
      "Trajectory:  ['0.51', '1.00', '0.87', '0.31', '0.03', '0.01', '0.00', '0.01', '0.11', '0.60', '0.82', '0.83', '0.64', '0.50', '0.53', '0.79', '0.97', '0.99', '0.99']\n",
      "Last Action:  tensor([0.9931, 0.9723, 0.9862, 0.9916, 0.9855, 0.7790, 0.9564, 0.9877, 0.9519,\n",
      "        0.9444], device='cuda:0')\n",
      "Loss: 0.5090910792350769 -0.855236291885376\n",
      "Loss: 0.43872642517089844 -0.9345319867134094\n",
      "Loss: 0.4042636454105377 -0.8807901740074158\n",
      "Loss: 0.4013713598251343 -0.543228030204773\n",
      "Loss: 0.4035017490386963 -0.7903800010681152\n",
      "Loss: 0.4266759753227234 -0.9230336546897888\n",
      "Loss: 0.337118923664093 -0.5263497829437256\n",
      "Policy Reward: tensor(1.0702, device='cuda:0')\n",
      "Trajectory:  ['0.07', '1.00', '0.73', '0.25', '0.00', '0.00', '0.00', '0.00', '0.11', '0.41', '0.64', '0.74', '0.65', '0.35', '0.23', '0.49', '0.99', '1.00', '0.99']\n",
      "Last Action:  tensor([0.9863, 0.9783, 0.8489, 0.9655, 0.9973, 0.9864, 0.9041, 0.8397, 0.9583,\n",
      "        0.9844], device='cuda:0')\n",
      "Loss: 0.418447345495224 -0.9281811714172363\n",
      "Loss: 0.38150063157081604 -0.4440954029560089\n",
      "Loss: 0.4045092761516571 -0.4709615111351013\n",
      "Loss: 0.3856503367424011 -0.43408361077308655\n",
      "Loss: 0.4190284311771393 -0.5730450749397278\n",
      "Loss: 0.4139081537723541 -0.5243083238601685\n",
      "Loss: 0.39103880524635315 -0.34886038303375244\n",
      "Policy Reward: tensor(1.1125, device='cuda:0')\n",
      "Trajectory:  ['0.05', '1.00', '0.79', '0.13', '0.00', '0.00', '0.00', '0.00', '0.10', '0.35', '0.51', '0.54', '0.39', '0.22', '0.34', '0.78', '1.00', '0.99', '0.95']\n",
      "Last Action:  tensor([0.9532, 0.9864, 0.9967, 0.8646, 0.9617, 0.9973, 0.9689, 0.9695, 0.9588,\n",
      "        0.9635], device='cuda:0')\n",
      "Loss: 0.3790561854839325 -0.8614186644554138\n",
      "Loss: 0.43819016218185425 -0.8956665396690369\n",
      "Loss: 0.39026594161987305 -0.48915204405784607\n",
      "Loss: 0.33882439136505127 -0.4827582836151123\n",
      "Loss: 0.40419700741767883 -0.7271246314048767\n",
      "Loss: 0.47515085339546204 -1.0636359453201294\n",
      "Loss: 0.427337110042572 -0.835283100605011\n",
      "Policy Reward: tensor(1.2529, device='cuda:0')\n",
      "Trajectory:  ['0.46', '1.00', '0.81', '0.22', '0.01', '0.00', '0.00', '0.00', '0.16', '0.47', '0.80', '0.59', '0.47', '0.34', '0.31', '0.57', '0.99', '0.99', '0.98']\n",
      "Last Action:  tensor([0.9783, 0.9436, 0.9653, 0.9879, 0.9736, 0.9912, 0.9766, 0.9558, 0.9764,\n",
      "        0.9865], device='cuda:0')\n",
      "Bigstep:  21\n",
      "Loss: 0.422371506690979 -0.5532383918762207\n",
      "Loss: 0.43629807233810425 -0.8393864631652832\n",
      "Loss: 0.4207064211368561 -0.808228611946106\n",
      "Loss: 0.4615615904331207 -0.34242483973503113\n",
      "Loss: 0.4137732982635498 -0.6574748158454895\n",
      "Loss: 0.3644322454929352 -0.32885056734085083\n",
      "Loss: 0.3989980220794678 -0.8869158029556274\n",
      "Policy Reward: tensor(1.1600, device='cuda:0')\n",
      "Trajectory:  ['0.23', '0.30', '0.13', '0.03', '0.00', '0.00', '0.00', '0.00', '0.04', '0.30', '0.62', '0.72', '0.45', '0.20', '0.10', '0.06', '0.19', '0.65', '0.73']\n",
      "Last Action:  tensor([0.7260, 0.9008, 0.8862, 0.7403, 0.9164, 0.6095, 0.8076, 0.7330, 0.8927,\n",
      "        0.9147], device='cuda:0')\n",
      "Loss: 0.492158442735672 -0.9267198443412781\n",
      "Loss: 0.3763057291507721 -0.6244788765907288\n",
      "Loss: 0.39551615715026855 -0.6898701190948486\n",
      "Loss: 0.39320558309555054 -0.6681357622146606\n",
      "Loss: 0.3215366303920746 -0.21227459609508514\n",
      "Loss: 0.3775792717933655 -0.6342348456382751\n",
      "Loss: 0.43359267711639404 -1.029210090637207\n",
      "Policy Reward: tensor(1.2222, device='cuda:0')\n",
      "Trajectory:  ['0.53', '1.00', '0.92', '0.17', '0.01', '0.00', '0.00', '0.00', '0.02', '0.22', '0.47', '0.61', '0.58', '0.41', '0.22', '0.14', '0.21', '0.51', '0.87']\n",
      "Last Action:  tensor([0.8665, 0.8770, 0.8697, 0.5572, 0.7557, 0.7005, 0.7400, 0.9316, 0.8861,\n",
      "        0.6470], device='cuda:0')\n",
      "Loss: 0.3365299701690674 -0.8248398900032043\n",
      "Loss: 0.47655290365219116 -0.9707837104797363\n",
      "Loss: 0.40629929304122925 -0.8807879686355591\n",
      "Loss: 0.42008644342422485 -0.9861375689506531\n",
      "Loss: 0.40790608525276184 -1.1882743835449219\n",
      "Loss: 0.36986011266708374 -0.7653403878211975\n",
      "Loss: 0.3287569582462311 -0.67967689037323\n",
      "Policy Reward: tensor(1.1677, device='cuda:0')\n",
      "Trajectory:  ['0.56', '1.00', '0.97', '0.16', '0.02', '0.01', '0.00', '0.00', '0.01', '0.07', '0.59', '0.87', '0.80', '0.41', '0.13', '0.10', '0.20', '0.33', '0.81']\n",
      "Last Action:  tensor([0.8144, 0.9629, 0.8605, 0.7347, 0.7481, 0.5407, 0.5432, 0.8871, 0.7943,\n",
      "        0.7003], device='cuda:0')\n",
      "Loss: 0.3815813958644867 -0.7280967235565186\n",
      "Loss: 0.42025449872016907 -1.027431845664978\n",
      "Loss: 0.4462811052799225 -1.3544710874557495\n",
      "Loss: 0.3867280185222626 -0.9090664386749268\n",
      "Loss: 0.3726770579814911 -0.6113491654396057\n",
      "Loss: 0.40166574716567993 -1.1496168375015259\n",
      "Loss: 0.4265895485877991 -1.2587394714355469\n",
      "Policy Reward: tensor(1.2104, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.85', '0.32', '0.20', '0.06', '0.01', '0.01', '0.04', '0.36', '0.75', '0.80', '0.40', '0.17', '0.15', '0.35', '0.60', '0.73', '0.52', '0.36']\n",
      "Last Action:  tensor([0.3561, 0.5289, 0.6867, 0.8326, 0.8005, 0.2465, 0.4166, 0.3166, 0.8356,\n",
      "        0.5639], device='cuda:0')\n",
      "Loss: 0.38612303137779236 -0.8160136938095093\n",
      "Loss: 0.4490397274494171 -0.924636960029602\n",
      "Loss: 0.400456041097641 -1.1093556880950928\n",
      "Loss: 0.42837512493133545 -0.8907575607299805\n",
      "Loss: 0.4317801296710968 -1.3568553924560547\n",
      "Loss: 0.3979097604751587 -1.0730005502700806\n",
      "Loss: 0.36597955226898193 -0.9881414175033569\n",
      "Policy Reward: tensor(1.1190, device='cuda:0')\n",
      "Trajectory:  ['0.05', '0.90', '0.46', '0.19', '0.09', '0.03', '0.02', '0.02', '0.18', '0.55', '0.79', '0.78', '0.50', '0.21', '0.15', '0.18', '0.23', '0.41', '0.68']\n",
      "Last Action:  tensor([0.6788, 0.7716, 0.8324, 0.4492, 0.9260, 0.7319, 0.7446, 0.9601, 0.9577,\n",
      "        0.5810], device='cuda:0')\n",
      "Loss: 0.4250510036945343 -1.1839138269424438\n",
      "Loss: 0.3618232011795044 -0.6400769352912903\n",
      "Loss: 0.4043079912662506 -0.7841852307319641\n",
      "Loss: 0.3228064179420471 -0.8446217775344849\n",
      "Loss: 0.39899376034736633 -1.0266857147216797\n",
      "Loss: 0.3730689287185669 -0.9903615713119507\n",
      "Loss: 0.3526642322540283 -0.6324710249900818\n",
      "Policy Reward: tensor(1.1385, device='cuda:0')\n",
      "Trajectory:  ['0.58', '1.00', '0.98', '0.17', '0.02', '0.00', '0.00', '0.00', '0.02', '0.25', '0.48', '0.50', '0.32', '0.20', '0.23', '0.32', '0.40', '0.47', '0.51']\n",
      "Last Action:  tensor([0.5090, 0.8201, 0.8203, 0.7565, 0.8574, 0.6431, 0.3011, 0.3632, 0.3488,\n",
      "        0.3856], device='cuda:0')\n",
      "Loss: 0.3868824541568756 -0.7137891054153442\n",
      "Loss: 0.39738956093788147 -0.875092625617981\n",
      "Loss: 0.4548720717430115 -1.0089918375015259\n",
      "Loss: 0.4815410375595093 -1.0452800989151\n",
      "Loss: 0.39522647857666016 -0.9600047469139099\n",
      "Loss: 0.4194616675376892 -1.2798224687576294\n",
      "Loss: 0.4044985771179199 -1.0324554443359375\n",
      "Policy Reward: tensor(1.2725, device='cuda:0')\n",
      "Trajectory:  ['0.51', '1.00', '0.91', '0.11', '0.01', '0.00', '0.00', '0.00', '0.04', '0.32', '0.57', '0.56', '0.37', '0.22', '0.21', '0.31', '0.59', '0.76', '0.70']\n",
      "Last Action:  tensor([0.6954, 0.3400, 0.9081, 0.3085, 0.8113, 0.7680, 0.2887, 0.9157, 0.6656,\n",
      "        0.7636], device='cuda:0')\n",
      "Loss: 0.4050174355506897 -0.8522344827651978\n",
      "Loss: 0.34527716040611267 -0.8790369629859924\n",
      "Loss: 0.39639702439308167 -1.1599797010421753\n",
      "Loss: 0.40621405839920044 -0.9161581993103027\n",
      "Loss: 0.42144349217414856 -1.082499384880066\n",
      "Loss: 0.5203544497489929 -0.6867159008979797\n",
      "Loss: 0.40020766854286194 -0.8052282929420471\n",
      "Policy Reward: tensor(1.1005, device='cuda:0')\n",
      "Trajectory:  ['0.03', '1.00', '0.78', '0.16', '0.11', '0.08', '0.04', '0.02', '0.08', '0.45', '0.79', '0.83', '0.58', '0.29', '0.15', '0.19', '0.22', '0.30', '0.55']\n",
      "Last Action:  tensor([0.5503, 0.6245, 0.7761, 0.3650, 0.8812, 0.9260, 0.7822, 0.7513, 0.6823,\n",
      "        0.7484], device='cuda:0')\n",
      "Bigstep:  22\n",
      "Loss: 0.31389811635017395 0.03488115593791008\n",
      "Loss: 0.32112666964530945 0.39132118225097656\n",
      "Loss: 0.3959140479564667 -0.639269232749939\n",
      "Loss: 0.4511423707008362 -0.5274916291236877\n",
      "Loss: 0.31087374687194824 -0.39379680156707764\n",
      "Loss: 0.36892563104629517 -0.41865378618240356\n",
      "Loss: 0.40217745304107666 -0.6051225066184998\n",
      "Policy Reward: tensor(1.0196, device='cuda:0')\n",
      "Trajectory:  ['0.57', '1.00', '0.80', '0.02', '0.00', '0.00', '0.00', '0.00', '0.02', '0.27', '0.51', '0.76', '0.44', '0.38', '0.30', '0.28', '0.38', '0.60', '0.71']\n",
      "Last Action:  tensor([0.7121, 0.5434, 0.8244, 0.8279, 0.7618, 0.1709, 0.5902, 0.9555, 0.5602,\n",
      "        0.5672], device='cuda:0')\n",
      "Loss: 0.4114094376564026 -0.6232376098632812\n",
      "Loss: 0.4427810311317444 -0.7648143172264099\n",
      "Loss: 0.35636478662490845 -0.7021539211273193\n",
      "Loss: 0.43591535091400146 -0.8200944662094116\n",
      "Loss: 0.34585702419281006 -0.6124316453933716\n",
      "Loss: 0.40338626503944397 -0.9099453091621399\n",
      "Loss: 0.37685173749923706 -0.24652019143104553\n",
      "Policy Reward: tensor(1.0576, device='cuda:0')\n",
      "Trajectory:  ['0.39', '1.00', '0.49', '0.00', '0.00', '0.00', '0.00', '0.00', '0.04', '0.43', '0.76', '0.74', '0.42', '0.33', '0.30', '0.39', '0.50', '0.55', '0.38']\n",
      "Last Action:  tensor([0.3839, 0.2766, 0.9366, 0.2397, 0.5388, 0.6439, 0.6760, 0.7017, 0.5769,\n",
      "        0.5476], device='cuda:0')\n",
      "Loss: 0.45315197110176086 -0.603168249130249\n",
      "Loss: 0.39684975147247314 -0.47755250334739685\n",
      "Loss: 0.3911011219024658 -0.5714663863182068\n",
      "Loss: 0.3706028163433075 -0.47360923886299133\n",
      "Loss: 0.38333284854888916 -0.8195450305938721\n",
      "Loss: 0.4040062427520752 -0.5332711338996887\n",
      "Loss: 0.4217517375946045 -0.3666002154350281\n",
      "Policy Reward: tensor(1.1901, device='cuda:0')\n",
      "Trajectory:  ['0.35', '1.00', '0.67', '0.00', '0.00', '0.00', '0.00', '0.00', '0.12', '0.53', '0.64', '0.52', '0.43', '0.39', '0.33', '0.34', '0.51', '0.77', '0.87']\n",
      "Last Action:  tensor([0.8676, 0.5528, 0.2813, 0.6785, 0.4613, 0.6369, 0.7410, 0.8863, 0.3941,\n",
      "        0.9489], device='cuda:0')\n",
      "Loss: 0.43798813223838806 -0.8312690854072571\n",
      "Loss: 0.37371671199798584 -0.5476653575897217\n",
      "Loss: 0.4325471520423889 -0.8779391646385193\n",
      "Loss: 0.4330984950065613 -0.3491196036338806\n",
      "Loss: 0.32429829239845276 -0.48649460077285767\n",
      "Loss: 0.41965118050575256 -0.39061427116394043\n",
      "Loss: 0.4467092752456665 -0.7871329188346863\n",
      "Policy Reward: tensor(1.0895, device='cuda:0')\n",
      "Trajectory:  ['0.03', '0.47', '0.03', '0.01', '0.00', '0.01', '0.01', '0.04', '0.21', '0.61', '0.89', '0.91', '0.81', '0.69', '0.52', '0.30', '0.30', '0.50', '0.89']\n",
      "Last Action:  tensor([0.8912, 0.4774, 0.9045, 0.3637, 0.8484, 0.5139, 0.6609, 0.6302, 0.7520,\n",
      "        0.5462], device='cuda:0')\n",
      "Loss: 0.3930113911628723 -0.7690680027008057\n",
      "Loss: 0.4635603725910187 -0.5687744617462158\n",
      "Loss: 0.49785116314888 -0.7157042026519775\n",
      "Loss: 0.39507877826690674 -0.6916360855102539\n",
      "Loss: 0.3810173273086548 -0.6805217266082764\n",
      "Loss: 0.35479116439819336 -0.1929793357849121\n",
      "Loss: 0.3718634843826294 -0.6119779348373413\n",
      "Policy Reward: tensor(1.0863, device='cuda:0')\n",
      "Trajectory:  ['0.07', '0.99', '0.44', '0.03', '0.01', '0.00', '0.00', '0.01', '0.25', '0.55', '0.68', '0.60', '0.48', '0.48', '0.45', '0.39', '0.45', '0.71', '0.88']\n",
      "Last Action:  tensor([0.8838, 0.5885, 0.3553, 0.6704, 0.7294, 0.5178, 0.5313, 0.8329, 0.8619,\n",
      "        0.5072], device='cuda:0')\n",
      "Loss: 0.41362830996513367 -0.676598310470581\n",
      "Loss: 0.3560754954814911 -0.31937089562416077\n",
      "Loss: 0.4373495280742645 -0.5984857678413391\n",
      "Loss: 0.3641253113746643 -0.5213561058044434\n",
      "Loss: 0.3929864168167114 -0.7519874572753906\n",
      "Loss: 0.4236574172973633 -0.9416847825050354\n",
      "Loss: 0.38767972588539124 -0.8139607310295105\n",
      "Policy Reward: tensor(1.1020, device='cuda:0')\n",
      "Trajectory:  ['0.03', '0.98', '0.42', '0.01', '0.00', '0.00', '0.01', '0.03', '0.38', '0.70', '0.72', '0.56', '0.38', '0.36', '0.43', '0.47', '0.40', '0.38', '0.39']\n",
      "Last Action:  tensor([0.3879, 0.6757, 0.3512, 0.5778, 0.5662, 0.8321, 0.8069, 0.4713, 0.5482,\n",
      "        0.6405], device='cuda:0')\n",
      "Loss: 0.40450453758239746 -0.6574112176895142\n",
      "Loss: 0.41469746828079224 -0.7913607954978943\n",
      "Loss: 0.4310542047023773 -0.6880958676338196\n",
      "Loss: 0.4139689803123474 -0.6520978212356567\n",
      "Loss: 0.33468469977378845 -0.4471086859703064\n",
      "Loss: 0.43910565972328186 -0.8031852841377258\n",
      "Loss: 0.30282095074653625 -0.24147436022758484\n",
      "Policy Reward: tensor(1.1775, device='cuda:0')\n",
      "Trajectory:  ['0.05', '0.98', '0.32', '0.02', '0.00', '0.00', '0.00', '0.02', '0.26', '0.54', '0.66', '0.54', '0.49', '0.50', '0.47', '0.42', '0.51', '0.72', '0.84']\n",
      "Last Action:  tensor([0.8365, 0.5739, 0.5576, 0.5535, 0.5104, 0.6405, 0.8191, 0.4130, 0.5813,\n",
      "        0.7151], device='cuda:0')\n",
      "Loss: 0.43869462609291077 -1.015141248703003\n",
      "Loss: 0.4476962387561798 -0.9562764167785645\n",
      "Loss: 0.36988136172294617 -0.4267301559448242\n",
      "Loss: 0.36930474638938904 -0.5489121079444885\n",
      "Loss: 0.42592236399650574 -0.634070634841919\n",
      "Loss: 0.34595510363578796 -0.3938297927379608\n",
      "Loss: 0.31751254200935364 -0.48875918984413147\n",
      "Policy Reward: tensor(1.2831, device='cuda:0')\n",
      "Trajectory:  ['0.58', '0.15', '0.05', '0.00', '0.00', '0.00', '0.00', '0.01', '0.13', '0.51', '0.79', '0.58', '0.28', '0.15', '0.15', '0.31', '0.78', '0.90', '0.64']\n",
      "Last Action:  tensor([0.6430, 0.5160, 0.4162, 0.9731, 0.5425, 0.5329, 0.5620, 0.2547, 0.3601,\n",
      "        0.5656], device='cuda:0')\n",
      "Bigstep:  23\n",
      "Loss: 0.43336430191993713 -0.028917698189616203\n",
      "Loss: 0.3883819878101349 0.057719938457012177\n",
      "Loss: 0.5038634538650513 -0.8655223846435547\n",
      "Loss: 0.44241732358932495 -0.2794479727745056\n",
      "Loss: 0.39444923400878906 -0.30655062198638916\n",
      "Loss: 0.43881452083587646 -0.5255024433135986\n",
      "Loss: 0.3882488012313843 -0.41868409514427185\n",
      "Policy Reward: tensor(1.0633, device='cuda:0')\n",
      "Trajectory:  ['0.57', '1.00', '0.51', '0.00', '0.00', '0.00', '0.00', '0.00', '0.04', '0.21', '0.42', '0.37', '0.20', '0.29', '0.36', '0.40', '0.50', '0.54', '0.50']\n",
      "Last Action:  tensor([0.5008, 0.6407, 0.2878, 0.4119, 0.6344, 0.5270, 0.3922, 0.4529, 0.3810,\n",
      "        0.5980], device='cuda:0')\n",
      "Loss: 0.43106594681739807 -0.4303446114063263\n",
      "Loss: 0.4086115062236786 -0.7239383459091187\n",
      "Loss: 0.438283771276474 -0.2986396551132202\n",
      "Loss: 0.4216293692588806 -0.6250770092010498\n",
      "Loss: 0.4169592559337616 -0.5277798175811768\n",
      "Loss: 0.38664767146110535 -0.6659365892410278\n",
      "Loss: 0.3908129632472992 -0.4145505130290985\n",
      "Policy Reward: tensor(1.0245, device='cuda:0')\n",
      "Trajectory:  ['0.29', '0.86', '0.02', '0.00', '0.00', '0.00', '0.01', '0.06', '0.34', '0.66', '0.87', '0.90', '0.88', '0.83', '0.72', '0.59', '0.44', '0.28', '0.07']\n",
      "Last Action:  tensor([0.0738, 0.3992, 0.3338, 0.2601, 0.3987, 0.6426, 0.5673, 0.4459, 0.0971,\n",
      "        0.2929], device='cuda:0')\n",
      "Loss: 0.36680078506469727 -0.40329721570014954\n",
      "Loss: 0.46881407499313354 -0.7417674660682678\n",
      "Loss: 0.38002854585647583 -0.683014988899231\n",
      "Loss: 0.43659302592277527 -0.5649449229240417\n",
      "Loss: 0.39554694294929504 -0.4692091643810272\n",
      "Loss: 0.3654493987560272 -0.3191000819206238\n",
      "Loss: 0.45626014471054077 -0.7813094258308411\n",
      "Policy Reward: tensor(1.0821, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.65', '0.00', '0.00', '0.00', '0.00', '0.00', '0.02', '0.11', '0.31', '0.53', '0.48', '0.32', '0.26', '0.35', '0.57', '0.53', '0.47', '0.46']\n",
      "Last Action:  tensor([0.4587, 0.5876, 0.7867, 0.6110, 0.4179, 0.5356, 0.4514, 0.4429, 0.4077,\n",
      "        0.2152], device='cuda:0')\n",
      "Loss: 0.45017775893211365 -0.8230754733085632\n",
      "Loss: 0.393297016620636 -0.6496457457542419\n",
      "Loss: 0.44615843892097473 -0.6650000214576721\n",
      "Loss: 0.438186377286911 -0.5287892818450928\n",
      "Loss: 0.40870407223701477 -0.5399148464202881\n",
      "Loss: 0.47577038407325745 -0.5927643179893494\n",
      "Loss: 0.4184030294418335 -0.30778932571411133\n",
      "Policy Reward: tensor(1.0542, device='cuda:0')\n",
      "Trajectory:  ['0.11', '0.95', '0.01', '0.00', '0.00', '0.00', '0.00', '0.01', '0.11', '0.38', '0.65', '0.69', '0.52', '0.46', '0.60', '0.73', '0.70', '0.60', '0.45']\n",
      "Last Action:  tensor([0.4494, 0.5712, 0.5266, 0.4054, 0.6110, 0.1219, 0.4374, 0.5500, 0.5910,\n",
      "        0.6631], device='cuda:0')\n",
      "Loss: 0.4184732139110565 -0.7572429776191711\n",
      "Loss: 0.3774365186691284 -0.26831987500190735\n",
      "Loss: 0.476614773273468 -0.8412725329399109\n",
      "Loss: 0.35423561930656433 -0.5232892036437988\n",
      "Loss: 0.4062502086162567 -0.466472327709198\n",
      "Loss: 0.45313623547554016 -0.6146168112754822\n",
      "Loss: 0.47588008642196655 -0.8093747496604919\n",
      "Policy Reward: tensor(1.2100, device='cuda:0')\n",
      "Trajectory:  ['0.59', '1.00', '0.42', '0.00', '0.00', '0.00', '0.00', '0.00', '0.04', '0.31', '0.63', '0.74', '0.48', '0.46', '0.61', '0.69', '0.70', '0.61', '0.46']\n",
      "Last Action:  tensor([0.4635, 0.4617, 0.4715, 0.7152, 0.2299, 0.4915, 0.5073, 0.8191, 0.6778,\n",
      "        0.5421], device='cuda:0')\n",
      "Loss: 0.37562304735183716 -0.27625012397766113\n",
      "Loss: 0.3042234480381012 -0.21050536632537842\n",
      "Loss: 0.36637961864471436 -0.061129797250032425\n",
      "Loss: 0.49381330609321594 -0.7578504085540771\n",
      "Loss: 0.42271697521209717 -0.36239540576934814\n",
      "Loss: 0.40729963779449463 -0.5402650833129883\n",
      "Loss: 0.5139039158821106 -0.8707360625267029\n",
      "Policy Reward: tensor(1.0382, device='cuda:0')\n",
      "Trajectory:  ['0.05', '0.31', '0.00', '0.00', '0.00', '0.00', '0.00', '0.01', '0.04', '0.20', '0.45', '0.67', '0.74', '0.60', '0.46', '0.46', '0.65', '0.82', '0.81']\n",
      "Last Action:  tensor([0.8083, 0.7752, 0.3838, 0.6694, 0.2992, 0.7847, 0.7668, 0.6964, 0.6630,\n",
      "        0.4502], device='cuda:0')\n",
      "Loss: 0.46379581093788147 -0.9091256260871887\n",
      "Loss: 0.404440701007843 -0.7818582057952881\n",
      "Loss: 0.42789748311042786 -0.30752238631248474\n",
      "Loss: 0.44243618845939636 -0.69322669506073\n",
      "Loss: 0.398247092962265 -0.3420906066894531\n",
      "Loss: 0.41749274730682373 -0.7107031941413879\n",
      "Loss: 0.4720083475112915 -0.9951080679893494\n",
      "Policy Reward: tensor(1.1168, device='cuda:0')\n",
      "Trajectory:  ['0.30', '0.97', '0.02', '0.00', '0.00', '0.00', '0.00', '0.01', '0.15', '0.32', '0.52', '0.35', '0.28', '0.35', '0.49', '0.54', '0.48', '0.37', '0.29']\n",
      "Last Action:  tensor([0.2865, 0.5376, 0.4377, 0.4978, 0.7180, 0.5558, 0.6369, 0.5955, 0.7444,\n",
      "        0.8036], device='cuda:0')\n",
      "Loss: 0.3840789496898651 -0.36034563183784485\n",
      "Loss: 0.3854306936264038 -0.5290020108222961\n",
      "Loss: 0.4518532454967499 -0.6097796559333801\n",
      "Loss: 0.4112145006656647 -0.5013302564620972\n",
      "Loss: 0.46659576892852783 -0.48559650778770447\n",
      "Loss: 0.4595504403114319 -0.8335515856742859\n",
      "Loss: 0.442373126745224 -0.7426119446754456\n",
      "Policy Reward: tensor(1.0335, device='cuda:0')\n",
      "Trajectory:  ['0.61', '0.88', '0.19', '0.00', '0.00', '0.00', '0.01', '0.06', '0.35', '0.65', '0.90', '0.90', '0.86', '0.79', '0.66', '0.59', '0.57', '0.56', '0.58']\n",
      "Last Action:  tensor([0.5814, 0.5507, 0.3864, 0.7513, 0.4621, 0.6574, 0.1434, 0.6835, 0.6077,\n",
      "        0.5534], device='cuda:0')\n",
      "Bigstep:  24\n",
      "Loss: 0.47937285900115967 0.12244851142168045\n",
      "Loss: 0.48183301091194153 -0.04728095605969429\n",
      "Loss: 0.516542911529541 -0.4083610475063324\n",
      "Loss: 0.3730110824108124 -0.2811419665813446\n",
      "Loss: 0.4445626735687256 -0.31056979298591614\n",
      "Loss: 0.42454177141189575 -0.2809658646583557\n",
      "Loss: 0.3582836985588074 -0.23205891251564026\n",
      "Policy Reward: tensor(1.0587, device='cuda:0')\n",
      "Trajectory:  ['0.08', '0.77', '0.00', '0.00', '0.00', '0.00', '0.00', '0.05', '0.31', '0.65', '0.84', '0.74', '0.82', '0.84', '0.80', '0.65', '0.62', '0.52', '0.36']\n",
      "Last Action:  tensor([0.3590, 0.2494, 0.3598, 0.0746, 0.5779, 0.1205, 0.7660, 0.8429, 0.4212,\n",
      "        0.4585], device='cuda:0')\n",
      "Loss: 0.38038134574890137 -0.384975790977478\n",
      "Loss: 0.39326807856559753 -0.15323695540428162\n",
      "Loss: 0.44321873784065247 -0.7620568871498108\n",
      "Loss: 0.3859516382217407 -0.3121350407600403\n",
      "Loss: 0.3614284098148346 -0.26816248893737793\n",
      "Loss: 0.40045252442359924 -0.5307785272598267\n",
      "Loss: 0.4716953635215759 -0.8876155614852905\n",
      "Policy Reward: tensor(1.2241, device='cuda:0')\n",
      "Trajectory:  ['0.13', '0.62', '0.00', '0.00', '0.00', '0.00', '0.00', '0.03', '0.55', '0.86', '0.95', '0.93', '0.92', '0.89', '0.84', '0.79', '0.73', '0.61', '0.45']\n",
      "Last Action:  tensor([0.4454, 0.1215, 0.1155, 0.1368, 0.4787, 0.2232, 0.4709, 0.7211, 0.2850,\n",
      "        0.2051], device='cuda:0')\n",
      "Loss: 0.46637189388275146 -0.7606009244918823\n",
      "Loss: 0.4100271165370941 -0.7093729972839355\n",
      "Loss: 0.3905273675918579 -0.5595051646232605\n",
      "Loss: 0.376312255859375 -0.4922170042991638\n",
      "Loss: 0.403905987739563 -0.575765073299408\n",
      "Loss: 0.3402976989746094 -0.179666206240654\n",
      "Loss: 0.45432358980178833 -0.7295390963554382\n",
      "Policy Reward: tensor(1.1783, device='cuda:0')\n",
      "Trajectory:  ['0.53', '0.96', '0.04', '0.00', '0.00', '0.00', '0.00', '0.03', '0.39', '0.83', '0.86', '0.86', '0.87', '0.82', '0.65', '0.42', '0.34', '0.14', '0.08']\n",
      "Last Action:  tensor([0.0810, 0.8075, 0.7732, 0.6185, 0.8450, 0.4671, 0.3058, 0.5548, 0.3199,\n",
      "        0.1650], device='cuda:0')\n",
      "Loss: 0.3269692063331604 -0.016531048342585564\n",
      "Loss: 0.4179900884628296 -0.6621880531311035\n",
      "Loss: 0.4008570611476898 -0.3323676288127899\n",
      "Loss: 0.3749377727508545 -0.6667090654373169\n",
      "Loss: 0.4720473289489746 -0.9162652492523193\n",
      "Loss: 0.45583629608154297 -0.8495734333992004\n",
      "Loss: 0.32486698031425476 -0.4050981402397156\n",
      "Policy Reward: tensor(1.0312, device='cuda:0')\n",
      "Trajectory:  ['0.41', '1.00', '0.09', '0.00', '0.00', '0.00', '0.00', '0.03', '0.37', '0.73', '0.85', '0.82', '0.84', '0.84', '0.74', '0.42', '0.24', '0.07', '0.14']\n",
      "Last Action:  tensor([0.1420, 0.2098, 0.1460, 0.2910, 0.3230, 0.4406, 0.0720, 0.3641, 0.4019,\n",
      "        0.0907], device='cuda:0')\n",
      "Loss: 0.4374258518218994 -0.5810346603393555\n",
      "Loss: 0.3880150318145752 -0.4264261722564697\n",
      "Loss: 0.573103129863739 -1.050987958908081\n",
      "Loss: 0.42483627796173096 -0.3411071002483368\n",
      "Loss: 0.4732115864753723 -0.5733692646026611\n",
      "Loss: 0.44922134280204773 -0.5668116211891174\n",
      "Loss: 0.4754330813884735 -0.6392555832862854\n",
      "Policy Reward: tensor(1.1640, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.75', '0.00', '0.00', '0.00', '0.00', '0.00', '0.02', '0.17', '0.41', '0.69', '0.66', '0.68', '0.78', '0.84', '0.80', '0.63', '0.46', '0.43']\n",
      "Last Action:  tensor([0.4343, 0.0295, 0.1764, 0.0679, 0.1551, 0.5722, 0.2753, 0.0890, 0.2257,\n",
      "        0.1025], device='cuda:0')\n",
      "Loss: 0.40087494254112244 -0.5253345966339111\n",
      "Loss: 0.4749111831188202 -0.6210148930549622\n",
      "Loss: 0.4517146646976471 -0.597919225692749\n",
      "Loss: 0.34047526121139526 -0.2750208377838135\n",
      "Loss: 0.4401666522026062 -0.6058763265609741\n",
      "Loss: 0.4347436726093292 -0.7164941430091858\n",
      "Loss: 0.3421582877635956 -0.5243720412254333\n",
      "Policy Reward: tensor(1.1590, device='cuda:0')\n",
      "Trajectory:  ['0.65', '0.96', '0.10', '0.00', '0.00', '0.00', '0.00', '0.02', '0.51', '0.86', '0.89', '0.90', '0.91', '0.88', '0.68', '0.50', '0.22', '0.09', '0.23']\n",
      "Last Action:  tensor([0.2253, 0.1045, 0.1684, 0.8715, 0.1215, 0.5095, 0.8717, 0.1039, 0.1750,\n",
      "        0.3521], device='cuda:0')\n",
      "Loss: 0.39629215002059937 -0.8212180137634277\n",
      "Loss: 0.43280330300331116 -0.333889901638031\n",
      "Loss: 0.4149130880832672 -0.6281594038009644\n",
      "Loss: 0.3983289897441864 -0.5864807367324829\n",
      "Loss: 0.43268856406211853 -0.5294017791748047\n",
      "Loss: 0.38951534032821655 -0.38024574518203735\n",
      "Loss: 0.48951026797294617 -0.8088663220405579\n",
      "Policy Reward: tensor(1.0791, device='cuda:0')\n",
      "Trajectory:  ['0.52', '1.00', '0.18', '0.00', '0.00', '0.00', '0.00', '0.01', '0.13', '0.39', '0.67', '0.81', '0.80', '0.76', '0.61', '0.35', '0.16', '0.07', '0.25']\n",
      "Last Action:  tensor([0.2504, 0.2835, 0.1215, 0.6485, 0.4690, 0.0879, 0.2477, 0.3418, 0.1515,\n",
      "        0.9590], device='cuda:0')\n",
      "Loss: 0.3955744802951813 -0.40673309564590454\n",
      "Loss: 0.32387590408325195 -0.19246172904968262\n",
      "Loss: 0.3557588756084442 -0.5584493279457092\n",
      "Loss: 0.39002999663352966 -0.37261325120925903\n",
      "Loss: 0.3912251889705658 -0.6674030423164368\n",
      "Loss: 0.35418304800987244 -0.4406117796897888\n",
      "Loss: 0.3850114047527313 -0.511043906211853\n",
      "Policy Reward: tensor(1.1125, device='cuda:0')\n",
      "Trajectory:  ['0.56', '0.99', '0.05', '0.00', '0.00', '0.00', '0.00', '0.02', '0.39', '0.74', '0.88', '0.87', '0.89', '0.85', '0.69', '0.51', '0.33', '0.10', '0.14']\n",
      "Last Action:  tensor([0.1367, 0.8072, 0.3858, 0.0819, 0.3811, 0.7010, 0.1299, 0.9872, 0.4965,\n",
      "        0.3437], device='cuda:0')\n",
      "Bigstep:  25\n",
      "Loss: 0.5325586199760437 -0.4625488519668579\n",
      "Loss: 0.4464374780654907 -0.21326944231987\n",
      "Loss: 0.4423539638519287 -0.005428692325949669\n",
      "Loss: 0.5022658705711365 -0.24806740880012512\n",
      "Loss: 0.46767106652259827 -0.12889333069324493\n",
      "Loss: 0.4531354606151581 -0.2749258279800415\n",
      "Loss: 0.4479343593120575 -0.4127126634120941\n",
      "Policy Reward: tensor(1.0606, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.83', '0.01', '0.00', '0.00', '0.00', '0.01', '0.05', '0.22', '0.48', '0.70', '0.90', '0.94', '0.96', '0.95', '0.91', '0.75', '0.61', '0.44']\n",
      "Last Action:  tensor([0.4401, 0.5106, 0.4588, 0.0763, 0.5826, 0.2859, 0.6692, 0.6046, 0.3569,\n",
      "        0.9255], device='cuda:0')\n",
      "Loss: 0.4567944407463074 -0.4262082874774933\n",
      "Loss: 0.4889819025993347 -0.25298359990119934\n",
      "Loss: 0.5112909078598022 -0.3207967281341553\n",
      "Loss: 0.45541682839393616 -0.5947109460830688\n",
      "Loss: 0.49905508756637573 -0.5507731437683105\n",
      "Loss: 0.5404788255691528 -0.863667905330658\n",
      "Loss: 0.5201716423034668 -0.9909234642982483\n",
      "Policy Reward: tensor(1.1837, device='cuda:0')\n",
      "Trajectory:  ['0.50', '1.00', '0.64', '0.00', '0.00', '0.00', '0.02', '0.15', '0.52', '0.90', '0.99', '1.00', '1.00', '0.97', '0.91', '0.75', '0.59', '0.53', '0.36']\n",
      "Last Action:  tensor([0.3559, 0.6533, 0.2570, 0.2628, 0.1029, 0.0618, 0.5528, 0.3684, 0.9194,\n",
      "        0.9458], device='cuda:0')\n",
      "Loss: 0.45302239060401917 -0.5913044214248657\n",
      "Loss: 0.4919080436229706 -0.40543049573898315\n",
      "Loss: 0.48149359226226807 -0.6679123044013977\n",
      "Loss: 0.49860748648643494 -0.5897095799446106\n",
      "Loss: 0.48997846245765686 -0.9493011236190796\n",
      "Loss: 0.49799948930740356 -0.6373547315597534\n",
      "Loss: 0.43660208582878113 -0.385680615901947\n",
      "Policy Reward: tensor(1.1764, device='cuda:0')\n",
      "Trajectory:  ['0.01', '0.88', '0.01', '0.00', '0.00', '0.00', '0.00', '0.02', '0.36', '0.72', '0.92', '0.98', '0.98', '0.97', '0.91', '0.71', '0.52', '0.23', '0.16']\n",
      "Last Action:  tensor([0.1559, 0.6268, 0.1205, 0.3595, 0.9695, 0.2408, 0.1168, 0.1484, 0.2219,\n",
      "        0.4326], device='cuda:0')\n",
      "Loss: 0.5442339777946472 -0.9175944924354553\n",
      "Loss: 0.545265793800354 -0.7291300296783447\n",
      "Loss: 0.3954378664493561 -0.3613830804824829\n",
      "Loss: 0.40415093302726746 -0.3091804087162018\n",
      "Loss: 0.5151215195655823 -0.7749923467636108\n",
      "Loss: 0.48674559593200684 -0.656485915184021\n",
      "Loss: 0.49631455540657043 -0.43549367785453796\n",
      "Policy Reward: tensor(1.0923, device='cuda:0')\n",
      "Trajectory:  ['0.44', '1.00', '0.10', '0.00', '0.00', '0.00', '0.00', '0.06', '0.49', '0.81', '0.93', '0.96', '0.97', '0.96', '0.84', '0.55', '0.37', '0.14', '0.13']\n",
      "Last Action:  tensor([0.1317, 0.1547, 0.1166, 0.0942, 0.1109, 0.1516, 0.2409, 0.1168, 0.5326,\n",
      "        0.1502], device='cuda:0')\n",
      "Loss: 0.5092382431030273 -0.653770387172699\n",
      "Loss: 0.3867782652378082 -0.3212181627750397\n",
      "Loss: 0.4786602556705475 -0.5699104070663452\n",
      "Loss: 0.44642174243927 -0.587878406047821\n",
      "Loss: 0.5005477666854858 -0.8638015985488892\n",
      "Loss: 0.4344507157802582 -0.6559337377548218\n",
      "Loss: 0.45896005630493164 -0.43080011010169983\n",
      "Policy Reward: tensor(1.0595, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.87', '0.01', '0.00', '0.00', '0.00', '0.00', '0.04', '0.45', '0.77', '0.94', '0.99', '0.99', '0.98', '0.89', '0.69', '0.37', '0.17', '0.13']\n",
      "Last Action:  tensor([0.1329, 0.5338, 0.2315, 0.3468, 0.1248, 0.0992, 0.2421, 0.3362, 0.4383,\n",
      "        0.6918], device='cuda:0')\n",
      "Loss: 0.4515710473060608 -0.5984703898429871\n",
      "Loss: 0.39685937762260437 -0.6150767803192139\n",
      "Loss: 0.494619756937027 -0.8357301950454712\n",
      "Loss: 0.4762607514858246 -0.5305317640304565\n",
      "Loss: 0.5551944375038147 -1.0949839353561401\n",
      "Loss: 0.47986799478530884 -0.652949869632721\n",
      "Loss: 0.4215180575847626 -0.9720066785812378\n",
      "Policy Reward: tensor(1.1995, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.84', '0.00', '0.00', '0.00', '0.00', '0.00', '0.02', '0.24', '0.55', '0.76', '0.88', '0.97', '0.99', '0.94', '0.78', '0.50', '0.23', '0.18']\n",
      "Last Action:  tensor([0.1833, 0.5442, 0.5133, 0.1785, 0.6127, 0.9868, 0.9915, 0.1700, 0.7287,\n",
      "        0.3954], device='cuda:0')\n",
      "Loss: 0.432229220867157 -0.8812196850776672\n",
      "Loss: 0.4679931700229645 -0.7401977181434631\n",
      "Loss: 0.4351106882095337 -0.645159900188446\n",
      "Loss: 0.5280568599700928 -0.8096652626991272\n",
      "Loss: 0.4754064679145813 -0.9152705073356628\n",
      "Loss: 0.412789911031723 -0.5440113544464111\n",
      "Loss: 0.44904178380966187 -0.6015433073043823\n",
      "Policy Reward: tensor(1.1877, device='cuda:0')\n",
      "Trajectory:  ['0.06', '0.86', '0.01', '0.00', '0.00', '0.00', '0.00', '0.03', '0.50', '0.85', '0.98', '1.00', '1.00', '0.99', '0.87', '0.66', '0.34', '0.27', '0.23']\n",
      "Last Action:  tensor([0.2267, 0.1222, 0.1329, 0.1590, 0.1922, 0.2844, 0.0883, 0.0763, 0.2461,\n",
      "        0.1696], device='cuda:0')\n",
      "Loss: 0.41029027104377747 -0.6566315293312073\n",
      "Loss: 0.4275183081626892 -0.5545496940612793\n",
      "Loss: 0.387608140707016 -0.4545326232910156\n",
      "Loss: 0.4406304359436035 -0.529616117477417\n",
      "Loss: 0.5611798167228699 -0.7932937741279602\n",
      "Loss: 0.48448964953422546 -0.4281913936138153\n",
      "Loss: 0.5052346587181091 -0.601356029510498\n",
      "Policy Reward: tensor(1.1366, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.89', '0.03', '0.00', '0.00', '0.00', '0.01', '0.03', '0.22', '0.59', '0.89', '1.00', '1.00', '1.00', '1.00', '0.98', '0.82', '0.64', '0.47']\n",
      "Last Action:  tensor([0.4663, 0.8534, 0.4879, 0.9853, 0.6094, 0.5027, 0.8256, 0.9937, 0.9912,\n",
      "        0.4105], device='cuda:0')\n",
      "Bigstep:  26\n",
      "Loss: 0.4396360218524933 -0.6909272074699402\n",
      "Loss: 0.6046140789985657 -1.0942907333374023\n",
      "Loss: 0.46621158719062805 -1.15998113155365\n",
      "Loss: 0.5746331810951233 -1.0323967933654785\n",
      "Loss: 0.4460070729255676 -1.028749704360962\n",
      "Loss: 0.4571530520915985 -1.2136105298995972\n",
      "Loss: 0.5540458559989929 -1.4192737340927124\n",
      "Policy Reward: tensor(1.0609, device='cuda:0')\n",
      "Trajectory:  ['0.30', '1.00', '0.10', '0.00', '0.00', '0.00', '0.00', '0.17', '0.89', '0.99', '1.00', '1.00', '1.00', '0.98', '0.90', '0.75', '0.57', '0.67', '0.52']\n",
      "Last Action:  tensor([0.5193, 0.1197, 0.2430, 0.0892, 0.1293, 0.9742, 0.8310, 0.7247, 0.1251,\n",
      "        0.1235], device='cuda:0')\n",
      "Loss: 0.5046648383140564 -1.022283673286438\n",
      "Loss: 0.4775201082229614 -1.0049165487289429\n",
      "Loss: 0.40200212597846985 -1.11764395236969\n",
      "Loss: 0.5267378687858582 -1.0876877307891846\n",
      "Loss: 0.47069600224494934 -1.3308378458023071\n",
      "Loss: 0.5118343830108643 -1.2818667888641357\n",
      "Loss: 0.47736406326293945 -1.0815157890319824\n",
      "Policy Reward: tensor(1.2371, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.99', '0.00', '0.00', '0.00', '0.00', '0.00', '0.04', '0.21', '0.43', '0.69', '0.98', '1.00', '1.00', '1.00', '1.00', '0.95', '0.70', '0.60']\n",
      "Last Action:  tensor([0.5952, 0.1329, 0.5960, 0.2681, 0.9910, 0.9943, 0.5121, 0.5161, 0.4034,\n",
      "        0.9938], device='cuda:0')\n",
      "Loss: 0.47778865694999695 -1.3832879066467285\n",
      "Loss: 0.5426762700080872 -1.62955641746521\n",
      "Loss: 0.48932716250419617 -1.296244740486145\n",
      "Loss: 0.457934707403183 -1.008192539215088\n",
      "Loss: 0.4743901789188385 -1.2972363233566284\n",
      "Loss: 0.44279614090919495 -1.334499716758728\n",
      "Loss: 0.4800693690776825 -1.2643944025039673\n",
      "Policy Reward: tensor(1.1370, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.01', '0.00', '0.00', '0.00', '0.00', '0.04', '0.61', '0.98', '1.00', '1.00', '1.00', '1.00', '1.00', '0.97', '0.77', '0.46', '0.25']\n",
      "Last Action:  tensor([0.2467, 0.2892, 0.1323, 0.2856, 0.1637, 0.2280, 0.4774, 0.5388, 0.1248,\n",
      "        0.8658], device='cuda:0')\n",
      "Loss: 0.467363566160202 -1.1428555250167847\n",
      "Loss: 0.519755482673645 -1.2772995233535767\n",
      "Loss: 0.47049152851104736 -1.2111809253692627\n",
      "Loss: 0.4926634728908539 -1.5080645084381104\n",
      "Loss: 0.506781816482544 -1.2817234992980957\n",
      "Loss: 0.5310163497924805 -1.5961378812789917\n",
      "Loss: 0.39194971323013306 -1.0516282320022583\n",
      "Policy Reward: tensor(1.1435, device='cuda:0')\n",
      "Trajectory:  ['0.61', '1.00', '0.20', '0.00', '0.00', '0.00', '0.00', '0.05', '0.64', '0.98', '1.00', '1.00', '1.00', '1.00', '0.95', '0.76', '0.52', '0.31', '0.36']\n",
      "Last Action:  tensor([0.3602, 0.2391, 0.5584, 0.6221, 0.1958, 0.2541, 0.3888, 0.5827, 0.1423,\n",
      "        0.8881], device='cuda:0')\n",
      "Loss: 0.4002011716365814 -0.9920987486839294\n",
      "Loss: 0.5239259600639343 -1.2815237045288086\n",
      "Loss: 0.5085059404373169 -1.4935095310211182\n",
      "Loss: 0.5097386240959167 -1.138250708580017\n",
      "Loss: 0.46832025051116943 -1.3739700317382812\n",
      "Loss: 0.4292125999927521 -1.12909996509552\n",
      "Loss: 0.39117076992988586 -1.0080350637435913\n",
      "Policy Reward: tensor(1.2831, device='cuda:0')\n",
      "Trajectory:  ['0.12', '0.25', '0.02', '0.00', '0.00', '0.00', '0.00', '0.02', '0.46', '0.97', '0.99', '1.00', '1.00', '1.00', '0.99', '0.93', '0.71', '0.50', '0.26']\n",
      "Last Action:  tensor([0.2638, 0.8070, 0.6195, 0.3649, 0.1706, 0.5527, 0.8349, 0.9903, 0.2367,\n",
      "        0.9969], device='cuda:0')\n",
      "Loss: 0.3877425789833069 -1.3446087837219238\n",
      "Loss: 0.4498246908187866 -1.1976398229599\n",
      "Loss: 0.4745969772338867 -1.331925630569458\n",
      "Loss: 0.4765133857727051 -1.2366797924041748\n",
      "Loss: 0.4095093011856079 -1.3741943836212158\n",
      "Loss: 0.4288673996925354 -1.030173897743225\n",
      "Loss: 0.42431893944740295 -0.997105598449707\n",
      "Policy Reward: tensor(1.1040, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.97', '0.01', '0.00', '0.00', '0.00', '0.01', '0.03', '0.16', '0.49', '0.71', '0.98', '1.00', '1.00', '1.00', '1.00', '1.00', '0.94', '0.73']\n",
      "Last Action:  tensor([0.7331, 0.4302, 0.2878, 0.1443, 0.4084, 0.1604, 0.0789, 0.6297, 0.1917,\n",
      "        0.4227], device='cuda:0')\n",
      "Loss: 0.40419062972068787 -1.1066981554031372\n",
      "Loss: 0.5269055962562561 -1.3024061918258667\n",
      "Loss: 0.4440614581108093 -0.9738441705703735\n",
      "Loss: 0.38251152634620667 -1.1042335033416748\n",
      "Loss: 0.4353417158126831 -1.0902998447418213\n",
      "Loss: 0.44158709049224854 -1.3115695714950562\n",
      "Loss: 0.5019170641899109 -1.428066611289978\n",
      "Policy Reward: tensor(1.2752, device='cuda:0')\n",
      "Trajectory:  ['0.36', '1.00', '0.03', '0.00', '0.00', '0.00', '0.00', '0.07', '0.69', '0.99', '1.00', '1.00', '1.00', '1.00', '1.00', '0.97', '0.89', '0.75', '0.60']\n",
      "Last Action:  tensor([0.6050, 0.1373, 0.0532, 0.3434, 0.2430, 0.4116, 0.2925, 0.9899, 0.2184,\n",
      "        0.1790], device='cuda:0')\n",
      "Loss: 0.412807822227478 -1.4176839590072632\n",
      "Loss: 0.4519672095775604 -1.5395225286483765\n",
      "Loss: 0.5601015686988831 -1.3518977165222168\n",
      "Loss: 0.4726407825946808 -1.1848584413528442\n",
      "Loss: 0.5143843293190002 -1.1688765287399292\n",
      "Loss: 0.5569146871566772 -1.4161242246627808\n",
      "Loss: 0.512062132358551 -1.1959877014160156\n",
      "Policy Reward: tensor(1.1766, device='cuda:0')\n",
      "Trajectory:  ['0.02', '1.00', '0.05', '0.00', '0.00', '0.00', '0.00', '0.06', '0.56', '0.99', '1.00', '1.00', '1.00', '1.00', '0.99', '0.96', '0.93', '0.94', '0.97']\n",
      "Last Action:  tensor([0.9695, 0.6671, 0.1952, 0.3224, 0.2461, 0.1812, 0.2690, 0.2163, 0.2624,\n",
      "        0.3202], device='cuda:0')\n",
      "Bigstep:  27\n",
      "Loss: 0.49125227332115173 -0.42698121070861816\n",
      "Loss: 0.5522840023040771 -0.8890496492385864\n",
      "Loss: 0.5792468786239624 -1.0727589130401611\n",
      "Loss: 0.5263684391975403 -0.39003345370292664\n",
      "Loss: 0.512696385383606 -0.5278872847557068\n",
      "Loss: 0.48692023754119873 -0.6395466327667236\n",
      "Loss: 0.5204784870147705 -0.8530842065811157\n",
      "Policy Reward: tensor(0.9950, device='cuda:0')\n",
      "Trajectory:  ['0.06', '1.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.05', '0.40', '0.59', '0.81', '0.95', '0.99', '0.99', '0.97', '0.83', '0.62', '0.33', '0.24']\n",
      "Last Action:  tensor([0.2427, 0.3353, 0.2875, 0.1556, 0.3870, 0.4307, 0.2613, 0.4646, 0.3559,\n",
      "        0.4109], device='cuda:0')\n",
      "Loss: 0.463141530752182 -0.8038402199745178\n",
      "Loss: 0.4651666581630707 -0.8093388676643372\n",
      "Loss: 0.544195294380188 -1.25562584400177\n",
      "Loss: 0.5316202044487 -0.9306097030639648\n",
      "Loss: 0.49807924032211304 -0.7923195958137512\n",
      "Loss: 0.47612264752388 -0.8814557790756226\n",
      "Loss: 0.551362931728363 -0.9885005354881287\n",
      "Policy Reward: tensor(1.1282, device='cuda:0')\n",
      "Trajectory:  ['0.19', '1.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.05', '0.40', '0.62', '0.75', '0.80', '0.85', '0.88', '0.83', '0.56', '0.30', '0.21', '0.19']\n",
      "Last Action:  tensor([0.1899, 0.7280, 0.1631, 0.2724, 0.1795, 0.8656, 0.9284, 0.1649, 0.2694,\n",
      "        0.4068], device='cuda:0')\n",
      "Loss: 0.4100978672504425 -0.5448325872421265\n",
      "Loss: 0.4971659183502197 -0.6796826720237732\n",
      "Loss: 0.4523806571960449 -0.6317788362503052\n",
      "Loss: 0.4034598767757416 -0.5709762573242188\n",
      "Loss: 0.44962936639785767 -1.0002456903457642\n",
      "Loss: 0.4489010274410248 -0.8526864647865295\n",
      "Loss: 0.5266847014427185 -0.8494279384613037\n",
      "Policy Reward: tensor(1.2682, device='cuda:0')\n",
      "Trajectory:  ['0.08', '1.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.03', '0.34', '0.63', '0.81', '0.78', '0.83', '0.92', '0.95', '0.93', '0.75', '0.45', '0.24']\n",
      "Last Action:  tensor([0.2432, 0.4559, 0.3554, 0.3043, 0.2546, 0.6429, 0.2627, 0.2560, 0.3866,\n",
      "        0.2835], device='cuda:0')\n",
      "Loss: 0.4804900288581848 -0.6759618520736694\n",
      "Loss: 0.5373145341873169 -0.8042452335357666\n",
      "Loss: 0.5279099345207214 -0.6186423301696777\n",
      "Loss: 0.5350528955459595 -0.9498603343963623\n",
      "Loss: 0.5610270500183105 -1.3577754497528076\n",
      "Loss: 0.45109304785728455 -0.8984419703483582\n",
      "Loss: 0.4875833988189697 -1.0317219495773315\n",
      "Policy Reward: tensor(1.2129, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.82', '0.00', '0.00', '0.00', '0.00', '0.00', '0.02', '0.21', '0.42', '0.61', '0.52', '0.52', '0.50', '0.51', '0.60', '0.78', '0.80', '0.68']\n",
      "Last Action:  tensor([0.6795, 0.6349, 0.6844, 0.7162, 0.5309, 0.2670, 0.3230, 0.2626, 0.2419,\n",
      "        0.5001], device='cuda:0')\n",
      "Loss: 0.5122117400169373 -0.8814237117767334\n",
      "Loss: 0.5759207010269165 -1.0972579717636108\n",
      "Loss: 0.522384762763977 -1.057627558708191\n",
      "Loss: 0.5075485706329346 -1.162063479423523\n",
      "Loss: 0.5145602226257324 -0.8317683935165405\n",
      "Loss: 0.3890434205532074 -0.727391242980957\n",
      "Loss: 0.3958800137042999 -0.7213774919509888\n",
      "Policy Reward: tensor(1.2641, device='cuda:0')\n",
      "Trajectory:  ['0.42', '1.00', '0.01', '0.00', '0.00', '0.00', '0.00', '0.03', '0.30', '0.61', '0.73', '0.68', '0.69', '0.80', '0.82', '0.69', '0.49', '0.28', '0.43']\n",
      "Last Action:  tensor([0.4307, 0.2952, 0.2643, 0.4001, 0.5334, 0.6609, 0.9335, 0.2737, 0.3367,\n",
      "        0.5145], device='cuda:0')\n",
      "Loss: 0.4853518009185791 -0.9036696553230286\n",
      "Loss: 0.4330142140388489 -0.9171969890594482\n",
      "Loss: 0.5045171976089478 -1.0756361484527588\n",
      "Loss: 0.5117783546447754 -1.073500633239746\n",
      "Loss: 0.5435235500335693 -1.0130736827850342\n",
      "Loss: 0.4736327528953552 -0.7475013136863708\n",
      "Loss: 0.5372503399848938 -1.1491665840148926\n",
      "Policy Reward: tensor(1.2533, device='cuda:0')\n",
      "Trajectory:  ['0.37', '1.00', '0.05', '0.00', '0.00', '0.00', '0.00', '0.02', '0.26', '0.52', '0.62', '0.58', '0.60', '0.70', '0.68', '0.58', '0.48', '0.33', '0.29']\n",
      "Last Action:  tensor([0.2916, 0.5625, 0.3429, 0.2540, 0.4290, 0.2089, 0.1979, 0.3955, 0.3331,\n",
      "        0.3842], device='cuda:0')\n",
      "Loss: 0.4674532413482666 -0.6577516198158264\n",
      "Loss: 0.4928343594074249 -0.8699280023574829\n",
      "Loss: 0.46519842743873596 -1.2540446519851685\n",
      "Loss: 0.40654122829437256 -0.9696532487869263\n",
      "Loss: 0.4786525070667267 -1.1233739852905273\n",
      "Loss: 0.5825827717781067 -1.3360861539840698\n",
      "Loss: 0.44851812720298767 -0.596261203289032\n",
      "Policy Reward: tensor(1.0642, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.99', '0.01', '0.00', '0.01', '0.01', '0.02', '0.07', '0.28', '0.48', '0.64', '0.86', '0.81', '0.84', '0.92', '0.96', '0.92', '0.76', '0.41']\n",
      "Last Action:  tensor([0.4089, 0.7869, 0.2123, 0.6216, 0.3201, 0.5496, 0.8929, 0.2466, 0.5683,\n",
      "        0.5845], device='cuda:0')\n",
      "Loss: 0.5052497982978821 -1.0320367813110352\n",
      "Loss: 0.40299639105796814 -0.8627604246139526\n",
      "Loss: 0.4864892363548279 -0.8314467072486877\n",
      "Loss: 0.5719547271728516 -1.0932142734527588\n",
      "Loss: 0.5590841770172119 -0.8345029354095459\n",
      "Loss: 0.5566228032112122 -0.9628602862358093\n",
      "Loss: 0.43079665303230286 -0.8988234996795654\n",
      "Policy Reward: tensor(1.2430, device='cuda:0')\n",
      "Trajectory:  ['0.10', '0.97', '0.01', '0.00', '0.00', '0.00', '0.00', '0.03', '0.27', '0.51', '0.73', '0.89', '0.91', '0.93', '0.95', '0.96', '0.86', '0.68', '0.56']\n",
      "Last Action:  tensor([0.5636, 0.2662, 0.9336, 0.6256, 0.4128, 0.5065, 0.3942, 0.2465, 0.4393,\n",
      "        0.3728], device='cuda:0')\n",
      "Bigstep:  28\n",
      "Loss: 0.47414374351501465 -0.6163616180419922\n",
      "Loss: 0.6041308641433716 -1.0694245100021362\n",
      "Loss: 0.5465784072875977 -0.639479398727417\n",
      "Loss: 0.43868380784988403 -0.8997451663017273\n",
      "Loss: 0.5275791883468628 -0.8915676474571228\n",
      "Loss: 0.45518773794174194 -0.6366567015647888\n",
      "Loss: 0.5064035654067993 -1.3072961568832397\n",
      "Policy Reward: tensor(1.1778, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.01', '0.00', '0.00', '0.00', '0.00', '0.08', '0.41', '0.71', '0.89', '0.97', '0.95', '0.94', '0.88', '0.71', '0.68', '0.68', '0.83']\n",
      "Last Action:  tensor([0.8303, 0.4360, 0.6087, 0.5868, 0.9188, 0.9592, 0.3453, 0.6160, 0.7229,\n",
      "        0.4871], device='cuda:0')\n",
      "Loss: 0.5454036593437195 -1.2710211277008057\n",
      "Loss: 0.5145876407623291 -1.6001018285751343\n",
      "Loss: 0.541491687297821 -1.1661604642868042\n",
      "Loss: 0.42935267090797424 -0.9292386770248413\n",
      "Loss: 0.5105976462364197 -1.093129277229309\n",
      "Loss: 0.5365041494369507 -1.4200800657272339\n",
      "Loss: 0.4902258813381195 -1.02486252784729\n",
      "Policy Reward: tensor(1.1649, device='cuda:0')\n",
      "Trajectory:  ['0.81', '1.00', '0.60', '0.01', '0.00', '0.01', '0.01', '0.16', '0.55', '0.84', '0.94', '0.97', '0.98', '0.98', '0.95', '0.89', '0.78', '0.68', '0.56']\n",
      "Last Action:  tensor([0.5587, 0.8219, 0.6370, 0.6199, 0.5399, 0.5699, 0.5867, 0.5238, 0.6935,\n",
      "        0.4280], device='cuda:0')\n",
      "Loss: 0.48637887835502625 -1.2751681804656982\n",
      "Loss: 0.49943703413009644 -0.985114336013794\n",
      "Loss: 0.5188510417938232 -1.3310657739639282\n",
      "Loss: 0.5470830202102661 -1.1779590845108032\n",
      "Loss: 0.55345219373703 -1.3134136199951172\n",
      "Loss: 0.5194211602210999 -1.2782632112503052\n",
      "Loss: 0.5061416625976562 -1.092346429824829\n",
      "Policy Reward: tensor(1.2644, device='cuda:0')\n",
      "Trajectory:  ['0.86', '1.00', '0.42', '0.00', '0.00', '0.00', '0.00', '0.03', '0.85', '0.99', '0.98', '0.96', '0.97', '0.95', '0.84', '0.64', '0.57', '0.51', '0.55']\n",
      "Last Action:  tensor([0.5528, 0.5080, 0.6200, 0.6236, 0.7673, 0.4996, 0.5434, 0.6970, 0.5256,\n",
      "        0.9171], device='cuda:0')\n",
      "Loss: 0.4749876856803894 -1.1251304149627686\n",
      "Loss: 0.4776802659034729 -1.1513862609863281\n",
      "Loss: 0.4741896986961365 -1.0971705913543701\n",
      "Loss: 0.4525492489337921 -1.354492425918579\n",
      "Loss: 0.49858927726745605 -1.36237633228302\n",
      "Loss: 0.46029993891716003 -1.3319638967514038\n",
      "Loss: 0.5714852809906006 -1.3467612266540527\n",
      "Policy Reward: tensor(1.0646, device='cuda:0')\n",
      "Trajectory:  ['0.77', '1.00', '0.35', '0.00', '0.00', '0.00', '0.00', '0.05', '0.53', '0.93', '0.92', '0.94', '0.95', '0.96', '0.96', '0.89', '0.70', '0.57', '0.64']\n",
      "Last Action:  tensor([0.6360, 0.6214, 0.5341, 0.6988, 0.5172, 0.4653, 0.4309, 0.3863, 0.6279,\n",
      "        0.9098], device='cuda:0')\n",
      "Loss: 0.4611406922340393 -1.2003047466278076\n",
      "Loss: 0.4758707880973816 -1.2554763555526733\n",
      "Loss: 0.5789463520050049 -1.364630937576294\n",
      "Loss: 0.5066829919815063 -1.271844744682312\n",
      "Loss: 0.4443485140800476 -1.3116010427474976\n",
      "Loss: 0.5130835771560669 -1.506546974182129\n",
      "Loss: 0.5033803582191467 -1.4485198259353638\n",
      "Policy Reward: tensor(1.1727, device='cuda:0')\n",
      "Trajectory:  ['0.34', '1.00', '0.02', '0.00', '0.01', '0.03', '0.17', '0.41', '0.50', '0.86', '0.88', '0.91', '0.89', '0.81', '0.73', '0.75', '0.73', '0.69', '0.61']\n",
      "Last Action:  tensor([0.6124, 0.4654, 0.6572, 0.9215, 0.5860, 0.5589, 0.4856, 0.8129, 0.5472,\n",
      "        0.4511], device='cuda:0')\n",
      "Loss: 0.5033724904060364 -1.2569224834442139\n",
      "Loss: 0.5585741996765137 -1.1496999263763428\n",
      "Loss: 0.5067022442817688 -1.2363537549972534\n",
      "Loss: 0.546818196773529 -1.4075814485549927\n",
      "Loss: 0.5139762163162231 -1.3743622303009033\n",
      "Loss: 0.432685524225235 -1.02827787399292\n",
      "Loss: 0.5050431489944458 -1.3525136709213257\n",
      "Policy Reward: tensor(1.1809, device='cuda:0')\n",
      "Trajectory:  ['0.77', '1.00', '0.36', '0.00', '0.00', '0.00', '0.00', '0.03', '0.40', '0.71', '0.79', '0.81', '0.82', '0.86', '0.86', '0.73', '0.65', '0.60', '0.60']\n",
      "Last Action:  tensor([0.6046, 0.5674, 0.4234, 0.9179, 0.5797, 0.3998, 0.8315, 0.5876, 0.7486,\n",
      "        0.5473], device='cuda:0')\n",
      "Loss: 0.4584268033504486 -1.3170329332351685\n",
      "Loss: 0.48917263746261597 -1.742195963859558\n",
      "Loss: 0.4978143572807312 -1.4095205068588257\n",
      "Loss: 0.5356093645095825 -1.1524802446365356\n",
      "Loss: 0.4696718454360962 -1.3708992004394531\n",
      "Loss: 0.4716704785823822 -1.2664692401885986\n",
      "Loss: 0.5012699961662292 -1.2020281553268433\n",
      "Policy Reward: tensor(1.1057, device='cuda:0')\n",
      "Trajectory:  ['0.01', '0.88', '0.01', '0.01', '0.03', '0.10', '0.25', '0.32', '0.72', '0.97', '0.99', '0.99', '0.97', '0.94', '0.83', '0.68', '0.63', '0.72', '0.84']\n",
      "Last Action:  tensor([0.8439, 0.5371, 0.7497, 0.6037, 0.6032, 0.9117, 0.3662, 0.6090, 0.4302,\n",
      "        0.5749], device='cuda:0')\n",
      "Loss: 0.5015382766723633 -1.6031044721603394\n",
      "Loss: 0.4446360468864441 -1.263087511062622\n",
      "Loss: 0.5262936949729919 -1.6468850374221802\n",
      "Loss: 0.45395779609680176 -0.8900399804115295\n",
      "Loss: 0.44349560141563416 -1.228522539138794\n",
      "Loss: 0.5839998126029968 -1.267654299736023\n",
      "Loss: 0.5097642540931702 -1.212702989578247\n",
      "Policy Reward: tensor(1.0087, device='cuda:0')\n",
      "Trajectory:  ['0.89', '1.00', '0.67', '0.02', '0.00', '0.00', '0.00', '0.04', '0.94', '0.97', '0.95', '0.94', '0.93', '0.90', '0.81', '0.70', '0.62', '0.55', '0.50']\n",
      "Last Action:  tensor([0.5029, 0.5501, 0.5144, 0.5450, 0.4693, 0.8383, 0.9032, 0.5271, 0.4471,\n",
      "        0.7127], device='cuda:0')\n",
      "Bigstep:  29\n",
      "Loss: 0.5786314606666565 -0.5587953925132751\n",
      "Loss: 0.5355566143989563 -0.9730607271194458\n",
      "Loss: 0.4475250840187073 -0.8329640626907349\n",
      "Loss: 0.45654618740081787 -1.05697762966156\n",
      "Loss: 0.4765581786632538 -1.0056425333023071\n",
      "Loss: 0.39712879061698914 -0.6763252019882202\n",
      "Loss: 0.557969868183136 -1.024680256843567\n",
      "Policy Reward: tensor(1.1967, device='cuda:0')\n",
      "Trajectory:  ['0.27', '1.00', '0.02', '0.00', '0.00', '0.00', '0.00', '0.49', '0.99', '0.99', '0.94', '0.90', '0.88', '0.71', '0.46', '0.39', '0.43', '0.60', '0.87']\n",
      "Last Action:  tensor([0.8744, 0.3718, 0.5087, 0.1953, 0.3251, 0.7187, 0.4158, 0.4363, 0.3394,\n",
      "        0.6410], device='cuda:0')\n",
      "Loss: 0.4960438907146454 -1.3480429649353027\n",
      "Loss: 0.4637264609336853 -1.4002286195755005\n",
      "Loss: 0.45940062403678894 -1.0484707355499268\n",
      "Loss: 0.41449466347694397 -0.5654771327972412\n",
      "Loss: 0.4678017199039459 -0.927117109298706\n",
      "Loss: 0.4846478998661041 -0.8109678030014038\n",
      "Loss: 0.47983431816101074 -0.8811948895454407\n",
      "Policy Reward: tensor(1.1985, device='cuda:0')\n",
      "Trajectory:  ['0.33', '1.00', '0.12', '0.00', '0.00', '0.00', '0.00', '0.61', '0.99', '0.98', '0.90', '0.90', '0.91', '0.85', '0.61', '0.38', '0.40', '0.36', '0.43']\n",
      "Last Action:  tensor([0.4315, 0.4280, 0.7061, 0.4017, 0.8915, 0.5324, 0.4069, 0.6448, 0.3557,\n",
      "        0.2508], device='cuda:0')\n",
      "Loss: 0.503533124923706 -1.3186407089233398\n",
      "Loss: 0.4257912039756775 -1.063542127609253\n",
      "Loss: 0.43520796298980713 -0.7685568332672119\n",
      "Loss: 0.4292530119419098 -1.2242563962936401\n",
      "Loss: 0.44573697447776794 -1.1336078643798828\n",
      "Loss: 0.4471670091152191 -0.8687711358070374\n",
      "Loss: 0.45907360315322876 -0.937360405921936\n",
      "Policy Reward: tensor(1.1552, device='cuda:0')\n",
      "Trajectory:  ['0.18', '1.00', '0.01', '0.00', '0.00', '0.00', '0.00', '0.10', '0.78', '0.97', '0.99', '0.91', '0.87', '0.80', '0.62', '0.41', '0.38', '0.43', '0.66']\n",
      "Last Action:  tensor([0.6557, 0.4472, 0.3262, 0.2787, 0.4802, 0.4840, 0.5316, 0.6123, 0.3436,\n",
      "        0.4281], device='cuda:0')\n",
      "Loss: 0.41399651765823364 -0.9508440494537354\n",
      "Loss: 0.5300244092941284 -1.2343693971633911\n",
      "Loss: 0.39890700578689575 -0.7729393839836121\n",
      "Loss: 0.4065530002117157 -0.8043980002403259\n",
      "Loss: 0.42546093463897705 -1.1148817539215088\n",
      "Loss: 0.447261780500412 -0.7418864965438843\n",
      "Loss: 0.40356746315956116 -0.9546608924865723\n",
      "Policy Reward: tensor(1.1359, device='cuda:0')\n",
      "Trajectory:  ['0.08', '1.00', '0.01', '0.00', '0.00', '0.01', '0.02', '0.11', '0.38', '0.62', '0.87', '0.99', '0.94', '0.89', '0.91', '0.90', '0.80', '0.54', '0.37']\n",
      "Last Action:  tensor([0.3713, 0.5670, 0.5949, 0.4611, 0.5734, 0.2819, 0.1868, 0.5798, 0.2788,\n",
      "        0.9973], device='cuda:0')\n",
      "Loss: 0.43154001235961914 -1.5022865533828735\n",
      "Loss: 0.456773042678833 -1.205657720565796\n",
      "Loss: 0.4495699107646942 -1.0452792644500732\n",
      "Loss: 0.46044912934303284 -0.8786175847053528\n",
      "Loss: 0.45407557487487793 -0.8035065531730652\n",
      "Loss: 0.5290235877037048 -1.0812760591506958\n",
      "Loss: 0.5011447668075562 -1.2519108057022095\n",
      "Policy Reward: tensor(1.2144, device='cuda:0')\n",
      "Trajectory:  ['0.55', '0.74', '0.31', '0.03', '0.02', '0.05', '0.15', '0.36', '0.60', '0.69', '0.79', '0.89', '0.91', '0.90', '0.86', '0.73', '0.59', '0.68', '0.43']\n",
      "Last Action:  tensor([0.4348, 0.2920, 0.4444, 0.3133, 0.7469, 0.2644, 0.2776, 0.4231, 0.4259,\n",
      "        0.2927], device='cuda:0')\n",
      "Loss: 0.39416566491127014 -0.8539966344833374\n",
      "Loss: 0.3981364965438843 -0.9082266688346863\n",
      "Loss: 0.48705753684043884 -1.2610090970993042\n",
      "Loss: 0.4641478955745697 -1.478429913520813\n",
      "Loss: 0.4627586901187897 -1.1362981796264648\n",
      "Loss: 0.433933824300766 -1.0214377641677856\n",
      "Loss: 0.5118710398674011 -1.2580875158309937\n",
      "Policy Reward: tensor(1.2436, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.02', '0.00', '0.01', '0.02', '0.04', '0.13', '0.46', '0.86', '0.99', '0.97', '0.92', '0.93', '0.95', '0.91', '0.74', '0.51', '0.41']\n",
      "Last Action:  tensor([0.4138, 0.3962, 0.4931, 0.4049, 0.3366, 0.4281, 0.5933, 0.1458, 0.8674,\n",
      "        0.3807], device='cuda:0')\n",
      "Loss: 0.49176040291786194 -1.2983273267745972\n",
      "Loss: 0.42874348163604736 -0.7475149035453796\n",
      "Loss: 0.4310481548309326 -1.0517044067382812\n",
      "Loss: 0.4246816635131836 -1.1605685949325562\n",
      "Loss: 0.5382888913154602 -1.3233410120010376\n",
      "Loss: 0.4604387879371643 -0.7153648734092712\n",
      "Loss: 0.45241057872772217 -1.118186593055725\n",
      "Policy Reward: tensor(1.2287, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.99', '0.00', '0.00', '0.01', '0.01', '0.02', '0.07', '0.28', '0.50', '0.72', '0.90', '0.99', '0.97', '0.93', '0.92', '0.79', '0.53', '0.31']\n",
      "Last Action:  tensor([0.3148, 0.3322, 0.4320, 0.4153, 0.6107, 0.2986, 0.2400, 0.5091, 0.2606,\n",
      "        0.4238], device='cuda:0')\n",
      "Loss: 0.5081098675727844 -1.1321382522583008\n",
      "Loss: 0.4542040228843689 -1.4138017892837524\n",
      "Loss: 0.41080334782600403 -1.0435295104980469\n",
      "Loss: 0.4671103060245514 -1.270607829093933\n",
      "Loss: 0.40729787945747375 -1.0359357595443726\n",
      "Loss: 0.5059303641319275 -0.9903659820556641\n",
      "Loss: 0.5206122994422913 -0.9940576553344727\n",
      "Policy Reward: tensor(1.1685, device='cuda:0')\n",
      "Trajectory:  ['0.80', '1.00', '0.21', '0.00', '0.00', '0.00', '0.00', '0.38', '0.99', '0.99', '0.97', '0.94', '0.94', '0.84', '0.54', '0.44', '0.44', '0.38', '0.22']\n",
      "Last Action:  tensor([0.2191, 0.3029, 0.3941, 0.2955, 0.3158, 0.2922, 0.2058, 0.4842, 0.2377,\n",
      "        0.4748], device='cuda:0')\n",
      "Bigstep:  30\n",
      "Loss: 0.4196876287460327 -0.7028806209564209\n",
      "Loss: 0.49131155014038086 -1.0814489126205444\n",
      "Loss: 0.4525650143623352 -1.0818628072738647\n",
      "Loss: 0.4548250734806061 -1.1734602451324463\n",
      "Loss: 0.5262624025344849 -1.0568509101867676\n",
      "Loss: 0.4511544108390808 -1.1905571222305298\n",
      "Loss: 0.4332951307296753 -0.9194619655609131\n",
      "Policy Reward: tensor(1.2553, device='cuda:0')\n",
      "Trajectory:  ['0.23', '0.99', '0.10', '0.00', '0.00', '0.00', '0.16', '0.99', '0.99', '0.98', '0.92', '0.92', '0.89', '0.74', '0.50', '0.32', '0.39', '0.32', '0.59']\n",
      "Last Action:  tensor([0.5885, 0.3280, 0.3904, 0.1035, 0.3371, 0.3770, 0.9708, 0.4677, 0.1826,\n",
      "        0.3713], device='cuda:0')\n",
      "Loss: 0.3657609820365906 -0.7460229396820068\n",
      "Loss: 0.5377870202064514 -1.192598581314087\n",
      "Loss: 0.4691341817378998 -1.2002017498016357\n",
      "Loss: 0.3970223367214203 -1.0415877103805542\n",
      "Loss: 0.4733266234397888 -0.9390856027603149\n",
      "Loss: 0.44995784759521484 -1.0785106420516968\n",
      "Loss: 0.41220396757125854 -1.1784629821777344\n",
      "Policy Reward: tensor(1.0941, device='cuda:0')\n",
      "Trajectory:  ['0.41', '1.00', '0.02', '0.00', '0.00', '0.00', '0.00', '0.40', '0.97', '0.93', '0.76', '0.74', '0.77', '0.68', '0.47', '0.31', '0.36', '0.73', '0.98']\n",
      "Last Action:  tensor([0.9791, 0.3107, 0.4121, 0.5505, 0.8527, 0.7250, 0.8696, 0.2879, 0.3134,\n",
      "        0.8614], device='cuda:0')\n",
      "Loss: 0.49078884720802307 -1.5086414813995361\n",
      "Loss: 0.47315821051597595 -1.2793086767196655\n",
      "Loss: 0.38760891556739807 -0.7486805319786072\n",
      "Loss: 0.4059610366821289 -0.9969795346260071\n",
      "Loss: 0.4267292320728302 -1.1262726783752441\n",
      "Loss: 0.43765896558761597 -1.1478829383850098\n",
      "Loss: 0.4340212941169739 -1.0925198793411255\n",
      "Policy Reward: tensor(1.1270, device='cuda:0')\n",
      "Trajectory:  ['0.52', '1.00', '0.53', '0.00', '0.00', '0.00', '0.06', '0.98', '0.98', '0.98', '0.93', '0.86', '0.83', '0.77', '0.66', '0.49', '0.38', '0.33', '0.55']\n",
      "Last Action:  tensor([0.5516, 0.4393, 0.2419, 0.2613, 0.3435, 0.9612, 0.8838, 0.9717, 0.4175,\n",
      "        0.9418], device='cuda:0')\n",
      "Loss: 0.4279773533344269 -0.6154883503913879\n",
      "Loss: 0.515362560749054 -1.5557082891464233\n",
      "Loss: 0.5689051151275635 -1.4115002155303955\n",
      "Loss: 0.474176287651062 -1.4353203773498535\n",
      "Loss: 0.4830296039581299 -1.2956959009170532\n",
      "Loss: 0.5252559781074524 -1.2919645309448242\n",
      "Loss: 0.4204643666744232 -1.2253525257110596\n",
      "Policy Reward: tensor(1.1632, device='cuda:0')\n",
      "Trajectory:  ['0.13', '1.00', '0.01', '0.00', '0.00', '0.00', '0.00', '0.27', '0.96', '0.92', '0.78', '0.78', '0.82', '0.86', '0.80', '0.61', '0.34', '0.28', '0.32']\n",
      "Last Action:  tensor([0.3175, 0.4966, 0.9191, 0.1720, 0.2760, 0.5572, 0.3214, 0.7519, 0.9825,\n",
      "        0.2903], device='cuda:0')\n",
      "Loss: 0.463861882686615 -1.2490460872650146\n",
      "Loss: 0.4245406985282898 -0.9103295207023621\n",
      "Loss: 0.4741520285606384 -0.7161461114883423\n",
      "Loss: 0.512536346912384 -1.4665921926498413\n",
      "Loss: 0.401291161775589 -0.8256984353065491\n",
      "Loss: 0.44733965396881104 -1.1972615718841553\n",
      "Loss: 0.4088171124458313 -1.2059180736541748\n",
      "Policy Reward: tensor(1.1824, device='cuda:0')\n",
      "Trajectory:  ['0.32', '1.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.29', '0.96', '0.87', '0.80', '0.77', '0.77', '0.68', '0.46', '0.31', '0.25', '0.47', '0.97']\n",
      "Last Action:  tensor([0.9739, 0.3967, 0.5708, 0.3030, 0.1158, 0.3017, 0.5218, 0.3616, 0.6665,\n",
      "        0.2914], device='cuda:0')\n",
      "Loss: 0.4593256413936615 -1.2111790180206299\n",
      "Loss: 0.41998329758644104 -1.064181923866272\n",
      "Loss: 0.4589102268218994 -1.2715353965759277\n",
      "Loss: 0.48289260268211365 -1.3169349431991577\n",
      "Loss: 0.45013177394866943 -1.1697977781295776\n",
      "Loss: 0.4377839267253876 -1.2230831384658813\n",
      "Loss: 0.5123646259307861 -1.3610256910324097\n",
      "Policy Reward: tensor(1.2185, device='cuda:0')\n",
      "Trajectory:  ['0.02', '1.00', '0.00', '0.00', '0.01', '0.04', '0.16', '0.34', '0.49', '0.58', '0.59', '0.61', '0.78', '0.91', '0.97', '0.95', '0.84', '0.73', '0.61']\n",
      "Last Action:  tensor([0.6078, 0.2206, 0.2751, 0.8847, 0.3616, 0.6570, 0.5610, 0.5606, 0.3282,\n",
      "        0.9901], device='cuda:0')\n",
      "Loss: 0.5408291816711426 -1.5547027587890625\n",
      "Loss: 0.5294822454452515 -1.726188063621521\n",
      "Loss: 0.4590175151824951 -1.2720646858215332\n",
      "Loss: 0.4224587678909302 -1.3744843006134033\n",
      "Loss: 0.44935140013694763 -0.8988897204399109\n",
      "Loss: 0.42861703038215637 -1.2298133373260498\n",
      "Loss: 0.4764600098133087 -1.472166657447815\n",
      "Policy Reward: tensor(1.2126, device='cuda:0')\n",
      "Trajectory:  ['0.16', '1.00', '0.01', '0.01', '0.20', '0.52', '0.61', '0.64', '0.99', '1.00', '0.99', '0.95', '0.85', '0.70', '0.52', '0.46', '0.36', '0.31', '0.45']\n",
      "Last Action:  tensor([0.4454, 0.3240, 0.1736, 0.5550, 0.1717, 0.9964, 0.4603, 0.5802, 0.6377,\n",
      "        0.2887], device='cuda:0')\n",
      "Loss: 0.4869270920753479 -1.4609001874923706\n",
      "Loss: 0.3883751332759857 -0.7926375865936279\n",
      "Loss: 0.47348150610923767 -1.2397730350494385\n",
      "Loss: 0.40176019072532654 -1.280418872833252\n",
      "Loss: 0.4589745104312897 -1.1384648084640503\n",
      "Loss: 0.466595321893692 -1.1460862159729004\n",
      "Loss: 0.43889912962913513 -1.0295401811599731\n",
      "Policy Reward: tensor(1.1353, device='cuda:0')\n",
      "Trajectory:  ['0.55', '1.00', '0.17', '0.00', '0.00', '0.00', '0.08', '0.90', '0.89', '0.89', '0.94', '0.96', '0.96', '0.94', '0.82', '0.66', '0.41', '0.31', '0.50']\n",
      "Last Action:  tensor([0.4996, 0.2001, 0.6742, 0.3696, 0.2168, 0.5881, 0.3814, 0.8148, 0.8845,\n",
      "        0.7172], device='cuda:0')\n",
      "Bigstep:  31\n",
      "Loss: 0.4735219180583954 -0.902145504951477\n",
      "Loss: 0.43516305088996887 -0.600429356098175\n",
      "Loss: 0.4916408956050873 -1.1520706415176392\n",
      "Loss: 0.4763374328613281 -0.7585036158561707\n",
      "Loss: 0.4686497747898102 -1.0980228185653687\n",
      "Loss: 0.47655558586120605 -0.8657392263412476\n",
      "Loss: 0.43501248955726624 -1.1622233390808105\n",
      "Policy Reward: tensor(1.1563, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.99', '0.00', '0.00', '0.01', '0.02', '0.06', '0.23', '0.66', '0.79', '0.71', '0.78', '0.82', '0.84', '0.84', '0.74', '0.61', '0.45', '0.41']\n",
      "Last Action:  tensor([0.4090, 0.8603, 0.6623, 0.9579, 0.7906, 0.3963, 0.9761, 0.7560, 0.9403,\n",
      "        0.6700], device='cuda:0')\n",
      "Loss: 0.4985401928424835 -1.1218210458755493\n",
      "Loss: 0.48165181279182434 -0.8192925453186035\n",
      "Loss: 0.3860441744327545 -0.41902628540992737\n",
      "Loss: 0.4980882406234741 -0.7565032243728638\n",
      "Loss: 0.5137043595314026 -1.3535810708999634\n",
      "Loss: 0.461038202047348 -0.9266397953033447\n",
      "Loss: 0.43270862102508545 -0.7945395708084106\n",
      "Policy Reward: tensor(1.0760, device='cuda:0')\n",
      "Trajectory:  ['0.87', '0.77', '0.52', '0.28', '0.18', '0.19', '0.86', '0.79', '0.85', '0.71', '0.33', '0.22', '0.33', '0.65', '0.90', '0.90', '0.70', '0.48', '0.47']\n",
      "Last Action:  tensor([0.4660, 0.8859, 0.7700, 0.9952, 0.8702, 0.2123, 0.9756, 0.9920, 0.9864,\n",
      "        0.3774], device='cuda:0')\n",
      "Loss: 0.4558432996273041 -0.9618389010429382\n",
      "Loss: 0.5612586140632629 -1.1845247745513916\n",
      "Loss: 0.4822479486465454 -1.4296385049819946\n",
      "Loss: 0.46409371495246887 -0.9925453066825867\n",
      "Loss: 0.46958982944488525 -1.0121865272521973\n",
      "Loss: 0.4558263421058655 -1.2417895793914795\n",
      "Loss: 0.4302726089954376 -1.123876929283142\n",
      "Policy Reward: tensor(1.1133, device='cuda:0')\n",
      "Trajectory:  ['0.88', '0.74', '0.51', '0.20', '0.14', '0.39', '0.84', '0.71', '0.74', '0.61', '0.43', '0.45', '0.55', '0.83', '0.96', '0.70', '0.45', '0.31', '0.73']\n",
      "Last Action:  tensor([0.7258, 0.5784, 0.6412, 0.6830, 0.9526, 0.9807, 0.4333, 0.9488, 0.3227,\n",
      "        0.7399], device='cuda:0')\n",
      "Loss: 0.4994423985481262 -1.1341023445129395\n",
      "Loss: 0.5431354641914368 -1.0604413747787476\n",
      "Loss: 0.4103086292743683 -1.2451261281967163\n",
      "Loss: 0.4309510588645935 -1.029916763305664\n",
      "Loss: 0.46400168538093567 -1.037575602531433\n",
      "Loss: 0.45276713371276855 -0.9382747411727905\n",
      "Loss: 0.45429983735084534 -1.120845079421997\n",
      "Policy Reward: tensor(1.0704, device='cuda:0')\n",
      "Trajectory:  ['0.86', '0.92', '0.48', '0.08', '0.28', '0.72', '0.62', '0.89', '0.95', '0.77', '0.48', '0.44', '0.51', '0.63', '0.86', '0.95', '0.83', '0.58', '0.43']\n",
      "Last Action:  tensor([0.4345, 0.5110, 0.4000, 0.6533, 0.9927, 0.7354, 0.9466, 0.7566, 0.7556,\n",
      "        0.8672], device='cuda:0')\n",
      "Loss: 0.46010860800743103 -1.010861873626709\n",
      "Loss: 0.49989205598831177 -1.2095673084259033\n",
      "Loss: 0.4954896867275238 -0.9797161817550659\n",
      "Loss: 0.4744424521923065 -0.8968266248703003\n",
      "Loss: 0.4486050307750702 -1.1326956748962402\n",
      "Loss: 0.46460413932800293 -1.2061033248901367\n",
      "Loss: 0.4192567467689514 -1.0338079929351807\n",
      "Policy Reward: tensor(1.1275, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.01', '0.00', '0.01', '0.05', '0.18', '0.46', '0.86', '0.73', '0.99', '0.95', '0.90', '0.84', '0.74', '0.52', '0.47', '0.48', '0.48']\n",
      "Last Action:  tensor([0.4750, 0.9851, 0.8172, 0.3060, 0.5958, 0.4887, 0.9902, 0.3778, 0.4730,\n",
      "        0.9386], device='cuda:0')\n",
      "Loss: 0.44989243149757385 -0.9224329590797424\n",
      "Loss: 0.4595984220504761 -1.3453483581542969\n",
      "Loss: 0.46093523502349854 -0.9831532835960388\n",
      "Loss: 0.4979088306427002 -0.9403374195098877\n",
      "Loss: 0.4586394727230072 -1.1380174160003662\n",
      "Loss: 0.5072165131568909 -1.2343556880950928\n",
      "Loss: 0.4233100414276123 -1.0495448112487793\n",
      "Policy Reward: tensor(1.1045, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.99', '0.00', '0.00', '0.00', '0.01', '0.02', '0.06', '0.29', '0.79', '0.84', '0.79', '0.90', '0.91', '0.79', '0.62', '0.41', '0.28', '0.34']\n",
      "Last Action:  tensor([0.3359, 0.4641, 0.6464, 0.4202, 0.9681, 0.5631, 0.6090, 0.5635, 0.7620,\n",
      "        0.9737], device='cuda:0')\n",
      "Loss: 0.45725587010383606 -1.052678108215332\n",
      "Loss: 0.4639364778995514 -0.6483539342880249\n",
      "Loss: 0.4483625888824463 -1.119459629058838\n",
      "Loss: 0.42899537086486816 -0.960135817527771\n",
      "Loss: 0.40981629490852356 -0.8955264687538147\n",
      "Loss: 0.5072277188301086 -1.3624422550201416\n",
      "Loss: 0.41587314009666443 -1.003848671913147\n",
      "Policy Reward: tensor(1.1135, device='cuda:0')\n",
      "Trajectory:  ['0.83', '0.98', '0.56', '0.10', '0.21', '0.78', '0.59', '0.66', '0.83', '0.71', '0.47', '0.43', '0.48', '0.55', '0.62', '0.68', '0.64', '0.53', '0.44']\n",
      "Last Action:  tensor([0.4369, 0.8564, 0.3624, 0.9680, 0.8544, 0.9556, 0.6673, 0.4252, 0.7199,\n",
      "        0.2287], device='cuda:0')\n",
      "Loss: 0.385410338640213 -1.0069403648376465\n",
      "Loss: 0.5640745162963867 -1.2257190942764282\n",
      "Loss: 0.41682249307632446 -1.0592633485794067\n",
      "Loss: 0.45176753401756287 -1.0643240213394165\n",
      "Loss: 0.4749780297279358 -1.148274540901184\n",
      "Loss: 0.3862514793872833 -0.7436648607254028\n",
      "Loss: 0.5074397921562195 -1.2636977434158325\n",
      "Policy Reward: tensor(1.1319, device='cuda:0')\n",
      "Trajectory:  ['0.52', '1.00', '0.23', '0.00', '0.01', '0.02', '0.80', '1.00', '0.99', '0.98', '0.93', '0.84', '0.65', '0.55', '0.50', '0.53', '0.80', '0.89', '0.96']\n",
      "Last Action:  tensor([0.9613, 0.9889, 0.9556, 0.9674, 0.9533, 0.3579, 0.9536, 0.6173, 0.6660,\n",
      "        0.3530], device='cuda:0')\n",
      "Bigstep:  32\n",
      "Loss: 0.5026763081550598 -0.7312392592430115\n",
      "Loss: 0.48620912432670593 -0.3278637230396271\n",
      "Loss: 0.4259338080883026 -0.6650299429893494\n",
      "Loss: 0.5260598659515381 -1.0040982961654663\n",
      "Loss: 0.42717114090919495 -0.873989462852478\n",
      "Loss: 0.4523065686225891 -0.9489248991012573\n",
      "Loss: 0.46800658106803894 -0.8374793529510498\n",
      "Policy Reward: tensor(1.1636, device='cuda:0')\n",
      "Trajectory:  ['0.53', '1.00', '0.18', '0.00', '0.00', '0.00', '0.03', '0.57', '0.91', '0.87', '0.78', '0.70', '0.65', '0.61', '0.50', '0.31', '0.24', '0.70', '0.99']\n",
      "Last Action:  tensor([0.9933, 0.9862, 0.9734, 0.8839, 0.9786, 0.9929, 0.9234, 0.8369, 0.4113,\n",
      "        0.3534], device='cuda:0')\n",
      "Loss: 0.44766533374786377 -0.9583232998847961\n",
      "Loss: 0.5055492520332336 -1.0149281024932861\n",
      "Loss: 0.4156857430934906 -0.9554605484008789\n",
      "Loss: 0.48863810300827026 -1.0349668264389038\n",
      "Loss: 0.457710325717926 -0.8758488893508911\n",
      "Loss: 0.4536103308200836 -0.5165817141532898\n",
      "Loss: 0.5219018459320068 -0.9867408871650696\n",
      "Policy Reward: tensor(1.1921, device='cuda:0')\n",
      "Trajectory:  ['0.82', '1.00', '0.30', '0.03', '0.57', '0.62', '0.34', '0.54', '0.63', '0.69', '0.66', '0.51', '0.39', '0.36', '0.40', '0.51', '0.59', '0.55', '0.56']\n",
      "Last Action:  tensor([0.5600, 0.9799, 0.9927, 0.9779, 0.7977, 0.9570, 0.9704, 0.9959, 0.1176,\n",
      "        0.8927], device='cuda:0')\n",
      "Loss: 0.48818239569664 -0.9731810688972473\n",
      "Loss: 0.5000208020210266 -0.8158120512962341\n",
      "Loss: 0.47189846634864807 -1.0451788902282715\n",
      "Loss: 0.399344801902771 -0.6857239603996277\n",
      "Loss: 0.49591249227523804 -0.889406681060791\n",
      "Loss: 0.5238205194473267 -0.9448925256729126\n",
      "Loss: 0.4378478527069092 -1.021636724472046\n",
      "Policy Reward: tensor(1.1425, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.00', '0.00', '0.00', '0.01', '0.02', '0.07', '0.41', '0.64', '0.58', '0.75', '0.86', '0.87', '0.79', '0.59', '0.48', '0.33', '0.14']\n",
      "Last Action:  tensor([0.1417, 0.8585, 0.9572, 0.9868, 0.9586, 0.8855, 0.5594, 0.3399, 0.6615,\n",
      "        0.4618], device='cuda:0')\n",
      "Loss: 0.4809491038322449 -1.1136655807495117\n",
      "Loss: 0.49010246992111206 -1.0938650369644165\n",
      "Loss: 0.44212716817855835 -1.418952226638794\n",
      "Loss: 0.437736839056015 -1.2434390783309937\n",
      "Loss: 0.5148387551307678 -0.8772695660591125\n",
      "Loss: 0.35559388995170593 -0.6245116591453552\n",
      "Loss: 0.4807342290878296 -0.897821307182312\n",
      "Policy Reward: tensor(1.1754, device='cuda:0')\n",
      "Trajectory:  ['0.54', '1.00', '0.05', '0.00', '0.00', '0.00', '0.05', '0.77', '0.90', '0.93', '0.87', '0.77', '0.66', '0.60', '0.48', '0.22', '0.28', '0.86', '1.00']\n",
      "Last Action:  tensor([0.9959, 0.6741, 0.7343, 0.3102, 0.5886, 0.4748, 0.9896, 0.7776, 0.2986,\n",
      "        0.4813], device='cuda:0')\n",
      "Loss: 0.4127235412597656 -0.8425859808921814\n",
      "Loss: 0.5173975229263306 -1.0110223293304443\n",
      "Loss: 0.480987548828125 -1.266405701637268\n",
      "Loss: 0.43283262848854065 -1.013501524925232\n",
      "Loss: 0.39655745029449463 -0.7367403507232666\n",
      "Loss: 0.43301042914390564 -1.0372692346572876\n",
      "Loss: 0.4286274015903473 -0.8872586488723755\n",
      "Policy Reward: tensor(1.1230, device='cuda:0')\n",
      "Trajectory:  ['0.02', '1.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.08', '0.52', '0.72', '0.88', '0.89', '0.74', '0.49', '0.30', '0.14', '0.14', '0.87']\n",
      "Last Action:  tensor([0.8684, 0.2291, 0.9809, 0.9880, 0.7567, 0.6921, 0.9869, 0.3226, 0.1561,\n",
      "        0.5275], device='cuda:0')\n",
      "Loss: 0.45881059765815735 -1.2065509557724\n",
      "Loss: 0.4131128787994385 -0.7801770567893982\n",
      "Loss: 0.4879790246486664 -1.5473196506500244\n",
      "Loss: 0.4778487980365753 -1.2175015211105347\n",
      "Loss: 0.41409415006637573 -0.6975404620170593\n",
      "Loss: 0.45404133200645447 -1.0338551998138428\n",
      "Loss: 0.41036441922187805 -1.0622142553329468\n",
      "Policy Reward: tensor(1.0934, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.00', '0.00', '0.00', '0.01', '0.02', '0.12', '0.30', '0.46', '0.47', '0.66', '0.82', '0.96', '0.96', '0.85', '0.60', '0.37', '0.23']\n",
      "Last Action:  tensor([0.2280, 0.9616, 0.5637, 0.1809, 0.9799, 0.9506, 0.3592, 0.4732, 0.7531,\n",
      "        0.9210], device='cuda:0')\n",
      "Loss: 0.4540204703807831 -1.0625487565994263\n",
      "Loss: 0.43706899881362915 -1.2857862710952759\n",
      "Loss: 0.474364310503006 -0.875997006893158\n",
      "Loss: 0.4742048382759094 -1.0458050966262817\n",
      "Loss: 0.4303995370864868 -1.0259907245635986\n",
      "Loss: 0.4677612781524658 -0.7957251667976379\n",
      "Loss: 0.5153865814208984 -1.1439327001571655\n",
      "Policy Reward: tensor(1.2064, device='cuda:0')\n",
      "Trajectory:  ['0.61', '1.00', '0.40', '0.09', '0.22', '0.90', '0.48', '0.72', '0.79', '0.68', '0.36', '0.22', '0.17', '0.17', '0.92', '1.00', '0.97', '0.70', '0.37']\n",
      "Last Action:  tensor([0.3739, 0.7189, 0.7749, 0.1179, 0.9662, 0.9106, 0.9825, 0.3616, 0.4216,\n",
      "        0.3066], device='cuda:0')\n",
      "Loss: 0.5433228611946106 -1.4956005811691284\n",
      "Loss: 0.37723666429519653 -0.4872981309890747\n",
      "Loss: 0.486175537109375 -1.0704561471939087\n",
      "Loss: 0.4193066656589508 -1.0409820079803467\n",
      "Loss: 0.4781281352043152 -0.81700599193573\n",
      "Loss: 0.5273886919021606 -1.0669341087341309\n",
      "Loss: 0.5372949838638306 -1.2294681072235107\n",
      "Policy Reward: tensor(1.2468, device='cuda:0')\n",
      "Trajectory:  ['0.43', '1.00', '0.07', '0.00', '0.00', '0.00', '0.00', '0.17', '0.85', '0.82', '0.76', '0.71', '0.67', '0.57', '0.43', '0.24', '0.25', '0.77', '0.98']\n",
      "Last Action:  tensor([0.9835, 0.5842, 0.6658, 0.9745, 0.9959, 0.2862, 0.2233, 0.6688, 0.9964,\n",
      "        0.6722], device='cuda:0')\n",
      "Bigstep:  33\n",
      "Loss: 0.441214382648468 -0.18189848959445953\n",
      "Loss: 0.45295608043670654 -0.45821815729141235\n",
      "Loss: 0.4903876781463623 -0.8676508069038391\n",
      "Loss: 0.42567673325538635 -0.5125250220298767\n",
      "Loss: 0.4003809094429016 -0.6183844208717346\n",
      "Loss: 0.39778536558151245 -0.34937265515327454\n",
      "Loss: 0.5385311841964722 -0.7936782836914062\n",
      "Policy Reward: tensor(1.1681, device='cuda:0')\n",
      "Trajectory:  ['0.53', '1.00', '0.26', '0.03', '0.21', '0.68', '0.70', '0.94', '0.99', '0.97', '0.81', '0.57', '0.57', '0.61', '0.65', '0.70', '0.78', '0.87', '0.94']\n",
      "Last Action:  tensor([0.9438, 0.6807, 0.3209, 0.7539, 0.8739, 0.9534, 0.9779, 0.9455, 0.9766,\n",
      "        0.9270], device='cuda:0')\n",
      "Loss: 0.4757489562034607 -0.8604615926742554\n",
      "Loss: 0.4169662594795227 -1.1310667991638184\n",
      "Loss: 0.4252917170524597 -0.9734959602355957\n",
      "Loss: 0.45816242694854736 -0.8794899582862854\n",
      "Loss: 0.4302815794944763 -0.9460265636444092\n",
      "Loss: 0.3277527093887329 -0.6098300814628601\n",
      "Loss: 0.3971412777900696 -0.9786767959594727\n",
      "Policy Reward: tensor(1.0913, device='cuda:0')\n",
      "Trajectory:  ['0.36', '1.00', '0.02', '0.00', '0.18', '0.42', '0.44', '0.62', '0.83', '0.96', '0.95', '0.81', '0.59', '0.46', '0.45', '0.48', '0.58', '0.76', '0.87']\n",
      "Last Action:  tensor([0.8702, 0.5054, 0.7927, 0.9756, 0.6528, 0.9825, 0.9888, 0.9385, 0.5100,\n",
      "        0.7541], device='cuda:0')\n",
      "Loss: 0.39386945962905884 -0.7921848297119141\n",
      "Loss: 0.5159708857536316 -1.0515472888946533\n",
      "Loss: 0.43032124638557434 -1.0356698036193848\n",
      "Loss: 0.4068445861339569 -0.7883836030960083\n",
      "Loss: 0.45827335119247437 -1.2007578611373901\n",
      "Loss: 0.39026111364364624 -1.0883111953735352\n",
      "Loss: 0.4630241096019745 -0.8643772006034851\n",
      "Policy Reward: tensor(1.1647, device='cuda:0')\n",
      "Trajectory:  ['0.70', '1.00', '0.20', '0.20', '0.52', '0.58', '0.53', '0.66', '0.75', '0.81', '0.69', '0.39', '0.38', '0.55', '0.78', '0.78', '0.71', '0.66', '0.65']\n",
      "Last Action:  tensor([0.6513, 0.8410, 0.9291, 0.5365, 0.5041, 0.9468, 0.4567, 0.4694, 0.7124,\n",
      "        0.5539], device='cuda:0')\n",
      "Loss: 0.4512386620044708 -0.6413001418113708\n",
      "Loss: 0.4650827646255493 -0.9186586737632751\n",
      "Loss: 0.45692214369773865 -1.1182312965393066\n",
      "Loss: 0.4594397246837616 -1.2326302528381348\n",
      "Loss: 0.4003327786922455 -0.5614332556724548\n",
      "Loss: 0.4310941696166992 -0.8139875531196594\n",
      "Loss: 0.45549312233924866 -0.8254237174987793\n",
      "Policy Reward: tensor(1.0980, device='cuda:0')\n",
      "Trajectory:  ['0.54', '1.00', '0.18', '0.01', '0.08', '0.39', '0.73', '0.94', '0.99', '0.98', '0.85', '0.62', '0.48', '0.49', '0.49', '0.51', '0.71', '0.91', '0.92']\n",
      "Last Action:  tensor([0.9190, 0.8070, 0.8341, 0.4921, 0.9230, 0.8135, 0.9113, 0.5000, 0.3293,\n",
      "        0.9571], device='cuda:0')\n",
      "Loss: 0.4325019419193268 -0.5849908590316772\n",
      "Loss: 0.5289074182510376 -1.3519494533538818\n",
      "Loss: 0.4069229066371918 -0.71583092212677\n",
      "Loss: 0.3810928761959076 -0.5955113172531128\n",
      "Loss: 0.4552145302295685 -0.8324615359306335\n",
      "Loss: 0.37706440687179565 -0.6722834706306458\n",
      "Loss: 0.44851529598236084 -0.8460083603858948\n",
      "Policy Reward: tensor(1.1439, device='cuda:0')\n",
      "Trajectory:  ['0.58', '1.00', '0.23', '0.01', '0.42', '0.79', '0.65', '0.93', '0.98', '0.96', '0.82', '0.59', '0.42', '0.43', '0.44', '0.57', '0.82', '0.95', '0.92']\n",
      "Last Action:  tensor([0.9233, 0.9490, 0.9402, 0.5855, 0.7394, 0.8315, 0.4157, 0.8412, 0.9404,\n",
      "        0.9645], device='cuda:0')\n",
      "Loss: 0.47881361842155457 -1.0742771625518799\n",
      "Loss: 0.4205828309059143 -1.304559588432312\n",
      "Loss: 0.4444802701473236 -1.09502112865448\n",
      "Loss: 0.4513884484767914 -1.1561110019683838\n",
      "Loss: 0.4515601098537445 -1.0131152868270874\n",
      "Loss: 0.42183008790016174 -0.8591986894607544\n",
      "Loss: 0.4370773732662201 -1.0556069612503052\n",
      "Policy Reward: tensor(1.1340, device='cuda:0')\n",
      "Trajectory:  ['0.23', '0.96', '0.49', '0.05', '0.63', '0.97', '0.97', '0.98', '0.92', '0.62', '0.47', '0.48', '0.63', '0.84', '0.95', '0.84', '0.55', '0.33', '0.82']\n",
      "Last Action:  tensor([0.8206, 0.9384, 0.9616, 0.8898, 0.9066, 0.8811, 0.2853, 0.6128, 0.6835,\n",
      "        0.3798], device='cuda:0')\n",
      "Loss: 0.48809006810188293 -1.3932570219039917\n",
      "Loss: 0.44058355689048767 -1.1474575996398926\n",
      "Loss: 0.5039363503456116 -1.0430160760879517\n",
      "Loss: 0.4342503249645233 -0.9433432221412659\n",
      "Loss: 0.48115274310112 -1.203626036643982\n",
      "Loss: 0.4424753487110138 -0.8970457911491394\n",
      "Loss: 0.44254085421562195 -1.0105149745941162\n",
      "Policy Reward: tensor(1.1251, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.08', '0.06', '0.40', '0.64', '0.49', '0.77', '0.94', '0.99', '0.95', '0.59', '0.32', '0.37', '0.62', '0.97', '0.99', '0.91', '0.60']\n",
      "Last Action:  tensor([0.6021, 0.3265, 0.9197, 0.5825, 0.7533, 0.5769, 0.7470, 0.9418, 0.4950,\n",
      "        0.9555], device='cuda:0')\n",
      "Loss: 0.454149067401886 -1.2025610208511353\n",
      "Loss: 0.4781140387058258 -0.9825200438499451\n",
      "Loss: 0.3978723883628845 -0.9372270703315735\n",
      "Loss: 0.41216015815734863 -1.2240186929702759\n",
      "Loss: 0.4864968955516815 -0.978587806224823\n",
      "Loss: 0.4899163246154785 -1.4239349365234375\n",
      "Loss: 0.39863115549087524 -1.1955617666244507\n",
      "Policy Reward: tensor(1.1291, device='cuda:0')\n",
      "Trajectory:  ['0.42', '1.00', '0.04', '0.00', '0.13', '0.41', '0.51', '0.73', '0.90', '0.94', '0.85', '0.70', '0.53', '0.43', '0.38', '0.41', '0.76', '0.94', '0.92']\n",
      "Last Action:  tensor([0.9202, 0.8108, 0.9799, 0.8947, 0.9572, 0.6713, 0.9239, 0.8416, 0.6180,\n",
      "        0.9516], device='cuda:0')\n",
      "Bigstep:  34\n",
      "Loss: 0.4881090521812439 -0.6531899571418762\n",
      "Loss: 0.4147407114505768 -0.695374071598053\n",
      "Loss: 0.38176417350769043 -0.5324245691299438\n",
      "Loss: 0.38580143451690674 -0.47730183601379395\n",
      "Loss: 0.42149055004119873 -0.5270012021064758\n",
      "Loss: 0.4442631006240845 -0.6034452319145203\n",
      "Loss: 0.3177162706851959 -0.46917328238487244\n",
      "Policy Reward: tensor(1.2235, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.49', '0.30', '0.63', '0.90', '0.99', '0.99', '0.88', '0.60', '0.48', '0.72', '0.94', '0.85', '0.69', '0.68', '0.84', '0.91', '0.80']\n",
      "Last Action:  tensor([0.8015, 0.9500, 0.5934, 0.9341, 0.9194, 0.7589, 0.9358, 0.5169, 0.9360,\n",
      "        0.8455], device='cuda:0')\n",
      "Loss: 0.5143821239471436 -1.0126147270202637\n",
      "Loss: 0.3818669617176056 -0.5684831142425537\n",
      "Loss: 0.4800736904144287 -0.8778389096260071\n",
      "Loss: 0.362224280834198 -0.3186323344707489\n",
      "Loss: 0.41644906997680664 -0.9702509045600891\n",
      "Loss: 0.4574333429336548 -1.0047907829284668\n",
      "Loss: 0.4689003825187683 -0.5705240964889526\n",
      "Policy Reward: tensor(1.2011, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.99', '0.00', '0.00', '0.01', '0.02', '0.09', '0.21', '0.36', '0.48', '0.57', '0.70', '0.88', '0.98', '0.99', '0.94', '0.82', '0.70', '0.59']\n",
      "Last Action:  tensor([0.5860, 0.8791, 0.5371, 0.8637, 0.6325, 0.8242, 0.7970, 0.7937, 0.6262,\n",
      "        0.7265], device='cuda:0')\n",
      "Loss: 0.45532241463661194 -0.7651077508926392\n",
      "Loss: 0.45442527532577515 -0.7804973125457764\n",
      "Loss: 0.48247644305229187 -1.0560758113861084\n",
      "Loss: 0.38765206933021545 -0.634628176689148\n",
      "Loss: 0.41325947642326355 -0.9298282861709595\n",
      "Loss: 0.33769115805625916 -0.17604167759418488\n",
      "Loss: 0.41776221990585327 -0.8318682909011841\n",
      "Policy Reward: tensor(1.1093, device='cuda:0')\n",
      "Trajectory:  ['0.58', '1.00', '0.48', '0.01', '0.49', '0.93', '0.89', '0.99', '1.00', '1.00', '1.00', '0.99', '0.97', '0.94', '0.87', '0.82', '0.86', '0.88', '0.87']\n",
      "Last Action:  tensor([0.8675, 0.6496, 0.9358, 0.7919, 0.8656, 0.8830, 0.7554, 0.9369, 0.9378,\n",
      "        0.8725], device='cuda:0')\n",
      "Loss: 0.4076426327228546 -0.7089118361473083\n",
      "Loss: 0.4290132522583008 -0.8840996026992798\n",
      "Loss: 0.44670507311820984 -1.0333091020584106\n",
      "Loss: 0.4414229989051819 -0.7307291030883789\n",
      "Loss: 0.42408666014671326 -0.9010240435600281\n",
      "Loss: 0.3829074203968048 -0.7541159987449646\n",
      "Loss: 0.4063449800014496 -0.9277849197387695\n",
      "Policy Reward: tensor(1.0439, device='cuda:0')\n",
      "Trajectory:  ['0.42', '1.00', '0.11', '0.01', '0.37', '0.70', '0.90', '0.99', '1.00', '1.00', '0.99', '0.97', '0.92', '0.88', '0.81', '0.70', '0.65', '0.74', '0.89']\n",
      "Last Action:  tensor([0.8918, 0.9699, 0.7930, 0.7929, 0.5212, 0.5771, 0.6096, 0.7453, 0.9213,\n",
      "        0.6049], device='cuda:0')\n",
      "Loss: 0.38182103633880615 -0.51134192943573\n",
      "Loss: 0.4321171045303345 -0.7145411372184753\n",
      "Loss: 0.3855438530445099 -0.549538791179657\n",
      "Loss: 0.3910726308822632 -0.6686877608299255\n",
      "Loss: 0.4517650306224823 -0.6556524038314819\n",
      "Loss: 0.38581979274749756 -0.5388745665550232\n",
      "Loss: 0.40698593854904175 -0.8924822807312012\n",
      "Policy Reward: tensor(1.0678, device='cuda:0')\n",
      "Trajectory:  ['0.41', '1.00', '0.29', '0.02', '0.93', '0.92', '0.96', '1.00', '1.00', '0.95', '0.81', '0.78', '0.85', '0.94', '0.84', '0.72', '0.68', '0.84', '0.94']\n",
      "Last Action:  tensor([0.9362, 0.6551, 0.8663, 0.6311, 0.5259, 0.7311, 0.8155, 0.8399, 0.7506,\n",
      "        0.7972], device='cuda:0')\n",
      "Loss: 0.453933447599411 -1.095282793045044\n",
      "Loss: 0.497111976146698 -0.820785641670227\n",
      "Loss: 0.40019047260284424 -0.7700230479240417\n",
      "Loss: 0.394855260848999 -0.8227266669273376\n",
      "Loss: 0.4312971532344818 -0.8480867743492126\n",
      "Loss: 0.44328659772872925 -0.8029966950416565\n",
      "Loss: 0.4274311065673828 -0.5119001269340515\n",
      "Policy Reward: tensor(1.1581, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.99', '0.00', '0.01', '0.04', '0.19', '0.51', '0.82', '0.83', '0.89', '0.98', '1.00', '0.98', '0.85', '0.73', '0.74', '0.76', '0.73', '0.63']\n",
      "Last Action:  tensor([0.6335, 0.6366, 0.8764, 0.6987, 0.9063, 0.4344, 0.8355, 0.8689, 0.8788,\n",
      "        0.7194], device='cuda:0')\n",
      "Loss: 0.3697679340839386 -0.5322452187538147\n",
      "Loss: 0.4108499586582184 -0.9140032529830933\n",
      "Loss: 0.40468037128448486 -0.6611957550048828\n",
      "Loss: 0.4176362156867981 -0.7982518076896667\n",
      "Loss: 0.4282074570655823 -0.25678110122680664\n",
      "Loss: 0.43251654505729675 -0.9904127717018127\n",
      "Loss: 0.38158032298088074 -1.0468493700027466\n",
      "Policy Reward: tensor(1.1299, device='cuda:0')\n",
      "Trajectory:  ['0.19', '1.00', '0.06', '0.18', '0.62', '0.71', '0.78', '0.86', '0.92', '0.96', '0.93', '0.81', '0.61', '0.64', '0.69', '0.64', '0.60', '0.58', '0.59']\n",
      "Last Action:  tensor([0.5930, 0.8979, 0.7499, 0.8648, 0.9462, 0.4846, 0.8667, 0.8581, 0.9623,\n",
      "        0.5996], device='cuda:0')\n",
      "Loss: 0.4130723476409912 -0.8584508895874023\n",
      "Loss: 0.3380260765552521 -0.4799571633338928\n",
      "Loss: 0.3971495032310486 -0.5051119327545166\n",
      "Loss: 0.4679930806159973 -0.7190362811088562\n",
      "Loss: 0.48545965552330017 -0.8316869735717773\n",
      "Loss: 0.3669637143611908 -0.9150088429450989\n",
      "Loss: 0.40105122327804565 -0.5800408124923706\n",
      "Policy Reward: tensor(1.1569, device='cuda:0')\n",
      "Trajectory:  ['0.60', '1.00', '0.56', '0.09', '0.63', '0.88', '0.90', '0.97', '0.98', '0.95', '0.81', '0.66', '0.64', '0.70', '0.74', '0.69', '0.63', '0.62', '0.67']\n",
      "Last Action:  tensor([0.6674, 0.5352, 0.9373, 0.9744, 0.8321, 0.4945, 0.6925, 0.7317, 0.7589,\n",
      "        0.8088], device='cuda:0')\n",
      "Bigstep:  35\n",
      "Loss: 0.4537162780761719 -0.5682183504104614\n",
      "Loss: 0.3624946177005768 0.1476161926984787\n",
      "Loss: 0.4151119291782379 -0.44159236550331116\n",
      "Loss: 0.3414595425128937 -0.10798095166683197\n",
      "Loss: 0.3821578919887543 -0.41749364137649536\n",
      "Loss: 0.33995434641838074 -0.35662710666656494\n",
      "Loss: 0.4135511815547943 -0.6774745583534241\n",
      "Policy Reward: tensor(1.0763, device='cuda:0')\n",
      "Trajectory:  ['0.24', '1.00', '0.15', '0.08', '0.67', '0.81', '0.97', '1.00', '1.00', '1.00', '1.00', '0.99', '0.98', '0.95', '0.92', '0.85', '0.84', '0.94', '0.97']\n",
      "Last Action:  tensor([0.9723, 0.9662, 0.9644, 0.7799, 0.8787, 0.8833, 0.9431, 0.9319, 0.9662,\n",
      "        0.9786], device='cuda:0')\n",
      "Loss: 0.38679200410842896 -0.7128658890724182\n",
      "Loss: 0.3349594175815582 -0.3895764946937561\n",
      "Loss: 0.3739685118198395 -0.3751254975795746\n",
      "Loss: 0.3637857139110565 -0.42148280143737793\n",
      "Loss: 0.31855669617652893 -0.3351643681526184\n",
      "Loss: 0.41690802574157715 -0.6048257946968079\n",
      "Loss: 0.4329226613044739 -0.8555944561958313\n",
      "Policy Reward: tensor(1.1150, device='cuda:0')\n",
      "Trajectory:  ['0.67', '0.85', '0.87', '0.28', '0.46', '0.87', '0.99', '1.00', '1.00', '1.00', '1.00', '0.98', '0.97', '0.95', '0.93', '0.93', '0.95', '0.96', '0.97']\n",
      "Last Action:  tensor([0.9704, 0.8820, 0.9663, 0.9732, 0.9644, 0.9598, 0.4853, 0.8562, 0.7810,\n",
      "        0.8696], device='cuda:0')\n",
      "Loss: 0.3761182725429535 -0.4762457609176636\n",
      "Loss: 0.4397145211696625 -0.47631388902664185\n",
      "Loss: 0.3923640847206116 -0.7448074221611023\n",
      "Loss: 0.44220876693725586 -0.5937678813934326\n",
      "Loss: 0.436913400888443 -0.7061780691146851\n",
      "Loss: 0.49211183190345764 -0.6886863708496094\n",
      "Loss: 0.42528036236763 -0.7507444024085999\n",
      "Policy Reward: tensor(1.1302, device='cuda:0')\n",
      "Trajectory:  ['0.04', '1.00', '0.02', '0.25', '0.52', '0.61', '0.65', '0.78', '0.97', '1.00', '1.00', '1.00', '1.00', '0.99', '0.98', '0.96', '0.91', '0.84', '0.86']\n",
      "Last Action:  tensor([0.8561, 0.9737, 0.9679, 0.9673, 0.8583, 0.9795, 0.8645, 0.8341, 0.7029,\n",
      "        0.7762], device='cuda:0')\n",
      "Loss: 0.3425154983997345 -0.3943077325820923\n",
      "Loss: 0.4056878983974457 -0.7647814750671387\n",
      "Loss: 0.3219682276248932 0.07293368875980377\n",
      "Loss: 0.3361864984035492 -0.2395738959312439\n",
      "Loss: 0.3790466785430908 -0.4928252696990967\n",
      "Loss: 0.3324732780456543 -0.6276445984840393\n",
      "Loss: 0.3434799313545227 -0.49481287598609924\n",
      "Policy Reward: tensor(1.1144, device='cuda:0')\n",
      "Trajectory:  ['0.43', '1.00', '0.67', '0.03', '0.99', '0.99', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '0.98', '0.96', '0.87', '0.84', '0.92', '0.96', '0.95']\n",
      "Last Action:  tensor([0.9549, 0.7741, 0.8537, 0.7336, 0.7829, 0.9758, 0.6666, 0.9652, 0.9711,\n",
      "        0.7565], device='cuda:0')\n",
      "Loss: 0.4723777174949646 -0.7791517972946167\n",
      "Loss: 0.4310901463031769 -0.6196174025535583\n",
      "Loss: 0.40288451313972473 -0.544331967830658\n",
      "Loss: 0.4043007493019104 -0.5675643086433411\n",
      "Loss: 0.3170606195926666 -0.4508848190307617\n",
      "Loss: 0.40704813599586487 -0.3394775390625\n",
      "Loss: 0.39885425567626953 -0.23884978890419006\n",
      "Policy Reward: tensor(1.1407, device='cuda:0')\n",
      "Trajectory:  ['0.02', '1.00', '0.00', '0.02', '0.12', '0.31', '0.46', '0.58', '0.70', '0.87', '0.99', '1.00', '1.00', '1.00', '0.99', '0.97', '0.90', '0.75', '0.64']\n",
      "Last Action:  tensor([0.6373, 0.9125, 0.9651, 0.9645, 0.9273, 0.5756, 0.9674, 0.9568, 0.9561,\n",
      "        0.9771], device='cuda:0')\n",
      "Loss: 0.4455190896987915 -0.629266619682312\n",
      "Loss: 0.4250428080558777 -0.8546770215034485\n",
      "Loss: 0.3754867911338806 -0.5762437582015991\n",
      "Loss: 0.346640020608902 -0.6619969010353088\n",
      "Loss: 0.47814005613327026 -0.9728553295135498\n",
      "Loss: 0.3994081914424896 -0.5882167816162109\n",
      "Loss: 0.3320075571537018 -0.27565160393714905\n",
      "Policy Reward: tensor(1.2221, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.00', '0.02', '0.07', '0.24', '0.49', '0.61', '0.72', '0.81', '0.94', '1.00', '1.00', '1.00', '0.99', '0.97', '0.93', '0.85', '0.76']\n",
      "Last Action:  tensor([0.7584, 0.9483, 0.9001, 0.9206, 0.9565, 0.8701, 0.9729, 0.9306, 0.7933,\n",
      "        0.9716], device='cuda:0')\n",
      "Loss: 0.3413858413696289 -0.5505469441413879\n",
      "Loss: 0.4106109142303467 -0.4355047345161438\n",
      "Loss: 0.44165927171707153 -0.6971883177757263\n",
      "Loss: 0.4009203314781189 -0.7544340491294861\n",
      "Loss: 0.3997434079647064 -0.525354266166687\n",
      "Loss: 0.431575745344162 -0.6317390203475952\n",
      "Loss: 0.37540125846862793 -0.6211838126182556\n",
      "Policy Reward: tensor(1.1413, device='cuda:0')\n",
      "Trajectory:  ['0.23', '1.00', '0.52', '0.13', '0.75', '0.98', '1.00', '1.00', '1.00', '1.00', '1.00', '0.99', '0.95', '0.87', '0.78', '0.76', '0.87', '0.95', '0.97']\n",
      "Last Action:  tensor([0.9699, 0.9547, 0.9747, 0.7011, 0.8829, 0.8718, 0.9840, 0.6584, 0.7828,\n",
      "        0.7101], device='cuda:0')\n",
      "Loss: 0.38313108682632446 -0.6317991018295288\n",
      "Loss: 0.4556024372577667 -0.7686522006988525\n",
      "Loss: 0.391844242811203 -0.5558493733406067\n",
      "Loss: 0.47612515091896057 -0.6612351536750793\n",
      "Loss: 0.3107739984989166 -0.0023920610547065735\n",
      "Loss: 0.34600499272346497 -0.4242152273654938\n",
      "Loss: 0.38358110189437866 -0.4484807252883911\n",
      "Policy Reward: tensor(1.1721, device='cuda:0')\n",
      "Trajectory:  ['0.15', '1.00', '0.56', '0.45', '0.74', '0.99', '1.00', '1.00', '1.00', '1.00', '1.00', '0.98', '0.94', '0.90', '0.85', '0.81', '0.79', '0.75', '0.73']\n",
      "Last Action:  tensor([0.7292, 0.6804, 0.6124, 0.9679, 0.9668, 0.9744, 0.7196, 0.9315, 0.9783,\n",
      "        0.9700], device='cuda:0')\n",
      "Bigstep:  36\n",
      "Loss: 0.3757345378398895 0.09220542013645172\n",
      "Loss: 0.39173802733421326 -0.050649479031562805\n",
      "Loss: 0.29425153136253357 0.2914517819881439\n",
      "Loss: 0.33964475989341736 0.03854614496231079\n",
      "Loss: 0.35410502552986145 0.00576435960829258\n",
      "Loss: 0.37174084782600403 -0.2543708086013794\n",
      "Loss: 0.33697253465652466 -0.12194711714982986\n",
      "Policy Reward: tensor(1.1543, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.01', '0.10', '0.27', '0.37', '0.60', '0.83', '0.98', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '0.99', '0.98', '0.97', '0.95']\n",
      "Last Action:  tensor([0.9507, 0.9744, 0.9836, 0.9838, 0.7182, 0.7999, 0.7875, 0.9700, 0.8191,\n",
      "        0.9838], device='cuda:0')\n",
      "Loss: 0.3561147451400757 -0.14745818078517914\n",
      "Loss: 0.414423406124115 -0.04331757500767708\n",
      "Loss: 0.3882743716239929 0.006168991327285767\n",
      "Loss: 0.35532280802726746 0.17384907603263855\n",
      "Loss: 0.33934199810028076 0.1632094383239746\n",
      "Loss: 0.3701029121875763 -0.20126591622829437\n",
      "Loss: 0.3538236916065216 -0.12793543934822083\n",
      "Policy Reward: tensor(1.0738, device='cuda:0')\n",
      "Trajectory:  ['0.60', '1.00', '0.85', '0.30', '0.75', '0.99', '1.00', '0.99', '0.97', '0.84', '0.77', '0.82', '0.78', '0.81', '0.80', '0.80', '0.82', '0.81', '0.80']\n",
      "Last Action:  tensor([0.7958, 0.8793, 0.9774, 0.7399, 0.9904, 0.9848, 0.9762, 0.9847, 0.9850,\n",
      "        0.9575], device='cuda:0')\n",
      "Loss: 0.35740038752555847 -0.25107860565185547\n",
      "Loss: 0.431527316570282 -0.2147672027349472\n",
      "Loss: 0.34555137157440186 0.14571905136108398\n",
      "Loss: 0.39073488116264343 0.1530105024576187\n",
      "Loss: 0.35100695490837097 -0.09512640535831451\n",
      "Loss: 0.37814030051231384 -0.08936794102191925\n",
      "Loss: 0.37631481885910034 -0.05315963923931122\n",
      "Policy Reward: tensor(1.0532, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.99', '0.01', '0.02', '0.11', '0.40', '0.58', '0.74', '0.90', '0.99', '1.00', '1.00', '1.00', '1.00', '0.99', '0.96', '0.81', '0.71', '0.79']\n",
      "Last Action:  tensor([0.7914, 0.9864, 0.9844, 0.7928, 0.8523, 0.9393, 0.9328, 0.9510, 0.8499,\n",
      "        0.9912], device='cuda:0')\n",
      "Loss: 0.40650877356529236 -0.22300677001476288\n",
      "Loss: 0.45313096046447754 -0.3284923732280731\n",
      "Loss: 0.36069661378860474 -0.15654966235160828\n",
      "Loss: 0.3342752754688263 -0.3479911983013153\n",
      "Loss: 0.35742053389549255 0.13989514112472534\n",
      "Loss: 0.3744574785232544 -0.08686652034521103\n",
      "Loss: 0.30022889375686646 0.25449618697166443\n",
      "Policy Reward: tensor(0.9797, device='cuda:0')\n",
      "Trajectory:  ['0.06', '1.00', '0.66', '0.33', '0.67', '0.98', '1.00', '1.00', '1.00', '0.99', '0.90', '0.90', '0.86', '0.86', '0.88', '0.88', '0.84', '0.81', '0.80']\n",
      "Last Action:  tensor([0.8023, 0.6834, 0.9797, 0.9551, 0.9810, 0.9214, 0.9495, 0.8551, 0.9668,\n",
      "        0.9915], device='cuda:0')\n",
      "Loss: 0.4590729773044586 -0.35809725522994995\n",
      "Loss: 0.3449602425098419 0.06953783333301544\n",
      "Loss: 0.38286522030830383 0.04027325659990311\n",
      "Loss: 0.35920870304107666 -0.1589345633983612\n",
      "Loss: 0.30594199895858765 0.16101107001304626\n",
      "Loss: 0.33650675415992737 0.06280592083930969\n",
      "Loss: 0.3163609504699707 0.010264858603477478\n",
      "Policy Reward: tensor(1.2037, device='cuda:0')\n",
      "Trajectory:  ['0.57', '1.00', '0.99', '0.18', '0.60', '0.98', '0.99', '1.00', '1.00', '1.00', '1.00', '1.00', '0.98', '0.92', '0.94', '0.98', '0.98', '0.98', '0.96']\n",
      "Last Action:  tensor([0.9635, 0.6777, 0.8073, 0.9788, 0.9742, 0.8951, 0.9462, 0.9682, 0.9717,\n",
      "        0.9764], device='cuda:0')\n",
      "Loss: 0.3741041123867035 0.11228954792022705\n",
      "Loss: 0.3718608021736145 -0.189491406083107\n",
      "Loss: 0.37653446197509766 -0.35782700777053833\n",
      "Loss: 0.3296531140804291 -0.015896324068307877\n",
      "Loss: 0.35026493668556213 -0.13218356668949127\n",
      "Loss: 0.316720575094223 0.1692662239074707\n",
      "Loss: 0.386981725692749 -0.40971049666404724\n",
      "Policy Reward: tensor(1.1325, device='cuda:0')\n",
      "Trajectory:  ['0.07', '0.98', '0.52', '0.41', '0.45', '0.57', '0.75', '0.97', '0.99', '0.99', '0.98', '0.90', '0.82', '0.77', '0.76', '0.72', '0.69', '0.69', '0.72']\n",
      "Last Action:  tensor([0.7216, 0.7337, 0.9579, 0.6984, 0.8106, 0.8033, 0.8732, 0.9604, 0.9198,\n",
      "        0.9604], device='cuda:0')\n",
      "Loss: 0.2742103040218353 0.3390862047672272\n",
      "Loss: 0.3315793573856354 -0.17833876609802246\n",
      "Loss: 0.36229440569877625 -0.2230439931154251\n",
      "Loss: 0.3565200865268707 -0.47364160418510437\n",
      "Loss: 0.446444034576416 -0.2901104688644409\n",
      "Loss: 0.4158455729484558 -0.5762495398521423\n",
      "Loss: 0.33718252182006836 0.04473688080906868\n",
      "Policy Reward: tensor(1.0362, device='cuda:0')\n",
      "Trajectory:  ['0.11', '0.98', '0.40', '0.43', '0.54', '0.70', '0.87', '0.99', '0.99', '0.81', '0.61', '0.55', '0.46', '0.46', '0.65', '0.89', '0.88', '0.77', '0.60']\n",
      "Last Action:  tensor([0.6014, 0.9277, 0.6215, 0.9021, 0.9222, 0.7471, 0.7287, 0.8750, 0.9223,\n",
      "        0.5602], device='cuda:0')\n",
      "Loss: 0.432746946811676 -0.30110976099967957\n",
      "Loss: 0.34488409757614136 -0.3581079840660095\n",
      "Loss: 0.355172336101532 -0.4812970459461212\n",
      "Loss: 0.3370586633682251 -0.3041137158870697\n",
      "Loss: 0.43292132019996643 -0.8134542107582092\n",
      "Loss: 0.3410094082355499 -0.34646791219711304\n",
      "Loss: 0.3391619622707367 -0.1906558871269226\n",
      "Policy Reward: tensor(1.0983, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.05', '0.22', '0.52', '0.65', '0.73', '0.82', '0.86', '0.65', '0.38', '0.27', '0.17', '0.36', '0.91', '0.90', '0.75', '0.43', '0.11']\n",
      "Last Action:  tensor([0.1136, 0.1615, 0.6496, 0.8520, 0.1714, 0.6246, 0.3082, 0.0880, 0.7367,\n",
      "        0.8549], device='cuda:0')\n",
      "Bigstep:  37\n",
      "Loss: 0.39105361700057983 -0.2527100741863251\n",
      "Loss: 0.39735138416290283 -0.40200915932655334\n",
      "Loss: 0.38443833589553833 -0.04569586366415024\n",
      "Loss: 0.3436911106109619 -0.09081399440765381\n",
      "Loss: 0.3945547342300415 -0.4585631489753723\n",
      "Loss: 0.3562672436237335 -0.5445398092269897\n",
      "Loss: 0.40242061018943787 -0.5166813135147095\n",
      "Policy Reward: tensor(1.2040, device='cuda:0')\n",
      "Trajectory:  ['0.41', '1.00', '0.53', '0.01', '0.29', '0.79', '0.91', '0.80', '0.55', '0.37', '0.27', '0.24', '0.21', '0.20', '0.26', '0.43', '0.56', '0.64', '0.66']\n",
      "Last Action:  tensor([0.6594, 0.1686, 0.4841, 0.5918, 0.6575, 0.1077, 0.1688, 0.2161, 0.7512,\n",
      "        0.8328], device='cuda:0')\n",
      "Loss: 0.344180703163147 -0.6056779026985168\n",
      "Loss: 0.3876824676990509 -0.14100927114486694\n",
      "Loss: 0.3737694025039673 -0.7621532678604126\n",
      "Loss: 0.3655838072299957 -0.7067134976387024\n",
      "Loss: 0.30160823464393616 -0.23791071772575378\n",
      "Loss: 0.3794246017932892 -0.6505696773529053\n",
      "Loss: 0.31242799758911133 -0.5874204635620117\n",
      "Policy Reward: tensor(1.1788, device='cuda:0')\n",
      "Trajectory:  ['0.39', '1.00', '0.78', '0.13', '0.33', '0.58', '0.68', '0.77', '0.63', '0.45', '0.36', '0.25', '0.18', '0.56', '0.99', '0.99', '0.92', '0.71', '0.31']\n",
      "Last Action:  tensor([0.3076, 0.0993, 0.7103, 0.1236, 0.8839, 0.4910, 0.7768, 0.4619, 0.1895,\n",
      "        0.0975], device='cuda:0')\n",
      "Loss: 0.31276440620422363 -0.6528894305229187\n",
      "Loss: 0.45482778549194336 -1.1901452541351318\n",
      "Loss: 0.3553069531917572 -0.5991218090057373\n",
      "Loss: 0.36395660042762756 -0.8032364845275879\n",
      "Loss: 0.4248497784137726 -0.9615752696990967\n",
      "Loss: 0.31806546449661255 -0.5293015837669373\n",
      "Loss: 0.3405613303184509 -0.5248743295669556\n",
      "Policy Reward: tensor(1.0493, device='cuda:0')\n",
      "Trajectory:  ['0.78', '1.00', '1.00', '0.47', '0.40', '0.73', '0.71', '0.80', '0.76', '0.65', '0.47', '0.30', '0.31', '0.39', '0.72', '0.80', '0.79', '0.64', '0.33']\n",
      "Last Action:  tensor([0.3310, 0.3806, 0.7674, 0.8908, 0.7798, 0.2435, 0.4006, 0.9159, 0.5711,\n",
      "        0.4452], device='cuda:0')\n",
      "Loss: 0.29333052039146423 -0.10775458812713623\n",
      "Loss: 0.3290082812309265 -0.33275002241134644\n",
      "Loss: 0.330074667930603 -0.3474932610988617\n",
      "Loss: 0.36782965064048767 -0.5169980525970459\n",
      "Loss: 0.35730627179145813 -0.687556266784668\n",
      "Loss: 0.3939949870109558 -0.6734830141067505\n",
      "Loss: 0.3438577353954315 -0.3573615550994873\n",
      "Policy Reward: tensor(1.1021, device='cuda:0')\n",
      "Trajectory:  ['0.79', '1.00', '1.00', '0.23', '0.32', '0.34', '0.44', '0.67', '0.65', '0.54', '0.52', '0.52', '0.50', '0.53', '0.55', '0.60', '0.62', '0.58', '0.62']\n",
      "Last Action:  tensor([0.6167, 0.0777, 0.3017, 0.6812, 0.0963, 0.1084, 0.2383, 0.7696, 0.8233,\n",
      "        0.1420], device='cuda:0')\n",
      "Loss: 0.3383568227291107 -0.49859336018562317\n",
      "Loss: 0.33556437492370605 -0.6991897821426392\n",
      "Loss: 0.3966732323169708 -0.6550827622413635\n",
      "Loss: 0.41658473014831543 -1.0621193647384644\n",
      "Loss: 0.37150707840919495 -0.6520116329193115\n",
      "Loss: 0.30957597494125366 -0.5319039225578308\n",
      "Loss: 0.34543853998184204 -0.792143702507019\n",
      "Policy Reward: tensor(1.1595, device='cuda:0')\n",
      "Trajectory:  ['0.84', '1.00', '1.00', '0.33', '0.28', '0.73', '0.74', '0.78', '0.76', '0.63', '0.50', '0.28', '0.24', '0.24', '0.59', '0.97', '0.79', '0.62', '0.34']\n",
      "Last Action:  tensor([0.3405, 0.1261, 0.1015, 0.7332, 0.1861, 0.6676, 0.7817, 0.7997, 0.6550,\n",
      "        0.1849], device='cuda:0')\n",
      "Loss: 0.3933393657207489 -0.6247131824493408\n",
      "Loss: 0.3261371850967407 -0.574240505695343\n",
      "Loss: 0.35095837712287903 -0.6755297780036926\n",
      "Loss: 0.393596351146698 -0.9380768537521362\n",
      "Loss: 0.24970917403697968 -0.38693568110466003\n",
      "Loss: 0.3464764356613159 -0.6159017086029053\n",
      "Loss: 0.32787245512008667 -0.46505337953567505\n",
      "Policy Reward: tensor(0.9746, device='cuda:0')\n",
      "Trajectory:  ['0.77', '1.00', '1.00', '0.28', '0.45', '0.81', '0.80', '0.82', '0.76', '0.62', '0.44', '0.42', '0.47', '0.56', '0.72', '0.64', '0.68', '0.54', '0.68']\n",
      "Last Action:  tensor([0.6809, 0.6407, 0.0704, 0.4249, 0.5558, 0.6149, 0.8461, 0.3589, 0.0951,\n",
      "        0.5979], device='cuda:0')\n",
      "Loss: 0.329708069562912 -0.6611107587814331\n",
      "Loss: 0.30293649435043335 -0.5002295970916748\n",
      "Loss: 0.39056137204170227 -0.6558486223220825\n",
      "Loss: 0.3002709448337555 -0.6931252479553223\n",
      "Loss: 0.39433255791664124 -0.9480476379394531\n",
      "Loss: 0.43285250663757324 -0.9617510437965393\n",
      "Loss: 0.35160118341445923 -0.6393394470214844\n",
      "Policy Reward: tensor(1.1891, device='cuda:0')\n",
      "Trajectory:  ['0.80', '1.00', '1.00', '0.48', '0.40', '0.64', '0.62', '0.73', '0.75', '0.63', '0.37', '0.26', '0.22', '0.41', '0.59', '0.65', '0.76', '0.68', '0.36']\n",
      "Last Action:  tensor([0.3619, 0.1602, 0.5355, 0.7453, 0.1995, 0.8609, 0.8847, 0.7887, 0.7102,\n",
      "        0.1176], device='cuda:0')\n",
      "Loss: 0.3653702735900879 -0.7408503293991089\n",
      "Loss: 0.3389478921890259 -0.8034895658493042\n",
      "Loss: 0.31107696890830994 -0.5709627866744995\n",
      "Loss: 0.3357526957988739 -0.7900691032409668\n",
      "Loss: 0.388420969247818 -0.5328052043914795\n",
      "Loss: 0.4488741159439087 -1.048262357711792\n",
      "Loss: 0.35828697681427 -0.5974135398864746\n",
      "Policy Reward: tensor(1.1148, device='cuda:0')\n",
      "Trajectory:  ['0.31', '1.00', '0.36', '0.15', '0.60', '0.74', '0.72', '0.48', '0.29', '0.21', '0.13', '0.10', '0.28', '0.89', '0.97', '0.82', '0.27', '0.10', '0.18']\n",
      "Last Action:  tensor([0.1775, 0.1992, 0.2235, 0.1311, 0.4676, 0.5666, 0.1720, 0.1055, 0.1209,\n",
      "        0.2096], device='cuda:0')\n",
      "Bigstep:  38\n",
      "Loss: 0.46856945753097534 0.09717418253421783\n",
      "Loss: 0.43285948038101196 -0.14617624878883362\n",
      "Loss: 0.41503918170928955 -0.7642097473144531\n",
      "Loss: 0.3905312120914459 -0.7772353887557983\n",
      "Loss: 0.34891533851623535 -0.9226906895637512\n",
      "Loss: 0.4718482196331024 -1.2691775560379028\n",
      "Loss: 0.40835654735565186 -0.6952490210533142\n",
      "Policy Reward: tensor(1.1468, device='cuda:0')\n",
      "Trajectory:  ['0.53', '1.00', '0.98', '0.18', '0.85', '0.84', '0.69', '0.77', '0.82', '0.77', '0.62', '0.38', '0.29', '0.48', '0.48', '0.51', '0.65', '0.78', '0.82']\n",
      "Last Action:  tensor([0.8228, 0.8952, 0.7554, 0.0811, 0.5347, 0.5101, 0.6634, 0.2812, 0.1024,\n",
      "        0.7161], device='cuda:0')\n",
      "Loss: 0.4049069583415985 -1.2714723348617554\n",
      "Loss: 0.4532544016838074 -1.0536737442016602\n",
      "Loss: 0.4838234484195709 -1.292708158493042\n",
      "Loss: 0.42211848497390747 -1.01481032371521\n",
      "Loss: 0.4363754987716675 -1.0436042547225952\n",
      "Loss: 0.3863877058029175 -0.8657681941986084\n",
      "Loss: 0.4373283088207245 -0.8640212416648865\n",
      "Policy Reward: tensor(1.1120, device='cuda:0')\n",
      "Trajectory:  ['0.35', '1.00', '0.74', '0.08', '0.21', '0.37', '0.34', '0.42', '0.42', '0.41', '0.40', '0.32', '0.32', '0.36', '0.32', '0.32', '0.36', '0.47', '0.52']\n",
      "Last Action:  tensor([0.5216, 0.4379, 0.4934, 0.5485, 0.3441, 0.2853, 0.0644, 0.5167, 0.3046,\n",
      "        0.8718], device='cuda:0')\n",
      "Loss: 0.37072059512138367 -1.0972394943237305\n",
      "Loss: 0.41105595231056213 -0.7568708062171936\n",
      "Loss: 0.4515810012817383 -1.0324493646621704\n",
      "Loss: 0.39429423213005066 -0.9220568537712097\n",
      "Loss: 0.38993385434150696 -1.0711508989334106\n",
      "Loss: 0.4546312093734741 -1.1332433223724365\n",
      "Loss: 0.41416388750076294 -1.0514988899230957\n",
      "Policy Reward: tensor(1.0616, device='cuda:0')\n",
      "Trajectory:  ['0.53', '1.00', '0.81', '0.09', '0.17', '0.34', '0.27', '0.24', '0.32', '0.36', '0.35', '0.29', '0.21', '0.23', '0.25', '0.23', '0.25', '0.33', '0.43']\n",
      "Last Action:  tensor([0.4274, 0.5226, 0.1310, 0.0349, 0.6932, 0.4306, 0.5128, 0.5809, 0.0735,\n",
      "        0.0912], device='cuda:0')\n",
      "Loss: 0.3593549132347107 -1.0011287927627563\n",
      "Loss: 0.3462192118167877 -0.7949253916740417\n",
      "Loss: 0.47495603561401367 -1.277942419052124\n",
      "Loss: 0.4148479700088501 -0.9497382640838623\n",
      "Loss: 0.3277428150177002 -0.749906063079834\n",
      "Loss: 0.4365791976451874 -1.0399401187896729\n",
      "Loss: 0.37209901213645935 -1.0717681646347046\n",
      "Policy Reward: tensor(1.2306, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.04', '0.06', '0.24', '0.55', '0.69', '0.27', '0.12', '0.06', '0.05', '0.06', '0.08', '0.09', '0.11', '0.21', '0.35', '0.54', '0.51']\n",
      "Last Action:  tensor([0.5096, 0.2544, 0.7645, 0.3722, 0.0633, 0.5097, 0.3077, 0.4736, 0.2161,\n",
      "        0.8886], device='cuda:0')\n",
      "Loss: 0.42009443044662476 -1.2172714471817017\n",
      "Loss: 0.3625316321849823 -1.1131246089935303\n",
      "Loss: 0.38322511315345764 -1.1245131492614746\n",
      "Loss: 0.40133312344551086 -1.0980345010757446\n",
      "Loss: 0.39185088872909546 -0.9886794686317444\n",
      "Loss: 0.37316760420799255 -0.923642635345459\n",
      "Loss: 0.39688411355018616 -1.08791184425354\n",
      "Policy Reward: tensor(1.0545, device='cuda:0')\n",
      "Trajectory:  ['0.24', '1.00', '0.52', '0.01', '0.43', '0.47', '0.29', '0.16', '0.16', '0.20', '0.15', '0.09', '0.16', '0.71', '0.98', '0.94', '0.63', '0.17', '0.12']\n",
      "Last Action:  tensor([0.1250, 0.1622, 0.6740, 0.0572, 0.3728, 0.1642, 0.4294, 0.5230, 0.0904,\n",
      "        0.1668], device='cuda:0')\n",
      "Loss: 0.40817198157310486 -1.0062638521194458\n",
      "Loss: 0.39216774702072144 -1.304062008857727\n",
      "Loss: 0.36190879344940186 -1.3036274909973145\n",
      "Loss: 0.39498183131217957 -1.002680778503418\n",
      "Loss: 0.33457574248313904 -0.7824844121932983\n",
      "Loss: 0.45904815196990967 -1.247929334640503\n",
      "Loss: 0.31860700249671936 -0.9559319019317627\n",
      "Policy Reward: tensor(1.0788, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.08', '0.15', '0.41', '0.66', '0.75', '0.32', '0.10', '0.03', '0.02', '0.02', '0.12', '0.23', '0.27', '0.26', '0.27', '0.33', '0.43']\n",
      "Last Action:  tensor([0.4298, 0.4816, 0.2973, 0.0994, 0.4025, 0.0771, 0.5278, 0.3761, 0.0882,\n",
      "        0.5979], device='cuda:0')\n",
      "Loss: 0.4524233639240265 -1.3635636568069458\n",
      "Loss: 0.43909573554992676 -0.8504083156585693\n",
      "Loss: 0.3411514461040497 -0.943693995475769\n",
      "Loss: 0.4003904163837433 -1.1793118715286255\n",
      "Loss: 0.40728387236595154 -0.8814495801925659\n",
      "Loss: 0.32620078325271606 -0.8280326128005981\n",
      "Loss: 0.4838050901889801 -1.2285761833190918\n",
      "Policy Reward: tensor(1.1332, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.99', '0.01', '0.01', '0.06', '0.21', '0.43', '0.50', '0.27', '0.09', '0.03', '0.02', '0.05', '0.06', '0.05', '0.04', '0.07', '0.12', '0.26']\n",
      "Last Action:  tensor([0.2637, 0.1125, 0.6615, 0.8322, 0.7323, 0.3724, 0.2118, 0.8508, 0.3262,\n",
      "        0.6599], device='cuda:0')\n",
      "Loss: 0.37311631441116333 -1.1537222862243652\n",
      "Loss: 0.4306010603904724 -1.2637007236480713\n",
      "Loss: 0.46053823828697205 -1.1928083896636963\n",
      "Loss: 0.4320513606071472 -1.151942491531372\n",
      "Loss: 0.3754257261753082 -1.1834644079208374\n",
      "Loss: 0.3674936592578888 -1.0824575424194336\n",
      "Loss: 0.4383116364479065 -0.9669968485832214\n",
      "Policy Reward: tensor(1.1000, device='cuda:0')\n",
      "Trajectory:  ['0.48', '1.00', '0.87', '0.17', '0.34', '0.40', '0.26', '0.19', '0.22', '0.29', '0.29', '0.18', '0.12', '0.18', '0.38', '0.82', '0.89', '0.70', '0.29']\n",
      "Last Action:  tensor([0.2912, 0.1033, 0.7271, 0.1036, 0.0373, 0.1953, 0.5547, 0.2074, 0.0423,\n",
      "        0.1555], device='cuda:0')\n",
      "Bigstep:  39\n",
      "Loss: 0.4580346941947937 -0.6431282758712769\n",
      "Loss: 0.46474045515060425 -1.0294182300567627\n",
      "Loss: 0.3870333433151245 -1.024521827697754\n",
      "Loss: 0.3993716239929199 -1.104076862335205\n",
      "Loss: 0.3556153178215027 -1.3072346448898315\n",
      "Loss: 0.3515922725200653 -1.3460474014282227\n",
      "Loss: 0.36591944098472595 -0.9386290311813354\n",
      "Policy Reward: tensor(1.1064, device='cuda:0')\n",
      "Trajectory:  ['0.63', '1.00', '0.85', '0.11', '0.02', '0.06', '0.08', '0.09', '0.17', '0.22', '0.20', '0.16', '0.12', '0.12', '0.19', '0.27', '0.23', '0.24', '0.28']\n",
      "Last Action:  tensor([0.2824, 0.1672, 0.3958, 0.7333, 0.0520, 0.2048, 0.5618, 0.3854, 0.5737,\n",
      "        0.1667], device='cuda:0')\n",
      "Loss: 0.3958042860031128 -1.1286035776138306\n",
      "Loss: 0.31259775161743164 -1.3369882106781006\n",
      "Loss: 0.30846598744392395 -1.358791470527649\n",
      "Loss: 0.35097619891166687 -1.300842523574829\n",
      "Loss: 0.36064988374710083 -1.2431219816207886\n",
      "Loss: 0.32046499848365784 -1.1335322856903076\n",
      "Loss: 0.49611011147499084 -1.5773072242736816\n",
      "Policy Reward: tensor(1.0410, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.21', '0.10', '0.19', '0.11', '0.04', '0.02', '0.02', '0.03', '0.05', '0.07', '0.08', '0.06', '0.06', '0.09', '0.14', '0.21', '0.22']\n",
      "Last Action:  tensor([0.2235, 0.6586, 0.6015, 0.0953, 0.2492, 0.5653, 0.4388, 0.2860, 0.2464,\n",
      "        0.6047], device='cuda:0')\n",
      "Loss: 0.3705514073371887 -1.289870023727417\n",
      "Loss: 0.4690994918346405 -1.6459753513336182\n",
      "Loss: 0.33688440918922424 -1.3360942602157593\n",
      "Loss: 0.36695632338523865 -1.1606134176254272\n",
      "Loss: 0.3693332374095917 -1.4167171716690063\n",
      "Loss: 0.377947062253952 -1.4760147333145142\n",
      "Loss: 0.38064441084861755 -1.2081111669540405\n",
      "Policy Reward: tensor(1.0094, device='cuda:0')\n",
      "Trajectory:  ['0.53', '1.00', '0.98', '0.09', '0.05', '0.05', '0.05', '0.08', '0.07', '0.04', '0.02', '0.01', '0.04', '0.12', '0.41', '0.82', '0.80', '0.55', '0.30']\n",
      "Last Action:  tensor([0.3014, 0.6581, 0.2180, 0.7052, 0.1758, 0.3835, 0.1154, 0.1241, 0.1745,\n",
      "        0.7276], device='cuda:0')\n",
      "Loss: 0.4271652400493622 -1.6278040409088135\n",
      "Loss: 0.36167943477630615 -1.3777073621749878\n",
      "Loss: 0.42430639266967773 -1.378651738166809\n",
      "Loss: 0.4765986204147339 -1.5627409219741821\n",
      "Loss: 0.3773246109485626 -1.1163443326950073\n",
      "Loss: 0.327953577041626 -1.4956190586090088\n",
      "Loss: 0.3889404535293579 -1.2843596935272217\n",
      "Policy Reward: tensor(1.0382, device='cuda:0')\n",
      "Trajectory:  ['0.30', '1.00', '0.59', '0.17', '0.05', '0.03', '0.02', '0.02', '0.04', '0.08', '0.08', '0.04', '0.04', '0.10', '0.19', '0.28', '0.36', '0.40', '0.34']\n",
      "Last Action:  tensor([0.3441, 0.2349, 0.5326, 0.2131, 0.1537, 0.2766, 0.2164, 0.5038, 0.1527,\n",
      "        0.6564], device='cuda:0')\n",
      "Loss: 0.32914090156555176 -1.07535719871521\n",
      "Loss: 0.4142962396144867 -1.4383416175842285\n",
      "Loss: 0.3591059446334839 -1.1586084365844727\n",
      "Loss: 0.40670108795166016 -1.0274920463562012\n",
      "Loss: 0.35369354486465454 -1.6005337238311768\n",
      "Loss: 0.32880041003227234 -0.8084362149238586\n",
      "Loss: 0.3824930787086487 -1.3673855066299438\n",
      "Policy Reward: tensor(1.1951, device='cuda:0')\n",
      "Trajectory:  ['0.33', '1.00', '0.79', '0.00', '0.01', '0.04', '0.10', '0.08', '0.05', '0.03', '0.02', '0.02', '0.05', '0.07', '0.13', '0.23', '0.34', '0.37', '0.27']\n",
      "Last Action:  tensor([0.2698, 0.3384, 0.2221, 0.4545, 0.6604, 0.3707, 0.1855, 0.0932, 0.3416,\n",
      "        0.4836], device='cuda:0')\n",
      "Loss: 0.34506121277809143 -1.2031975984573364\n",
      "Loss: 0.34281888604164124 -1.2061156034469604\n",
      "Loss: 0.36829665303230286 -1.2176663875579834\n",
      "Loss: 0.3574420213699341 -1.2406243085861206\n",
      "Loss: 0.38742318749427795 -1.2168586254119873\n",
      "Loss: 0.41974449157714844 -1.7172966003417969\n",
      "Loss: 0.3697104752063751 -1.1748673915863037\n",
      "Policy Reward: tensor(1.0862, device='cuda:0')\n",
      "Trajectory:  ['0.48', '1.00', '0.81', '0.05', '0.05', '0.08', '0.04', '0.03', '0.02', '0.02', '0.01', '0.01', '0.01', '0.05', '0.31', '0.88', '0.82', '0.57', '0.18']\n",
      "Last Action:  tensor([0.1843, 0.1713, 0.8146, 0.3008, 0.2611, 0.3272, 0.3075, 0.0778, 0.3097,\n",
      "        0.6379], device='cuda:0')\n",
      "Loss: 0.3143097758293152 -1.1253474950790405\n",
      "Loss: 0.36582672595977783 -1.023820161819458\n",
      "Loss: 0.3888039290904999 -1.2765480279922485\n",
      "Loss: 0.369173139333725 -1.3666235208511353\n",
      "Loss: 0.4150831401348114 -1.6384141445159912\n",
      "Loss: 0.3368813693523407 -0.8772543668746948\n",
      "Loss: 0.38546401262283325 -1.2016181945800781\n",
      "Policy Reward: tensor(1.0415, device='cuda:0')\n",
      "Trajectory:  ['0.05', '1.00', '0.49', '0.01', '0.08', '0.05', '0.02', '0.01', '0.01', '0.01', '0.01', '0.01', '0.02', '0.06', '0.22', '0.57', '0.69', '0.56', '0.16']\n",
      "Last Action:  tensor([0.1566, 0.6867, 0.6303, 0.5611, 0.6849, 0.4139, 0.4432, 0.6859, 0.4201,\n",
      "        0.3297], device='cuda:0')\n",
      "Loss: 0.29908931255340576 -1.1499531269073486\n",
      "Loss: 0.4291308522224426 -1.039352536201477\n",
      "Loss: 0.36292895674705505 -1.5459916591644287\n",
      "Loss: 0.34252044558525085 -1.0394539833068848\n",
      "Loss: 0.34380102157592773 -1.3294957876205444\n",
      "Loss: 0.34403547644615173 -1.277541160583496\n",
      "Loss: 0.47044533491134644 -1.5022304058074951\n",
      "Policy Reward: tensor(1.0882, device='cuda:0')\n",
      "Trajectory:  ['0.66', '1.00', '0.84', '0.13', '0.02', '0.05', '0.07', '0.11', '0.08', '0.04', '0.02', '0.01', '0.03', '0.07', '0.24', '0.54', '0.87', '0.84', '0.70']\n",
      "Last Action:  tensor([0.7013, 0.7150, 0.3908, 0.5388, 0.6868, 0.4481, 0.2613, 0.3278, 0.2725,\n",
      "        0.2176], device='cuda:0')\n",
      "Bigstep:  40\n",
      "Loss: 0.3571639657020569 0.3593911826610565\n",
      "Loss: 0.36063191294670105 -0.10454855859279633\n",
      "Loss: 0.36149823665618896 -0.3232908248901367\n",
      "Loss: 0.42431578040122986 -0.2688884735107422\n",
      "Loss: 0.35555973649024963 -0.2632780373096466\n",
      "Loss: 0.34291380643844604 -0.3832239806652069\n",
      "Loss: 0.38237470388412476 -0.8278398513793945\n",
      "Policy Reward: tensor(1.0813, device='cuda:0')\n",
      "Trajectory:  ['0.49', '1.00', '0.85', '0.22', '0.29', '0.51', '0.40', '0.33', '0.21', '0.16', '0.09', '0.04', '0.07', '0.50', '0.99', '0.80', '0.71', '0.39', '0.20']\n",
      "Last Action:  tensor([0.1975, 0.5445, 0.2554, 0.6495, 0.1495, 0.0786, 0.8067, 0.1199, 0.3375,\n",
      "        0.4096], device='cuda:0')\n",
      "Loss: 0.4158172011375427 -0.6789624094963074\n",
      "Loss: 0.43590670824050903 -0.9086674451828003\n",
      "Loss: 0.3740024268627167 -0.474854975938797\n",
      "Loss: 0.3780144155025482 -0.4363982379436493\n",
      "Loss: 0.337126761674881 -0.7370250225067139\n",
      "Loss: 0.3847556710243225 -0.8524184823036194\n",
      "Loss: 0.37527668476104736 -0.6448228359222412\n",
      "Policy Reward: tensor(1.1362, device='cuda:0')\n",
      "Trajectory:  ['0.49', '0.95', '0.89', '0.54', '0.37', '0.49', '0.62', '0.73', '0.77', '0.75', '0.64', '0.48', '0.50', '0.62', '0.48', '0.48', '0.53', '0.53', '0.55']\n",
      "Last Action:  tensor([0.5525, 0.5552, 0.6965, 0.8936, 0.8325, 0.5337, 0.7175, 0.9532, 0.9800,\n",
      "        0.8206], device='cuda:0')\n",
      "Loss: 0.3710933029651642 -0.6498957872390747\n",
      "Loss: 0.35995474457740784 -0.9568459391593933\n",
      "Loss: 0.30590274930000305 -0.7522173523902893\n",
      "Loss: 0.3527362644672394 -0.8503929376602173\n",
      "Loss: 0.29053887724876404 -0.7452007532119751\n",
      "Loss: 0.3936834931373596 -1.0553598403930664\n",
      "Loss: 0.37764111161231995 -0.9813235402107239\n",
      "Policy Reward: tensor(0.9717, device='cuda:0')\n",
      "Trajectory:  ['0.04', '1.00', '0.42', '0.65', '0.87', '0.66', '0.67', '0.61', '0.65', '0.63', '0.35', '0.22', '0.10', '0.13', '0.62', '0.92', '0.93', '0.87', '0.65']\n",
      "Last Action:  tensor([0.6536, 0.9809, 0.4480, 0.8364, 0.3076, 0.9430, 0.7374, 0.7689, 0.1264,\n",
      "        0.7321], device='cuda:0')\n",
      "Loss: 0.3990780711174011 -0.6139661073684692\n",
      "Loss: 0.34852078557014465 -0.8630967736244202\n",
      "Loss: 0.346326619386673 -0.7241346836090088\n",
      "Loss: 0.39334315061569214 -0.810302197933197\n",
      "Loss: 0.4254987835884094 -0.9681660532951355\n",
      "Loss: 0.3603193759918213 -0.9619157910346985\n",
      "Loss: 0.33162617683410645 -0.8623740077018738\n",
      "Policy Reward: tensor(1.0182, device='cuda:0')\n",
      "Trajectory:  ['0.44', '1.00', '0.86', '0.49', '0.65', '0.73', '0.74', '0.79', '0.81', '0.73', '0.59', '0.52', '0.46', '0.34', '0.25', '0.38', '0.69', '0.88', '0.81']\n",
      "Last Action:  tensor([0.8083, 0.8933, 0.6231, 0.8256, 0.7723, 0.1183, 0.9085, 0.6904, 0.5713,\n",
      "        0.8219], device='cuda:0')\n",
      "Loss: 0.40450841188430786 -0.5827292799949646\n",
      "Loss: 0.4188331663608551 -0.9445440769195557\n",
      "Loss: 0.38168078660964966 -0.6981625556945801\n",
      "Loss: 0.36896416544914246 -0.8999121189117432\n",
      "Loss: 0.3640550971031189 -1.0530294179916382\n",
      "Loss: 0.3150278627872467 -0.5965085029602051\n",
      "Loss: 0.3514899015426636 -0.49563902616500854\n",
      "Policy Reward: tensor(1.0969, device='cuda:0')\n",
      "Trajectory:  ['0.57', '1.00', '0.86', '0.50', '0.49', '0.67', '0.84', '0.90', '0.85', '0.75', '0.46', '0.36', '0.34', '0.38', '0.41', '0.44', '0.49', '0.56', '0.69']\n",
      "Last Action:  tensor([0.6927, 0.8632, 0.7905, 0.2656, 0.8203, 0.9309, 0.7960, 0.8773, 0.9067,\n",
      "        0.3708], device='cuda:0')\n",
      "Loss: 0.4034608006477356 -0.9435139894485474\n",
      "Loss: 0.35040342807769775 -0.6735419034957886\n",
      "Loss: 0.34490737318992615 -0.8666542768478394\n",
      "Loss: 0.3890354633331299 -1.1393941640853882\n",
      "Loss: 0.3862403631210327 -0.8379229307174683\n",
      "Loss: 0.31264835596084595 -0.5874157547950745\n",
      "Loss: 0.3381156325340271 -0.7559415698051453\n",
      "Policy Reward: tensor(1.1090, device='cuda:0')\n",
      "Trajectory:  ['0.53', '0.98', '0.88', '0.56', '0.33', '0.38', '0.51', '0.61', '0.76', '0.79', '0.65', '0.48', '0.39', '0.10', '0.21', '0.49', '0.74', '0.80', '0.68']\n",
      "Last Action:  tensor([0.6844, 0.7880, 0.2271, 0.7242, 0.5340, 0.6320, 0.4210, 0.9132, 0.9071,\n",
      "        0.2894], device='cuda:0')\n",
      "Loss: 0.39257529377937317 -1.09954833984375\n",
      "Loss: 0.4546950161457062 -1.2196977138519287\n",
      "Loss: 0.3864247500896454 -0.7906996607780457\n",
      "Loss: 0.3487085998058319 -0.5918711423873901\n",
      "Loss: 0.4719879925251007 -1.0986734628677368\n",
      "Loss: 0.3238779604434967 -0.7081245183944702\n",
      "Loss: 0.3148047924041748 -0.7875975966453552\n",
      "Policy Reward: tensor(0.9949, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.02', '0.03', '0.17', '0.41', '0.82', '0.96', '0.92', '0.62', '0.43', '0.16', '0.01', '0.01', '0.25', '0.73', '0.89', '0.90', '0.70']\n",
      "Last Action:  tensor([0.7047, 0.9155, 0.4049, 0.9550, 0.8276, 0.8207, 0.5265, 0.8717, 0.8595,\n",
      "        0.8110], device='cuda:0')\n",
      "Loss: 0.4184407889842987 -1.0133734941482544\n",
      "Loss: 0.31655585765838623 -0.6698497533798218\n",
      "Loss: 0.40546587109565735 -1.2186537981033325\n",
      "Loss: 0.4013010859489441 -0.868580162525177\n",
      "Loss: 0.3694652020931244 -0.6827437281608582\n",
      "Loss: 0.47243669629096985 -1.0259349346160889\n",
      "Loss: 0.3550621271133423 -0.689540445804596\n",
      "Policy Reward: tensor(1.1192, device='cuda:0')\n",
      "Trajectory:  ['0.20', '1.00', '0.88', '0.09', '0.72', '0.94', '0.91', '0.90', '0.89', '0.78', '0.57', '0.36', '0.25', '0.35', '0.44', '0.52', '0.74', '0.92', '0.87']\n",
      "Last Action:  tensor([0.8687, 0.8870, 0.8403, 0.6062, 0.8254, 0.9036, 0.4022, 0.8622, 0.9376,\n",
      "        0.8609], device='cuda:0')\n",
      "Bigstep:  41\n",
      "Loss: 0.3492248058319092 0.9947364926338196\n",
      "Loss: 0.32384493947029114 -0.05039582774043083\n",
      "Loss: 0.2675807476043701 0.17140550911426544\n",
      "Loss: 0.3764805495738983 -0.2999570667743683\n",
      "Loss: 0.3621731698513031 0.04043922945857048\n",
      "Loss: 0.36026132106781006 -0.1827583760023117\n",
      "Loss: 0.3133420944213867 -0.31043994426727295\n",
      "Policy Reward: tensor(1.1491, device='cuda:0')\n",
      "Trajectory:  ['0.03', '1.00', '0.04', '0.02', '0.33', '0.72', '0.84', '0.71', '0.66', '0.63', '0.33', '0.04', '0.00', '0.04', '0.31', '0.49', '0.49', '0.54', '0.49']\n",
      "Last Action:  tensor([0.4860, 0.5028, 0.3581, 0.6456, 0.2717, 0.3606, 0.2778, 0.2247, 0.4863,\n",
      "        0.3538], device='cuda:0')\n",
      "Loss: 0.3091634511947632 -0.2692362070083618\n",
      "Loss: 0.27105873823165894 -0.30824267864227295\n",
      "Loss: 0.28728407621383667 -0.37009575963020325\n",
      "Loss: 0.27526840567588806 -0.2299136072397232\n",
      "Loss: 0.3663906753063202 -0.3474847078323364\n",
      "Loss: 0.3690333068370819 -0.42988497018814087\n",
      "Loss: 0.3212038278579712 -0.1860746294260025\n",
      "Policy Reward: tensor(1.0666, device='cuda:0')\n",
      "Trajectory:  ['0.07', '1.00', '0.33', '0.13', '0.48', '0.55', '0.56', '0.65', '0.70', '0.65', '0.38', '0.12', '0.04', '0.28', '0.63', '0.51', '0.45', '0.55', '0.67']\n",
      "Last Action:  tensor([0.6739, 0.7156, 0.3986, 0.6265, 0.9831, 0.7440, 0.4642, 0.8678, 0.4706,\n",
      "        0.4884], device='cuda:0')\n",
      "Loss: 0.36760348081588745 -0.4308740794658661\n",
      "Loss: 0.3162086606025696 -0.20369921624660492\n",
      "Loss: 0.2676399350166321 -0.26915809512138367\n",
      "Loss: 0.32595181465148926 -0.45139601826667786\n",
      "Loss: 0.31613650918006897 -0.30993327498435974\n",
      "Loss: 0.3062140643596649 -0.21649618446826935\n",
      "Loss: 0.32093119621276855 -0.3702830374240875\n",
      "Policy Reward: tensor(1.1263, device='cuda:0')\n",
      "Trajectory:  ['0.20', '0.84', '0.35', '0.41', '0.71', '0.90', '0.91', '0.94', '0.89', '0.67', '0.55', '0.57', '0.45', '0.44', '0.49', '0.68', '0.81', '0.91', '0.76']\n",
      "Last Action:  tensor([0.7557, 0.7268, 0.7926, 0.2857, 0.7716, 0.3583, 0.6709, 0.4563, 0.7548,\n",
      "        0.4457], device='cuda:0')\n",
      "Loss: 0.4210280179977417 -0.7516707181930542\n",
      "Loss: 0.33335256576538086 -0.3062986135482788\n",
      "Loss: 0.27759701013565063 -0.3094802796840668\n",
      "Loss: 0.38478654623031616 -0.4609280228614807\n",
      "Loss: 0.2970465123653412 -0.10551854223012924\n",
      "Loss: 0.3181965947151184 -0.580263614654541\n",
      "Loss: 0.24281735718250275 -0.10747358202934265\n",
      "Policy Reward: tensor(1.0872, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.42', '0.26', '0.39', '0.39', '0.50', '0.66', '0.74', '0.67', '0.45', '0.25', '0.07', '0.09', '0.39', '0.58', '0.40', '0.31', '0.24']\n",
      "Last Action:  tensor([0.2428, 0.3180, 0.7183, 0.5825, 0.6041, 0.5271, 0.0409, 0.7657, 0.7371,\n",
      "        0.3922], device='cuda:0')\n",
      "Loss: 0.3231172561645508 -0.6111827492713928\n",
      "Loss: 0.3171532452106476 -0.525791585445404\n",
      "Loss: 0.2916230261325836 -0.37075063586235046\n",
      "Loss: 0.37522733211517334 -0.5703624486923218\n",
      "Loss: 0.30515819787979126 -0.524951696395874\n",
      "Loss: 0.26515766978263855 -0.3202640116214752\n",
      "Loss: 0.3768920302391052 -0.5882816910743713\n",
      "Policy Reward: tensor(1.1438, device='cuda:0')\n",
      "Trajectory:  ['0.41', '1.00', '0.81', '0.01', '0.33', '0.64', '0.74', '0.85', '0.87', '0.80', '0.50', '0.25', '0.12', '0.22', '0.51', '0.36', '0.36', '0.51', '0.57']\n",
      "Last Action:  tensor([0.5655, 0.6981, 0.1235, 0.0539, 0.5557, 0.1557, 0.4554, 0.2451, 0.7106,\n",
      "        0.1713], device='cuda:0')\n",
      "Loss: 0.33553534746170044 -0.46701908111572266\n",
      "Loss: 0.36941662430763245 -0.5436832308769226\n",
      "Loss: 0.3587173521518707 -0.5786580443382263\n",
      "Loss: 0.33304476737976074 -0.4746430516242981\n",
      "Loss: 0.33978837728500366 -0.6557331085205078\n",
      "Loss: 0.3321118652820587 -0.3740288019180298\n",
      "Loss: 0.36889809370040894 -0.18218806385993958\n",
      "Policy Reward: tensor(1.0823, device='cuda:0')\n",
      "Trajectory:  ['0.15', '1.00', '0.23', '0.00', '0.36', '0.65', '0.58', '0.64', '0.58', '0.57', '0.35', '0.10', '0.02', '0.23', '0.65', '0.51', '0.37', '0.39', '0.25']\n",
      "Last Action:  tensor([0.2463, 0.2606, 0.4686, 0.5273, 0.3123, 0.2434, 0.5953, 0.4158, 0.2856,\n",
      "        0.2705], device='cuda:0')\n",
      "Loss: 0.3286394476890564 -0.44810616970062256\n",
      "Loss: 0.3072970509529114 -0.3849364221096039\n",
      "Loss: 0.2536386251449585 -0.3459174633026123\n",
      "Loss: 0.34492027759552 -0.1948331892490387\n",
      "Loss: 0.33829039335250854 -0.39006292819976807\n",
      "Loss: 0.2957848012447357 -0.31494632363319397\n",
      "Loss: 0.339573472738266 -0.4985705614089966\n",
      "Policy Reward: tensor(1.1582, device='cuda:0')\n",
      "Trajectory:  ['0.58', '1.00', '0.93', '0.04', '0.23', '0.59', '0.53', '0.70', '0.74', '0.73', '0.56', '0.31', '0.16', '0.11', '0.40', '0.44', '0.35', '0.56', '0.74']\n",
      "Last Action:  tensor([0.7360, 0.0286, 0.1880, 0.3779, 0.3329, 0.8196, 0.7125, 0.3010, 0.4401,\n",
      "        0.8252], device='cuda:0')\n",
      "Loss: 0.3592070937156677 -0.3961331248283386\n",
      "Loss: 0.2896885275840759 -0.2978977859020233\n",
      "Loss: 0.349714457988739 -0.7831556797027588\n",
      "Loss: 0.26047590374946594 -0.34153494238853455\n",
      "Loss: 0.27537408471107483 -0.4906432032585144\n",
      "Loss: 0.4190916419029236 -0.5625944137573242\n",
      "Loss: 0.3839932084083557 -0.5543200373649597\n",
      "Policy Reward: tensor(1.0839, device='cuda:0')\n",
      "Trajectory:  ['0.01', '0.89', '0.33', '0.23', '0.32', '0.44', '0.54', '0.64', '0.69', '0.50', '0.24', '0.10', '0.13', '0.32', '0.31', '0.20', '0.32', '0.34', '0.33']\n",
      "Last Action:  tensor([0.3347, 0.9277, 0.7474, 0.1975, 0.7276, 0.4413, 0.7805, 0.4435, 0.7770,\n",
      "        0.1410], device='cuda:0')\n",
      "Bigstep:  42\n",
      "Loss: 0.3852773904800415 0.4693982005119324\n",
      "Loss: 0.43245506286621094 -0.3815860152244568\n",
      "Loss: 0.4026205241680145 -0.5823516249656677\n",
      "Loss: 0.4587087631225586 -0.7961482405662537\n",
      "Loss: 0.3763575255870819 -0.6403634548187256\n",
      "Loss: 0.3879358172416687 -0.6819682717323303\n",
      "Loss: 0.2976408898830414 -0.5586560368537903\n",
      "Policy Reward: tensor(1.1477, device='cuda:0')\n",
      "Trajectory:  ['0.26', '1.00', '0.84', '0.11', '0.85', '0.99', '0.98', '0.99', '0.98', '0.93', '0.75', '0.50', '0.36', '0.17', '0.84', '0.99', '0.96', '0.83', '0.67']\n",
      "Last Action:  tensor([0.6743, 0.2393, 0.8556, 0.6853, 0.1790, 0.4137, 0.9012, 0.7203, 0.6430,\n",
      "        0.0898], device='cuda:0')\n",
      "Loss: 0.4127294421195984 -0.9390315413475037\n",
      "Loss: 0.3391173183917999 -0.39192456007003784\n",
      "Loss: 0.40923193097114563 -0.8495320081710815\n",
      "Loss: 0.32604849338531494 -0.4650140404701233\n",
      "Loss: 0.35328060388565063 -0.6797432899475098\n",
      "Loss: 0.3793599009513855 -0.7129611968994141\n",
      "Loss: 0.3559543192386627 -0.798893392086029\n",
      "Policy Reward: tensor(1.1194, device='cuda:0')\n",
      "Trajectory:  ['0.59', '0.89', '0.62', '0.53', '0.56', '0.58', '0.57', '0.59', '0.60', '0.53', '0.48', '0.49', '0.38', '0.19', '0.33', '0.54', '0.79', '0.85', '0.83']\n",
      "Last Action:  tensor([0.8342, 0.2816, 0.7436, 0.2010, 0.8657, 0.7112, 0.0962, 0.7957, 0.8847,\n",
      "        0.6965], device='cuda:0')\n",
      "Loss: 0.3946351110935211 -0.7223232388496399\n",
      "Loss: 0.3505985140800476 -0.37741249799728394\n",
      "Loss: 0.3817598521709442 -0.4934774339199066\n",
      "Loss: 0.4546327590942383 -0.8889968991279602\n",
      "Loss: 0.334941029548645 -0.8129809498786926\n",
      "Loss: 0.40941300988197327 -0.6730002760887146\n",
      "Loss: 0.36591020226478577 -0.6519522666931152\n",
      "Policy Reward: tensor(1.1543, device='cuda:0')\n",
      "Trajectory:  ['0.57', '0.78', '0.85', '0.36', '0.09', '0.34', '0.65', '0.80', '0.98', '0.98', '0.80', '0.38', '0.29', '0.14', '0.43', '0.90', '0.49', '0.57', '0.51']\n",
      "Last Action:  tensor([0.5073, 0.6971, 0.6831, 0.8307, 0.3622, 0.6764, 0.1886, 0.3787, 0.1988,\n",
      "        0.9650], device='cuda:0')\n",
      "Loss: 0.36083370447158813 -0.7894065380096436\n",
      "Loss: 0.34915342926979065 -0.7117963433265686\n",
      "Loss: 0.32725632190704346 -0.5860828757286072\n",
      "Loss: 0.40441569685935974 -0.8898445963859558\n",
      "Loss: 0.40478774905204773 -0.46903958916664124\n",
      "Loss: 0.3463461101055145 -0.5487434267997742\n",
      "Loss: 0.3038123846054077 -0.5066397786140442\n",
      "Policy Reward: tensor(1.0945, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.11', '0.31', '0.66', '0.81', '0.79', '0.79', '0.83', '0.74', '0.34', '0.20', '0.11', '0.09', '0.62', '0.66', '0.44', '0.59', '0.47']\n",
      "Last Action:  tensor([0.4712, 0.2350, 0.2629, 0.8907, 0.8796, 0.4008, 0.6481, 0.2687, 0.2910,\n",
      "        0.3692], device='cuda:0')\n",
      "Loss: 0.33414480090141296 -0.5074768662452698\n",
      "Loss: 0.3760356605052948 -0.5895266532897949\n",
      "Loss: 0.43341052532196045 -1.0131443738937378\n",
      "Loss: 0.3101362884044647 -0.7417290806770325\n",
      "Loss: 0.3554023802280426 -0.6517693996429443\n",
      "Loss: 0.33128198981285095 -0.5656772255897522\n",
      "Loss: 0.3636653423309326 -0.9252824783325195\n",
      "Policy Reward: tensor(1.1201, device='cuda:0')\n",
      "Trajectory:  ['0.54', '1.00', '0.92', '0.04', '0.15', '0.72', '0.87', '0.98', '0.99', '0.92', '0.60', '0.37', '0.17', '0.51', '0.81', '0.69', '0.65', '0.56', '0.30']\n",
      "Last Action:  tensor([0.3006, 0.6370, 0.8498, 0.2057, 0.7161, 0.8458, 0.8731, 0.8147, 0.8320,\n",
      "        0.5791], device='cuda:0')\n",
      "Loss: 0.33723098039627075 -0.8852545022964478\n",
      "Loss: 0.36831846833229065 -0.9231870174407959\n",
      "Loss: 0.3465104103088379 -0.660682201385498\n",
      "Loss: 0.4204525947570801 -0.6206347346305847\n",
      "Loss: 0.3961796760559082 -0.7451255321502686\n",
      "Loss: 0.4240138828754425 -0.8959288001060486\n",
      "Loss: 0.32575902342796326 -0.8473323583602905\n",
      "Policy Reward: tensor(1.2100, device='cuda:0')\n",
      "Trajectory:  ['0.04', '1.00', '0.48', '0.31', '0.71', '0.76', '0.85', '0.90', '0.89', '0.64', '0.26', '0.19', '0.18', '0.50', '0.60', '0.33', '0.33', '0.32', '0.35']\n",
      "Last Action:  tensor([0.3523, 0.4519, 0.6445, 0.2828, 0.3220, 0.6990, 0.8153, 0.5522, 0.5582,\n",
      "        0.6558], device='cuda:0')\n",
      "Loss: 0.3130858242511749 -0.6405686140060425\n",
      "Loss: 0.4565315246582031 -1.127276062965393\n",
      "Loss: 0.29978856444358826 -0.5491318702697754\n",
      "Loss: 0.29610475897789 -0.5743838548660278\n",
      "Loss: 0.3779079020023346 -0.9473612904548645\n",
      "Loss: 0.4087923765182495 -0.8568704724311829\n",
      "Loss: 0.3505547046661377 -0.7353581190109253\n",
      "Policy Reward: tensor(1.1287, device='cuda:0')\n",
      "Trajectory:  ['0.58', '1.00', '0.97', '0.12', '0.24', '0.60', '0.66', '0.86', '0.98', '0.94', '0.67', '0.31', '0.25', '0.30', '0.83', '0.66', '0.35', '0.26', '0.17']\n",
      "Last Action:  tensor([0.1733, 0.0911, 0.5631, 0.9638, 0.0260, 0.5611, 0.6972, 0.2745, 0.6400,\n",
      "        0.1453], device='cuda:0')\n",
      "Loss: 0.370682030916214 -0.8715612888336182\n",
      "Loss: 0.4179200530052185 -1.0776211023330688\n",
      "Loss: 0.3559669554233551 -0.7896755337715149\n",
      "Loss: 0.30315402150154114 -0.8700668215751648\n",
      "Loss: 0.40078699588775635 -0.8981994986534119\n",
      "Loss: 0.3584664463996887 -0.8721718788146973\n",
      "Loss: 0.3828623592853546 -0.9521896243095398\n",
      "Policy Reward: tensor(1.0450, device='cuda:0')\n",
      "Trajectory:  ['0.02', '1.00', '0.65', '0.52', '0.57', '0.61', '0.70', '0.82', '0.84', '0.55', '0.22', '0.04', '0.12', '0.80', '0.75', '0.38', '0.15', '0.03', '0.08']\n",
      "Last Action:  tensor([0.0810, 0.5282, 0.2457, 0.8578, 0.3284, 0.3312, 0.7503, 0.6261, 0.2955,\n",
      "        0.3506], device='cuda:0')\n",
      "Bigstep:  43\n",
      "Loss: 0.4315544366836548 -0.0841018334031105\n",
      "Loss: 0.41297608613967896 0.15111999213695526\n",
      "Loss: 0.3672489523887634 -0.14150959253311157\n",
      "Loss: 0.44971713423728943 -0.08537198603153229\n",
      "Loss: 0.353058785200119 -0.3686305284500122\n",
      "Loss: 0.4009058475494385 -0.32710006833076477\n",
      "Loss: 0.37896066904067993 -0.15806393325328827\n",
      "Policy Reward: tensor(1.3452, device='cuda:0')\n",
      "Trajectory:  ['0.03', '1.00', '0.58', '0.37', '0.76', '0.88', '0.97', '0.97', '0.89', '0.57', '0.34', '0.49', '0.55', '0.58', '0.39', '0.40', '0.53', '0.60', '0.59']\n",
      "Last Action:  tensor([0.5944, 0.2441, 0.7161, 0.3608, 0.5291, 0.5607, 0.1536, 0.8873, 0.9012,\n",
      "        0.7621], device='cuda:0')\n",
      "Loss: 0.3620868921279907 -0.31733596324920654\n",
      "Loss: 0.3527568578720093 0.029639586806297302\n",
      "Loss: 0.3793718218803406 -0.49526602029800415\n",
      "Loss: 0.36395263671875 -0.3184281587600708\n",
      "Loss: 0.4347233176231384 -0.5498086810112\n",
      "Loss: 0.4202975630760193 -0.4363754987716675\n",
      "Loss: 0.40515372157096863 -0.20125167071819305\n",
      "Policy Reward: tensor(1.0906, device='cuda:0')\n",
      "Trajectory:  ['0.66', '0.94', '0.94', '0.13', '0.15', '0.55', '0.71', '0.85', '1.00', '1.00', '0.87', '0.50', '0.36', '0.79', '0.95', '0.74', '0.64', '0.53', '0.37']\n",
      "Last Action:  tensor([0.3697, 0.3306, 0.1329, 0.1388, 0.5966, 0.8075, 0.7689, 0.0445, 0.0373,\n",
      "        0.7402], device='cuda:0')\n",
      "Loss: 0.4857921004295349 -0.6333839893341064\n",
      "Loss: 0.4409094452857971 -0.510051965713501\n",
      "Loss: 0.3384723365306854 -0.2637302577495575\n",
      "Loss: 0.5420354604721069 -0.6054227352142334\n",
      "Loss: 0.3605504333972931 -0.34601157903671265\n",
      "Loss: 0.4068141579627991 -0.4724602997303009\n",
      "Loss: 0.3246302902698517 -0.3942720890045166\n",
      "Policy Reward: tensor(1.0561, device='cuda:0')\n",
      "Trajectory:  ['0.72', '1.00', '0.96', '0.18', '0.26', '0.81', '0.98', '0.99', '1.00', '0.99', '0.81', '0.41', '0.46', '0.86', '0.82', '0.46', '0.67', '0.55', '0.77']\n",
      "Last Action:  tensor([0.7721, 0.5702, 0.5991, 0.2631, 0.3538, 0.2588, 0.6609, 0.1156, 0.2099,\n",
      "        0.2078], device='cuda:0')\n",
      "Loss: 0.4132806658744812 -0.4303804636001587\n",
      "Loss: 0.37544459104537964 -0.4842911660671234\n",
      "Loss: 0.3838765323162079 -0.4413169324398041\n",
      "Loss: 0.3647414743900299 -0.20003390312194824\n",
      "Loss: 0.4748160243034363 -1.0171747207641602\n",
      "Loss: 0.3925672471523285 -0.6124229431152344\n",
      "Loss: 0.44029486179351807 -0.6356568932533264\n",
      "Policy Reward: tensor(1.2449, device='cuda:0')\n",
      "Trajectory:  ['0.73', '1.00', '0.99', '0.10', '0.35', '0.69', '0.71', '0.92', '1.00', '0.99', '0.75', '0.39', '0.54', '0.96', '0.88', '0.43', '0.36', '0.37', '0.47']\n",
      "Last Action:  tensor([0.4710, 0.2422, 0.4412, 0.2275, 0.6034, 0.0739, 0.6162, 0.7722, 0.8518,\n",
      "        0.1346], device='cuda:0')\n",
      "Loss: 0.3614789545536041 -0.3421955704689026\n",
      "Loss: 0.4141446053981781 -0.8314725756645203\n",
      "Loss: 0.5333529710769653 -0.6211080551147461\n",
      "Loss: 0.38451072573661804 -0.6835758090019226\n",
      "Loss: 0.36712270975112915 -0.41960325837135315\n",
      "Loss: 0.3502793610095978 -0.22535158693790436\n",
      "Loss: 0.3646708130836487 -0.4826376438140869\n",
      "Policy Reward: tensor(1.0801, device='cuda:0')\n",
      "Trajectory:  ['0.73', '1.00', '0.93', '0.12', '0.33', '0.36', '0.50', '0.68', '0.84', '0.95', '0.71', '0.41', '0.45', '0.93', '0.91', '0.52', '0.27', '0.30', '0.58']\n",
      "Last Action:  tensor([0.5811, 0.6379, 0.5843, 0.6353, 0.9067, 0.6578, 0.5765, 0.9553, 0.2007,\n",
      "        0.9064], device='cuda:0')\n",
      "Loss: 0.4241696894168854 -0.48399943113327026\n",
      "Loss: 0.4791375398635864 -0.5545573830604553\n",
      "Loss: 0.36386799812316895 -0.502856433391571\n",
      "Loss: 0.36820581555366516 -0.43628066778182983\n",
      "Loss: 0.3486539125442505 -0.4047772288322449\n",
      "Loss: 0.3984156548976898 -0.8794201016426086\n",
      "Loss: 0.4163658022880554 -0.8069448471069336\n",
      "Policy Reward: tensor(1.1680, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.02', '0.10', '0.57', '0.83', '0.96', '0.99', '0.97', '0.81', '0.35', '0.15', '0.20', '0.92', '0.92', '0.33', '0.10', '0.03', '0.08']\n",
      "Last Action:  tensor([0.0814, 0.9152, 0.8019, 0.8874, 0.7397, 0.6526, 0.5909, 0.5312, 0.7904,\n",
      "        0.9388], device='cuda:0')\n",
      "Loss: 0.31035810708999634 -0.21257156133651733\n",
      "Loss: 0.372048944234848 -0.712981104850769\n",
      "Loss: 0.42306721210479736 -0.7879133224487305\n",
      "Loss: 0.40503403544425964 -0.7311860918998718\n",
      "Loss: 0.36977335810661316 -0.4219735860824585\n",
      "Loss: 0.43738120794296265 -0.6034060120582581\n",
      "Loss: 0.43303269147872925 -0.6519085764884949\n",
      "Policy Reward: tensor(1.1019, device='cuda:0')\n",
      "Trajectory:  ['0.75', '1.00', '0.97', '0.13', '0.47', '0.77', '0.88', '0.99', '1.00', '0.99', '0.70', '0.46', '0.88', '0.99', '0.79', '0.31', '0.33', '0.70', '0.71']\n",
      "Last Action:  tensor([0.7062, 0.6609, 0.8746, 0.1327, 0.8097, 0.5583, 0.7490, 0.5425, 0.5629,\n",
      "        0.6864], device='cuda:0')\n",
      "Loss: 0.35665109753608704 -0.5444290041923523\n",
      "Loss: 0.36966562271118164 -0.5424323081970215\n",
      "Loss: 0.3638477921485901 -0.4440068006515503\n",
      "Loss: 0.3243405520915985 -0.4201660752296448\n",
      "Loss: 0.35166385769844055 -0.6078945994377136\n",
      "Loss: 0.374531626701355 -0.5756698250770569\n",
      "Loss: 0.3852579593658447 -0.45580026507377625\n",
      "Policy Reward: tensor(1.1597, device='cuda:0')\n",
      "Trajectory:  ['0.43', '1.00', '0.93', '0.15', '0.39', '0.65', '0.81', '0.90', '0.99', '0.96', '0.83', '0.73', '0.77', '0.88', '0.98', '0.98', '0.90', '0.76', '0.78']\n",
      "Last Action:  tensor([0.7817, 0.1916, 0.8404, 0.4954, 0.7718, 0.6725, 0.1175, 0.8909, 0.7953,\n",
      "        0.6032], device='cuda:0')\n",
      "Bigstep:  44\n",
      "Loss: 0.49507004022598267 0.4082135260105133\n",
      "Loss: 0.4517481327056885 0.15444964170455933\n",
      "Loss: 0.4508797228336334 -0.5395892858505249\n",
      "Loss: 0.4644516110420227 -0.44114336371421814\n",
      "Loss: 0.36649566888809204 -0.41641563177108765\n",
      "Loss: 0.4772047996520996 -0.9214182496070862\n",
      "Loss: 0.45932310819625854 -0.6260889768600464\n",
      "Policy Reward: tensor(1.2303, device='cuda:0')\n",
      "Trajectory:  ['0.35', '1.00', '0.86', '0.04', '0.55', '0.84', '0.91', '1.00', '1.00', '0.95', '0.52', '0.26', '0.50', '0.97', '0.80', '0.38', '0.49', '0.27', '0.73']\n",
      "Last Action:  tensor([0.7280, 0.3410, 0.0450, 0.0116, 0.2797, 0.0322, 0.2542, 0.7979, 0.0208,\n",
      "        0.1141], device='cuda:0')\n",
      "Loss: 0.4637276828289032 -0.9844104647636414\n",
      "Loss: 0.35738858580589294 -0.3704358637332916\n",
      "Loss: 0.4802916944026947 -0.6565566062927246\n",
      "Loss: 0.4248781204223633 -0.4013840854167938\n",
      "Loss: 0.4436216354370117 -0.3755858838558197\n",
      "Loss: 0.48544546961784363 -0.7059966921806335\n",
      "Loss: 0.4567391872406006 -0.77550208568573\n",
      "Policy Reward: tensor(1.1800, device='cuda:0')\n",
      "Trajectory:  ['0.07', '1.00', '0.75', '0.40', '0.79', '0.80', '0.85', '0.90', '0.92', '0.82', '0.59', '0.38', '0.07', '0.14', '0.95', '0.98', '0.86', '0.62', '0.33']\n",
      "Last Action:  tensor([0.3324, 0.0589, 0.5676, 0.2841, 0.0211, 0.2852, 0.0452, 0.5541, 0.4197,\n",
      "        0.0896], device='cuda:0')\n",
      "Loss: 0.3815622925758362 -0.3653357923030853\n",
      "Loss: 0.3770201802253723 -0.4878334105014801\n",
      "Loss: 0.4252506494522095 -0.8181337118148804\n",
      "Loss: 0.37400689721107483 -0.4649978578090668\n",
      "Loss: 0.41469722986221313 -0.5495012402534485\n",
      "Loss: 0.3574323058128357 -0.7002200484275818\n",
      "Loss: 0.4622343182563782 -0.8667665123939514\n",
      "Policy Reward: tensor(1.1544, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.02', '0.19', '0.73', '0.89', '0.92', '0.97', '0.96', '0.72', '0.31', '0.06', '0.06', '0.87', '0.97', '0.32', '0.11', '0.03', '0.08']\n",
      "Last Action:  tensor([0.0756, 0.0591, 0.0461, 0.1713, 0.4772, 0.3635, 0.0314, 0.0326, 0.6771,\n",
      "        0.9768], device='cuda:0')\n",
      "Loss: 0.411021888256073 -0.3531402349472046\n",
      "Loss: 0.4302590489387512 -0.7836263179779053\n",
      "Loss: 0.4486316740512848 -0.7197239398956299\n",
      "Loss: 0.3747658431529999 -0.7645480036735535\n",
      "Loss: 0.38963592052459717 -0.39796122908592224\n",
      "Loss: 0.4379749298095703 -0.5013173222541809\n",
      "Loss: 0.3741622865200043 -0.6717251539230347\n",
      "Policy Reward: tensor(1.2562, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.00', '0.01', '0.55', '0.77', '0.89', '0.97', '0.99', '0.88', '0.48', '0.20', '0.02', '0.20', '0.96', '0.50', '0.35', '0.19', '0.04']\n",
      "Last Action:  tensor([0.0388, 0.1474, 0.0439, 0.0802, 0.1730, 0.1069, 0.1120, 0.0725, 0.0504,\n",
      "        0.0952], device='cuda:0')\n",
      "Loss: 0.44905170798301697 -0.5395570397377014\n",
      "Loss: 0.4423670470714569 -0.8258638381958008\n",
      "Loss: 0.3864690959453583 -0.6903916001319885\n",
      "Loss: 0.3526785373687744 -0.5691025853157043\n",
      "Loss: 0.4740493595600128 -1.0324162244796753\n",
      "Loss: 0.4125175178050995 -0.818932056427002\n",
      "Loss: 0.3651384711265564 -0.6106739044189453\n",
      "Policy Reward: tensor(1.1502, device='cuda:0')\n",
      "Trajectory:  ['0.31', '1.00', '0.78', '0.01', '0.27', '0.50', '0.53', '0.51', '0.52', '0.48', '0.18', '0.01', '0.01', '0.94', '0.96', '0.35', '0.20', '0.04', '0.14']\n",
      "Last Action:  tensor([0.1395, 0.7217, 0.0833, 0.0502, 0.8694, 0.8722, 0.2087, 0.2436, 0.1843,\n",
      "        0.0935], device='cuda:0')\n",
      "Loss: 0.3862164318561554 -0.5434492230415344\n",
      "Loss: 0.40789368748664856 -0.6925727128982544\n",
      "Loss: 0.34271883964538574 -0.43408507108688354\n",
      "Loss: 0.35876938700675964 -0.7265470623970032\n",
      "Loss: 0.4106600284576416 -0.619041383266449\n",
      "Loss: 0.3932530879974365 -0.6946908831596375\n",
      "Loss: 0.4227663576602936 -0.9519253969192505\n",
      "Policy Reward: tensor(1.1871, device='cuda:0')\n",
      "Trajectory:  ['0.48', '1.00', '0.41', '0.20', '0.79', '0.79', '0.84', '0.97', '0.90', '0.96', '0.66', '0.52', '0.26', '0.11', '0.69', '0.97', '0.86', '0.95', '0.88']\n",
      "Last Action:  tensor([0.8811, 0.9323, 0.3115, 0.6336, 0.1233, 0.0549, 0.0277, 0.0867, 0.0590,\n",
      "        0.8158], device='cuda:0')\n",
      "Loss: 0.4044460654258728 -0.44747671484947205\n",
      "Loss: 0.3524341285228729 -0.6678062677383423\n",
      "Loss: 0.40432092547416687 -0.6607474088668823\n",
      "Loss: 0.4618547558784485 -1.2732923030853271\n",
      "Loss: 0.4870346784591675 -1.1642417907714844\n",
      "Loss: 0.34680986404418945 -0.8000275492668152\n",
      "Loss: 0.427674263715744 -0.6430846452713013\n",
      "Policy Reward: tensor(1.2415, device='cuda:0')\n",
      "Trajectory:  ['0.42', '1.00', '0.80', '0.08', '0.32', '0.60', '0.66', '0.69', '0.81', '0.85', '0.59', '0.20', '0.03', '0.20', '0.98', '0.66', '0.34', '0.19', '0.06']\n",
      "Last Action:  tensor([0.0633, 0.7547, 0.0598, 0.3935, 0.9186, 0.0660, 0.8422, 0.0765, 0.7416,\n",
      "        0.1742], device='cuda:0')\n",
      "Loss: 0.4281311333179474 -1.0703164339065552\n",
      "Loss: 0.3668529689311981 -0.6631055474281311\n",
      "Loss: 0.39255115389823914 -0.9970702528953552\n",
      "Loss: 0.4214434325695038 -0.7004241943359375\n",
      "Loss: 0.42527905106544495 -0.8667022585868835\n",
      "Loss: 0.45569559931755066 -0.8478417992591858\n",
      "Loss: 0.38929080963134766 -1.0345439910888672\n",
      "Policy Reward: tensor(1.1947, device='cuda:0')\n",
      "Trajectory:  ['0.12', '1.00', '0.83', '0.21', '0.75', '0.91', '0.96', '0.90', '0.97', '0.63', '0.39', '0.10', '0.07', '0.89', '0.99', '0.83', '0.70', '0.57', '0.47']\n",
      "Last Action:  tensor([0.4734, 0.0501, 0.0952, 0.0597, 0.0426, 0.2398, 0.9264, 0.9538, 0.0784,\n",
      "        0.0822], device='cuda:0')\n",
      "Bigstep:  45\n",
      "Loss: 0.4211510121822357 -0.4776552617549896\n",
      "Loss: 0.46283379197120667 -0.7146108746528625\n",
      "Loss: 0.37540626525878906 -0.9790955781936646\n",
      "Loss: 0.4687945246696472 -0.8109334707260132\n",
      "Loss: 0.36055663228034973 -0.731438159942627\n",
      "Loss: 0.42104724049568176 -1.0735231637954712\n",
      "Loss: 0.4325714409351349 -1.0501787662506104\n",
      "Policy Reward: tensor(1.1771, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.06', '0.14', '0.69', '0.90', '0.89', '0.91', '0.89', '0.67', '0.35', '0.19', '0.24', '0.69', '0.61', '0.32', '0.29', '0.27', '0.32']\n",
      "Last Action:  tensor([0.3170, 0.4069, 0.3549, 0.0877, 0.1805, 0.0368, 0.2396, 0.3626, 0.0990,\n",
      "        0.4873], device='cuda:0')\n",
      "Loss: 0.37750640511512756 -0.7948275208473206\n",
      "Loss: 0.4556001126766205 -1.1137447357177734\n",
      "Loss: 0.3502236306667328 -0.6841446757316589\n",
      "Loss: 0.43746069073677063 -1.2654552459716797\n",
      "Loss: 0.39487382769584656 -0.8154093623161316\n",
      "Loss: 0.4322049915790558 -1.1066815853118896\n",
      "Loss: 0.32881516218185425 -0.7688639760017395\n",
      "Policy Reward: tensor(1.1172, device='cuda:0')\n",
      "Trajectory:  ['0.54', '0.31', '0.71', '0.38', '0.55', '0.80', '0.93', '0.97', '0.98', '0.94', '0.82', '0.59', '0.37', '0.52', '0.52', '0.54', '0.46', '0.59', '0.77']\n",
      "Last Action:  tensor([0.7739, 0.1095, 0.7682, 0.4450, 0.0956, 0.5899, 0.4273, 0.1349, 0.1675,\n",
      "        0.1420], device='cuda:0')\n",
      "Loss: 0.42613574862480164 -0.9606163501739502\n",
      "Loss: 0.30914968252182007 -0.6195175051689148\n",
      "Loss: 0.3808511793613434 -0.7859731316566467\n",
      "Loss: 0.4699711501598358 -1.4221220016479492\n",
      "Loss: 0.534980297088623 -1.521948218345642\n",
      "Loss: 0.49274948239326477 -1.029662847518921\n",
      "Loss: 0.42751258611679077 -1.2022333145141602\n",
      "Policy Reward: tensor(1.2168, device='cuda:0')\n",
      "Trajectory:  ['0.39', '1.00', '0.83', '0.07', '0.32', '0.66', '0.82', '0.92', '0.98', '0.81', '0.58', '0.48', '0.43', '0.52', '0.81', '0.53', '0.50', '0.49', '0.55']\n",
      "Last Action:  tensor([0.5521, 0.1837, 0.9022, 0.3300, 0.4086, 0.1177, 0.2697, 0.8948, 0.3716,\n",
      "        0.0734], device='cuda:0')\n",
      "Loss: 0.3622574508190155 -1.0105067491531372\n",
      "Loss: 0.41581133008003235 -1.0900616645812988\n",
      "Loss: 0.4752419590950012 -1.2922255992889404\n",
      "Loss: 0.4437507092952728 -1.0937291383743286\n",
      "Loss: 0.33265817165374756 -0.5854524374008179\n",
      "Loss: 0.39350560307502747 -1.061402678489685\n",
      "Loss: 0.4305422902107239 -1.1972647905349731\n",
      "Policy Reward: tensor(1.2351, device='cuda:0')\n",
      "Trajectory:  ['0.34', '1.00', '0.90', '0.05', '0.27', '0.64', '0.79', '0.82', '0.93', '0.87', '0.60', '0.44', '0.47', '0.82', '0.91', '0.56', '0.28', '0.11', '0.14']\n",
      "Last Action:  tensor([0.1446, 0.2927, 0.5146, 0.2898, 0.3089, 0.9209, 0.8349, 0.3494, 0.1734,\n",
      "        0.5339], device='cuda:0')\n",
      "Loss: 0.40293648838996887 -1.0806303024291992\n",
      "Loss: 0.38461410999298096 -0.5359888076782227\n",
      "Loss: 0.4092545807361603 -1.178498387336731\n",
      "Loss: 0.3932134509086609 -0.5845557451248169\n",
      "Loss: 0.4545430839061737 -1.3493270874023438\n",
      "Loss: 0.40985333919525146 -0.9042543768882751\n",
      "Loss: 0.4103771150112152 -0.9000742435455322\n",
      "Policy Reward: tensor(1.3494, device='cuda:0')\n",
      "Trajectory:  ['0.57', '1.00', '0.69', '0.38', '0.36', '0.76', '0.89', '0.99', '1.00', '0.98', '0.84', '0.63', '0.89', '0.86', '0.93', '0.40', '0.48', '0.50', '0.49']\n",
      "Last Action:  tensor([0.4862, 0.3812, 0.1809, 0.0743, 0.1080, 0.6925, 0.0872, 0.3013, 0.3610,\n",
      "        0.3748], device='cuda:0')\n",
      "Loss: 0.420734167098999 -1.239061951637268\n",
      "Loss: 0.35712647438049316 -0.7461960911750793\n",
      "Loss: 0.3162078261375427 -0.762488842010498\n",
      "Loss: 0.3132820129394531 -0.42828258872032166\n",
      "Loss: 0.4406775236129761 -0.8547526001930237\n",
      "Loss: 0.561603844165802 -1.421335220336914\n",
      "Loss: 0.49391257762908936 -1.4209580421447754\n",
      "Policy Reward: tensor(1.2382, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.99', '0.00', '0.00', '0.48', '0.58', '0.90', '0.97', '0.97', '0.92', '0.64', '0.37', '0.31', '0.38', '0.41', '0.57', '0.71', '0.28', '0.26']\n",
      "Last Action:  tensor([0.2609, 0.8351, 0.2954, 0.3896, 0.1190, 0.0512, 0.6729, 0.0756, 0.0934,\n",
      "        0.2124], device='cuda:0')\n",
      "Loss: 0.36459577083587646 -0.7695357203483582\n",
      "Loss: 0.42456820607185364 -0.9613382816314697\n",
      "Loss: 0.35535019636154175 -0.7823259234428406\n",
      "Loss: 0.38027137517929077 -0.9910943508148193\n",
      "Loss: 0.5585043430328369 -1.6102643013000488\n",
      "Loss: 0.35301676392555237 -0.7728198170661926\n",
      "Loss: 0.3601028025150299 -0.8810710310935974\n",
      "Policy Reward: tensor(1.2323, device='cuda:0')\n",
      "Trajectory:  ['0.02', '1.00', '0.03', '0.05', '0.67', '0.77', '0.84', '0.94', '0.94', '0.86', '0.60', '0.46', '0.38', '0.36', '0.91', '0.57', '0.24', '0.14', '0.08']\n",
      "Last Action:  tensor([0.0762, 0.2481, 0.1798, 0.1243, 0.2075, 0.1693, 0.1128, 0.0827, 0.1344,\n",
      "        0.4798], device='cuda:0')\n",
      "Loss: 0.4425203800201416 -1.3267160654067993\n",
      "Loss: 0.4246503412723541 -1.0565249919891357\n",
      "Loss: 0.44651034474372864 -1.2426570653915405\n",
      "Loss: 0.38521987199783325 -1.1135817766189575\n",
      "Loss: 0.3816000819206238 -0.49337536096572876\n",
      "Loss: 0.41747307777404785 -1.3832337856292725\n",
      "Loss: 0.40634554624557495 -1.1337082386016846\n",
      "Policy Reward: tensor(1.1918, device='cuda:0')\n",
      "Trajectory:  ['0.24', '0.97', '0.76', '0.21', '0.44', '0.79', '0.91', '0.98', '0.99', '0.88', '0.57', '0.43', '0.35', '0.44', '0.83', '0.63', '0.16', '0.16', '0.22']\n",
      "Last Action:  tensor([0.2179, 0.2009, 0.5996, 0.5396, 0.1177, 0.8068, 0.8495, 0.2729, 0.5910,\n",
      "        0.4670], device='cuda:0')\n",
      "Bigstep:  46\n",
      "Loss: 0.3162713050842285 0.029842806980013847\n",
      "Loss: 0.4491494596004486 -0.9225192070007324\n",
      "Loss: 0.4123668968677521 -0.6201330423355103\n",
      "Loss: 0.4238619804382324 -0.5221924781799316\n",
      "Loss: 0.46077945828437805 -0.84486985206604\n",
      "Loss: 0.3449864983558655 -0.0816560834646225\n",
      "Loss: 0.40210628509521484 -0.5765773057937622\n",
      "Policy Reward: tensor(1.1080, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.08', '0.10', '0.58', '0.85', '0.90', '0.93', '0.95', '0.71', '0.23', '0.13', '0.08', '0.84', '0.99', '0.26', '0.04', '0.01', '0.04']\n",
      "Last Action:  tensor([0.0378, 0.0174, 0.0328, 0.0290, 0.3614, 0.0529, 0.8337, 0.6762, 0.0897,\n",
      "        0.0207], device='cuda:0')\n",
      "Loss: 0.3771684169769287 -0.520959198474884\n",
      "Loss: 0.4250357151031494 -0.6881343126296997\n",
      "Loss: 0.39833956956863403 -0.7081983685493469\n",
      "Loss: 0.46715256571769714 -0.557015597820282\n",
      "Loss: 0.3560223877429962 -0.5621609687805176\n",
      "Loss: 0.4586177170276642 -0.853439211845398\n",
      "Loss: 0.4159420430660248 -0.4157312512397766\n",
      "Policy Reward: tensor(1.2295, device='cuda:0')\n",
      "Trajectory:  ['0.13', '1.00', '0.79', '0.00', '0.18', '0.58', '0.81', '0.86', '0.94', '0.69', '0.34', '0.23', '0.16', '0.62', '0.92', '0.17', '0.05', '0.02', '0.05']\n",
      "Last Action:  tensor([0.0452, 0.0164, 0.0238, 0.9017, 0.2094, 0.6337, 0.0046, 0.2173, 0.2294,\n",
      "        0.0478], device='cuda:0')\n",
      "Loss: 0.33429744839668274 -0.3817192316055298\n",
      "Loss: 0.3924636244773865 -1.1217410564422607\n",
      "Loss: 0.3312360942363739 -0.4484326243400574\n",
      "Loss: 0.3441280722618103 -0.7024704217910767\n",
      "Loss: 0.3595856726169586 -0.5276713967323303\n",
      "Loss: 0.3647887408733368 -0.5485327839851379\n",
      "Loss: 0.41450169682502747 -0.555538535118103\n",
      "Policy Reward: tensor(1.3594, device='cuda:0')\n",
      "Trajectory:  ['0.32', '1.00', '0.85', '0.01', '0.18', '0.42', '0.56', '0.59', '0.62', '0.49', '0.17', '0.04', '0.02', '0.91', '0.99', '0.35', '0.05', '0.00', '0.03']\n",
      "Last Action:  tensor([0.0335, 0.0113, 0.0664, 0.0128, 0.6420, 0.0801, 0.6648, 0.3755, 0.3486,\n",
      "        0.0116], device='cuda:0')\n",
      "Loss: 0.38449105620384216 -0.44826391339302063\n",
      "Loss: 0.5126326680183411 -1.2351270914077759\n",
      "Loss: 0.36044731736183167 -0.23803485929965973\n",
      "Loss: 0.49154457449913025 -1.3341668844223022\n",
      "Loss: 0.41630688309669495 -0.6858505606651306\n",
      "Loss: 0.4522840082645416 -1.0499321222305298\n",
      "Loss: 0.39855560660362244 -0.9690765738487244\n",
      "Policy Reward: tensor(1.1970, device='cuda:0')\n",
      "Trajectory:  ['0.25', '1.00', '0.86', '0.12', '0.50', '0.83', '0.87', '0.94', '0.94', '0.72', '0.82', '0.47', '0.57', '0.16', '0.06', '0.83', '0.98', '0.98', '0.85']\n",
      "Last Action:  tensor([0.8489, 0.0663, 0.1427, 0.1776, 0.0333, 0.1782, 0.0108, 0.0249, 0.0214,\n",
      "        0.0205], device='cuda:0')\n",
      "Loss: 0.4456702768802643 -1.0083199739456177\n",
      "Loss: 0.4181337058544159 -0.8582801222801208\n",
      "Loss: 0.5057090520858765 -1.4520078897476196\n",
      "Loss: 0.43558916449546814 -1.2966383695602417\n",
      "Loss: 0.36597898602485657 -0.7515004873275757\n",
      "Loss: 0.32703739404678345 -0.32329776883125305\n",
      "Loss: 0.38487398624420166 -0.7108545899391174\n",
      "Policy Reward: tensor(1.1414, device='cuda:0')\n",
      "Trajectory:  ['0.39', '1.00', '0.78', '0.04', '0.23', '0.55', '0.75', '0.90', '0.99', '0.86', '0.40', '0.23', '0.16', '0.24', '0.95', '0.58', '0.07', '0.04', '0.04']\n",
      "Last Action:  tensor([0.0402, 0.2924, 0.0190, 0.0220, 0.0219, 0.1299, 0.0584, 0.0575, 0.3028,\n",
      "        0.1305], device='cuda:0')\n",
      "Loss: 0.3536522686481476 -0.5708552598953247\n",
      "Loss: 0.4860583543777466 -1.108368158340454\n",
      "Loss: 0.42602959275245667 -1.1791390180587769\n",
      "Loss: 0.3913581371307373 -0.4901079535484314\n",
      "Loss: 0.38453397154808044 -0.27108272910118103\n",
      "Loss: 0.35015130043029785 -0.8452126383781433\n",
      "Loss: 0.41831424832344055 -0.6170046329498291\n",
      "Policy Reward: tensor(1.2914, device='cuda:0')\n",
      "Trajectory:  ['0.25', '1.00', '0.73', '0.23', '0.53', '0.78', '0.88', '0.98', '0.98', '0.88', '0.64', '0.19', '0.10', '0.10', '0.85', '0.96', '0.40', '0.28', '0.14']\n",
      "Last Action:  tensor([0.1403, 0.6066, 0.0328, 0.0140, 0.0407, 0.0314, 0.0319, 0.9094, 0.1574,\n",
      "        0.7124], device='cuda:0')\n",
      "Loss: 0.4636077582836151 -0.8367854356765747\n",
      "Loss: 0.32927942276000977 -0.3591485321521759\n",
      "Loss: 0.4288432002067566 -0.5208585858345032\n",
      "Loss: 0.47512662410736084 -0.9915321469306946\n",
      "Loss: 0.3657991588115692 -0.8114854693412781\n",
      "Loss: 0.31813845038414 -0.14661669731140137\n",
      "Loss: 0.3779016435146332 -0.845089316368103\n",
      "Policy Reward: tensor(1.1833, device='cuda:0')\n",
      "Trajectory:  ['0.30', '1.00', '0.80', '0.04', '0.22', '0.68', '0.87', '0.97', '0.99', '0.76', '0.39', '0.31', '0.11', '0.47', '0.98', '0.18', '0.14', '0.09', '0.05']\n",
      "Last Action:  tensor([0.0456, 0.0209, 0.0370, 0.0232, 0.0093, 0.1865, 0.0221, 0.3566, 0.1025,\n",
      "        0.0051], device='cuda:0')\n",
      "Loss: 0.36232003569602966 -0.8733777403831482\n",
      "Loss: 0.35104119777679443 -0.7026861906051636\n",
      "Loss: 0.35790786147117615 -0.5124080777168274\n",
      "Loss: 0.4303285479545593 -0.7264754176139832\n",
      "Loss: 0.37100017070770264 -1.100624680519104\n",
      "Loss: 0.4411791265010834 -0.8654658794403076\n",
      "Loss: 0.46859169006347656 -0.9736291766166687\n",
      "Policy Reward: tensor(1.1862, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.08', '0.16', '0.46', '0.79', '0.94', '0.97', '0.96', '0.76', '0.42', '0.25', '0.09', '0.26', '0.98', '0.74', '0.17', '0.01', '0.01']\n",
      "Last Action:  tensor([0.0069, 0.4729, 0.0083, 0.0095, 0.0194, 0.7045, 0.8035, 0.6007, 0.0200,\n",
      "        0.0248], device='cuda:0')\n",
      "Bigstep:  47\n",
      "Loss: 0.4187157154083252 -0.45220574736595154\n",
      "Loss: 0.37747567892074585 -0.37800365686416626\n",
      "Loss: 0.47003063559532166 -0.6348007917404175\n",
      "Loss: 0.4110177457332611 -0.5132362246513367\n",
      "Loss: 0.42934757471084595 -0.5397853255271912\n",
      "Loss: 0.3542546033859253 -0.7441414594650269\n",
      "Loss: 0.3725847899913788 -0.6702708601951599\n",
      "Policy Reward: tensor(1.1431, device='cuda:0')\n",
      "Trajectory:  ['0.44', '1.00', '0.80', '0.02', '0.14', '0.34', '0.72', '0.75', '0.75', '0.37', '0.08', '0.02', '0.07', '0.78', '0.65', '0.03', '0.00', '0.01', '0.04']\n",
      "Last Action:  tensor([0.0360, 0.0591, 0.0692, 0.0239, 0.0461, 0.0529, 0.0905, 0.0574, 0.0454,\n",
      "        0.0204], device='cuda:0')\n",
      "Loss: 0.4590383768081665 -1.148782730102539\n",
      "Loss: 0.38798511028289795 -0.5500202178955078\n",
      "Loss: 0.3515932857990265 -0.5530850291252136\n",
      "Loss: 0.42483004927635193 -0.42056870460510254\n",
      "Loss: 0.3960791826248169 -0.5459852814674377\n",
      "Loss: 0.41197577118873596 -0.6254977583885193\n",
      "Loss: 0.44322532415390015 -0.8734297752380371\n",
      "Policy Reward: tensor(1.2860, device='cuda:0')\n",
      "Trajectory:  ['0.26', '1.00', '0.82', '0.01', '0.29', '0.70', '0.87', '0.99', '0.95', '0.35', '0.08', '0.02', '0.06', '0.55', '0.67', '0.03', '0.06', '0.16', '0.19']\n",
      "Last Action:  tensor([0.1872, 0.1099, 0.1455, 0.1219, 0.2910, 0.1738, 0.0694, 0.0027, 0.2238,\n",
      "        0.0909], device='cuda:0')\n",
      "Loss: 0.3779871463775635 -1.0660582780838013\n",
      "Loss: 0.4459877908229828 -0.6653243899345398\n",
      "Loss: 0.4339108467102051 -0.6150636076927185\n",
      "Loss: 0.4379402995109558 -0.4921180307865143\n",
      "Loss: 0.43232905864715576 -0.7316651940345764\n",
      "Loss: 0.5024846196174622 -1.102341651916504\n",
      "Loss: 0.4285506308078766 -0.7670997977256775\n",
      "Policy Reward: tensor(1.3047, device='cuda:0')\n",
      "Trajectory:  ['0.42', '1.00', '0.60', '0.01', '0.10', '0.59', '0.87', '0.97', '0.99', '0.77', '0.24', '0.10', '0.02', '0.16', '0.74', '0.34', '0.02', '0.10', '0.38']\n",
      "Last Action:  tensor([0.3813, 0.0952, 0.0301, 0.1660, 0.0191, 0.0188, 0.2289, 0.0275, 0.0485,\n",
      "        0.2348], device='cuda:0')\n",
      "Loss: 0.4671964943408966 -0.8907081484794617\n",
      "Loss: 0.3965242803096771 -0.8710075616836548\n",
      "Loss: 0.47446486353874207 -0.7766931653022766\n",
      "Loss: 0.44408851861953735 -0.5598600506782532\n",
      "Loss: 0.4149876534938812 -0.710614800453186\n",
      "Loss: 0.38897138833999634 -0.9393526315689087\n",
      "Loss: 0.3920993208885193 -0.5836153030395508\n",
      "Policy Reward: tensor(1.1905, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.02', '0.09', '0.67', '0.80', '0.98', '1.00', '0.96', '0.63', '0.23', '0.04', '0.04', '0.51', '0.71', '0.05', '0.01', '0.02', '0.09']\n",
      "Last Action:  tensor([0.0913, 0.0191, 0.0262, 0.0810, 0.0409, 0.0256, 0.1301, 0.3482, 0.1732,\n",
      "        0.0647], device='cuda:0')\n",
      "Loss: 0.42343267798423767 -0.7747687697410583\n",
      "Loss: 0.4751484990119934 -1.0634936094284058\n",
      "Loss: 0.5151663422584534 -0.891854465007782\n",
      "Loss: 0.386543333530426 -0.6600322723388672\n",
      "Loss: 0.3630048632621765 -0.49571922421455383\n",
      "Loss: 0.35701897740364075 -0.8122367858886719\n",
      "Loss: 0.49872472882270813 -0.8657931089401245\n",
      "Policy Reward: tensor(1.2454, device='cuda:0')\n",
      "Trajectory:  ['0.41', '1.00', '0.76', '0.05', '0.33', '0.57', '0.70', '0.78', '0.87', '0.56', '0.11', '0.01', '0.01', '0.47', '0.92', '0.14', '0.01', '0.01', '0.03']\n",
      "Last Action:  tensor([0.0277, 0.0433, 0.0414, 0.1420, 0.2358, 0.0526, 0.0187, 0.2335, 0.0066,\n",
      "        0.1376], device='cuda:0')\n",
      "Loss: 0.41208916902542114 -0.4336506724357605\n",
      "Loss: 0.41769108176231384 -0.6793320178985596\n",
      "Loss: 0.4567609131336212 -0.9102382659912109\n",
      "Loss: 0.390520304441452 -0.7807952761650085\n",
      "Loss: 0.46141335368156433 -0.9098923802375793\n",
      "Loss: 0.44713082909584045 -0.6723154187202454\n",
      "Loss: 0.3593073785305023 -0.5469997525215149\n",
      "Policy Reward: tensor(1.2140, device='cuda:0')\n",
      "Trajectory:  ['0.16', '1.00', '0.84', '0.03', '0.23', '0.53', '0.78', '0.95', '0.90', '0.25', '0.04', '0.01', '0.23', '0.84', '0.21', '0.02', '0.01', '0.02', '0.13']\n",
      "Last Action:  tensor([0.1304, 0.0615, 0.0227, 0.8461, 0.1722, 0.1048, 0.1280, 0.0508, 0.0247,\n",
      "        0.0653], device='cuda:0')\n",
      "Loss: 0.3606773912906647 -0.38152608275413513\n",
      "Loss: 0.3947698175907135 -0.6397392749786377\n",
      "Loss: 0.412689208984375 -0.9974789619445801\n",
      "Loss: 0.4713422954082489 -0.8400517702102661\n",
      "Loss: 0.334847629070282 -0.4957703948020935\n",
      "Loss: 0.39703842997550964 -0.5113738775253296\n",
      "Loss: 0.4546092450618744 -0.9189507961273193\n",
      "Policy Reward: tensor(1.2635, device='cuda:0')\n",
      "Trajectory:  ['0.28', '1.00', '0.82', '0.02', '0.21', '0.51', '0.60', '0.79', '0.89', '0.42', '0.07', '0.01', '0.04', '0.60', '0.81', '0.03', '0.00', '0.01', '0.04']\n",
      "Last Action:  tensor([0.0445, 0.1081, 0.0509, 0.6284, 0.1337, 0.2155, 0.1512, 0.0208, 0.1507,\n",
      "        0.0597], device='cuda:0')\n",
      "Loss: 0.37161046266555786 -0.26890310645103455\n",
      "Loss: 0.34773683547973633 -0.7026726603507996\n",
      "Loss: 0.341033399105072 -0.3101375699043274\n",
      "Loss: 0.5216015577316284 -1.2601544857025146\n",
      "Loss: 0.3232877254486084 -0.177659809589386\n",
      "Loss: 0.511244535446167 -1.4240214824676514\n",
      "Loss: 0.4410693645477295 -0.9366212487220764\n",
      "Policy Reward: tensor(1.2989, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.16', '0.36', '0.64', '0.60', '0.75', '0.92', '0.86', '0.36', '0.04', '0.01', '0.02', '0.46', '0.73', '0.06', '0.01', '0.04', '0.12']\n",
      "Last Action:  tensor([0.1175, 0.0291, 0.0801, 0.3116, 0.0154, 0.0355, 0.0351, 0.0056, 0.0857,\n",
      "        0.0287], device='cuda:0')\n",
      "Bigstep:  48\n",
      "Loss: 0.38696837425231934 -0.1559334397315979\n",
      "Loss: 0.36931145191192627 0.02407604455947876\n",
      "Loss: 0.43702733516693115 -0.4327528476715088\n",
      "Loss: 0.4844290614128113 -1.1890926361083984\n",
      "Loss: 0.41195860505104065 -0.3401641845703125\n",
      "Loss: 0.3206980526447296 -0.03811374679207802\n",
      "Loss: 0.3235630393028259 -0.2082223743200302\n",
      "Policy Reward: tensor(1.1909, device='cuda:0')\n",
      "Trajectory:  ['0.51', '1.00', '0.47', '0.10', '0.30', '0.55', '0.84', '0.96', '0.53', '0.05', '0.00', '0.00', '0.08', '0.68', '0.29', '0.00', '0.01', '0.05', '0.15']\n",
      "Last Action:  tensor([0.1489, 0.2716, 0.1397, 0.0545, 0.1635, 0.1448, 0.0241, 0.0627, 0.1626,\n",
      "        0.1063], device='cuda:0')\n",
      "Loss: 0.3667345941066742 -0.21097245812416077\n",
      "Loss: 0.354182630777359 -0.2121494710445404\n",
      "Loss: 0.32852816581726074 -0.42497509717941284\n",
      "Loss: 0.4170507490634918 -0.6628538966178894\n",
      "Loss: 0.40527766942977905 -0.4749927520751953\n",
      "Loss: 0.4117581844329834 -0.6294923424720764\n",
      "Loss: 0.30259543657302856 -0.4045637845993042\n",
      "Policy Reward: tensor(1.2243, device='cuda:0')\n",
      "Trajectory:  ['0.37', '1.00', '0.76', '0.01', '0.27', '0.55', '0.68', '0.85', '0.62', '0.05', '0.00', '0.00', '0.25', '0.81', '0.03', '0.00', '0.00', '0.03', '0.15']\n",
      "Last Action:  tensor([0.1479, 0.2371, 0.1282, 0.2203, 0.1103, 0.1935, 0.0173, 0.1467, 0.1684,\n",
      "        0.4109], device='cuda:0')\n",
      "Loss: 0.376552015542984 -0.3943505585193634\n",
      "Loss: 0.42477938532829285 -0.8551285862922668\n",
      "Loss: 0.3722677528858185 -0.29434844851493835\n",
      "Loss: 0.4383387267589569 -0.624122142791748\n",
      "Loss: 0.444029837846756 -0.7986860275268555\n",
      "Loss: 0.4452655613422394 -0.9230272173881531\n",
      "Loss: 0.43263617157936096 -0.9541829228401184\n",
      "Policy Reward: tensor(1.3498, device='cuda:0')\n",
      "Trajectory:  ['0.45', '1.00', '0.79', '0.01', '0.24', '0.53', '0.81', '0.98', '0.63', '0.04', '0.00', '0.01', '0.35', '0.16', '0.01', '0.00', '0.05', '0.20', '0.17']\n",
      "Last Action:  tensor([0.1653, 0.1137, 0.1916, 0.2627, 0.0466, 0.1388, 0.0812, 0.1148, 0.0455,\n",
      "        0.2332], device='cuda:0')\n",
      "Loss: 0.33906933665275574 -0.4641134738922119\n",
      "Loss: 0.38794755935668945 -0.6602153182029724\n",
      "Loss: 0.3901003301143646 -0.6807988882064819\n",
      "Loss: 0.48051559925079346 -0.4202088713645935\n",
      "Loss: 0.3330826163291931 -0.336531400680542\n",
      "Loss: 0.4760495722293854 -0.8521305322647095\n",
      "Loss: 0.4180775284767151 -0.7235585451126099\n",
      "Policy Reward: tensor(1.2007, device='cuda:0')\n",
      "Trajectory:  ['0.50', '1.00', '0.81', '0.04', '0.16', '0.39', '0.68', '0.81', '0.61', '0.02', '0.00', '0.00', '0.02', '0.70', '0.22', '0.00', '0.00', '0.01', '0.05']\n",
      "Last Action:  tensor([0.0545, 0.2190, 0.2403, 0.2525, 0.0574, 0.1591, 0.0733, 0.0922, 0.0374,\n",
      "        0.5337], device='cuda:0')\n",
      "Loss: 0.3660755753517151 -0.5674803256988525\n",
      "Loss: 0.4049626290798187 -0.47874122858047485\n",
      "Loss: 0.4127773344516754 -0.67469322681427\n",
      "Loss: 0.39423486590385437 -0.4302390217781067\n",
      "Loss: 0.34577620029449463 -0.37794479727745056\n",
      "Loss: 0.4076099991798401 -0.7845640182495117\n",
      "Loss: 0.4718562662601471 -0.8705458045005798\n",
      "Policy Reward: tensor(1.1499, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.60', '0.15', '0.46', '0.73', '0.98', '0.90', '0.57', '0.04', '0.00', '0.00', '0.03', '0.41', '0.46', '0.21', '0.04', '0.03', '0.06']\n",
      "Last Action:  tensor([0.0562, 0.2141, 0.0650, 0.1320, 0.1272, 0.1479, 0.1907, 0.0707, 0.2102,\n",
      "        0.1949], device='cuda:0')\n",
      "Loss: 0.41135305166244507 -0.7500205039978027\n",
      "Loss: 0.45441490411758423 -0.7678460478782654\n",
      "Loss: 0.3523828387260437 -0.29326552152633667\n",
      "Loss: 0.430576890707016 -0.6337651014328003\n",
      "Loss: 0.4850877523422241 -0.8359366059303284\n",
      "Loss: 0.3630658984184265 -0.16759082674980164\n",
      "Loss: 0.3605538308620453 -0.9219399690628052\n",
      "Policy Reward: tensor(1.1556, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.08', '0.33', '0.67', '0.84', '0.92', '0.91', '0.43', '0.02', '0.00', '0.00', '0.14', '0.36', '0.02', '0.01', '0.04', '0.12', '0.17']\n",
      "Last Action:  tensor([0.1717, 0.2018, 0.2274, 0.1739, 0.1977, 0.2629, 0.2653, 0.1907, 0.1984,\n",
      "        0.2976], device='cuda:0')\n",
      "Loss: 0.3709699809551239 -0.7428421974182129\n",
      "Loss: 0.5355539917945862 -1.1866636276245117\n",
      "Loss: 0.3882184326648712 -0.5760865807533264\n",
      "Loss: 0.44975772500038147 -0.9893437623977661\n",
      "Loss: 0.31656333804130554 -0.03234068304300308\n",
      "Loss: 0.4059944450855255 -0.49956512451171875\n",
      "Loss: 0.4155726730823517 -0.9993436932563782\n",
      "Policy Reward: tensor(1.1767, device='cuda:0')\n",
      "Trajectory:  ['0.72', '1.00', '0.78', '0.07', '0.37', '0.63', '0.74', '0.82', '0.60', '0.04', '0.00', '0.00', '0.05', '0.84', '0.12', '0.00', '0.00', '0.02', '0.12']\n",
      "Last Action:  tensor([0.1240, 0.2368, 0.0653, 0.3823, 0.0678, 0.4385, 0.0189, 0.1105, 0.2173,\n",
      "        0.0351], device='cuda:0')\n",
      "Loss: 0.4254927635192871 -0.5749684572219849\n",
      "Loss: 0.3922934830188751 -0.8752436637878418\n",
      "Loss: 0.36388838291168213 -0.3333806097507477\n",
      "Loss: 0.4391680359840393 -0.7112506628036499\n",
      "Loss: 0.39587849378585815 -0.9063382148742676\n",
      "Loss: 0.44034814834594727 -0.5374327301979065\n",
      "Loss: 0.3915252387523651 -0.46426886320114136\n",
      "Policy Reward: tensor(1.1696, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.02', '0.11', '0.49', '0.39', '0.73', '0.96', '0.95', '0.34', '0.01', '0.00', '0.00', '0.07', '0.05', '0.01', '0.04', '0.16', '0.21']\n",
      "Last Action:  tensor([0.2088, 0.1728, 0.1698, 0.1674, 0.2067, 0.2005, 0.1491, 0.0295, 0.0946,\n",
      "        0.1059], device='cuda:0')\n",
      "Bigstep:  49\n",
      "Loss: 0.4279141128063202 -0.557694137096405\n",
      "Loss: 0.3972075581550598 -0.296678751707077\n",
      "Loss: 0.3685016334056854 -0.5004809498786926\n",
      "Loss: 0.3502824306488037 -0.4680359661579132\n",
      "Loss: 0.3534483313560486 -0.4531380832195282\n",
      "Loss: 0.4107755422592163 -0.4732978940010071\n",
      "Loss: 0.3603062033653259 -0.6748772263526917\n",
      "Policy Reward: tensor(1.2271, device='cuda:0')\n",
      "Trajectory:  ['0.04', '1.00', '0.71', '0.23', '0.63', '0.85', '0.99', '0.99', '0.41', '0.02', '0.00', '0.09', '0.98', '0.42', '0.00', '0.00', '0.01', '0.06', '0.20']\n",
      "Last Action:  tensor([0.1987, 0.0176, 0.1891, 0.0487, 0.0771, 0.1667, 0.1965, 0.5544, 0.0116,\n",
      "        0.0377], device='cuda:0')\n",
      "Loss: 0.39925745129585266 -0.8471899628639221\n",
      "Loss: 0.4406602382659912 -0.7924442887306213\n",
      "Loss: 0.4671911299228668 -1.238463044166565\n",
      "Loss: 0.34064826369285583 -0.44202089309692383\n",
      "Loss: 0.4103023409843445 -1.0899062156677246\n",
      "Loss: 0.47585803270339966 -1.0268868207931519\n",
      "Loss: 0.3614004850387573 -0.5628374814987183\n",
      "Policy Reward: tensor(1.1607, device='cuda:0')\n",
      "Trajectory:  ['0.29', '1.00', '0.81', '0.02', '0.13', '0.51', '0.71', '0.95', '0.99', '0.23', '0.01', '0.00', '0.02', '0.27', '0.86', '0.10', '0.01', '0.03', '0.10']\n",
      "Last Action:  tensor([0.0951, 0.1320, 0.1321, 0.0692, 0.0757, 0.0707, 0.0687, 0.3125, 0.1146,\n",
      "        0.0708], device='cuda:0')\n",
      "Loss: 0.40968531370162964 -0.7385415434837341\n",
      "Loss: 0.39283978939056396 -0.8849905133247375\n",
      "Loss: 0.3348851501941681 -0.6628137826919556\n",
      "Loss: 0.3840985596179962 -0.9073746800422668\n",
      "Loss: 0.4289388954639435 -0.7191029191017151\n",
      "Loss: 0.45153775811195374 -1.0425889492034912\n",
      "Loss: 0.434116393327713 -0.8947150111198425\n",
      "Policy Reward: tensor(1.3552, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.14', '0.44', '0.63', '0.78', '0.98', '1.00', '0.94', '0.17', '0.01', '0.00', '0.62', '0.94', '0.04', '0.00', '0.01', '0.05', '0.28']\n",
      "Last Action:  tensor([0.2761, 0.0747, 0.3163, 0.0355, 0.2634, 0.0287, 0.0163, 0.0752, 0.0371,\n",
      "        0.1536], device='cuda:0')\n",
      "Loss: 0.34046903252601624 -0.8643417954444885\n",
      "Loss: 0.37643295526504517 -0.9528195261955261\n",
      "Loss: 0.33288800716400146 -0.45678427815437317\n",
      "Loss: 0.4552672803401947 -0.9469433426856995\n",
      "Loss: 0.3621103763580322 -1.0386713743209839\n",
      "Loss: 0.37028491497039795 -0.5129073858261108\n",
      "Loss: 0.4074176251888275 -0.8995139002799988\n",
      "Policy Reward: tensor(1.2491, device='cuda:0')\n",
      "Trajectory:  ['0.03', '1.00', '0.56', '0.33', '0.60', '0.87', '1.00', '0.99', '0.37', '0.01', '0.00', '0.03', '0.83', '0.62', '0.00', '0.00', '0.02', '0.10', '0.21']\n",
      "Last Action:  tensor([0.2051, 0.1836, 0.0713, 0.2346, 0.0145, 0.0632, 0.2081, 0.3518, 0.1170,\n",
      "        0.1542], device='cuda:0')\n",
      "Loss: 0.3285005986690521 -0.7643521428108215\n",
      "Loss: 0.4001425802707672 -0.8353888988494873\n",
      "Loss: 0.3984909951686859 -1.1941457986831665\n",
      "Loss: 0.34683123230934143 -0.8514477014541626\n",
      "Loss: 0.40597841143608093 -1.043349266052246\n",
      "Loss: 0.37227630615234375 -0.6124237775802612\n",
      "Loss: 0.40640392899513245 -0.8909403681755066\n",
      "Policy Reward: tensor(1.1143, device='cuda:0')\n",
      "Trajectory:  ['0.38', '1.00', '0.77', '0.03', '0.26', '0.37', '0.60', '0.94', '0.92', '0.09', '0.00', '0.04', '0.97', '0.74', '0.01', '0.00', '0.04', '0.17', '0.29']\n",
      "Last Action:  tensor([0.2896, 0.3877, 0.0764, 0.4152, 0.1238, 0.0563, 0.2732, 0.1830, 0.1519,\n",
      "        0.3569], device='cuda:0')\n",
      "Loss: 0.37730470299720764 -0.7899546027183533\n",
      "Loss: 0.4163040816783905 -0.9678159952163696\n",
      "Loss: 0.4096405804157257 -1.153179407119751\n",
      "Loss: 0.3538106083869934 -0.9111074805259705\n",
      "Loss: 0.40603187680244446 -0.9958569407463074\n",
      "Loss: 0.42213183641433716 -0.8282834887504578\n",
      "Loss: 0.40162423253059387 -0.8327326774597168\n",
      "Policy Reward: tensor(1.2211, device='cuda:0')\n",
      "Trajectory:  ['0.29', '1.00', '0.85', '0.04', '0.19', '0.34', '0.56', '0.94', '0.98', '0.24', '0.00', '0.00', '0.06', '0.99', '0.59', '0.00', '0.00', '0.00', '0.03']\n",
      "Last Action:  tensor([0.0348, 0.0601, 0.0448, 0.1860, 0.0877, 0.0423, 0.1308, 0.3107, 0.1767,\n",
      "        0.1765], device='cuda:0')\n",
      "Loss: 0.3676532208919525 -0.5749809741973877\n",
      "Loss: 0.3049072325229645 -0.4917912483215332\n",
      "Loss: 0.40284743905067444 -0.8870902061462402\n",
      "Loss: 0.4563468396663666 -0.9419588446617126\n",
      "Loss: 0.4061174988746643 -0.8309874534606934\n",
      "Loss: 0.4755524694919586 -1.133396863937378\n",
      "Loss: 0.37158864736557007 -0.9364131093025208\n",
      "Policy Reward: tensor(1.2843, device='cuda:0')\n",
      "Trajectory:  ['0.02', '1.00', '0.57', '0.25', '0.65', '0.96', '0.98', '0.99', '0.80', '0.13', '0.00', '0.01', '0.93', '0.97', '0.12', '0.00', '0.00', '0.02', '0.13']\n",
      "Last Action:  tensor([0.1322, 0.0913, 0.1045, 0.1696, 0.0961, 0.5473, 0.1221, 0.1347, 0.5133,\n",
      "        0.2059], device='cuda:0')\n",
      "Loss: 0.3933470845222473 -0.8504880666732788\n",
      "Loss: 0.3961906433105469 -0.8319351673126221\n",
      "Loss: 0.39261847734451294 -0.6926578283309937\n",
      "Loss: 0.39662978053092957 -0.9778105616569519\n",
      "Loss: 0.399026483297348 -0.5409108400344849\n",
      "Loss: 0.3586345613002777 -0.7914121150970459\n",
      "Loss: 0.48333510756492615 -1.165290355682373\n",
      "Policy Reward: tensor(1.1442, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.25', '0.28', '0.56', '0.96', '0.99', '1.00', '0.98', '0.31', '0.01', '0.01', '0.03', '0.91', '0.28', '0.04', '0.04', '0.05', '0.15']\n",
      "Last Action:  tensor([0.1541, 0.0324, 0.2203, 0.0203, 0.0538, 0.1617, 0.0236, 0.0867, 0.0376,\n",
      "        0.0246], device='cuda:0')\n",
      "Bigstep:  50\n",
      "Loss: 0.34184274077415466 0.1169804185628891\n",
      "Loss: 0.37135857343673706 -0.6494103670120239\n",
      "Loss: 0.40789783000946045 -0.8404170274734497\n",
      "Loss: 0.3513062298297882 -0.47357112169265747\n",
      "Loss: 0.4480494558811188 -0.6095578074455261\n",
      "Loss: 0.3798021674156189 -0.6341735124588013\n",
      "Loss: 0.37071025371551514 -0.8054996728897095\n",
      "Policy Reward: tensor(1.1415, device='cuda:0')\n",
      "Trajectory:  ['0.52', '1.00', '0.92', '0.08', '0.31', '0.69', '0.88', '1.00', '0.99', '0.26', '0.01', '0.03', '0.96', '0.95', '0.02', '0.00', '0.01', '0.03', '0.13']\n",
      "Last Action:  tensor([0.1267, 0.1149, 0.1205, 0.7215, 0.2919, 0.2333, 0.1578, 0.3427, 0.1031,\n",
      "        0.1736], device='cuda:0')\n",
      "Loss: 0.33787801861763 -0.3206641972064972\n",
      "Loss: 0.3829987645149231 -0.7761932015419006\n",
      "Loss: 0.43035006523132324 -0.6627494096755981\n",
      "Loss: 0.4254288673400879 -0.8744117021560669\n",
      "Loss: 0.46977871656417847 -0.7958201766014099\n",
      "Loss: 0.35691243410110474 -0.33794447779655457\n",
      "Loss: 0.3642456829547882 -0.5170786380767822\n",
      "Policy Reward: tensor(1.1726, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.68', '0.45', '0.88', '0.99', '0.99', '0.76', '0.13', '0.01', '0.02', '0.95', '0.94', '0.02', '0.00', '0.01', '0.05', '0.12', '0.11']\n",
      "Last Action:  tensor([0.1075, 0.6328, 0.1721, 0.0145, 0.3779, 0.0944, 0.3979, 0.3215, 0.4502,\n",
      "        0.0680], device='cuda:0')\n",
      "Loss: 0.4569392800331116 -0.6704318523406982\n",
      "Loss: 0.39152437448501587 -0.6688085198402405\n",
      "Loss: 0.42814409732818604 -1.0484702587127686\n",
      "Loss: 0.3576538562774658 -0.6313923001289368\n",
      "Loss: 0.43565717339515686 -0.8017672896385193\n",
      "Loss: 0.39890772104263306 -0.8462178707122803\n",
      "Loss: 0.47190430760383606 -0.9536918997764587\n",
      "Policy Reward: tensor(1.2387, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.43', '0.19', '0.61', '0.67', '0.60', '0.52', '0.91', '0.65', '0.07', '0.32', '0.47', '0.70', '0.25', '0.41', '0.15', '0.19', '0.46']\n",
      "Last Action:  tensor([0.4637, 0.1462, 0.2263, 0.1294, 0.1140, 0.1644, 0.1951, 0.1938, 0.1609,\n",
      "        0.4491], device='cuda:0')\n",
      "Loss: 0.41806039214134216 -0.6624630689620972\n",
      "Loss: 0.420499712228775 -1.0208371877670288\n",
      "Loss: 0.42105159163475037 -1.0422042608261108\n",
      "Loss: 0.3850683867931366 -0.5432296395301819\n",
      "Loss: 0.33130893111228943 -0.3940446972846985\n",
      "Loss: 0.43086087703704834 -0.8844044804573059\n",
      "Loss: 0.43119436502456665 -0.7989490032196045\n",
      "Policy Reward: tensor(1.1692, device='cuda:0')\n",
      "Trajectory:  ['0.08', '1.00', '0.59', '0.26', '0.65', '0.82', '0.90', '0.85', '0.29', '0.01', '0.01', '0.89', '0.99', '0.16', '0.01', '0.02', '0.05', '0.22', '0.37']\n",
      "Last Action:  tensor([0.3659, 0.4882, 0.3725, 0.1189, 0.2858, 0.2978, 0.2130, 0.2098, 0.1024,\n",
      "        0.2742], device='cuda:0')\n",
      "Loss: 0.3973044157028198 -0.4284382164478302\n",
      "Loss: 0.4461171627044678 -1.0040611028671265\n",
      "Loss: 0.43232420086860657 -0.8137393593788147\n",
      "Loss: 0.3477136194705963 -0.472910612821579\n",
      "Loss: 0.3758303225040436 -0.9192126989364624\n",
      "Loss: 0.48489782214164734 -0.9756284356117249\n",
      "Loss: 0.41936346888542175 -0.6244666576385498\n",
      "Policy Reward: tensor(1.2380, device='cuda:0')\n",
      "Trajectory:  ['0.53', '1.00', '0.84', '0.19', '0.31', '0.70', '0.87', '0.97', '0.68', '0.11', '0.00', '0.02', '0.94', '0.98', '0.14', '0.00', '0.01', '0.04', '0.18']\n",
      "Last Action:  tensor([0.1826, 0.1124, 0.0860, 0.4464, 0.6465, 0.1694, 0.2380, 0.1740, 0.3929,\n",
      "        0.4826], device='cuda:0')\n",
      "Loss: 0.330178439617157 -0.42951080203056335\n",
      "Loss: 0.43309566378593445 -0.6422839164733887\n",
      "Loss: 0.35842010378837585 -0.6022987365722656\n",
      "Loss: 0.4213341176509857 -0.6390761137008667\n",
      "Loss: 0.4248616099357605 -0.7402829527854919\n",
      "Loss: 0.34371501207351685 -0.592391848564148\n",
      "Loss: 0.3985651731491089 -0.8531501889228821\n",
      "Policy Reward: tensor(1.1707, device='cuda:0')\n",
      "Trajectory:  ['0.10', '1.00', '0.69', '0.30', '0.84', '0.92', '0.88', '0.88', '0.67', '0.17', '0.02', '0.01', '0.72', '0.89', '0.67', '0.09', '0.05', '0.11', '0.31']\n",
      "Last Action:  tensor([0.3069, 0.3061, 0.2247, 0.2779, 0.3281, 0.1150, 0.0348, 0.3651, 0.1920,\n",
      "        0.0537], device='cuda:0')\n",
      "Loss: 0.3676877021789551 -0.5174660086631775\n",
      "Loss: 0.38199156522750854 -0.7444154024124146\n",
      "Loss: 0.38010385632514954 -0.6343671679496765\n",
      "Loss: 0.3821445107460022 -0.5500012040138245\n",
      "Loss: 0.4015313684940338 -0.7618404626846313\n",
      "Loss: 0.389230340719223 -0.5301350355148315\n",
      "Loss: 0.3296543061733246 -0.5156505107879639\n",
      "Policy Reward: tensor(1.1980, device='cuda:0')\n",
      "Trajectory:  ['0.35', '1.00', '0.48', '0.32', '0.66', '0.87', '0.72', '0.91', '0.48', '0.67', '0.22', '0.02', '0.03', '0.90', '0.40', '0.65', '0.35', '0.08', '0.13']\n",
      "Last Action:  tensor([0.1304, 0.1470, 0.1876, 0.2202, 0.0965, 0.0220, 0.1045, 0.1817, 0.1080,\n",
      "        0.1040], device='cuda:0')\n",
      "Loss: 0.37209999561309814 -0.6077224016189575\n",
      "Loss: 0.3734331727027893 -0.5405580997467041\n",
      "Loss: 0.37082353234291077 -0.7332136034965515\n",
      "Loss: 0.40529099106788635 -1.0527687072753906\n",
      "Loss: 0.38097256422042847 -0.6233547925949097\n",
      "Loss: 0.44030123949050903 -0.9842981100082397\n",
      "Loss: 0.35041579604148865 -0.787294864654541\n",
      "Policy Reward: tensor(1.1773, device='cuda:0')\n",
      "Trajectory:  ['0.17', '1.00', '0.83', '0.06', '0.33', '0.72', '0.88', '0.86', '0.33', '0.01', '0.01', '0.84', '0.99', '0.57', '0.32', '0.90', '0.50', '0.25', '0.25']\n",
      "Last Action:  tensor([0.2530, 0.3248, 0.2513, 0.5336, 0.4246, 0.0656, 0.7533, 0.0277, 0.6948,\n",
      "        0.2118], device='cuda:0')\n",
      "Bigstep:  51\n",
      "Loss: 0.474099338054657 -0.271926611661911\n",
      "Loss: 0.393959641456604 0.11018285155296326\n",
      "Loss: 0.46378254890441895 -0.6314898729324341\n",
      "Loss: 0.3519679307937622 -0.07010830193758011\n",
      "Loss: 0.41281455755233765 -0.17295697331428528\n",
      "Loss: 0.3726375699043274 -0.14451663196086884\n",
      "Loss: 0.3289965093135834 -0.1027727872133255\n",
      "Policy Reward: tensor(1.1753, device='cuda:0')\n",
      "Trajectory:  ['0.13', '1.00', '0.82', '0.49', '0.95', '0.93', '0.87', '0.76', '0.77', '0.60', '0.50', '0.06', '0.01', '0.54', '0.98', '0.66', '0.30', '0.48', '0.86']\n",
      "Last Action:  tensor([0.8647, 0.2220, 0.5089, 0.2600, 0.3924, 0.8054, 0.3184, 0.3387, 0.0364,\n",
      "        0.5771], device='cuda:0')\n",
      "Loss: 0.3778204619884491 -0.18093442916870117\n",
      "Loss: 0.36943814158439636 -0.39361488819122314\n",
      "Loss: 0.38630446791648865 -0.44844818115234375\n",
      "Loss: 0.4556143879890442 -0.6037473678588867\n",
      "Loss: 0.42562243342399597 -0.15118014812469482\n",
      "Loss: 0.3821026086807251 -0.3705095648765564\n",
      "Loss: 0.4671199321746826 -0.33487799763679504\n",
      "Policy Reward: tensor(1.2037, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.44', '0.53', '0.94', '0.99', '0.97', '0.72', '0.21', '0.00', '0.03', '0.99', '0.98', '0.31', '0.87', '0.63', '0.47', '0.75', '0.59']\n",
      "Last Action:  tensor([0.5874, 0.0700, 0.6833, 0.6631, 0.3083, 0.1210, 0.5099, 0.5608, 0.4103,\n",
      "        0.2044], device='cuda:0')\n",
      "Loss: 0.40679141879081726 -0.3428930640220642\n",
      "Loss: 0.3760017156600952 -0.3545890152454376\n",
      "Loss: 0.33709850907325745 -0.15955212712287903\n",
      "Loss: 0.447837233543396 -0.6096150875091553\n",
      "Loss: 0.4499863386154175 -0.3935789465904236\n",
      "Loss: 0.362564355134964 -0.37905144691467285\n",
      "Loss: 0.3702813684940338 -0.16269680857658386\n",
      "Policy Reward: tensor(1.1534, device='cuda:0')\n",
      "Trajectory:  ['0.15', '1.00', '0.78', '0.07', '0.71', '0.98', '1.00', '0.96', '0.36', '0.02', '0.01', '0.88', '1.00', '0.33', '0.98', '0.46', '0.95', '0.53', '0.95']\n",
      "Last Action:  tensor([0.9462, 0.1424, 0.5247, 0.6548, 0.4451, 0.0113, 0.6921, 0.9104, 0.2033,\n",
      "        0.1554], device='cuda:0')\n",
      "Loss: 0.44133785367012024 -0.5977296829223633\n",
      "Loss: 0.4641021490097046 -0.457080602645874\n",
      "Loss: 0.3735511898994446 -0.42612120509147644\n",
      "Loss: 0.3874566853046417 -0.6067092418670654\n",
      "Loss: 0.3695038855075836 -0.4855072498321533\n",
      "Loss: 0.47037529945373535 -0.7858778238296509\n",
      "Loss: 0.43039655685424805 -0.3974211513996124\n",
      "Policy Reward: tensor(1.1137, device='cuda:0')\n",
      "Trajectory:  ['0.03', '1.00', '0.56', '0.53', '0.96', '1.00', '0.99', '0.79', '0.28', '0.01', '0.01', '0.96', '0.96', '0.31', '0.95', '0.38', '0.93', '0.41', '0.93']\n",
      "Last Action:  tensor([0.9266, 0.4408, 0.9313, 0.3143, 0.4389, 0.2459, 0.7842, 0.0168, 0.1646,\n",
      "        0.1450], device='cuda:0')\n",
      "Loss: 0.3899930417537689 -0.4885852038860321\n",
      "Loss: 0.3780343532562256 -0.5232255458831787\n",
      "Loss: 0.3815474808216095 -0.5225381255149841\n",
      "Loss: 0.41218340396881104 -0.4521932303905487\n",
      "Loss: 0.40156617760658264 -0.5697765946388245\n",
      "Loss: 0.40325701236724854 -0.7956249117851257\n",
      "Loss: 0.38384851813316345 0.007833104580640793\n",
      "Policy Reward: tensor(1.1210, device='cuda:0')\n",
      "Trajectory:  ['0.33', '1.00', '0.74', '0.26', '0.64', '0.99', '1.00', '0.99', '0.57', '0.03', '0.00', '0.80', '1.00', '0.61', '0.55', '0.91', '0.52', '0.60', '0.82']\n",
      "Last Action:  tensor([0.8158, 0.6188, 0.0610, 0.2637, 0.3081, 0.5865, 0.5754, 0.9244, 0.6614,\n",
      "        0.3439], device='cuda:0')\n",
      "Loss: 0.3717246949672699 -0.5651923418045044\n",
      "Loss: 0.4245590269565582 -0.38674086332321167\n",
      "Loss: 0.4184759259223938 -0.8632099032402039\n",
      "Loss: 0.33706873655319214 -0.5309714078903198\n",
      "Loss: 0.3536432981491089 -0.3661752939224243\n",
      "Loss: 0.3797071874141693 -0.6112483739852905\n",
      "Loss: 0.42839542031288147 -0.6379041075706482\n",
      "Policy Reward: tensor(1.2107, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.06', '0.33', '0.75', '0.88', '0.99', '0.91', '0.49', '0.07', '0.00', '0.03', '0.97', '0.96', '0.25', '0.99', '0.45', '0.42', '0.70']\n",
      "Last Action:  tensor([0.6967, 0.2606, 0.3836, 0.9423, 0.4585, 0.2430, 0.2388, 0.5403, 0.2993,\n",
      "        0.1673], device='cuda:0')\n",
      "Loss: 0.3521982729434967 -0.40302568674087524\n",
      "Loss: 0.3747251033782959 -0.22659216821193695\n",
      "Loss: 0.4534403383731842 -0.4931892156600952\n",
      "Loss: 0.3619355261325836 -0.07374309748411179\n",
      "Loss: 0.44763508439064026 -0.5107845067977905\n",
      "Loss: 0.3826785087585449 -0.5006381273269653\n",
      "Loss: 0.4053054451942444 -0.6811164021492004\n",
      "Policy Reward: tensor(1.2417, device='cuda:0')\n",
      "Trajectory:  ['0.18', '1.00', '0.77', '0.37', '0.92', '0.99', '0.98', '0.62', '0.11', '0.00', '0.04', '0.99', '0.97', '0.58', '0.64', '0.46', '0.58', '0.49', '0.26']\n",
      "Last Action:  tensor([0.2590, 0.1675, 0.0784, 0.2088, 0.6294, 0.4407, 0.7993, 0.2159, 0.8216,\n",
      "        0.7569], device='cuda:0')\n",
      "Loss: 0.3335168659687042 -0.3191085159778595\n",
      "Loss: 0.35387933254241943 -0.39524510502815247\n",
      "Loss: 0.33496737480163574 -0.4080178141593933\n",
      "Loss: 0.3964032530784607 -0.6054202914237976\n",
      "Loss: 0.35960301756858826 -0.47744908928871155\n",
      "Loss: 0.3898138701915741 -0.5550561547279358\n",
      "Loss: 0.39538341760635376 -0.3335251808166504\n",
      "Policy Reward: tensor(1.0955, device='cuda:0')\n",
      "Trajectory:  ['0.34', '1.00', '0.65', '0.03', '0.45', '0.99', '1.00', '1.00', '0.64', '0.08', '0.00', '0.01', '0.91', '0.95', '0.16', '0.81', '0.41', '0.32', '0.55']\n",
      "Last Action:  tensor([0.5472, 0.1250, 0.5099, 0.3322, 0.5067, 0.0376, 0.0298, 0.6445, 0.2890,\n",
      "        0.8012], device='cuda:0')\n",
      "Bigstep:  52\n",
      "Loss: 0.4298399090766907 -0.09871579706668854\n",
      "Loss: 0.4011710286140442 -0.057318031787872314\n",
      "Loss: 0.37503379583358765 -0.09922691434621811\n",
      "Loss: 0.37913191318511963 -0.5196782350540161\n",
      "Loss: 0.41646960377693176 -0.7719610333442688\n",
      "Loss: 0.38387638330459595 -0.478481262922287\n",
      "Loss: 0.29775121808052063 -0.25188082456588745\n",
      "Policy Reward: tensor(1.0907, device='cuda:0')\n",
      "Trajectory:  ['0.40', '1.00', '0.74', '0.02', '0.09', '0.59', '0.98', '1.00', '0.93', '0.35', '0.01', '0.00', '0.00', '0.00', '0.00', '0.01', '0.01', '0.01', '0.01']\n",
      "Last Action:  tensor([0.0121, 0.1889, 0.0367, 0.0560, 0.0175, 0.0227, 0.0148, 0.0366, 0.0082,\n",
      "        0.0421], device='cuda:0')\n",
      "Loss: 0.357153981924057 -0.540570080280304\n",
      "Loss: 0.3609617352485657 -0.6330711245536804\n",
      "Loss: 0.36680522561073303 -0.7678058743476868\n",
      "Loss: 0.33115899562835693 -0.1109803318977356\n",
      "Loss: 0.4232708215713501 -0.822641909122467\n",
      "Loss: 0.3655489385128021 -0.6933782696723938\n",
      "Loss: 0.4179442226886749 -0.8098778128623962\n",
      "Policy Reward: tensor(1.1714, device='cuda:0')\n",
      "Trajectory:  ['0.38', '1.00', '0.67', '0.01', '0.05', '0.38', '0.76', '0.98', '0.70', '0.14', '0.00', '0.01', '0.97', '0.84', '0.03', '0.07', '0.15', '0.02', '0.01']\n",
      "Last Action:  tensor([0.0058, 0.0089, 0.0425, 0.0272, 0.0392, 0.0524, 0.1011, 0.0269, 0.0245,\n",
      "        0.0153], device='cuda:0')\n",
      "Loss: 0.430069237947464 -0.40973004698753357\n",
      "Loss: 0.4362022876739502 -0.9001477956771851\n",
      "Loss: 0.389133483171463 -0.552958607673645\n",
      "Loss: 0.37009575963020325 -0.890531063079834\n",
      "Loss: 0.3278213143348694 -0.4716127812862396\n",
      "Loss: 0.403195321559906 -0.6959436535835266\n",
      "Loss: 0.39422550797462463 -0.6539025902748108\n",
      "Policy Reward: tensor(1.0877, device='cuda:0')\n",
      "Trajectory:  ['0.30', '1.00', '0.52', '0.09', '0.39', '0.65', '0.94', '0.96', '0.64', '0.24', '0.01', '0.03', '0.99', '0.78', '0.29', '0.02', '0.01', '0.01', '0.04']\n",
      "Last Action:  tensor([0.0417, 0.0485, 0.0116, 0.0184, 0.0239, 0.0113, 0.0468, 0.0755, 0.0184,\n",
      "        0.0145], device='cuda:0')\n",
      "Loss: 0.3299841284751892 -0.7106922268867493\n",
      "Loss: 0.36763641238212585 -0.53857421875\n",
      "Loss: 0.3634995222091675 -0.22980999946594238\n",
      "Loss: 0.34004533290863037 -0.7328590154647827\n",
      "Loss: 0.39643508195877075 -0.8115186095237732\n",
      "Loss: 0.41872385144233704 -0.6823258996009827\n",
      "Loss: 0.3399650454521179 -0.5948251485824585\n",
      "Policy Reward: tensor(1.2108, device='cuda:0')\n",
      "Trajectory:  ['0.25', '0.10', '0.02', '0.05', '0.09', '0.10', '0.09', '0.07', '0.05', '0.04', '0.03', '0.02', '0.02', '0.01', '0.01', '0.01', '0.01', '0.02', '0.04']\n",
      "Last Action:  tensor([0.0406, 0.0080, 0.0320, 0.0483, 0.0226, 0.1055, 0.0132, 0.0285, 0.0159,\n",
      "        0.0045], device='cuda:0')\n",
      "Loss: 0.4072987735271454 -0.6969658136367798\n",
      "Loss: 0.3943134546279907 -0.5495887994766235\n",
      "Loss: 0.466417521238327 -1.0378639698028564\n",
      "Loss: 0.39251774549484253 -0.3759832978248596\n",
      "Loss: 0.38917919993400574 -0.599977433681488\n",
      "Loss: 0.36362579464912415 -0.7446901202201843\n",
      "Loss: 0.3913857936859131 -0.5307060480117798\n",
      "Policy Reward: tensor(1.3031, device='cuda:0')\n",
      "Trajectory:  ['0.03', '1.00', '0.76', '0.03', '0.17', '0.54', '0.91', '0.97', '0.35', '0.01', '0.00', '0.59', '0.99', '0.12', '0.02', '0.01', '0.01', '0.02', '0.08']\n",
      "Last Action:  tensor([0.0758, 0.1279, 0.0106, 0.0355, 0.0491, 0.0479, 0.0092, 0.0191, 0.0299,\n",
      "        0.0178], device='cuda:0')\n",
      "Loss: 0.33992472290992737 -0.7115842700004578\n",
      "Loss: 0.37143683433532715 -0.7260520458221436\n",
      "Loss: 0.35235074162483215 -0.566426694393158\n",
      "Loss: 0.42408135533332825 -0.5283292531967163\n",
      "Loss: 0.38758811354637146 -0.8155195713043213\n",
      "Loss: 0.3502071499824524 -0.40760090947151184\n",
      "Loss: 0.402728796005249 -0.5325590968132019\n",
      "Policy Reward: tensor(1.3134, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.55', '0.24', '0.42', '0.69', '0.80', '0.82', '0.53', '0.19', '0.01', '0.06', '0.99', '0.76', '0.09', '0.06', '0.02', '0.01', '0.06']\n",
      "Last Action:  tensor([0.0626, 0.0328, 0.0986, 0.1817, 0.0391, 0.0123, 0.0387, 0.0251, 0.0039,\n",
      "        0.0045], device='cuda:0')\n",
      "Loss: 0.40686529874801636 -0.7474659085273743\n",
      "Loss: 0.37793806195259094 -0.6735776662826538\n",
      "Loss: 0.39009004831314087 -0.4752216637134552\n",
      "Loss: 0.32415980100631714 -0.3564215302467346\n",
      "Loss: 0.3457821309566498 -0.6822910904884338\n",
      "Loss: 0.34100309014320374 -0.41353705525398254\n",
      "Loss: 0.436221182346344 -0.686763346195221\n",
      "Policy Reward: tensor(1.2676, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.38', '0.30', '0.44', '0.62', '0.70', '0.90', '0.57', '0.13', '0.02', '0.01', '0.18', '0.85', '0.04', '0.00', '0.02', '0.11', '0.20']\n",
      "Last Action:  tensor([0.1996, 0.0307, 0.0343, 0.0288, 0.0072, 0.1034, 0.0096, 0.0999, 0.0100,\n",
      "        0.0116], device='cuda:0')\n",
      "Loss: 0.3359638750553131 -0.5116245150566101\n",
      "Loss: 0.3808063268661499 -0.8066945672035217\n",
      "Loss: 0.3963315784931183 -0.8416034579277039\n",
      "Loss: 0.36274588108062744 -0.7614431381225586\n",
      "Loss: 0.37245646119117737 -0.6371803283691406\n",
      "Loss: 0.35976603627204895 -0.36861875653266907\n",
      "Loss: 0.3250253200531006 -0.48669707775115967\n",
      "Policy Reward: tensor(1.0792, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.08', '0.30', '0.54', '0.61', '0.71', '0.81', '0.63', '0.17', '0.01', '0.10', '0.99', '0.49', '0.10', '0.21', '0.06', '0.00', '0.01']\n",
      "Last Action:  tensor([0.0080, 0.1111, 0.0460, 0.0472, 0.0245, 0.0468, 0.0355, 0.0490, 0.0073,\n",
      "        0.0129], device='cuda:0')\n",
      "Bigstep:  53\n",
      "Loss: 0.4068211019039154 0.043220117688179016\n",
      "Loss: 0.48019182682037354 -0.6195683479309082\n",
      "Loss: 0.39056825637817383 -0.5369924306869507\n",
      "Loss: 0.3643728494644165 -0.3965838849544525\n",
      "Loss: 0.38426968455314636 -0.6528101563453674\n",
      "Loss: 0.4198206663131714 -0.5033033490180969\n",
      "Loss: 0.40237802267074585 -0.46936658024787903\n",
      "Policy Reward: tensor(1.1671, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.80', '0.59', '0.52', '0.64', '0.82', '0.97', '0.86', '0.38', '0.10', '0.19', '1.00', '0.96', '0.37', '0.99', '0.66', '0.59', '0.91', '0.56']\n",
      "Last Action:  tensor([0.5563, 0.9873, 0.9673, 0.8707, 0.5574, 0.9419, 0.8659, 0.8352, 0.8522,\n",
      "        0.8802], device='cuda:0')\n",
      "Loss: 0.40601423382759094 -0.4960854649543762\n",
      "Loss: 0.4431857168674469 -0.5972997546195984\n",
      "Loss: 0.3439443111419678 -0.5625369548797607\n",
      "Loss: 0.4511795938014984 -0.7232493758201599\n",
      "Loss: 0.41956591606140137 -0.6247850060462952\n",
      "Loss: 0.4196009039878845 -0.5436817407608032\n",
      "Loss: 0.3811473846435547 -0.5309985280036926\n",
      "Policy Reward: tensor(1.0555, device='cuda:0')\n",
      "Trajectory:  ['0.02', '1.00', '0.90', '0.34', '0.67', '0.83', '0.89', '0.89', '0.76', '0.68', '0.53', '0.30', '0.79', '0.99', '0.94', '0.98', '0.90', '0.97', '0.70']\n",
      "Last Action:  tensor([0.6997, 0.7976, 0.8956, 0.8494, 0.7808, 0.5548, 0.9205, 0.3476, 0.9559,\n",
      "        0.9319], device='cuda:0')\n",
      "Loss: 0.36479246616363525 -0.3687068223953247\n",
      "Loss: 0.3900030255317688 -0.5430465340614319\n",
      "Loss: 0.4485478699207306 -0.9227412939071655\n",
      "Loss: 0.5553737282752991 -1.0646170377731323\n",
      "Loss: 0.40792059898376465 -0.5170565843582153\n",
      "Loss: 0.3956257104873657 -0.6007486581802368\n",
      "Loss: 0.4299646019935608 -0.6538667678833008\n",
      "Policy Reward: tensor(1.0001, device='cuda:0')\n",
      "Trajectory:  ['0.21', '1.00', '0.96', '0.06', '0.26', '0.58', '0.98', '1.00', '0.77', '0.54', '0.35', '0.86', '0.98', '0.98', '0.99', '0.99', '0.97', '0.93', '0.93']\n",
      "Last Action:  tensor([0.9344, 0.6308, 0.9154, 0.9058, 0.8488, 0.9004, 0.9179, 0.8486, 0.9134,\n",
      "        0.8779], device='cuda:0')\n",
      "Loss: 0.4035985767841339 -0.6382670402526855\n",
      "Loss: 0.3797673285007477 -0.544539749622345\n",
      "Loss: 0.44946324825286865 -0.9131175875663757\n",
      "Loss: 0.406805157661438 -0.5913074016571045\n",
      "Loss: 0.39996305108070374 -0.6790589094161987\n",
      "Loss: 0.3570510447025299 -0.44468504190444946\n",
      "Loss: 0.4197491705417633 -1.046697735786438\n",
      "Policy Reward: tensor(1.0517, device='cuda:0')\n",
      "Trajectory:  ['0.40', '1.00', '0.99', '0.27', '0.30', '0.52', '0.91', '1.00', '0.87', '0.55', '0.37', '0.84', '1.00', '0.97', '0.96', '0.98', '0.96', '0.93', '0.94']\n",
      "Last Action:  tensor([0.9396, 0.8876, 0.9314, 0.9376, 0.9014, 0.9125, 0.7679, 0.9258, 0.8993,\n",
      "        0.9169], device='cuda:0')\n",
      "Loss: 0.3502822518348694 -1.051324486732483\n",
      "Loss: 0.4176904261112213 -0.7735766768455505\n",
      "Loss: 0.375249981880188 -0.682270884513855\n",
      "Loss: 0.3944539725780487 -0.690285861492157\n",
      "Loss: 0.3805597126483917 -0.6018966436386108\n",
      "Loss: 0.32447919249534607 -0.5273455381393433\n",
      "Loss: 0.4205474853515625 -0.8122946619987488\n",
      "Policy Reward: tensor(1.2758, device='cuda:0')\n",
      "Trajectory:  ['0.38', '1.00', '0.98', '0.22', '0.41', '0.70', '0.99', '1.00', '0.86', '0.53', '0.35', '0.69', '1.00', '0.97', '0.86', '0.93', '0.94', '0.92', '0.93']\n",
      "Last Action:  tensor([0.9330, 0.8657, 0.9021, 0.8676, 0.8991, 0.9108, 0.6219, 0.8637, 0.8914,\n",
      "        0.9022], device='cuda:0')\n",
      "Loss: 0.37738069891929626 -0.6534560322761536\n",
      "Loss: 0.3741798996925354 -0.5545382499694824\n",
      "Loss: 0.3546891212463379 -0.40343719720840454\n",
      "Loss: 0.3899233341217041 -0.4768877923488617\n",
      "Loss: 0.426734060049057 -0.7255814671516418\n",
      "Loss: 0.40118247270584106 -0.47271689772605896\n",
      "Loss: 0.3986920118331909 -0.9303021430969238\n",
      "Policy Reward: tensor(1.0716, device='cuda:0')\n",
      "Trajectory:  ['0.43', '1.00', '0.99', '0.19', '0.32', '0.48', '0.72', '0.95', '0.81', '0.57', '0.34', '0.35', '1.00', '0.98', '0.70', '0.96', '0.92', '0.81', '0.90']\n",
      "Last Action:  tensor([0.9009, 0.8900, 0.7148, 0.9264, 0.8973, 0.6313, 0.8453, 0.1299, 0.8731,\n",
      "        0.8867], device='cuda:0')\n",
      "Loss: 0.3667055368423462 -1.0230156183242798\n",
      "Loss: 0.34698280692100525 -0.687729001045227\n",
      "Loss: 0.43672123551368713 -0.9111745953559875\n",
      "Loss: 0.39951616525650024 -0.4214467704296112\n",
      "Loss: 0.42858758568763733 -0.6126918196678162\n",
      "Loss: 0.4689965844154358 -0.6024662256240845\n",
      "Loss: 0.3922725021839142 -0.7856025099754333\n",
      "Policy Reward: tensor(1.1752, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.51', '0.54', '0.67', '0.78', '0.80', '0.84', '0.85', '0.77', '0.63', '0.64', '0.56', '0.31', '0.85', '0.98', '0.91', '0.96', '0.94']\n",
      "Last Action:  tensor([0.9427, 0.8440, 0.7858, 0.9370, 0.8964, 0.8145, 0.9135, 0.9265, 0.8956,\n",
      "        0.9374], device='cuda:0')\n",
      "Loss: 0.41453444957733154 -0.5776929259300232\n",
      "Loss: 0.40006110072135925 -0.7250961065292358\n",
      "Loss: 0.3420983850955963 -0.6098304390907288\n",
      "Loss: 0.4154435992240906 -0.6042105555534363\n",
      "Loss: 0.3621672987937927 -0.5836978554725647\n",
      "Loss: 0.35447797179222107 -0.775880753993988\n",
      "Loss: 0.35368502140045166 -0.7400990128517151\n",
      "Policy Reward: tensor(1.1710, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.32', '0.55', '0.69', '0.74', '0.78', '0.78', '0.68', '0.51', '0.25', '0.43', '1.00', '0.87', '0.87', '0.94', '0.85', '0.89', '0.80']\n",
      "Last Action:  tensor([0.7994, 0.9145, 0.8359, 0.9118, 0.7954, 0.8891, 0.8764, 0.9517, 0.9051,\n",
      "        0.8774], device='cuda:0')\n",
      "Bigstep:  54\n",
      "Loss: 0.3804670572280884 0.5136009454727173\n",
      "Loss: 0.4052432179450989 0.27037569880485535\n",
      "Loss: 0.2774500846862793 0.3803844153881073\n",
      "Loss: 0.427918404340744 0.060547348111867905\n",
      "Loss: 0.3699944019317627 0.16558235883712769\n",
      "Loss: 0.40279874205589294 0.3228512406349182\n",
      "Loss: 0.4263796806335449 0.2419763207435608\n",
      "Policy Reward: tensor(1.0613, device='cuda:0')\n",
      "Trajectory:  ['0.06', '1.00', '0.81', '0.56', '0.77', '0.90', '0.99', '0.99', '0.98', '0.95', '0.99', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9995, 0.9999, 0.9994, 0.9995, 0.9994, 0.9995, 0.9971, 0.9516, 0.9993,\n",
      "        0.9993], device='cuda:0')\n",
      "Loss: 0.4312933385372162 0.0073617324233055115\n",
      "Loss: 0.4633079469203949 -0.043769724667072296\n",
      "Loss: 0.3878025710582733 0.6348907947540283\n",
      "Loss: 0.2967894673347473 0.5644461512565613\n",
      "Loss: 0.3675607144832611 0.38142701983451843\n",
      "Loss: 0.34658193588256836 0.2613218128681183\n",
      "Loss: 0.31408506631851196 0.31195852160453796\n",
      "Policy Reward: tensor(1.0528, device='cuda:0')\n",
      "Trajectory:  ['0.15', '1.00', '0.97', '0.47', '0.65', '0.95', '1.00', '0.99', '0.96', '0.97', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9998, 0.9997, 0.9997, 0.9845, 0.9998, 0.9998, 0.9997, 0.9997, 0.9998,\n",
      "        0.9943], device='cuda:0')\n",
      "Loss: 0.3364318013191223 0.48429685831069946\n",
      "Loss: 0.3626791834831238 0.26873886585235596\n",
      "Loss: 0.3130740821361542 0.3787105977535248\n",
      "Loss: 0.28681284189224243 0.4675660729408264\n",
      "Loss: 0.39831405878067017 0.2959437966346741\n",
      "Loss: 0.42493417859077454 0.04895073175430298\n",
      "Loss: 0.3171251714229584 0.36365634202957153\n",
      "Policy Reward: tensor(1.0074, device='cuda:0')\n",
      "Trajectory:  ['0.32', '0.57', '0.99', '0.62', '0.62', '0.96', '1.00', '1.00', '0.98', '0.98', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9997, 0.9993, 0.9995, 0.9998, 0.9997, 0.9997, 0.9978, 0.9998, 0.9982,\n",
      "        0.9987], device='cuda:0')\n",
      "Loss: 0.3614892065525055 0.2401561737060547\n",
      "Loss: 0.4305918514728546 -0.2981693744659424\n",
      "Loss: 0.3776707649230957 0.3350893259048462\n",
      "Loss: 0.39442718029022217 0.2096354216337204\n",
      "Loss: 0.347033828496933 0.38497990369796753\n",
      "Loss: 0.3964103162288666 0.25999751687049866\n",
      "Loss: 0.38373231887817383 0.2743874490261078\n",
      "Policy Reward: tensor(1.0570, device='cuda:0')\n",
      "Trajectory:  ['0.33', '1.00', '1.00', '0.18', '0.41', '0.63', '0.90', '1.00', '0.99', '0.96', '0.98', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9997, 1.0000, 0.9997, 0.9986, 0.9993, 0.9997, 0.9997, 0.9984, 0.9997,\n",
      "        0.9997], device='cuda:0')\n",
      "Loss: 0.34038209915161133 0.35455262660980225\n",
      "Loss: 0.2997507154941559 0.4384322762489319\n",
      "Loss: 0.33914971351623535 0.21600213646888733\n",
      "Loss: 0.3394378423690796 0.3038409948348999\n",
      "Loss: 0.38817912340164185 0.08700340986251831\n",
      "Loss: 0.32997846603393555 0.2002759426832199\n",
      "Loss: 0.3401564061641693 -0.10645484924316406\n",
      "Policy Reward: tensor(0.9991, device='cuda:0')\n",
      "Trajectory:  ['0.26', '1.00', '1.00', '0.16', '0.26', '0.61', '0.91', '1.00', '0.98', '0.92', '0.97', '0.98', '0.99', '1.00', '1.00', '1.00', '1.00', '1.00', '0.99']\n",
      "Last Action:  tensor([0.9915, 0.9996, 0.9993, 0.9984, 0.9997, 0.9997, 0.9997, 0.9926, 0.9998,\n",
      "        0.9997], device='cuda:0')\n",
      "Loss: 0.353815495967865 0.16667217016220093\n",
      "Loss: 0.3908972144126892 0.2546151876449585\n",
      "Loss: 0.42384740710258484 0.13719767332077026\n",
      "Loss: 0.3881304860115051 0.4869665503501892\n",
      "Loss: 0.3454071581363678 0.37015438079833984\n",
      "Loss: 0.33510613441467285 0.17666825652122498\n",
      "Loss: 0.3541776239871979 0.2860393822193146\n",
      "Policy Reward: tensor(1.1022, device='cuda:0')\n",
      "Trajectory:  ['0.34', '0.54', '1.00', '0.80', '0.50', '0.97', '0.74', '0.89', '0.50', '0.97', '0.59', '0.97', '0.57', '0.98', '0.75', '0.81', '0.43', '0.79', '0.37']\n",
      "Last Action:  tensor([0.3670, 0.9997, 0.9996, 0.9998, 0.9998, 0.9998, 0.7958, 0.9996, 0.9888,\n",
      "        0.9998], device='cuda:0')\n",
      "Loss: 0.42097991704940796 0.04717771336436272\n",
      "Loss: 0.39899471402168274 0.0440877340734005\n",
      "Loss: 0.35981252789497375 0.13345541059970856\n",
      "Loss: 0.3834027945995331 0.39460262656211853\n",
      "Loss: 0.34961602091789246 0.4562998116016388\n",
      "Loss: 0.3198745548725128 0.33795255422592163\n",
      "Loss: 0.3489017188549042 0.3660966157913208\n",
      "Policy Reward: tensor(1.0289, device='cuda:0')\n",
      "Trajectory:  ['0.17', '1.00', '0.96', '0.43', '0.70', '0.86', '0.99', '1.00', '0.99', '0.98', '0.99', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9998, 0.9998, 0.9997, 0.9997, 0.9717, 0.9468, 0.9996, 0.9998, 0.9911,\n",
      "        0.9457], device='cuda:0')\n",
      "Loss: 0.3879234492778778 0.2817595601081848\n",
      "Loss: 0.39527949690818787 0.15613454580307007\n",
      "Loss: 0.3401772379875183 0.00926046073436737\n",
      "Loss: 0.3687698543071747 0.505851686000824\n",
      "Loss: 0.36468005180358887 0.19929039478302002\n",
      "Loss: 0.4141438603401184 -0.19695888459682465\n",
      "Loss: 0.376056969165802 -0.08696825057268143\n",
      "Policy Reward: tensor(1.0769, device='cuda:0')\n",
      "Trajectory:  ['0.35', '1.00', '1.00', '0.12', '0.31', '0.59', '0.87', '1.00', '0.99', '0.94', '0.97', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9997, 0.9995, 0.9532, 0.9999, 0.9997, 0.9997, 0.9998, 0.9998, 0.9998,\n",
      "        0.9928], device='cuda:0')\n",
      "Bigstep:  55\n",
      "Loss: 0.38036561012268066 0.6867992281913757\n",
      "Loss: 0.41134706139564514 0.3838433623313904\n",
      "Loss: 0.4085661768913269 0.861187219619751\n",
      "Loss: 0.3452606797218323 0.6138930916786194\n",
      "Loss: 0.3048136830329895 0.544161856174469\n",
      "Loss: 0.3081069886684418 0.4494905471801758\n",
      "Loss: 0.39919042587280273 0.27608737349510193\n",
      "Policy Reward: tensor(1.1473, device='cuda:0')\n",
      "Trajectory:  ['0.06', '1.00', '0.78', '0.47', '0.62', '0.74', '0.81', '0.87', '0.78', '0.47', '0.20', '0.08', '0.13', '1.00', '1.00', '0.81', '0.96', '0.97', '0.96']\n",
      "Last Action:  tensor([0.9615, 0.9765, 0.9787, 0.9920, 0.2053, 0.9745, 0.9699, 0.9951, 0.9814,\n",
      "        0.9762], device='cuda:0')\n",
      "Loss: 0.3864990472793579 0.03717879578471184\n",
      "Loss: 0.4114671051502228 0.08025040477514267\n",
      "Loss: 0.346394807100296 0.33840665221214294\n",
      "Loss: 0.38217195868492126 0.1557539701461792\n",
      "Loss: 0.3604483902454376 0.18658965826034546\n",
      "Loss: 0.3538954555988312 0.19321681559085846\n",
      "Loss: 0.34282180666923523 0.22206562757492065\n",
      "Policy Reward: tensor(1.0970, device='cuda:0')\n",
      "Trajectory:  ['0.23', '1.00', '0.97', '0.63', '0.50', '0.72', '0.67', '0.64', '0.56', '0.55', '0.43', '0.26', '0.12', '0.09', '0.09', '0.08', '0.14', '0.90', '0.65']\n",
      "Last Action:  tensor([0.6478, 0.7149, 0.9765, 0.4867, 0.9294, 0.8627, 0.7762, 0.0695, 0.7165,\n",
      "        0.7860], device='cuda:0')\n",
      "Loss: 0.37679049372673035 0.1134779155254364\n",
      "Loss: 0.34402334690093994 0.21315833926200867\n",
      "Loss: 0.3701724708080292 0.15945321321487427\n",
      "Loss: 0.3342985510826111 0.1886114776134491\n",
      "Loss: 0.36280345916748047 0.014431824907660484\n",
      "Loss: 0.37530481815338135 -0.19021286070346832\n",
      "Loss: 0.34430089592933655 0.2266424000263214\n",
      "Policy Reward: tensor(1.1995, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.94', '0.54', '0.71', '0.82', '0.73', '0.76', '0.60', '0.37', '0.10', '0.01', '0.07', '0.56', '0.96', '0.53', '0.47', '0.88', '0.81']\n",
      "Last Action:  tensor([0.8107, 0.8365, 0.8950, 0.1493, 0.7121, 0.6741, 0.2602, 0.2690, 0.8147,\n",
      "        0.7092], device='cuda:0')\n",
      "Loss: 0.4407292604446411 -0.29194021224975586\n",
      "Loss: 0.38581064343452454 0.07837676256895065\n",
      "Loss: 0.36635103821754456 -0.18793031573295593\n",
      "Loss: 0.3085669279098511 0.12448319792747498\n",
      "Loss: 0.3751143515110016 -0.17899349331855774\n",
      "Loss: 0.4120129644870758 -0.4668656289577484\n",
      "Loss: 0.37744367122650146 -0.1546960473060608\n",
      "Policy Reward: tensor(1.1626, device='cuda:0')\n",
      "Trajectory:  ['0.19', '0.55', '0.79', '0.54', '0.61', '0.74', '0.82', '0.77', '0.36', '0.05', '0.00', '0.03', '0.93', '0.91', '0.27', '0.66', '0.93', '0.35', '0.93']\n",
      "Last Action:  tensor([0.9283, 0.9049, 0.4775, 0.6551, 0.6043, 0.5191, 0.4836, 0.8748, 0.3416,\n",
      "        0.3219], device='cuda:0')\n",
      "Loss: 0.30962061882019043 -0.09781749546527863\n",
      "Loss: 0.37733814120292664 -0.08194206655025482\n",
      "Loss: 0.36261793971061707 -0.0013373401015996933\n",
      "Loss: 0.4100937843322754 -0.10675613582134247\n",
      "Loss: 0.36377865076065063 -0.1260262280702591\n",
      "Loss: 0.36651986837387085 -0.18886469304561615\n",
      "Loss: 0.3812721073627472 -0.15267914533615112\n",
      "Policy Reward: tensor(1.2227, device='cuda:0')\n",
      "Trajectory:  ['0.17', '1.00', '0.71', '0.24', '0.18', '0.44', '0.72', '0.82', '0.62', '0.22', '0.03', '0.01', '0.05', '0.66', '0.94', '0.27', '0.90', '0.44', '0.81']\n",
      "Last Action:  tensor([0.8134, 0.8686, 0.7293, 0.7293, 0.5575, 0.6625, 0.3988, 0.3577, 0.0326,\n",
      "        0.5720], device='cuda:0')\n",
      "Loss: 0.3154345750808716 -0.3285798728466034\n",
      "Loss: 0.309374064207077 -0.03228484094142914\n",
      "Loss: 0.38121503591537476 0.10859467089176178\n",
      "Loss: 0.394204705953598 -0.35042935609817505\n",
      "Loss: 0.3199416399002075 -0.01788516342639923\n",
      "Loss: 0.4646269679069519 -0.4516269564628601\n",
      "Loss: 0.4052315652370453 -0.39883512258529663\n",
      "Policy Reward: tensor(1.0458, device='cuda:0')\n",
      "Trajectory:  ['0.14', '1.00', '0.73', '0.11', '0.18', '0.52', '0.75', '0.80', '0.45', '0.14', '0.01', '0.01', '0.59', '0.98', '0.26', '0.80', '0.45', '0.94', '0.31']\n",
      "Last Action:  tensor([0.3096, 0.5726, 0.4566, 0.7740, 0.3559, 0.9418, 0.9235, 0.5720, 0.8924,\n",
      "        0.9028], device='cuda:0')\n",
      "Loss: 0.480146586894989 -0.6705355048179626\n",
      "Loss: 0.34801068902015686 -0.17775389552116394\n",
      "Loss: 0.35535958409309387 -0.15160749852657318\n",
      "Loss: 0.32178568840026855 -0.11623401194810867\n",
      "Loss: 0.33423763513565063 -0.05968184769153595\n",
      "Loss: 0.34768053889274597 -0.18437427282333374\n",
      "Loss: 0.4078442454338074 -0.18683674931526184\n",
      "Policy Reward: tensor(1.3037, device='cuda:0')\n",
      "Trajectory:  ['0.15', '1.00', '0.77', '0.46', '0.58', '0.71', '0.74', '0.57', '0.19', '0.01', '0.02', '0.63', '0.98', '0.20', '0.95', '0.32', '0.44', '0.95', '0.27']\n",
      "Last Action:  tensor([0.2695, 0.7311, 0.5374, 0.4189, 0.8804, 0.5362, 0.4336, 0.0295, 0.3690,\n",
      "        0.6552], device='cuda:0')\n",
      "Loss: 0.3552682101726532 -0.17260068655014038\n",
      "Loss: 0.34474802017211914 -0.015823177993297577\n",
      "Loss: 0.30799373984336853 0.006287168711423874\n",
      "Loss: 0.36682796478271484 -0.2962351441383362\n",
      "Loss: 0.30024033784866333 0.0225147046148777\n",
      "Loss: 0.4242710769176483 -0.38475483655929565\n",
      "Loss: 0.3843676745891571 -0.28291818499565125\n",
      "Policy Reward: tensor(1.1602, device='cuda:0')\n",
      "Trajectory:  ['0.06', '1.00', '0.90', '0.24', '0.47', '0.78', '0.89', '0.75', '0.29', '0.03', '0.00', '0.03', '0.12', '0.95', '0.68', '0.89', '0.48', '0.79', '0.44']\n",
      "Last Action:  tensor([0.4443, 0.9461, 0.5755, 0.7233, 0.9434, 0.4243, 0.7763, 0.3505, 0.8275,\n",
      "        0.4495], device='cuda:0')\n",
      "Bigstep:  56\n",
      "Loss: 0.4628438651561737 0.3378794491291046\n",
      "Loss: 0.4805181324481964 -0.16238710284233093\n",
      "Loss: 0.39477258920669556 0.09916278719902039\n",
      "Loss: 0.4351980984210968 0.019020069390535355\n",
      "Loss: 0.4988904595375061 -0.4904213845729828\n",
      "Loss: 0.48846691846847534 -0.4308190643787384\n",
      "Loss: 0.3945239186286926 -0.3120146095752716\n",
      "Policy Reward: tensor(1.0913, device='cuda:0')\n",
      "Trajectory:  ['0.15', '0.80', '0.79', '0.59', '0.45', '0.74', '0.59', '0.51', '0.52', '0.30', '0.30', '0.11', '0.05', '0.04', '0.04', '0.06', '0.07', '0.09', '0.11']\n",
      "Last Action:  tensor([0.1086, 0.1761, 0.3263, 0.0346, 0.1528, 0.3274, 0.0771, 0.5257, 0.2481,\n",
      "        0.3090], device='cuda:0')\n",
      "Loss: 0.3656928837299347 -0.17881987988948822\n",
      "Loss: 0.3867189586162567 0.1376502513885498\n",
      "Loss: 0.39310601353645325 0.017621416598558426\n",
      "Loss: 0.3489614725112915 -0.38375940918922424\n",
      "Loss: 0.39973199367523193 -0.275302529335022\n",
      "Loss: 0.3806547224521637 -0.5864629149436951\n",
      "Loss: 0.32390889525413513 -0.0649968683719635\n",
      "Policy Reward: tensor(1.0886, device='cuda:0')\n",
      "Trajectory:  ['0.05', '1.00', '0.83', '0.29', '0.52', '0.54', '0.58', '0.40', '0.09', '0.01', '0.00', '0.01', '0.01', '0.06', '0.39', '0.94', '0.27', '0.24', '0.27']\n",
      "Last Action:  tensor([0.2688, 0.0694, 0.4149, 0.2945, 0.5173, 0.4189, 0.4386, 0.1318, 0.7293,\n",
      "        0.4267], device='cuda:0')\n",
      "Loss: 0.3877093195915222 -0.5562893748283386\n",
      "Loss: 0.4527900815010071 -0.7933432459831238\n",
      "Loss: 0.475425124168396 -0.8065954446792603\n",
      "Loss: 0.3736809194087982 -0.15975096821784973\n",
      "Loss: 0.37870553135871887 -0.1490119844675064\n",
      "Loss: 0.334439218044281 -0.3081667423248291\n",
      "Loss: 0.3758579194545746 -0.4995264708995819\n",
      "Policy Reward: tensor(1.2018, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.40', '0.51', '0.56', '0.50', '0.46', '0.46', '0.36', '0.15', '0.02', '0.01', '0.02', '0.05', '0.10', '0.15', '0.19', '0.25', '0.32']\n",
      "Last Action:  tensor([0.3194, 0.9391, 0.0728, 0.2532, 0.0491, 0.1350, 0.0502, 0.1316, 0.4944,\n",
      "        0.2359], device='cuda:0')\n",
      "Loss: 0.4014577269554138 -0.7807652950286865\n",
      "Loss: 0.41213443875312805 -0.5778895616531372\n",
      "Loss: 0.404280424118042 -0.3690168261528015\n",
      "Loss: 0.36392149329185486 -0.3902919292449951\n",
      "Loss: 0.3757798969745636 -0.27445536851882935\n",
      "Loss: 0.39362213015556335 -0.3467828929424286\n",
      "Loss: 0.4946455955505371 -0.5730045437812805\n",
      "Policy Reward: tensor(1.1545, device='cuda:0')\n",
      "Trajectory:  ['0.39', '1.00', '0.75', '0.04', '0.15', '0.47', '0.60', '0.64', '0.41', '0.04', '0.01', '0.00', '0.00', '0.01', '0.04', '0.08', '0.17', '0.57', '0.26']\n",
      "Last Action:  tensor([0.2608, 0.2799, 0.4169, 0.2399, 0.3951, 0.7008, 0.2991, 0.3763, 0.3583,\n",
      "        0.2515], device='cuda:0')\n",
      "Loss: 0.47637543082237244 -0.8091056942939758\n",
      "Loss: 0.368116170167923 -0.43933629989624023\n",
      "Loss: 0.452134370803833 -0.5087495446205139\n",
      "Loss: 0.3417421877384186 -0.09960553795099258\n",
      "Loss: 0.3858617842197418 -0.7168897986412048\n",
      "Loss: 0.3992844521999359 -0.2655496299266815\n",
      "Loss: 0.45426324009895325 -0.9769734740257263\n",
      "Policy Reward: tensor(1.0526, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.36', '0.52', '0.53', '0.45', '0.40', '0.42', '0.34', '0.06', '0.01', '0.01', '0.01', '0.03', '0.07', '0.10', '0.13', '0.18', '0.27']\n",
      "Last Action:  tensor([0.2714, 0.8802, 0.1153, 0.1695, 0.0356, 0.3070, 0.4031, 0.1032, 0.3663,\n",
      "        0.1965], device='cuda:0')\n",
      "Loss: 0.383071631193161 -0.4356860816478729\n",
      "Loss: 0.34854692220687866 -0.41180166602134705\n",
      "Loss: 0.3546999394893646 -0.41740769147872925\n",
      "Loss: 0.38930314779281616 -0.5155240893363953\n",
      "Loss: 0.30975010991096497 -0.2404269278049469\n",
      "Loss: 0.4230928122997284 -0.5217281579971313\n",
      "Loss: 0.47918033599853516 -0.9637677669525146\n",
      "Policy Reward: tensor(1.1789, device='cuda:0')\n",
      "Trajectory:  ['0.42', '1.00', '0.80', '0.06', '0.39', '0.47', '0.49', '0.58', '0.40', '0.05', '0.00', '0.00', '0.01', '0.07', '0.25', '0.36', '0.16', '0.11', '0.50']\n",
      "Last Action:  tensor([0.4955, 0.2810, 0.9002, 0.0472, 0.4124, 0.0575, 0.2801, 0.0845, 0.3968,\n",
      "        0.3157], device='cuda:0')\n",
      "Loss: 0.43792620301246643 -0.6906364560127258\n",
      "Loss: 0.4206077754497528 -0.4631108343601227\n",
      "Loss: 0.4112449288368225 -0.41095805168151855\n",
      "Loss: 0.3481137454509735 -0.2653461992740631\n",
      "Loss: 0.4304628372192383 -0.7282707095146179\n",
      "Loss: 0.4167170524597168 -0.6953897476196289\n",
      "Loss: 0.36389392614364624 -0.3259129524230957\n",
      "Policy Reward: tensor(1.1431, device='cuda:0')\n",
      "Trajectory:  ['0.40', '1.00', '0.83', '0.44', '0.25', '0.41', '0.55', '0.56', '0.37', '0.06', '0.01', '0.01', '0.01', '0.01', '0.03', '0.04', '0.04', '0.04', '0.03']\n",
      "Last Action:  tensor([0.0340, 0.3513, 0.4728, 0.4488, 0.7086, 0.6187, 0.3934, 0.2954, 0.4250,\n",
      "        0.6220], device='cuda:0')\n",
      "Loss: 0.3743826150894165 -0.28444337844848633\n",
      "Loss: 0.4087211489677429 -0.6925055384635925\n",
      "Loss: 0.4042186737060547 -0.6466047167778015\n",
      "Loss: 0.4193355441093445 -0.3754585087299347\n",
      "Loss: 0.42928221821784973 -0.8661559224128723\n",
      "Loss: 0.4118698239326477 -0.5151033997535706\n",
      "Loss: 0.40713393688201904 -0.6512705087661743\n",
      "Policy Reward: tensor(1.2483, device='cuda:0')\n",
      "Trajectory:  ['0.43', '1.00', '0.79', '0.53', '0.42', '0.75', '0.68', '0.64', '0.43', '0.13', '0.01', '0.00', '0.02', '0.08', '0.12', '0.11', '0.09', '0.09', '0.10']\n",
      "Last Action:  tensor([0.1038, 0.3660, 0.5366, 0.6399, 0.2656, 0.3391, 0.3406, 0.3444, 0.3922,\n",
      "        0.0943], device='cuda:0')\n",
      "Bigstep:  57\n",
      "Loss: 0.4286843240261078 0.2535536289215088\n",
      "Loss: 0.4697420001029968 -0.38746756315231323\n",
      "Loss: 0.48040905594825745 -0.5783938765525818\n",
      "Loss: 0.40191650390625 -0.3842165470123291\n",
      "Loss: 0.39147815108299255 -0.45640048384666443\n",
      "Loss: 0.34248197078704834 -0.2980029881000519\n",
      "Loss: 0.4310967028141022 -0.9201826453208923\n",
      "Policy Reward: tensor(1.1472, device='cuda:0')\n",
      "Trajectory:  ['0.39', '0.86', '0.73', '0.65', '0.74', '0.84', '0.82', '0.76', '0.56', '0.14', '0.00', '0.01', '0.05', '0.29', '0.81', '0.43', '0.32', '0.45', '0.88']\n",
      "Last Action:  tensor([0.8821, 0.0337, 0.4782, 0.0180, 0.8039, 0.4007, 0.4965, 0.5981, 0.5230,\n",
      "        0.4955], device='cuda:0')\n",
      "Loss: 0.3518601655960083 -0.7512983679771423\n",
      "Loss: 0.3934360444545746 -0.08582589775323868\n",
      "Loss: 0.43816912174224854 -0.518933892250061\n",
      "Loss: 0.37070363759994507 -0.5647163987159729\n",
      "Loss: 0.4313817620277405 -0.519017219543457\n",
      "Loss: 0.37958434224128723 -0.40919971466064453\n",
      "Loss: 0.35141047835350037 -0.5221668481826782\n",
      "Policy Reward: tensor(1.2406, device='cuda:0')\n",
      "Trajectory:  ['0.39', '1.00', '0.90', '0.33', '0.75', '0.87', '0.87', '0.82', '0.57', '0.13', '0.01', '0.01', '0.40', '0.97', '0.70', '0.40', '0.23', '0.89', '0.71']\n",
      "Last Action:  tensor([0.7107, 0.7975, 0.6738, 0.5779, 0.4293, 0.3210, 0.3026, 0.9503, 0.3634,\n",
      "        0.0103], device='cuda:0')\n",
      "Loss: 0.4789319336414337 -0.8913120627403259\n",
      "Loss: 0.4436701238155365 -0.6372559666633606\n",
      "Loss: 0.33931320905685425 -0.2916068136692047\n",
      "Loss: 0.3903883993625641 -0.7071327567100525\n",
      "Loss: 0.33407285809516907 -0.5005791187286377\n",
      "Loss: 0.39650312066078186 -0.9006826877593994\n",
      "Loss: 0.4609158933162689 -0.44541290402412415\n",
      "Policy Reward: tensor(1.2440, device='cuda:0')\n",
      "Trajectory:  ['0.31', '1.00', '0.87', '0.05', '0.43', '0.88', '0.88', '0.89', '0.78', '0.32', '0.00', '0.00', '0.00', '0.02', '0.07', '0.25', '0.90', '0.20', '0.05']\n",
      "Last Action:  tensor([0.0496, 0.0483, 0.6006, 0.4321, 0.0932, 0.4924, 0.1349, 0.0137, 0.4998,\n",
      "        0.2875], device='cuda:0')\n",
      "Loss: 0.4449619650840759 -0.9109919667243958\n",
      "Loss: 0.37026914954185486 -0.559920072555542\n",
      "Loss: 0.3553110361099243 -0.6914723515510559\n",
      "Loss: 0.38662847876548767 -0.7465200424194336\n",
      "Loss: 0.5446069240570068 -1.0396206378936768\n",
      "Loss: 0.4359723925590515 -0.7666686177253723\n",
      "Loss: 0.34882408380508423 -0.6664949059486389\n",
      "Policy Reward: tensor(1.1651, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.23', '0.62', '0.86', '0.86', '0.79', '0.77', '0.73', '0.50', '0.05', '0.00', '0.00', '0.03', '0.16', '0.29', '0.21', '0.09', '0.09']\n",
      "Last Action:  tensor([0.0859, 0.2739, 0.0989, 0.0214, 0.7067, 0.5444, 0.6181, 0.0079, 0.1007,\n",
      "        0.1961], device='cuda:0')\n",
      "Loss: 0.40050235390663147 -0.5098771452903748\n",
      "Loss: 0.35952138900756836 -0.37934544682502747\n",
      "Loss: 0.4267738461494446 -0.6540173888206482\n",
      "Loss: 0.3848074674606323 -0.4310098886489868\n",
      "Loss: 0.3791497051715851 -0.6041045188903809\n",
      "Loss: 0.4198705852031708 -0.4057037830352783\n",
      "Loss: 0.3851700723171234 -0.40000641345977783\n",
      "Policy Reward: tensor(1.1259, device='cuda:0')\n",
      "Trajectory:  ['0.44', '1.00', '0.81', '0.53', '0.59', '0.84', '0.86', '0.72', '0.13', '0.00', '0.00', '0.02', '0.21', '0.76', '0.96', '0.07', '0.14', '0.38', '0.43']\n",
      "Last Action:  tensor([0.4277, 0.1474, 0.3958, 0.0418, 0.5154, 0.2141, 0.1828, 0.4026, 0.3567,\n",
      "        0.3267], device='cuda:0')\n",
      "Loss: 0.3590507209300995 -0.4502512812614441\n",
      "Loss: 0.4223380386829376 -0.906158447265625\n",
      "Loss: 0.3745194375514984 -0.6158149242401123\n",
      "Loss: 0.39867401123046875 -0.5873662829399109\n",
      "Loss: 0.46736568212509155 -0.5900220274925232\n",
      "Loss: 0.4010540544986725 -0.7194010615348816\n",
      "Loss: 0.4101450741291046 -0.6792939901351929\n",
      "Policy Reward: tensor(1.2576, device='cuda:0')\n",
      "Trajectory:  ['0.42', '0.78', '0.84', '0.51', '0.63', '0.83', '0.88', '0.86', '0.56', '0.03', '0.00', '0.01', '0.19', '0.96', '0.94', '0.32', '0.47', '0.67', '0.59']\n",
      "Last Action:  tensor([0.5910, 0.0355, 0.0408, 0.0174, 0.0113, 0.0370, 0.7554, 0.7029, 0.2230,\n",
      "        0.4587], device='cuda:0')\n",
      "Loss: 0.442963570356369 -0.44488856196403503\n",
      "Loss: 0.404947966337204 -0.6711701154708862\n",
      "Loss: 0.37307286262512207 -0.6184109449386597\n",
      "Loss: 0.3786028325557709 -0.8527295589447021\n",
      "Loss: 0.32939332723617554 -0.6863139271736145\n",
      "Loss: 0.40098434686660767 -0.5694650411605835\n",
      "Loss: 0.37455156445503235 -0.6638450026512146\n",
      "Policy Reward: tensor(1.1983, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.50', '0.80', '0.90', '0.85', '0.79', '0.80', '0.65', '0.12', '0.00', '0.00', '0.01', '0.18', '0.93', '0.35', '0.25', '0.62', '0.42']\n",
      "Last Action:  tensor([0.4201, 0.8442, 0.3037, 0.8953, 0.3566, 0.0157, 0.3166, 0.3764, 0.0073,\n",
      "        0.4159], device='cuda:0')\n",
      "Loss: 0.40900719165802 -0.8787972331047058\n",
      "Loss: 0.4035123884677887 -0.7530099749565125\n",
      "Loss: 0.35242873430252075 -0.3987116515636444\n",
      "Loss: 0.4890207052230835 -1.2882124185562134\n",
      "Loss: 0.5164942741394043 -0.792754590511322\n",
      "Loss: 0.4047199785709381 -0.528229296207428\n",
      "Loss: 0.3348686695098877 -0.5075147747993469\n",
      "Policy Reward: tensor(1.1396, device='cuda:0')\n",
      "Trajectory:  ['0.06', '1.00', '0.90', '0.73', '0.92', '0.91', '0.86', '0.82', '0.82', '0.74', '0.78', '0.63', '0.46', '0.17', '0.16', '0.74', '0.91', '0.72', '0.97']\n",
      "Last Action:  tensor([0.9673, 0.6755, 0.1940, 0.4940, 0.2037, 0.8121, 0.0108, 0.3813, 0.3209,\n",
      "        0.6458], device='cuda:0')\n",
      "Bigstep:  58\n",
      "Loss: 0.3879581689834595 -0.2562125325202942\n",
      "Loss: 0.4230838716030121 -0.43383660912513733\n",
      "Loss: 0.38682422041893005 -0.1032368615269661\n",
      "Loss: 0.40285447239875793 -0.17739170789718628\n",
      "Loss: 0.44585734605789185 -0.8439961671829224\n",
      "Loss: 0.34366574883461 -0.5743709802627563\n",
      "Loss: 0.29263243079185486 -0.3676622807979584\n",
      "Policy Reward: tensor(1.1736, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.46', '0.53', '0.66', '0.67', '0.68', '0.75', '0.68', '0.22', '0.00', '0.00', '0.01', '0.14', '0.93', '0.47', '0.36', '0.81', '0.33']\n",
      "Last Action:  tensor([0.3277, 0.2474, 0.1699, 0.2834, 0.0502, 0.2861, 0.5812, 0.3149, 0.9262,\n",
      "        0.1568], device='cuda:0')\n",
      "Loss: 0.4848242700099945 -0.8747443556785583\n",
      "Loss: 0.39411354064941406 -0.7880434393882751\n",
      "Loss: 0.3979525566101074 -1.1889835596084595\n",
      "Loss: 0.30733633041381836 -0.5161301493644714\n",
      "Loss: 0.36633995175361633 -0.582785427570343\n",
      "Loss: 0.41502729058265686 -0.6416161060333252\n",
      "Loss: 0.3824920952320099 -0.7171594500541687\n",
      "Policy Reward: tensor(1.2340, device='cuda:0')\n",
      "Trajectory:  ['0.40', '0.56', '0.66', '0.34', '0.44', '0.75', '0.88', '0.81', '0.69', '0.09', '0.00', '0.00', '0.05', '0.92', '0.73', '0.18', '0.91', '0.53', '0.17']\n",
      "Last Action:  tensor([0.1697, 0.1201, 0.1080, 0.1070, 0.9661, 0.5239, 0.1555, 0.2229, 0.1996,\n",
      "        0.9034], device='cuda:0')\n",
      "Loss: 0.37099847197532654 -0.7533877491950989\n",
      "Loss: 0.4263386130332947 -0.8137083053588867\n",
      "Loss: 0.36366045475006104 -0.44138041138648987\n",
      "Loss: 0.3946184813976288 -0.29195818305015564\n",
      "Loss: 0.4190473258495331 -0.8691384792327881\n",
      "Loss: 0.5080695748329163 -0.892696738243103\n",
      "Loss: 0.3318251371383667 -0.5729475021362305\n",
      "Policy Reward: tensor(1.2178, device='cuda:0')\n",
      "Trajectory:  ['0.22', '1.00', '0.75', '0.00', '0.08', '0.35', '0.71', '0.82', '0.68', '0.05', '0.00', '0.00', '0.01', '0.43', '0.99', '0.12', '0.33', '0.97', '0.20']\n",
      "Last Action:  tensor([0.1998, 0.7744, 0.7940, 0.7834, 0.0385, 0.1654, 0.3935, 0.9267, 0.0999,\n",
      "        0.8778], device='cuda:0')\n",
      "Loss: 0.3693884611129761 -0.8282136917114258\n",
      "Loss: 0.39698511362075806 -0.8805809020996094\n",
      "Loss: 0.4084673225879669 -0.5705630779266357\n",
      "Loss: 0.4277626872062683 -0.6557182669639587\n",
      "Loss: 0.38665273785591125 -0.7779234051704407\n",
      "Loss: 0.36857572197914124 -0.16288676857948303\n",
      "Loss: 0.3844835162162781 -0.3994823098182678\n",
      "Policy Reward: tensor(1.2389, device='cuda:0')\n",
      "Trajectory:  ['0.39', '1.00', '0.94', '0.03', '0.39', '0.50', '0.60', '0.82', '0.78', '0.26', '0.00', '0.00', '0.00', '0.09', '0.94', '0.35', '0.34', '0.87', '0.19']\n",
      "Last Action:  tensor([0.1861, 0.5394, 0.1024, 0.5753, 0.0366, 0.2472, 0.3737, 0.5290, 0.0460,\n",
      "        0.1038], device='cuda:0')\n",
      "Loss: 0.4121636152267456 -0.4619219899177551\n",
      "Loss: 0.37726932764053345 -0.7248868942260742\n",
      "Loss: 0.3536178469657898 -0.46455565094947815\n",
      "Loss: 0.4150196611881256 -0.9588772058486938\n",
      "Loss: 0.4213578701019287 -0.48325496912002563\n",
      "Loss: 0.40679776668548584 -0.6733533143997192\n",
      "Loss: 0.4837046265602112 -1.0293662548065186\n",
      "Policy Reward: tensor(1.1818, device='cuda:0')\n",
      "Trajectory:  ['0.04', '1.00', '0.74', '0.26', '0.56', '0.73', '0.78', '0.80', '0.54', '0.04', '0.00', '0.00', '0.05', '0.40', '0.76', '0.27', '0.53', '0.61', '0.24']\n",
      "Last Action:  tensor([0.2433, 0.0747, 0.1800, 0.3470, 0.4154, 0.5219, 0.2463, 0.2572, 0.9722,\n",
      "        0.0954], device='cuda:0')\n",
      "Loss: 0.3852323591709137 -0.7769258618354797\n",
      "Loss: 0.39314860105514526 -0.5888203978538513\n",
      "Loss: 0.43026354908943176 -0.9660634994506836\n",
      "Loss: 0.41630858182907104 -0.5818064212799072\n",
      "Loss: 0.3741791546344757 -0.8352876901626587\n",
      "Loss: 0.39243167638778687 -0.5571291446685791\n",
      "Loss: 0.40846580266952515 -0.7941881418228149\n",
      "Policy Reward: tensor(1.2615, device='cuda:0')\n",
      "Trajectory:  ['0.34', '1.00', '0.84', '0.08', '0.24', '0.61', '0.79', '0.84', '0.69', '0.19', '0.03', '0.01', '0.04', '0.25', '0.98', '0.42', '0.01', '0.02', '0.07']\n",
      "Last Action:  tensor([0.0677, 0.3893, 0.0430, 0.2323, 0.0509, 0.1339, 0.3293, 0.0848, 0.2307,\n",
      "        0.0401], device='cuda:0')\n",
      "Loss: 0.36779606342315674 -0.5598543882369995\n",
      "Loss: 0.3651845455169678 -0.6272408962249756\n",
      "Loss: 0.43174639344215393 -0.8404313325881958\n",
      "Loss: 0.3689059913158417 -0.8432677984237671\n",
      "Loss: 0.3684656620025635 -0.639287531375885\n",
      "Loss: 0.42551711201667786 -0.8054269552230835\n",
      "Loss: 0.4254310429096222 -0.5006518363952637\n",
      "Policy Reward: tensor(1.1343, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.12', '0.43', '0.60', '0.63', '0.66', '0.74', '0.77', '0.55', '0.11', '0.00', '0.00', '0.02', '0.19', '0.91', '0.21', '0.60', '0.44']\n",
      "Last Action:  tensor([0.4402, 0.4862, 0.0524, 0.0377, 0.1570, 0.0040, 0.2703, 0.0506, 0.0761,\n",
      "        0.1383], device='cuda:0')\n",
      "Loss: 0.3863621950149536 -0.29704952239990234\n",
      "Loss: 0.397630512714386 -0.8271819353103638\n",
      "Loss: 0.3293694257736206 -0.4865993559360504\n",
      "Loss: 0.2937667965888977 -0.44409093260765076\n",
      "Loss: 0.37696102261543274 -0.8050158619880676\n",
      "Loss: 0.37212854623794556 -0.9062261581420898\n",
      "Loss: 0.4215598404407501 -0.8510215878486633\n",
      "Policy Reward: tensor(1.2061, device='cuda:0')\n",
      "Trajectory:  ['0.40', '1.00', '0.79', '0.03', '0.17', '0.20', '0.48', '0.78', '0.71', '0.09', '0.00', '0.00', '0.02', '0.07', '0.12', '0.22', '0.09', '0.03', '0.10']\n",
      "Last Action:  tensor([0.1031, 0.1267, 0.2710, 0.1981, 0.3730, 0.3819, 0.2933, 0.3911, 0.0918,\n",
      "        0.4726], device='cuda:0')\n",
      "Bigstep:  59\n",
      "Loss: 0.3865428566932678 0.34384146332740784\n",
      "Loss: 0.40562447905540466 0.03572893887758255\n",
      "Loss: 0.38517624139785767 -0.06372499465942383\n",
      "Loss: 0.3960832953453064 -0.22699789702892303\n",
      "Loss: 0.41704851388931274 -0.4227154552936554\n",
      "Loss: 0.39209020137786865 -0.22900788486003876\n",
      "Loss: 0.37580356001853943 -0.39686456322669983\n",
      "Policy Reward: tensor(1.2955, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.38', '0.65', '0.70', '0.76', '0.77', '0.77', '0.65', '0.07', '0.00', '0.00', '0.01', '0.10', '0.87', '0.22', '0.49', '0.83', '0.03']\n",
      "Last Action:  tensor([0.0272, 0.6890, 0.3285, 0.1650, 0.2205, 0.0293, 0.3761, 0.4868, 0.0840,\n",
      "        0.1538], device='cuda:0')\n",
      "Loss: 0.37341639399528503 -0.2995690107345581\n",
      "Loss: 0.4663132131099701 -0.525381863117218\n",
      "Loss: 0.4273480772972107 -0.41302672028541565\n",
      "Loss: 0.44641804695129395 -0.6779865622520447\n",
      "Loss: 0.4020761549472809 -0.5328702330589294\n",
      "Loss: 0.37777915596961975 -0.4636061489582062\n",
      "Loss: 0.447018027305603 -0.5032904148101807\n",
      "Policy Reward: tensor(1.1216, device='cuda:0')\n",
      "Trajectory:  ['0.28', '1.00', '0.88', '0.08', '0.41', '0.78', '0.85', '0.80', '0.64', '0.08', '0.00', '0.01', '0.02', '0.04', '0.09', '0.12', '0.15', '0.20', '0.32']\n",
      "Last Action:  tensor([0.3234, 0.6298, 0.0335, 0.1651, 0.1705, 0.7148, 0.1199, 0.0311, 0.1271,\n",
      "        0.2135], device='cuda:0')\n",
      "Loss: 0.39870527386665344 -0.30500248074531555\n",
      "Loss: 0.36010947823524475 -0.2530709207057953\n",
      "Loss: 0.3903714418411255 -0.4059324562549591\n",
      "Loss: 0.3559483587741852 -0.280914306640625\n",
      "Loss: 0.4439546763896942 -0.47470226883888245\n",
      "Loss: 0.434922993183136 -0.4236067533493042\n",
      "Loss: 0.5032923817634583 -0.5933724045753479\n",
      "Policy Reward: tensor(1.1913, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.53', '0.71', '0.81', '0.82', '0.78', '0.78', '0.59', '0.02', '0.00', '0.00', '0.02', '0.56', '0.56', '0.05', '0.50', '0.56', '0.30']\n",
      "Last Action:  tensor([0.2960, 0.4070, 0.4281, 0.2119, 0.1971, 0.7674, 0.0482, 0.1292, 0.1670,\n",
      "        0.1216], device='cuda:0')\n",
      "Loss: 0.3924253582954407 -0.27517595887184143\n",
      "Loss: 0.3954720199108124 -0.527915358543396\n",
      "Loss: 0.44764044880867004 -0.601229190826416\n",
      "Loss: 0.4375009536743164 -0.399906188249588\n",
      "Loss: 0.43894997239112854 -0.4467204809188843\n",
      "Loss: 0.4052729904651642 -0.4014568626880646\n",
      "Loss: 0.4345889389514923 -0.6978341937065125\n",
      "Policy Reward: tensor(1.2046, device='cuda:0')\n",
      "Trajectory:  ['0.36', '1.00', '0.90', '0.28', '0.69', '0.80', '0.90', '0.77', '0.41', '0.01', '0.00', '0.00', '0.68', '0.91', '0.14', '0.79', '0.57', '0.08', '0.20']\n",
      "Last Action:  tensor([0.1968, 0.0710, 0.4055, 0.5660, 0.5092, 0.5723, 0.1170, 0.1949, 0.0449,\n",
      "        0.0556], device='cuda:0')\n",
      "Loss: 0.3788287937641144 -0.6197403073310852\n",
      "Loss: 0.4346519708633423 -0.3239520788192749\n",
      "Loss: 0.45503371953964233 -0.6477728486061096\n",
      "Loss: 0.4331497550010681 -0.21245737373828888\n",
      "Loss: 0.4128241539001465 -0.5731747150421143\n",
      "Loss: 0.4354848563671112 -0.18055805563926697\n",
      "Loss: 0.45599859952926636 -0.6794565320014954\n",
      "Policy Reward: tensor(1.1859, device='cuda:0')\n",
      "Trajectory:  ['0.38', '1.00', '0.86', '0.34', '0.14', '0.27', '0.49', '0.41', '0.08', '0.00', '0.00', '0.00', '0.06', '0.69', '0.76', '0.02', '0.28', '0.31', '0.01']\n",
      "Last Action:  tensor([0.0133, 0.0479, 0.5193, 0.4697, 0.0683, 0.0306, 0.0676, 0.0154, 0.1815,\n",
      "        0.1482], device='cuda:0')\n",
      "Loss: 0.42465195059776306 -0.2600806951522827\n",
      "Loss: 0.36826789379119873 -0.056502535939216614\n",
      "Loss: 0.36675670742988586 -0.28415974974632263\n",
      "Loss: 0.3530651032924652 -0.34907278418540955\n",
      "Loss: 0.4150508940219879 -0.5296867489814758\n",
      "Loss: 0.43107402324676514 -0.19718614220619202\n",
      "Loss: 0.44380253553390503 -0.8865483999252319\n",
      "Policy Reward: tensor(1.1976, device='cuda:0')\n",
      "Trajectory:  ['0.26', '1.00', '0.83', '0.10', '0.21', '0.47', '0.75', '0.84', '0.44', '0.00', '0.00', '0.00', '0.05', '0.96', '0.55', '0.35', '0.72', '0.47', '0.09']\n",
      "Last Action:  tensor([0.0908, 0.0181, 0.5415, 0.1221, 0.2753, 0.7451, 0.4167, 0.1889, 0.2756,\n",
      "        0.1836], device='cuda:0')\n",
      "Loss: 0.35403454303741455 -0.3161982595920563\n",
      "Loss: 0.3694949448108673 -0.27316632866859436\n",
      "Loss: 0.44977104663848877 -0.4334850013256073\n",
      "Loss: 0.3491218090057373 -0.1078343465924263\n",
      "Loss: 0.44932588934898376 -0.5332156419754028\n",
      "Loss: 0.40241846442222595 -0.6871212720870972\n",
      "Loss: 0.40189093351364136 -0.3863653540611267\n",
      "Policy Reward: tensor(1.2595, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.80', '0.63', '0.70', '0.74', '0.80', '0.82', '0.57', '0.04', '0.00', '0.00', '0.06', '0.71', '0.57', '0.19', '0.97', '0.19', '0.29']\n",
      "Last Action:  tensor([0.2893, 0.4313, 0.7948, 0.1751, 0.0144, 0.0464, 0.0166, 0.7914, 0.0253,\n",
      "        0.0302], device='cuda:0')\n",
      "Loss: 0.38340336084365845 -0.4167472720146179\n",
      "Loss: 0.46154922246932983 -0.566280722618103\n",
      "Loss: 0.441910982131958 -0.7355453968048096\n",
      "Loss: 0.42665958404541016 -0.5524692535400391\n",
      "Loss: 0.4597281217575073 -0.36817142367362976\n",
      "Loss: 0.3916212320327759 -0.7356078624725342\n",
      "Loss: 0.44443008303642273 -0.3815653622150421\n",
      "Policy Reward: tensor(1.3205, device='cuda:0')\n",
      "Trajectory:  ['0.42', '1.00', '0.86', '0.28', '0.21', '0.35', '0.62', '0.84', '0.72', '0.01', '0.00', '0.00', '0.03', '0.80', '0.65', '0.11', '0.97', '0.58', '0.11']\n",
      "Last Action:  tensor([0.1129, 0.1592, 0.2268, 0.1368, 0.2723, 0.3309, 0.2473, 0.1089, 0.0350,\n",
      "        0.1321], device='cuda:0')\n",
      "Bigstep:  60\n",
      "Loss: 0.3796919882297516 0.29465898871421814\n",
      "Loss: 0.4210076332092285 -0.053764209151268005\n",
      "Loss: 0.40439286828041077 0.03394502028822899\n",
      "Loss: 0.356509804725647 0.060051076114177704\n",
      "Loss: 0.2687043249607086 0.40234455466270447\n",
      "Loss: 0.3908579647541046 -0.18063722550868988\n",
      "Loss: 0.45086705684661865 -0.18413349986076355\n",
      "Policy Reward: tensor(1.1429, device='cuda:0')\n",
      "Trajectory:  ['0.33', '1.00', '0.64', '0.00', '0.20', '0.43', '0.60', '0.77', '0.84', '0.57', '0.03', '0.00', '0.00', '0.04', '0.79', '0.92', '0.07', '0.99', '0.74']\n",
      "Last Action:  tensor([0.7367, 0.9500, 0.3433, 0.6999, 0.2344, 0.8800, 0.8306, 0.0232, 0.2742,\n",
      "        0.2599], device='cuda:0')\n",
      "Loss: 0.43180614709854126 -0.4225732088088989\n",
      "Loss: 0.3724013566970825 -0.10361933708190918\n",
      "Loss: 0.49441030621528625 -0.10971991717815399\n",
      "Loss: 0.38461071252822876 -0.3441910147666931\n",
      "Loss: 0.42068377137184143 -0.24295280873775482\n",
      "Loss: 0.3421086072921753 -0.09141553938388824\n",
      "Loss: 0.4012311100959778 -0.21796667575836182\n",
      "Policy Reward: tensor(1.1955, device='cuda:0')\n",
      "Trajectory:  ['0.04', '1.00', '0.50', '0.57', '0.60', '0.63', '0.74', '0.89', '0.91', '0.52', '0.01', '0.00', '0.00', '0.13', '0.96', '0.22', '0.50', '0.98', '0.06']\n",
      "Last Action:  tensor([0.0598, 0.4867, 0.7322, 0.8329, 0.2878, 0.0298, 0.4092, 0.6060, 0.5705,\n",
      "        0.1895], device='cuda:0')\n",
      "Loss: 0.3889163136482239 0.21984291076660156\n",
      "Loss: 0.353152334690094 0.009357087314128876\n",
      "Loss: 0.4147789776325226 -0.28781557083129883\n",
      "Loss: 0.36931636929512024 -0.2061382532119751\n",
      "Loss: 0.3667374849319458 -0.05926993861794472\n",
      "Loss: 0.4152367115020752 -0.3161719739437103\n",
      "Loss: 0.37867122888565063 -0.32593345642089844\n",
      "Policy Reward: tensor(1.1817, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.18', '0.47', '0.48', '0.50', '0.57', '0.75', '0.94', '0.97', '0.65', '0.13', '0.00', '0.01', '0.10', '0.90', '0.23', '0.68', '0.62']\n",
      "Last Action:  tensor([0.6180, 0.2248, 0.6514, 0.0937, 0.0636, 0.8882, 0.7061, 0.5667, 0.0583,\n",
      "        0.8258], device='cuda:0')\n",
      "Loss: 0.4038892984390259 -0.3387084901332855\n",
      "Loss: 0.42339223623275757 -0.24024343490600586\n",
      "Loss: 0.42103955149650574 -0.4597690999507904\n",
      "Loss: 0.38772737979888916 -0.2406209409236908\n",
      "Loss: 0.3853009343147278 -0.35045382380485535\n",
      "Loss: 0.3555276095867157 -0.03374709188938141\n",
      "Loss: 0.37380069494247437 -0.5737616419792175\n",
      "Policy Reward: tensor(1.2776, device='cuda:0')\n",
      "Trajectory:  ['0.01', '0.99', '0.46', '0.49', '0.42', '0.53', '0.77', '0.83', '0.91', '0.43', '0.00', '0.00', '0.00', '0.00', '0.03', '0.07', '0.20', '0.19', '0.05']\n",
      "Last Action:  tensor([0.0451, 0.0627, 0.7175, 0.1115, 0.0328, 0.2391, 0.5106, 0.0607, 0.0377,\n",
      "        0.2656], device='cuda:0')\n",
      "Loss: 0.4387982189655304 -0.2704589366912842\n",
      "Loss: 0.37002426385879517 0.004848225973546505\n",
      "Loss: 0.45071282982826233 -0.03092319332063198\n",
      "Loss: 0.4322616457939148 -0.2862513065338135\n",
      "Loss: 0.4165290594100952 -0.44073110818862915\n",
      "Loss: 0.45755451917648315 -0.43330439925193787\n",
      "Loss: 0.4432085454463959 -0.20794999599456787\n",
      "Policy Reward: tensor(1.2543, device='cuda:0')\n",
      "Trajectory:  ['0.32', '1.00', '0.54', '0.01', '0.17', '0.47', '0.66', '0.87', '0.98', '0.74', '0.03', '0.00', '0.00', '0.00', '0.01', '0.03', '0.04', '0.07', '0.12']\n",
      "Last Action:  tensor([0.1203, 0.0617, 0.1473, 0.7196, 0.2221, 0.6348, 0.1259, 0.0870, 0.2836,\n",
      "        0.2852], device='cuda:0')\n",
      "Loss: 0.31841713190078735 -0.007523764856159687\n",
      "Loss: 0.396941602230072 -0.05762745440006256\n",
      "Loss: 0.42170482873916626 -0.2652207911014557\n",
      "Loss: 0.4533354640007019 -0.24485695362091064\n",
      "Loss: 0.4283241033554077 -0.4661165773868561\n",
      "Loss: 0.4047982096672058 -0.08198974281549454\n",
      "Loss: 0.3849930167198181 -0.07617249339818954\n",
      "Policy Reward: tensor(1.1561, device='cuda:0')\n",
      "Trajectory:  ['0.28', '1.00', '0.51', '0.01', '0.23', '0.48', '0.60', '0.84', '0.97', '0.82', '0.14', '0.00', '0.00', '0.20', '1.00', '0.19', '0.83', '0.47', '0.24']\n",
      "Last Action:  tensor([0.2381, 0.0868, 0.1778, 0.6630, 0.7160, 0.2388, 0.8362, 0.0462, 0.2313,\n",
      "        0.6415], device='cuda:0')\n",
      "Loss: 0.38933417201042175 -0.33678507804870605\n",
      "Loss: 0.45459339022636414 -0.5711910128593445\n",
      "Loss: 0.3028571307659149 -0.21074311435222626\n",
      "Loss: 0.44321611523628235 -0.5299853086471558\n",
      "Loss: 0.4338966906070709 -0.2262936681509018\n",
      "Loss: 0.40057694911956787 -0.5490013360977173\n",
      "Loss: 0.31050965189933777 0.08426651358604431\n",
      "Policy Reward: tensor(1.1741, device='cuda:0')\n",
      "Trajectory:  ['0.35', '1.00', '0.48', '0.05', '0.25', '0.48', '0.70', '0.93', '0.99', '0.77', '0.11', '0.00', '0.00', '0.10', '0.99', '0.19', '0.57', '0.81', '0.02']\n",
      "Last Action:  tensor([0.0220, 0.9897, 0.3998, 0.0143, 0.1257, 0.0643, 0.0606, 0.4324, 0.9176,\n",
      "        0.1418], device='cuda:0')\n",
      "Loss: 0.3907831013202667 -0.399395614862442\n",
      "Loss: 0.4321902394294739 -0.2638648450374603\n",
      "Loss: 0.3774849474430084 -0.2718058228492737\n",
      "Loss: 0.4035308063030243 -0.2548908293247223\n",
      "Loss: 0.4521167278289795 -0.5672668218612671\n",
      "Loss: 0.37058165669441223 -0.6388870477676392\n",
      "Loss: 0.3376862704753876 -0.13897362351417542\n",
      "Policy Reward: tensor(1.2350, device='cuda:0')\n",
      "Trajectory:  ['0.25', '1.00', '0.48', '0.00', '0.17', '0.45', '0.66', '0.90', '0.98', '0.76', '0.22', '0.01', '0.00', '0.02', '0.69', '0.91', '0.03', '0.50', '0.99']\n",
      "Last Action:  tensor([0.9855, 0.1767, 0.9801, 0.3631, 0.1500, 0.5555, 0.7030, 0.4585, 0.0293,\n",
      "        0.0761], device='cuda:0')\n",
      "Bigstep:  61\n",
      "Loss: 0.40207764506340027 -0.4003937542438507\n",
      "Loss: 0.37381061911582947 0.1835104078054428\n",
      "Loss: 0.4651619493961334 -0.44308602809906006\n",
      "Loss: 0.3965146839618683 0.007959112524986267\n",
      "Loss: 0.34926342964172363 -0.3939504325389862\n",
      "Loss: 0.34461721777915955 -0.2841223180294037\n",
      "Loss: 0.38814470171928406 -0.4216820001602173\n",
      "Policy Reward: tensor(1.0696, device='cuda:0')\n",
      "Trajectory:  ['0.44', '1.00', '0.71', '0.07', '0.23', '0.59', '0.82', '0.96', '0.95', '0.76', '0.29', '0.00', '0.00', '0.54', '1.00', '0.35', '0.96', '0.57', '0.52']\n",
      "Last Action:  tensor([0.5232, 0.0287, 0.9524, 0.2196, 0.9445, 0.9779, 0.9945, 0.0194, 0.9336,\n",
      "        0.2116], device='cuda:0')\n",
      "Loss: 0.4557708203792572 -0.5552171468734741\n",
      "Loss: 0.4013381600379944 -0.35364505648612976\n",
      "Loss: 0.39809325337409973 -0.4204922020435333\n",
      "Loss: 0.3826671242713928 -0.32873260974884033\n",
      "Loss: 0.4147138297557831 -0.33140677213668823\n",
      "Loss: 0.38773322105407715 -0.35905858874320984\n",
      "Loss: 0.3935971260070801 -0.5711162090301514\n",
      "Policy Reward: tensor(1.1941, device='cuda:0')\n",
      "Trajectory:  ['0.53', '0.65', '0.51', '0.41', '0.65', '0.83', '0.94', '0.98', '1.00', '0.95', '0.35', '0.00', '0.01', '0.99', '0.86', '0.18', '0.92', '0.82', '0.06']\n",
      "Last Action:  tensor([0.0560, 0.0243, 0.2270, 0.0076, 0.2355, 0.0721, 0.1608, 0.8349, 0.4701,\n",
      "        0.4647], device='cuda:0')\n",
      "Loss: 0.3220602571964264 -0.3721189796924591\n",
      "Loss: 0.4578545093536377 -0.49444371461868286\n",
      "Loss: 0.4040693938732147 -0.17710505425930023\n",
      "Loss: 0.3563230633735657 -0.09937752783298492\n",
      "Loss: 0.4459216296672821 -0.5197874307632446\n",
      "Loss: 0.41676080226898193 -0.300920695066452\n",
      "Loss: 0.4236224591732025 -0.5699504613876343\n",
      "Policy Reward: tensor(1.0949, device='cuda:0')\n",
      "Trajectory:  ['0.39', '0.96', '0.51', '0.69', '0.78', '0.89', '0.91', '0.94', '0.94', '0.93', '0.90', '0.87', '0.86', '0.86', '0.85', '0.85', '0.85', '0.85', '0.85']\n",
      "Last Action:  tensor([0.8537, 0.3059, 0.9837, 0.2204, 0.3704, 0.0428, 0.6835, 0.4142, 0.2541,\n",
      "        0.0640], device='cuda:0')\n",
      "Loss: 0.35200244188308716 -0.28497564792633057\n",
      "Loss: 0.38855433464050293 -0.4472964406013489\n",
      "Loss: 0.42898860573768616 -0.7955685257911682\n",
      "Loss: 0.37130406498908997 -0.636350154876709\n",
      "Loss: 0.43489494919776917 -0.6327545642852783\n",
      "Loss: 0.42752283811569214 -0.7729365825653076\n",
      "Loss: 0.4688909649848938 -0.6543796062469482\n",
      "Policy Reward: tensor(1.1198, device='cuda:0')\n",
      "Trajectory:  ['0.48', '1.00', '0.66', '0.02', '0.18', '0.54', '0.76', '0.88', '0.99', '1.00', '0.93', '0.59', '0.04', '0.05', '0.97', '0.70', '0.31', '0.99', '0.46']\n",
      "Last Action:  tensor([0.4578, 0.2073, 0.9762, 0.2137, 0.1578, 0.6868, 0.9926, 0.9834, 0.2989,\n",
      "        0.1187], device='cuda:0')\n",
      "Loss: 0.41071003675460815 -0.8384177684783936\n",
      "Loss: 0.38675403594970703 -0.5677295923233032\n",
      "Loss: 0.3747427463531494 -0.5099277496337891\n",
      "Loss: 0.40938159823417664 -0.38349467515945435\n",
      "Loss: 0.42971307039260864 -0.49422687292099\n",
      "Loss: 0.4054863452911377 -0.6170373558998108\n",
      "Loss: 0.40197262167930603 -0.14013901352882385\n",
      "Policy Reward: tensor(1.2091, device='cuda:0')\n",
      "Trajectory:  ['0.62', '1.00', '0.77', '0.16', '0.39', '0.61', '0.90', '0.99', '1.00', '0.86', '0.15', '0.00', '0.02', '0.99', '0.94', '0.53', '0.95', '0.58', '0.51']\n",
      "Last Action:  tensor([0.5062, 0.6072, 0.9477, 0.0769, 0.9353, 0.6129, 0.2714, 0.1179, 0.1945,\n",
      "        0.9154], device='cuda:0')\n",
      "Loss: 0.4140605628490448 -0.5121992826461792\n",
      "Loss: 0.46792200207710266 -0.6484022736549377\n",
      "Loss: 0.3726288676261902 -0.5783308744430542\n",
      "Loss: 0.3497132360935211 -0.4885737895965576\n",
      "Loss: 0.38903260231018066 -0.5917149782180786\n",
      "Loss: 0.37629082798957825 -0.4951463043689728\n",
      "Loss: 0.4040941894054413 -0.5871439576148987\n",
      "Policy Reward: tensor(1.3226, device='cuda:0')\n",
      "Trajectory:  ['0.51', '1.00', '0.73', '0.30', '0.35', '0.53', '0.80', '0.95', '1.00', '0.98', '0.35', '0.00', '0.00', '0.01', '0.21', '0.99', '0.26', '0.07', '0.05']\n",
      "Last Action:  tensor([0.0453, 0.0127, 0.9449, 0.8167, 0.3406, 0.1796, 0.1476, 0.2410, 0.5412,\n",
      "        0.5523], device='cuda:0')\n",
      "Loss: 0.369485467672348 -0.49579134583473206\n",
      "Loss: 0.30988994240760803 -0.21219536662101746\n",
      "Loss: 0.4050869643688202 -0.41867315769195557\n",
      "Loss: 0.34240978956222534 -0.5553618669509888\n",
      "Loss: 0.3623002767562866 -0.7190811634063721\n",
      "Loss: 0.3709820806980133 -0.42710500955581665\n",
      "Loss: 0.3497753143310547 -0.639649510383606\n",
      "Policy Reward: tensor(1.1852, device='cuda:0')\n",
      "Trajectory:  ['0.38', '1.00', '0.76', '0.02', '0.26', '0.66', '0.84', '0.99', '1.00', '0.87', '0.14', '0.00', '0.09', '1.00', '0.64', '0.24', '1.00', '0.49', '0.05']\n",
      "Last Action:  tensor([0.0483, 0.0685, 0.0492, 0.9473, 0.1167, 0.1108, 0.0663, 0.3376, 0.2352,\n",
      "        0.6701], device='cuda:0')\n",
      "Loss: 0.43244463205337524 -0.6136422753334045\n",
      "Loss: 0.31213778257369995 -0.355825275182724\n",
      "Loss: 0.3548992872238159 -0.3812722861766815\n",
      "Loss: 0.42933037877082825 -0.6563321948051453\n",
      "Loss: 0.3626778721809387 -0.3370457887649536\n",
      "Loss: 0.409097284078598 -0.5075886845588684\n",
      "Loss: 0.33521753549575806 -0.3846741020679474\n",
      "Policy Reward: tensor(1.2288, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.39', '0.51', '0.62', '0.63', '0.76', '0.86', '0.95', '1.00', '1.00', '0.79', '0.06', '0.00', '0.12', '0.99', '0.42', '0.41', '0.99']\n",
      "Last Action:  tensor([0.9942, 0.2555, 0.2860, 0.4099, 0.3724, 0.0628, 0.0771, 0.3979, 0.9257,\n",
      "        0.8663], device='cuda:0')\n",
      "Bigstep:  62\n",
      "Loss: 0.3760533630847931 -0.09002473950386047\n",
      "Loss: 0.3571734130382538 0.540134608745575\n",
      "Loss: 0.4718065559864044 -0.2927808463573456\n",
      "Loss: 0.4128526449203491 -0.18872104585170746\n",
      "Loss: 0.39937132596969604 -0.3892849385738373\n",
      "Loss: 0.42091578245162964 -0.3422956168651581\n",
      "Loss: 0.3948614299297333 -0.43169158697128296\n",
      "Policy Reward: tensor(1.2208, device='cuda:0')\n",
      "Trajectory:  ['0.20', '1.00', '0.80', '0.02', '0.30', '0.82', '0.95', '1.00', '0.99', '0.68', '0.01', '0.00', '0.01', '0.94', '0.88', '0.11', '0.99', '0.78', '0.02']\n",
      "Last Action:  tensor([0.0215, 0.8481, 0.9540, 0.3785, 0.3484, 0.0307, 0.0252, 0.2611, 0.6645,\n",
      "        0.3456], device='cuda:0')\n",
      "Loss: 0.40965479612350464 -0.0779157429933548\n",
      "Loss: 0.3689379096031189 -0.048693813383579254\n",
      "Loss: 0.37081271409988403 -0.5074405074119568\n",
      "Loss: 0.4250324070453644 -0.33994603157043457\n",
      "Loss: 0.408582478761673 -0.24126732349395752\n",
      "Loss: 0.38390886783599854 -0.1435624361038208\n",
      "Loss: 0.36661601066589355 -0.36683422327041626\n",
      "Policy Reward: tensor(1.1802, device='cuda:0')\n",
      "Trajectory:  ['0.48', '0.26', '0.39', '0.51', '0.59', '0.94', '1.00', '1.00', '1.00', '0.98', '0.56', '0.02', '0.00', '0.02', '0.15', '0.56', '0.93', '0.91', '0.78']\n",
      "Last Action:  tensor([0.7782, 0.1176, 0.4883, 0.9659, 0.2429, 0.1246, 0.2309, 0.1660, 0.4420,\n",
      "        0.0747], device='cuda:0')\n",
      "Loss: 0.4325626492500305 -0.43654298782348633\n",
      "Loss: 0.37487471103668213 -0.43723851442337036\n",
      "Loss: 0.3843671679496765 -0.26691678166389465\n",
      "Loss: 0.4433906078338623 -0.26209717988967896\n",
      "Loss: 0.4114706516265869 -0.47343552112579346\n",
      "Loss: 0.3768828213214874 -0.274904727935791\n",
      "Loss: 0.408113032579422 -0.3385332226753235\n",
      "Policy Reward: tensor(1.2307, device='cuda:0')\n",
      "Trajectory:  ['0.27', '0.68', '0.43', '0.17', '0.54', '0.93', '1.00', '1.00', '0.93', '0.12', '0.00', '0.00', '0.67', '0.99', '0.27', '0.12', '0.73', '0.79', '0.07']\n",
      "Last Action:  tensor([0.0705, 0.2559, 0.2001, 0.8968, 0.4002, 0.0893, 0.8657, 0.8460, 0.1860,\n",
      "        0.8816], device='cuda:0')\n",
      "Loss: 0.4363294541835785 -0.5058349370956421\n",
      "Loss: 0.3866027593612671 -0.5307664275169373\n",
      "Loss: 0.42448073625564575 -0.430608868598938\n",
      "Loss: 0.4473479986190796 -0.6278968453407288\n",
      "Loss: 0.34480851888656616 -0.33740168809890747\n",
      "Loss: 0.41906535625457764 -0.3599243760108948\n",
      "Loss: 0.4020054340362549 -0.3601281940937042\n",
      "Policy Reward: tensor(1.1212, device='cuda:0')\n",
      "Trajectory:  ['0.17', '1.00', '0.82', '0.04', '0.32', '0.80', '1.00', '1.00', '1.00', '0.72', '0.05', '0.00', '0.00', '0.35', '0.87', '0.53', '0.35', '0.40', '0.92']\n",
      "Last Action:  tensor([0.9231, 0.9592, 0.9952, 0.1672, 0.3470, 0.8513, 0.2526, 0.7000, 0.4072,\n",
      "        0.9784], device='cuda:0')\n",
      "Loss: 0.501356303691864 -0.580289900302887\n",
      "Loss: 0.2951122522354126 -0.33137255907058716\n",
      "Loss: 0.3848218321800232 -0.3984326124191284\n",
      "Loss: 0.33867698907852173 -0.356738418340683\n",
      "Loss: 0.44694265723228455 -0.41807621717453003\n",
      "Loss: 0.40852293372154236 -0.6577053666114807\n",
      "Loss: 0.41156497597694397 -0.5242810845375061\n",
      "Policy Reward: tensor(1.1853, device='cuda:0')\n",
      "Trajectory:  ['0.33', '1.00', '0.60', '0.02', '0.16', '0.87', '0.99', '1.00', '1.00', '0.83', '0.14', '0.00', '0.00', '0.02', '0.37', '0.99', '0.41', '0.36', '0.92']\n",
      "Last Action:  tensor([0.9205, 0.1675, 0.2977, 0.1185, 0.0762, 0.9656, 0.3421, 0.3114, 0.2081,\n",
      "        0.0537], device='cuda:0')\n",
      "Loss: 0.3306964635848999 -0.3980337083339691\n",
      "Loss: 0.39423587918281555 -0.5758264064788818\n",
      "Loss: 0.4038606286048889 -0.671208381652832\n",
      "Loss: 0.4074360728263855 -0.5444859266281128\n",
      "Loss: 0.4510684609413147 -0.6958832740783691\n",
      "Loss: 0.3915468752384186 -0.6112217903137207\n",
      "Loss: 0.46228960156440735 -0.49650269746780396\n",
      "Policy Reward: tensor(1.1503, device='cuda:0')\n",
      "Trajectory:  ['0.30', '1.00', '0.68', '0.06', '0.20', '0.77', '0.94', '1.00', '1.00', '0.84', '0.11', '0.00', '0.00', '0.02', '0.44', '0.99', '0.47', '0.56', '0.95']\n",
      "Last Action:  tensor([0.9510, 0.2742, 0.1705, 0.1994, 0.3021, 0.5932, 0.2745, 0.1455, 0.9974,\n",
      "        0.7813], device='cuda:0')\n",
      "Loss: 0.3096204400062561 0.059597816318273544\n",
      "Loss: 0.46644437313079834 -0.6465498208999634\n",
      "Loss: 0.3951137065887451 -0.4230934977531433\n",
      "Loss: 0.38414841890335083 -0.3860582113265991\n",
      "Loss: 0.4726966917514801 -0.4733014702796936\n",
      "Loss: 0.38202470541000366 -0.7088279724121094\n",
      "Loss: 0.38526034355163574 -0.40295881032943726\n",
      "Policy Reward: tensor(1.0938, device='cuda:0')\n",
      "Trajectory:  ['0.33', '1.00', '0.68', '0.03', '0.27', '0.87', '0.98', '1.00', '0.99', '0.60', '0.03', '0.00', '0.03', '0.15', '0.23', '0.39', '0.57', '0.41', '0.72']\n",
      "Last Action:  tensor([0.7239, 0.9218, 0.2384, 0.7553, 0.1244, 0.2791, 0.1648, 0.2567, 0.2349,\n",
      "        0.2341], device='cuda:0')\n",
      "Loss: 0.38320279121398926 -0.48675301671028137\n",
      "Loss: 0.398185670375824 -0.288860023021698\n",
      "Loss: 0.48038914799690247 -0.7653817534446716\n",
      "Loss: 0.42205432057380676 -0.5859299898147583\n",
      "Loss: 0.4310722053050995 -0.47486287355422974\n",
      "Loss: 0.3515652120113373 -0.4206322729587555\n",
      "Loss: 0.3707275688648224 -0.19326205551624298\n",
      "Policy Reward: tensor(1.1983, device='cuda:0')\n",
      "Trajectory:  ['0.38', '1.00', '0.67', '0.07', '0.29', '0.88', '0.99', '1.00', '0.99', '0.65', '0.06', '0.00', '0.05', '0.99', '0.70', '0.18', '0.98', '0.64', '0.29']\n",
      "Last Action:  tensor([0.2871, 0.3058, 0.4508, 0.2645, 0.3206, 0.5796, 0.1995, 0.9971, 0.9885,\n",
      "        0.3052], device='cuda:0')\n",
      "Bigstep:  63\n",
      "Loss: 0.3673665225505829 -0.24491168558597565\n",
      "Loss: 0.3625664710998535 -0.19804872572422028\n",
      "Loss: 0.38285908102989197 -0.1709083914756775\n",
      "Loss: 0.4553890526294708 -0.5477386713027954\n",
      "Loss: 0.4055386483669281 -0.4371093511581421\n",
      "Loss: 0.3686749339103699 -0.6096919775009155\n",
      "Loss: 0.40221041440963745 -0.7818478941917419\n",
      "Policy Reward: tensor(1.2115, device='cuda:0')\n",
      "Trajectory:  ['0.37', '1.00', '0.75', '0.11', '0.63', '0.98', '1.00', '1.00', '0.99', '0.50', '0.01', '0.00', '0.03', '0.95', '0.85', '0.58', '0.96', '0.89', '0.99']\n",
      "Last Action:  tensor([0.9889, 0.2435, 0.3173, 0.3733, 0.3357, 0.9761, 0.4456, 0.3543, 0.2736,\n",
      "        0.9995], device='cuda:0')\n",
      "Loss: 0.4654352366924286 -1.0737394094467163\n",
      "Loss: 0.4364803433418274 -0.6327601075172424\n",
      "Loss: 0.3783472776412964 -0.38540270924568176\n",
      "Loss: 0.3657628893852234 -0.2179366797208786\n",
      "Loss: 0.39601436257362366 -0.7374394536018372\n",
      "Loss: 0.3890785276889801 -0.6804836988449097\n",
      "Loss: 0.43825072050094604 -0.44660213589668274\n",
      "Policy Reward: tensor(1.1811, device='cuda:0')\n",
      "Trajectory:  ['0.27', '0.91', '0.43', '0.13', '0.82', '1.00', '1.00', '1.00', '0.80', '0.15', '0.00', '0.00', '0.06', '0.99', '0.87', '0.30', '0.75', '0.98', '0.60']\n",
      "Last Action:  tensor([0.6001, 0.9964, 0.2867, 0.2396, 0.1538, 0.9767, 0.9955, 0.1124, 0.3332,\n",
      "        0.0851], device='cuda:0')\n",
      "Loss: 0.41131725907325745 -1.002082109451294\n",
      "Loss: 0.3748953938484192 -0.4629054069519043\n",
      "Loss: 0.3684079647064209 -0.07566861808300018\n",
      "Loss: 0.3503645956516266 -0.7214948534965515\n",
      "Loss: 0.46248477697372437 -0.7492775917053223\n",
      "Loss: 0.34689316153526306 -0.5022217631340027\n",
      "Loss: 0.4386235773563385 -1.0322116613388062\n",
      "Policy Reward: tensor(1.1647, device='cuda:0')\n",
      "Trajectory:  ['0.26', '1.00', '0.80', '0.45', '0.98', '1.00', '1.00', '1.00', '1.00', '0.54', '0.02', '0.00', '0.07', '1.00', '0.63', '0.24', '0.99', '0.61', '0.26']\n",
      "Last Action:  tensor([0.2631, 0.3091, 0.1821, 0.3578, 0.1141, 0.6071, 0.9845, 0.0945, 0.6648,\n",
      "        0.4034], device='cuda:0')\n",
      "Loss: 0.4255125820636749 -0.6367872953414917\n",
      "Loss: 0.39513635635375977 -0.6468474864959717\n",
      "Loss: 0.3607757091522217 -0.5864759683609009\n",
      "Loss: 0.4010486900806427 -0.609817385673523\n",
      "Loss: 0.41816839575767517 -1.000138759613037\n",
      "Loss: 0.34580811858177185 -0.5275138020515442\n",
      "Loss: 0.3903917074203491 -0.5086466670036316\n",
      "Policy Reward: tensor(1.1953, device='cuda:0')\n",
      "Trajectory:  ['0.39', '1.00', '0.63', '0.05', '0.64', '0.99', '1.00', '1.00', '0.98', '0.59', '0.02', '0.00', '0.02', '0.99', '0.62', '0.26', '0.99', '0.47', '0.38']\n",
      "Last Action:  tensor([0.3834, 0.2938, 0.5246, 0.6365, 0.9806, 0.9282, 0.3285, 0.9960, 0.6960,\n",
      "        0.7656], device='cuda:0')\n",
      "Loss: 0.3713129460811615 -0.3172600567340851\n",
      "Loss: 0.3642575144767761 -0.41568082571029663\n",
      "Loss: 0.3708667457103729 -0.6236628890037537\n",
      "Loss: 0.3557080924510956 -0.5216168165206909\n",
      "Loss: 0.41590672731399536 -0.38360804319381714\n",
      "Loss: 0.4545292258262634 -0.9711143374443054\n",
      "Loss: 0.41159942746162415 -0.9032196402549744\n",
      "Policy Reward: tensor(1.1492, device='cuda:0')\n",
      "Trajectory:  ['0.36', '0.52', '0.94', '0.56', '0.79', '0.98', '1.00', '1.00', '0.81', '0.03', '0.00', '0.00', '0.02', '0.09', '0.72', '0.99', '0.98', '0.97', '1.00']\n",
      "Last Action:  tensor([0.9984, 0.8308, 0.2121, 0.4729, 0.3135, 0.9662, 0.2935, 0.6197, 0.2216,\n",
      "        0.1899], device='cuda:0')\n",
      "Loss: 0.4055018723011017 -0.6886286735534668\n",
      "Loss: 0.4300967752933502 -0.5526719689369202\n",
      "Loss: 0.4130035936832428 -0.7497578263282776\n",
      "Loss: 0.3795900344848633 -0.7558537721633911\n",
      "Loss: 0.4247424900531769 -0.7631714940071106\n",
      "Loss: 0.3496752381324768 -0.40247786045074463\n",
      "Loss: 0.42287391424179077 -0.6514004468917847\n",
      "Policy Reward: tensor(1.1880, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.64', '0.74', '0.88', '0.99', '1.00', '1.00', '0.94', '0.55', '0.03', '0.00', '0.01', '0.81', '0.92', '0.30', '0.98', '0.50', '0.36']\n",
      "Last Action:  tensor([0.3570, 0.3354, 0.2008, 0.8959, 0.4798, 0.4390, 0.3285, 0.9991, 0.5112,\n",
      "        0.8659], device='cuda:0')\n",
      "Loss: 0.3915458023548126 -0.7054641246795654\n",
      "Loss: 0.32845214009284973 -0.4940965175628662\n",
      "Loss: 0.3902873396873474 -0.7187021374702454\n",
      "Loss: 0.38549378514289856 -0.6626107096672058\n",
      "Loss: 0.38777080178260803 -0.585690438747406\n",
      "Loss: 0.3596557378768921 -0.7432727217674255\n",
      "Loss: 0.41650059819221497 -0.5501806139945984\n",
      "Policy Reward: tensor(1.0729, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.72', '0.56', '0.61', '0.95', '1.00', '1.00', '1.00', '0.70', '0.03', '0.00', '0.01', '0.03', '0.08', '0.48', '0.99', '0.98', '0.99', '1.00']\n",
      "Last Action:  tensor([0.9990, 0.4238, 0.4921, 0.8994, 0.3110, 0.7850, 0.7097, 0.3248, 0.3729,\n",
      "        0.9993], device='cuda:0')\n",
      "Loss: 0.3548034131526947 -0.5179709792137146\n",
      "Loss: 0.4577253460884094 -0.9246681332588196\n",
      "Loss: 0.3844899833202362 -0.695485532283783\n",
      "Loss: 0.4143725633621216 -0.8028193712234497\n",
      "Loss: 0.38768690824508667 -0.4464346468448639\n",
      "Loss: 0.4322010576725006 -0.9372003078460693\n",
      "Loss: 0.37182414531707764 -0.7401674389839172\n",
      "Policy Reward: tensor(1.2860, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.67', '0.64', '0.93', '1.00', '1.00', '1.00', '1.00', '0.57', '0.01', '0.00', '0.00', '0.01', '0.04', '0.51', '0.99', '0.40', '0.10']\n",
      "Last Action:  tensor([0.1003, 0.3298, 0.4414, 0.7922, 0.3762, 0.3141, 0.8858, 0.1685, 0.7241,\n",
      "        0.6649], device='cuda:0')\n",
      "Bigstep:  64\n",
      "Loss: 0.38127467036247253 -0.24309837818145752\n",
      "Loss: 0.3867942690849304 -0.06955809146165848\n",
      "Loss: 0.43403029441833496 -0.4302945137023926\n",
      "Loss: 0.3845878839492798 0.0016002878546714783\n",
      "Loss: 0.3838331997394562 -0.5520147085189819\n",
      "Loss: 0.41541117429733276 -0.6540222764015198\n",
      "Loss: 0.3668482303619385 0.006417595781385899\n",
      "Policy Reward: tensor(1.3538, device='cuda:0')\n",
      "Trajectory:  ['0.28', '1.00', '0.61', '0.01', '0.22', '0.98', '1.00', '1.00', '1.00', '0.57', '0.02', '0.00', '0.00', '0.01', '0.05', '0.15', '0.78', '1.00', '0.94']\n",
      "Last Action:  tensor([0.9405, 0.2515, 0.1708, 0.2294, 0.3105, 0.9506, 0.5097, 0.7390, 0.9700,\n",
      "        0.3087], device='cuda:0')\n",
      "Loss: 0.4733763635158539 -0.9221768975257874\n",
      "Loss: 0.41411179304122925 -0.4465358555316925\n",
      "Loss: 0.34937143325805664 -0.4437514841556549\n",
      "Loss: 0.37208646535873413 -0.3008241355419159\n",
      "Loss: 0.4046216607093811 -0.7051174640655518\n",
      "Loss: 0.33338218927383423 -0.3124430775642395\n",
      "Loss: 0.37527012825012207 -0.2574227750301361\n",
      "Policy Reward: tensor(1.1811, device='cuda:0')\n",
      "Trajectory:  ['0.21', '1.00', '0.72', '0.00', '0.22', '0.88', '0.99', '0.99', '0.67', '0.35', '0.01', '0.00', '0.05', '0.93', '0.74', '0.25', '0.98', '0.55', '0.33']\n",
      "Last Action:  tensor([0.3305, 0.5227, 0.6775, 0.9849, 0.5778, 0.3140, 0.8431, 0.9323, 0.0871,\n",
      "        0.5753], device='cuda:0')\n",
      "Loss: 0.4064400792121887 -0.7680764198303223\n",
      "Loss: 0.3198685646057129 -0.4048486053943634\n",
      "Loss: 0.35646918416023254 -0.6448184847831726\n",
      "Loss: 0.3618567883968353 -0.33657312393188477\n",
      "Loss: 0.39245903491973877 -0.5114898085594177\n",
      "Loss: 0.29535818099975586 -0.10524244606494904\n",
      "Loss: 0.39329794049263 -0.30464810132980347\n",
      "Policy Reward: tensor(1.1835, device='cuda:0')\n",
      "Trajectory:  ['0.32', '1.00', '0.44', '0.00', '0.15', '0.64', '0.99', '0.99', '0.80', '0.44', '0.02', '0.00', '0.01', '0.34', '0.97', '0.51', '0.82', '0.57', '0.66']\n",
      "Last Action:  tensor([0.6642, 0.9699, 0.5269, 0.8045, 0.9505, 0.4804, 0.2817, 0.3205, 0.6407,\n",
      "        0.4224], device='cuda:0')\n",
      "Loss: 0.43530896306037903 -0.61784428358078\n",
      "Loss: 0.4300505816936493 -0.5679314732551575\n",
      "Loss: 0.3984249234199524 -0.5739511847496033\n",
      "Loss: 0.35562533140182495 -0.47431614995002747\n",
      "Loss: 0.3348044157028198 -0.4812387228012085\n",
      "Loss: 0.3862287998199463 -0.7387444376945496\n",
      "Loss: 0.35100483894348145 -0.1925460398197174\n",
      "Policy Reward: tensor(1.1696, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.40', '0.49', '0.69', '0.71', '0.81', '0.84', '0.64', '0.35', '0.04', '0.01', '0.03', '0.67', '0.94', '0.25', '0.99', '0.58', '0.47']\n",
      "Last Action:  tensor([0.4654, 0.7009, 0.9069, 0.8434, 0.7234, 0.3908, 0.9906, 0.9727, 0.5627,\n",
      "        0.7145], device='cuda:0')\n",
      "Loss: 0.39108461141586304 -0.48290374875068665\n",
      "Loss: 0.353750616312027 -0.43208175897598267\n",
      "Loss: 0.46828460693359375 -1.0139824151992798\n",
      "Loss: 0.31425634026527405 -0.3809438645839691\n",
      "Loss: 0.2999604344367981 -0.3121107816696167\n",
      "Loss: 0.4196389615535736 -0.5146265625953674\n",
      "Loss: 0.4188717305660248 -0.8231568932533264\n",
      "Policy Reward: tensor(1.1974, device='cuda:0')\n",
      "Trajectory:  ['0.28', '1.00', '0.42', '0.01', '0.10', '0.48', '0.80', '0.99', '0.97', '0.63', '0.14', '0.00', '0.00', '0.04', '0.97', '0.52', '0.37', '0.92', '0.43']\n",
      "Last Action:  tensor([0.4305, 0.4284, 0.6817, 0.7292, 0.9211, 0.8098, 0.8073, 0.7903, 0.8525,\n",
      "        0.4704], device='cuda:0')\n",
      "Loss: 0.38113003969192505 -0.7753498554229736\n",
      "Loss: 0.3989388048648834 -0.46482908725738525\n",
      "Loss: 0.37666094303131104 -0.44865673780441284\n",
      "Loss: 0.3827838897705078 -0.5534260272979736\n",
      "Loss: 0.41504576802253723 -0.7844038009643555\n",
      "Loss: 0.39579129219055176 -0.3687371015548706\n",
      "Loss: 0.4668964445590973 -0.5430946350097656\n",
      "Policy Reward: tensor(1.1467, device='cuda:0')\n",
      "Trajectory:  ['0.43', '0.92', '0.54', '0.04', '0.08', '0.34', '0.64', '0.98', '1.00', '0.79', '0.25', '0.00', '0.00', '0.00', '0.14', '0.99', '0.59', '0.33', '0.50']\n",
      "Last Action:  tensor([0.4995, 0.6521, 0.5013, 0.9770, 0.4797, 0.9662, 0.5830, 0.9948, 0.7248,\n",
      "        0.8765], device='cuda:0')\n",
      "Loss: 0.3905525803565979 -0.5216675400733948\n",
      "Loss: 0.3663146197795868 -0.3734320402145386\n",
      "Loss: 0.32228022813796997 -0.4391658306121826\n",
      "Loss: 0.4538031816482544 -0.7664722204208374\n",
      "Loss: 0.42002174258232117 -0.7683767080307007\n",
      "Loss: 0.39995622634887695 -0.759242057800293\n",
      "Loss: 0.389112263917923 -0.9020847678184509\n",
      "Policy Reward: tensor(1.1808, device='cuda:0')\n",
      "Trajectory:  ['0.35', '1.00', '0.56', '0.02', '0.10', '0.58', '0.95', '0.99', '0.99', '0.70', '0.13', '0.00', '0.00', '0.00', '0.08', '0.83', '0.92', '0.49', '0.63']\n",
      "Last Action:  tensor([0.6289, 0.4245, 0.4936, 0.5822, 0.3884, 0.8951, 0.9554, 0.9821, 0.8766,\n",
      "        0.4472], device='cuda:0')\n",
      "Loss: 0.3708347678184509 -0.2615906596183777\n",
      "Loss: 0.3844379186630249 -0.3731131851673126\n",
      "Loss: 0.32431694865226746 -0.36033889651298523\n",
      "Loss: 0.4420062303543091 -0.8279332518577576\n",
      "Loss: 0.35051101446151733 -0.4230048954486847\n",
      "Loss: 0.4947746992111206 -0.37576326727867126\n",
      "Loss: 0.3376469016075134 -0.5350040197372437\n",
      "Policy Reward: tensor(1.2995, device='cuda:0')\n",
      "Trajectory:  ['0.22', '1.00', '0.51', '0.00', '0.05', '0.43', '0.76', '0.94', '0.81', '0.50', '0.12', '0.00', '0.00', '0.11', '0.99', '0.47', '0.42', '0.97', '0.33']\n",
      "Last Action:  tensor([0.3285, 0.4785, 0.5732, 0.7916, 0.9504, 0.9529, 0.4349, 0.9377, 0.2855,\n",
      "        0.2993], device='cuda:0')\n",
      "Bigstep:  65\n",
      "Loss: 0.3908032774925232 0.3761351406574249\n",
      "Loss: 0.37919583916664124 -0.43914949893951416\n",
      "Loss: 0.3565657138824463 -0.3120928108692169\n",
      "Loss: 0.31788170337677 -0.18737588822841644\n",
      "Loss: 0.3757495880126953 -0.2996698319911957\n",
      "Loss: 0.324503093957901 -0.16831259429454803\n",
      "Loss: 0.40161409974098206 -0.4601045548915863\n",
      "Policy Reward: tensor(1.1805, device='cuda:0')\n",
      "Trajectory:  ['0.35', '1.00', '0.84', '0.03', '0.06', '0.50', '0.89', '0.97', '0.98', '0.67', '0.27', '0.01', '0.00', '0.00', '0.14', '0.97', '0.91', '0.65', '0.87']\n",
      "Last Action:  tensor([0.8665, 0.9475, 0.9241, 0.5236, 0.8930, 0.7904, 0.5880, 0.5235, 0.3929,\n",
      "        0.4625], device='cuda:0')\n",
      "Loss: 0.3543739318847656 -0.2189796417951584\n",
      "Loss: 0.37923645973205566 0.0494554340839386\n",
      "Loss: 0.35860660672187805 -0.3971361219882965\n",
      "Loss: 0.4113873541355133 -0.693439245223999\n",
      "Loss: 0.4062967896461487 -0.498539537191391\n",
      "Loss: 0.434566855430603 -0.7785407900810242\n",
      "Loss: 0.3517366349697113 -0.3053012192249298\n",
      "Policy Reward: tensor(1.1171, device='cuda:0')\n",
      "Trajectory:  ['0.44', '0.97', '0.68', '0.37', '0.26', '0.49', '0.91', '0.97', '0.99', '0.99', '0.99', '0.88', '0.64', '0.51', '0.34', '0.19', '0.17', '0.95', '0.99']\n",
      "Last Action:  tensor([0.9883, 0.9857, 0.8718, 0.6431, 0.4958, 0.8774, 0.9380, 0.4580, 0.3478,\n",
      "        0.8088], device='cuda:0')\n",
      "Loss: 0.36268192529678345 -0.23966693878173828\n",
      "Loss: 0.3145223557949066 -0.1418083906173706\n",
      "Loss: 0.3670288920402527 -0.36515527963638306\n",
      "Loss: 0.33438217639923096 -0.19582144916057587\n",
      "Loss: 0.4357891380786896 -0.5686630010604858\n",
      "Loss: 0.4373758137226105 -0.7950002551078796\n",
      "Loss: 0.331309050321579 -0.518276572227478\n",
      "Policy Reward: tensor(1.0736, device='cuda:0')\n",
      "Trajectory:  ['0.34', '0.64', '0.73', '0.15', '0.15', '0.54', '0.84', '0.98', '0.66', '0.37', '0.04', '0.00', '0.01', '0.87', '0.85', '0.25', '0.91', '0.71', '0.31']\n",
      "Last Action:  tensor([0.3090, 0.9384, 0.3592, 0.9923, 0.4637, 0.7707, 0.9318, 0.9081, 0.8545,\n",
      "        0.7863], device='cuda:0')\n",
      "Loss: 0.3853035867214203 -0.41426506638526917\n",
      "Loss: 0.3356965482234955 -0.27467888593673706\n",
      "Loss: 0.35381218791007996 -0.18771913647651672\n",
      "Loss: 0.381030797958374 -0.7927927374839783\n",
      "Loss: 0.38418272137641907 -0.6421910524368286\n",
      "Loss: 0.3799552023410797 -0.3632454574108124\n",
      "Loss: 0.35328277945518494 -0.5985062718391418\n",
      "Policy Reward: tensor(1.2198, device='cuda:0')\n",
      "Trajectory:  ['0.28', '1.00', '0.69', '0.30', '0.45', '0.65', '0.82', '0.97', '0.86', '0.64', '0.58', '0.42', '0.05', '0.01', '0.09', '0.91', '0.78', '0.38', '0.92']\n",
      "Last Action:  tensor([0.9228, 0.9983, 0.5168, 0.4528, 0.5437, 0.8840, 0.8224, 0.7074, 0.9744,\n",
      "        0.4347], device='cuda:0')\n",
      "Loss: 0.40212637186050415 -0.3409249186515808\n",
      "Loss: 0.486617773771286 -0.5652819871902466\n",
      "Loss: 0.3979547917842865 -0.7260837554931641\n",
      "Loss: 0.3592992424964905 -0.34508219361305237\n",
      "Loss: 0.4007960259914398 -0.8528430461883545\n",
      "Loss: 0.3480331301689148 -0.4189279079437256\n",
      "Loss: 0.38329485058784485 -0.7890123724937439\n",
      "Policy Reward: tensor(1.2994, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.60', '0.61', '0.60', '0.68', '0.82', '0.94', '0.84', '0.63', '0.58', '0.40', '0.03', '0.01', '0.22', '0.99', '0.44', '0.42', '0.94']\n",
      "Last Action:  tensor([0.9406, 0.9371, 0.9272, 0.9818, 0.9172, 0.5475, 0.6807, 0.3944, 0.6010,\n",
      "        0.9943], device='cuda:0')\n",
      "Loss: 0.37023451924324036 -0.3095579147338867\n",
      "Loss: 0.36057475209236145 -0.6078487038612366\n",
      "Loss: 0.34762656688690186 -0.48170405626296997\n",
      "Loss: 0.4404406249523163 -0.5675256848335266\n",
      "Loss: 0.30124956369400024 -0.5396424531936646\n",
      "Loss: 0.37772276997566223 -0.7244901061058044\n",
      "Loss: 0.4229835271835327 -0.6494836211204529\n",
      "Policy Reward: tensor(1.2000, device='cuda:0')\n",
      "Trajectory:  ['0.44', '1.00', '0.74', '0.10', '0.12', '0.31', '0.64', '0.92', '0.99', '0.72', '0.52', '0.51', '0.11', '0.01', '0.05', '0.97', '0.75', '0.32', '0.94']\n",
      "Last Action:  tensor([0.9438, 0.7313, 0.9716, 0.7951, 0.6147, 0.9199, 0.6159, 0.9529, 0.9252,\n",
      "        0.4334], device='cuda:0')\n",
      "Loss: 0.41352006793022156 -0.4701674282550812\n",
      "Loss: 0.4049686789512634 -0.7075687050819397\n",
      "Loss: 0.37206053733825684 -0.6013975143432617\n",
      "Loss: 0.37785813212394714 -0.7667881846427917\n",
      "Loss: 0.36643683910369873 -0.33609116077423096\n",
      "Loss: 0.4015992283821106 -0.6470934748649597\n",
      "Loss: 0.37263140082359314 -0.6666342616081238\n",
      "Policy Reward: tensor(1.1028, device='cuda:0')\n",
      "Trajectory:  ['0.35', '1.00', '0.84', '0.02', '0.07', '0.39', '0.78', '0.91', '0.90', '0.60', '0.56', '0.57', '0.36', '0.17', '0.34', '0.98', '0.41', '0.95', '0.55']\n",
      "Last Action:  tensor([0.5510, 0.5758, 0.7712, 0.9803, 0.9154, 0.4802, 0.6442, 0.5068, 0.9092,\n",
      "        0.3426], device='cuda:0')\n",
      "Loss: 0.36288464069366455 -0.45186418294906616\n",
      "Loss: 0.4432753622531891 -0.4435335695743561\n",
      "Loss: 0.45097893476486206 -0.9046879410743713\n",
      "Loss: 0.37352803349494934 -0.5836169123649597\n",
      "Loss: 0.352261483669281 -0.47204670310020447\n",
      "Loss: 0.3864174783229828 -0.6178596615791321\n",
      "Loss: 0.376548171043396 -0.6602290868759155\n",
      "Policy Reward: tensor(1.2223, device='cuda:0')\n",
      "Trajectory:  ['0.00', '0.96', '0.43', '0.41', '0.34', '0.57', '0.90', '0.97', '0.95', '0.80', '0.92', '0.86', '0.98', '0.97', '0.96', '0.98', '0.99', '0.98', '0.92']\n",
      "Last Action:  tensor([0.9210, 0.7798, 0.6983, 0.8706, 0.9705, 0.8479, 0.4747, 0.8220, 0.9995,\n",
      "        0.5193], device='cuda:0')\n",
      "Bigstep:  66\n",
      "Loss: 0.3949548900127411 0.05018173158168793\n",
      "Loss: 0.35253000259399414 0.32490354776382446\n",
      "Loss: 0.385116845369339 -0.046537112444639206\n",
      "Loss: 0.4433916509151459 -0.2468472272157669\n",
      "Loss: 0.29067742824554443 0.07947918772697449\n",
      "Loss: 0.34393805265426636 0.3210129141807556\n",
      "Loss: 0.34774836897850037 -0.43417295813560486\n",
      "Policy Reward: tensor(1.2004, device='cuda:0')\n",
      "Trajectory:  ['0.14', '1.00', '0.53', '0.24', '0.29', '0.38', '0.55', '0.70', '0.76', '0.50', '0.31', '0.22', '0.05', '0.02', '0.12', '0.76', '0.94', '0.49', '0.68']\n",
      "Last Action:  tensor([0.6828, 0.9069, 0.9990, 0.9977, 0.9296, 0.7374, 0.9744, 0.9706, 0.9878,\n",
      "        0.8034], device='cuda:0')\n",
      "Loss: 0.4103737771511078 -0.3006439507007599\n",
      "Loss: 0.34677854180336 -0.2462545782327652\n",
      "Loss: 0.40243521332740784 -0.2820487320423126\n",
      "Loss: 0.31586018204689026 -0.167866051197052\n",
      "Loss: 0.3334367871284485 0.2117878794670105\n",
      "Loss: 0.3258323669433594 0.05798851698637009\n",
      "Loss: 0.3744489848613739 -0.021647917106747627\n",
      "Policy Reward: tensor(1.0511, device='cuda:0')\n",
      "Trajectory:  ['0.40', '1.00', '0.72', '0.01', '0.26', '0.65', '0.79', '0.79', '0.57', '0.32', '0.29', '0.20', '0.16', '0.21', '0.75', '0.93', '0.74', '0.94', '0.86']\n",
      "Last Action:  tensor([0.8608, 0.9033, 0.8026, 0.9723, 0.8241, 0.8177, 0.9616, 0.6782, 0.8746,\n",
      "        0.8392], device='cuda:0')\n",
      "Loss: 0.3786369562149048 -0.5576986074447632\n",
      "Loss: 0.384431391954422 -0.22373837232589722\n",
      "Loss: 0.40056055784225464 -0.30880677700042725\n",
      "Loss: 0.41059449315071106 0.03821315988898277\n",
      "Loss: 0.3753485679626465 -0.2999741733074188\n",
      "Loss: 0.3021848499774933 0.012117315083742142\n",
      "Loss: 0.3856513202190399 -0.18789835274219513\n",
      "Policy Reward: tensor(1.2279, device='cuda:0')\n",
      "Trajectory:  ['0.38', '1.00', '0.64', '0.05', '0.21', '0.82', '0.96', '0.96', '0.95', '0.66', '0.42', '0.32', '0.08', '0.01', '0.01', '0.02', '0.06', '0.19', '0.80']\n",
      "Last Action:  tensor([0.7975, 0.9993, 0.8655, 0.4055, 0.7755, 0.9956, 0.8922, 0.6422, 0.9638,\n",
      "        0.6748], device='cuda:0')\n",
      "Loss: 0.343378484249115 -0.37389305233955383\n",
      "Loss: 0.4616466462612152 -0.5014316439628601\n",
      "Loss: 0.3948899507522583 -0.2758992910385132\n",
      "Loss: 0.3071574568748474 0.057672783732414246\n",
      "Loss: 0.38982996344566345 -0.18181854486465454\n",
      "Loss: 0.4789213240146637 -0.4296189546585083\n",
      "Loss: 0.3077958822250366 -0.1152515783905983\n",
      "Policy Reward: tensor(1.1294, device='cuda:0')\n",
      "Trajectory:  ['0.36', '0.68', '0.79', '0.14', '0.24', '0.60', '0.82', '0.79', '0.46', '0.31', '0.14', '0.03', '0.01', '0.62', '0.99', '0.51', '0.73', '0.79', '0.48']\n",
      "Last Action:  tensor([0.4823, 0.2592, 0.5700, 0.6683, 0.9804, 0.4035, 0.9148, 0.2478, 0.5000,\n",
      "        0.5516], device='cuda:0')\n",
      "Loss: 0.3398878872394562 -0.22540119290351868\n",
      "Loss: 0.3384703993797302 0.0019883885979652405\n",
      "Loss: 0.41759681701660156 -0.3642025887966156\n",
      "Loss: 0.417495995759964 -0.3576095700263977\n",
      "Loss: 0.3518977463245392 -0.2189674973487854\n",
      "Loss: 0.3005078434944153 -0.07657252252101898\n",
      "Loss: 0.40390098094940186 -0.471815824508667\n",
      "Policy Reward: tensor(1.1384, device='cuda:0')\n",
      "Trajectory:  ['0.37', '1.00', '0.74', '0.02', '0.18', '0.57', '0.76', '0.79', '0.57', '0.31', '0.32', '0.17', '0.10', '0.16', '0.85', '0.86', '0.73', '0.90', '0.94']\n",
      "Last Action:  tensor([0.9387, 0.6363, 0.9654, 0.6005, 0.7258, 0.9300, 0.7937, 0.9340, 0.6753,\n",
      "        0.1040], device='cuda:0')\n",
      "Loss: 0.39443841576576233 -0.24942843616008759\n",
      "Loss: 0.3585870563983917 -0.09519065171480179\n",
      "Loss: 0.3914668560028076 -0.3918042778968811\n",
      "Loss: 0.31528526544570923 0.1504245102405548\n",
      "Loss: 0.3979574143886566 -0.31230613589286804\n",
      "Loss: 0.38489383459091187 -0.31580740213394165\n",
      "Loss: 0.41776150465011597 -0.24193066358566284\n",
      "Policy Reward: tensor(1.2003, device='cuda:0')\n",
      "Trajectory:  ['0.36', '1.00', '0.69', '0.02', '0.14', '0.52', '0.73', '0.82', '0.66', '0.32', '0.33', '0.13', '0.03', '0.06', '0.67', '0.94', '0.57', '0.93', '0.94']\n",
      "Last Action:  tensor([0.9436, 0.4467, 0.7589, 0.5591, 0.6316, 0.8390, 0.2869, 0.6741, 0.9242,\n",
      "        0.5245], device='cuda:0')\n",
      "Loss: 0.3494904935359955 -0.06863327324390411\n",
      "Loss: 0.3452804684638977 -0.0912582129240036\n",
      "Loss: 0.36822059750556946 -0.2829466164112091\n",
      "Loss: 0.3514667749404907 -0.17059612274169922\n",
      "Loss: 0.4173591732978821 -0.18967314064502716\n",
      "Loss: 0.4092257022857666 0.10551484674215317\n",
      "Loss: 0.38249990344047546 -0.19985833764076233\n",
      "Policy Reward: tensor(1.1910, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.50', '0.72', '0.78', '0.66', '0.59', '0.52', '0.39', '0.33', '0.36', '0.37', '0.30', '0.44', '0.95', '0.65', '0.93', '0.86', '0.77']\n",
      "Last Action:  tensor([0.7702, 0.6206, 0.1222, 0.8811, 0.9799, 0.9373, 0.6974, 0.9532, 0.9270,\n",
      "        0.9598], device='cuda:0')\n",
      "Loss: 0.30178630352020264 -0.18297609686851501\n",
      "Loss: 0.34951749444007874 0.053165629506111145\n",
      "Loss: 0.32520535588264465 0.035655196756124496\n",
      "Loss: 0.2883644700050354 -0.2833161950111389\n",
      "Loss: 0.38951539993286133 -0.1494930237531662\n",
      "Loss: 0.364138126373291 -0.3081788122653961\n",
      "Loss: 0.4216351807117462 -0.4804379940032959\n",
      "Policy Reward: tensor(1.2058, device='cuda:0')\n",
      "Trajectory:  ['0.37', '1.00', '0.62', '0.04', '0.33', '0.43', '0.71', '0.71', '0.58', '0.33', '0.30', '0.20', '0.03', '0.03', '0.87', '0.62', '0.51', '0.97', '0.43']\n",
      "Last Action:  tensor([0.4268, 0.8940, 0.5217, 0.8948, 0.7855, 0.9936, 0.8860, 0.7960, 0.4287,\n",
      "        0.8487], device='cuda:0')\n",
      "Bigstep:  67\n",
      "Loss: 0.4025737941265106 0.006035305559635162\n",
      "Loss: 0.3806202709674835 -0.21213147044181824\n",
      "Loss: 0.3904854357242584 0.051019709557294846\n",
      "Loss: 0.3298777937889099 0.11162972450256348\n",
      "Loss: 0.3051254451274872 -0.057738255709409714\n",
      "Loss: 0.3915046751499176 -0.12013229727745056\n",
      "Loss: 0.38512587547302246 -0.18604731559753418\n",
      "Policy Reward: tensor(1.0998, device='cuda:0')\n",
      "Trajectory:  ['0.58', '0.90', '0.89', '0.27', '0.32', '0.28', '0.41', '0.40', '0.29', '0.06', '0.02', '0.01', '0.00', '0.01', '0.34', '0.97', '0.46', '0.71', '0.79']\n",
      "Last Action:  tensor([0.7898, 0.0260, 0.9046, 0.5737, 0.5205, 0.4168, 0.9806, 0.8996, 0.2290,\n",
      "        0.6817], device='cuda:0')\n",
      "Loss: 0.3914283514022827 0.021615423262119293\n",
      "Loss: 0.3283616304397583 -0.16944245994091034\n",
      "Loss: 0.2871951758861542 -0.1349358707666397\n",
      "Loss: 0.3725222647190094 -0.357749342918396\n",
      "Loss: 0.3671010732650757 -0.5097299218177795\n",
      "Loss: 0.3372264802455902 -0.0392235592007637\n",
      "Loss: 0.3937993049621582 -0.31595170497894287\n",
      "Policy Reward: tensor(1.2325, device='cuda:0')\n",
      "Trajectory:  ['0.70', '1.00', '0.77', '0.14', '0.44', '0.32', '0.51', '0.52', '0.34', '0.09', '0.02', '0.01', '0.00', '0.00', '0.05', '0.82', '0.53', '0.46', '0.94']\n",
      "Last Action:  tensor([0.9374, 0.2820, 0.1000, 0.0303, 0.5442, 0.4230, 0.6365, 0.6525, 0.8251,\n",
      "        0.4019], device='cuda:0')\n",
      "Loss: 0.3008476793766022 0.03711981326341629\n",
      "Loss: 0.37708383798599243 -0.28355672955513\n",
      "Loss: 0.38945716619491577 -0.4424346387386322\n",
      "Loss: 0.3484870195388794 -0.4660682678222656\n",
      "Loss: 0.31581777334213257 -0.06154777109622955\n",
      "Loss: 0.3040779232978821 -0.3243432939052582\n",
      "Loss: 0.37179937958717346 -0.4490991234779358\n",
      "Policy Reward: tensor(1.0787, device='cuda:0')\n",
      "Trajectory:  ['0.66', '1.00', '0.80', '0.25', '0.69', '0.42', '0.66', '0.71', '0.50', '0.20', '0.09', '0.03', '0.02', '0.13', '0.97', '0.80', '0.83', '0.99', '1.00']\n",
      "Last Action:  tensor([0.9964, 0.9725, 0.9803, 0.8055, 0.5042, 0.6402, 0.7559, 0.6450, 0.6701,\n",
      "        0.1292], device='cuda:0')\n",
      "Loss: 0.3020678758621216 0.11849610507488251\n",
      "Loss: 0.4066745340824127 -0.48972639441490173\n",
      "Loss: 0.4044840931892395 -0.3086997866630554\n",
      "Loss: 0.40260857343673706 -0.34837228059768677\n",
      "Loss: 0.44015124440193176 -0.7549293637275696\n",
      "Loss: 0.3269025981426239 0.07209767401218414\n",
      "Loss: 0.4242457449436188 -0.6581636667251587\n",
      "Policy Reward: tensor(1.1990, device='cuda:0')\n",
      "Trajectory:  ['0.36', '1.00', '0.74', '0.01', '0.26', '0.39', '0.35', '0.34', '0.31', '0.09', '0.02', '0.01', '0.01', '0.04', '0.71', '0.61', '0.53', '0.95', '0.51']\n",
      "Last Action:  tensor([0.5102, 0.1384, 0.8919, 0.9306, 0.6648, 0.9514, 0.9897, 0.7900, 0.3255,\n",
      "        0.5025], device='cuda:0')\n",
      "Loss: 0.37967538833618164 -0.5121700167655945\n",
      "Loss: 0.3609866201877594 -0.19427010416984558\n",
      "Loss: 0.29377368092536926 -0.29983648657798767\n",
      "Loss: 0.3981963098049164 -0.2325427085161209\n",
      "Loss: 0.41412052512168884 -0.2010001242160797\n",
      "Loss: 0.4089832901954651 -0.624224841594696\n",
      "Loss: 0.3766687214374542 -0.3363483250141144\n",
      "Policy Reward: tensor(1.1291, device='cuda:0')\n",
      "Trajectory:  ['0.64', '1.00', '0.75', '0.06', '0.28', '0.29', '0.39', '0.29', '0.20', '0.07', '0.03', '0.01', '0.01', '0.01', '0.02', '0.66', '0.90', '0.42', '0.98']\n",
      "Last Action:  tensor([0.9779, 0.6782, 0.5836, 0.1064, 0.6713, 0.8329, 0.9846, 0.9785, 0.9462,\n",
      "        0.9418], device='cuda:0')\n",
      "Loss: 0.4081704318523407 -0.5075328350067139\n",
      "Loss: 0.3895808160305023 -0.10063379257917404\n",
      "Loss: 0.43614962697029114 -0.47766175866127014\n",
      "Loss: 0.4706374704837799 -0.541821300983429\n",
      "Loss: 0.3440399765968323 -0.2968170940876007\n",
      "Loss: 0.35927021503448486 -0.22485937178134918\n",
      "Loss: 0.3877813220024109 -0.6560735702514648\n",
      "Policy Reward: tensor(1.1787, device='cuda:0')\n",
      "Trajectory:  ['0.69', '0.97', '0.60', '0.85', '0.41', '0.70', '0.56', '0.73', '0.65', '0.49', '0.25', '0.18', '0.09', '0.04', '0.03', '0.43', '0.99', '0.83', '0.66']\n",
      "Last Action:  tensor([0.6552, 0.4087, 0.6247, 0.9664, 0.4456, 0.3470, 0.4555, 0.9571, 0.8076,\n",
      "        0.8830], device='cuda:0')\n",
      "Loss: 0.40129390358924866 -0.593226969242096\n",
      "Loss: 0.34759506583213806 -0.4295181632041931\n",
      "Loss: 0.37131524085998535 -0.19125448167324066\n",
      "Loss: 0.28676533699035645 -0.07540355622768402\n",
      "Loss: 0.43203645944595337 -0.5596193671226501\n",
      "Loss: 0.3860892653465271 -0.29279935359954834\n",
      "Loss: 0.3845241963863373 -0.4650242328643799\n",
      "Policy Reward: tensor(1.2370, device='cuda:0')\n",
      "Trajectory:  ['0.68', '1.00', '0.83', '0.38', '0.33', '0.61', '0.65', '0.75', '0.65', '0.53', '0.23', '0.06', '0.01', '0.01', '0.05', '0.87', '0.81', '0.67', '0.80']\n",
      "Last Action:  tensor([0.8035, 0.4868, 0.6396, 0.8731, 0.8715, 0.5310, 0.0118, 0.5518, 0.8734,\n",
      "        0.8567], device='cuda:0')\n",
      "Loss: 0.31442826986312866 -0.28124815225601196\n",
      "Loss: 0.3112281262874603 -0.5002160668373108\n",
      "Loss: 0.4273870289325714 -0.51287442445755\n",
      "Loss: 0.3740141987800598 -0.6271001100540161\n",
      "Loss: 0.40017738938331604 -0.45956510305404663\n",
      "Loss: 0.3417075574398041 -0.3261965811252594\n",
      "Loss: 0.37910354137420654 -0.4006831645965576\n",
      "Policy Reward: tensor(1.2014, device='cuda:0')\n",
      "Trajectory:  ['0.67', '1.00', '0.74', '0.02', '0.26', '0.27', '0.53', '0.46', '0.33', '0.14', '0.04', '0.01', '0.01', '0.01', '0.04', '0.67', '0.47', '0.69', '0.31']\n",
      "Last Action:  tensor([0.3128, 0.7864, 0.0204, 0.9164, 0.7555, 0.8046, 0.4011, 0.4106, 0.9337,\n",
      "        0.9747], device='cuda:0')\n",
      "Bigstep:  68\n",
      "Loss: 0.5788487792015076 -0.4677141010761261\n",
      "Loss: 0.40192970633506775 0.055262282490730286\n",
      "Loss: 0.3663308620452881 -0.5544896125793457\n",
      "Loss: 0.4609359800815582 -0.5981180667877197\n",
      "Loss: 0.4364537000656128 -0.8266100883483887\n",
      "Loss: 0.4016427993774414 -0.5752146244049072\n",
      "Loss: 0.42406293749809265 -0.9075202345848083\n",
      "Policy Reward: tensor(1.1860, device='cuda:0')\n",
      "Trajectory:  ['0.20', '1.00', '0.50', '0.02', '0.20', '0.21', '0.23', '0.21', '0.21', '0.16', '0.07', '0.03', '0.01', '0.01', '0.02', '0.64', '0.30', '0.49', '0.43']\n",
      "Last Action:  tensor([0.4338, 0.1428, 0.2434, 0.2050, 0.5826, 0.5615, 0.6679, 0.8515, 0.4983,\n",
      "        0.6584], device='cuda:0')\n",
      "Loss: 0.42664775252342224 -0.8167393803596497\n",
      "Loss: 0.4235822856426239 -1.0644958019256592\n",
      "Loss: 0.4665578305721283 -0.5774878859519958\n",
      "Loss: 0.410604327917099 -0.7073529362678528\n",
      "Loss: 0.3965235650539398 -0.6641753911972046\n",
      "Loss: 0.39892709255218506 -0.6400761008262634\n",
      "Loss: 0.4324594736099243 -0.6571690440177917\n",
      "Policy Reward: tensor(1.1490, device='cuda:0')\n",
      "Trajectory:  ['0.68', '0.36', '0.44', '0.53', '0.38', '0.64', '0.61', '0.73', '0.92', '0.96', '0.75', '0.45', '0.47', '0.66', '0.87', '0.96', '0.70', '0.57', '0.86']\n",
      "Last Action:  tensor([0.8600, 0.7791, 0.6055, 0.3776, 0.8338, 0.0710, 0.4794, 0.2243, 0.8060,\n",
      "        0.4215], device='cuda:0')\n",
      "Loss: 0.392841637134552 -0.8001257181167603\n",
      "Loss: 0.43510812520980835 -0.9071321487426758\n",
      "Loss: 0.38133105635643005 -0.6192473769187927\n",
      "Loss: 0.4224969744682312 -0.4506744146347046\n",
      "Loss: 0.4416019320487976 -0.840418815612793\n",
      "Loss: 0.39851880073547363 -0.5158842206001282\n",
      "Loss: 0.41578078269958496 -0.4423004686832428\n",
      "Policy Reward: tensor(1.1923, device='cuda:0')\n",
      "Trajectory:  ['0.12', '1.00', '0.76', '0.14', '0.37', '0.22', '0.09', '0.05', '0.03', '0.02', '0.01', '0.01', '0.01', '0.02', '0.14', '0.70', '0.51', '0.57', '0.89']\n",
      "Last Action:  tensor([0.8852, 0.6759, 0.4568, 0.9359, 0.3638, 0.5617, 0.8580, 0.1005, 0.7014,\n",
      "        0.1909], device='cuda:0')\n",
      "Loss: 0.45794785022735596 -0.8945169448852539\n",
      "Loss: 0.3718391954898834 -0.4517933428287506\n",
      "Loss: 0.45931246876716614 -0.9162991046905518\n",
      "Loss: 0.3493645489215851 -0.5587661862373352\n",
      "Loss: 0.4301449656486511 -0.7411545515060425\n",
      "Loss: 0.37128400802612305 -0.7639439702033997\n",
      "Loss: 0.4180671274662018 -1.066627025604248\n",
      "Policy Reward: tensor(1.1772, device='cuda:0')\n",
      "Trajectory:  ['0.12', '1.00', '0.84', '0.05', '0.19', '0.22', '0.12', '0.06', '0.04', '0.03', '0.02', '0.01', '0.01', '0.01', '0.03', '0.35', '0.71', '0.42', '0.28']\n",
      "Last Action:  tensor([0.2783, 0.5854, 0.3492, 0.5050, 0.5486, 0.9388, 0.1337, 0.3383, 0.5178,\n",
      "        0.6681], device='cuda:0')\n",
      "Loss: 0.48050734400749207 -0.6851672530174255\n",
      "Loss: 0.36709949374198914 -0.7046545743942261\n",
      "Loss: 0.4765544533729553 -1.1986057758331299\n",
      "Loss: 0.4154021143913269 -0.5130007863044739\n",
      "Loss: 0.34049710631370544 -0.6090686321258545\n",
      "Loss: 0.39623144268989563 -0.8144976496696472\n",
      "Loss: 0.44882720708847046 -1.1469913721084595\n",
      "Policy Reward: tensor(1.1916, device='cuda:0')\n",
      "Trajectory:  ['0.50', '1.00', '0.63', '0.02', '0.28', '0.26', '0.20', '0.11', '0.06', '0.03', '0.02', '0.01', '0.01', '0.01', '0.03', '0.50', '0.76', '0.34', '0.79']\n",
      "Last Action:  tensor([0.7862, 0.3615, 0.1703, 0.9356, 0.4216, 0.0437, 0.4597, 0.0475, 0.9475,\n",
      "        0.2509], device='cuda:0')\n",
      "Loss: 0.39127668738365173 -0.5159181952476501\n",
      "Loss: 0.38851431012153625 -0.9655312895774841\n",
      "Loss: 0.3998320698738098 -0.7780628204345703\n",
      "Loss: 0.3655585050582886 -0.5328661203384399\n",
      "Loss: 0.33996278047561646 -0.3888189196586609\n",
      "Loss: 0.479749470949173 -0.8362813591957092\n",
      "Loss: 0.3780674636363983 -1.0295482873916626\n",
      "Policy Reward: tensor(1.2697, device='cuda:0')\n",
      "Trajectory:  ['0.35', '1.00', '0.44', '0.01', '0.32', '0.16', '0.21', '0.11', '0.02', '0.01', '0.00', '0.00', '0.00', '0.00', '0.01', '0.08', '0.29', '0.55', '0.34']\n",
      "Last Action:  tensor([0.3358, 0.7473, 0.2737, 0.9545, 0.4237, 0.1638, 0.1457, 0.8420, 0.8576,\n",
      "        0.6593], device='cuda:0')\n",
      "Loss: 0.4676317274570465 -1.0084835290908813\n",
      "Loss: 0.4438750743865967 -0.9253960847854614\n",
      "Loss: 0.35211846232414246 -0.4680558145046234\n",
      "Loss: 0.40376439690589905 -0.6787798404693604\n",
      "Loss: 0.391225129365921 -0.552692711353302\n",
      "Loss: 0.4248022437095642 -0.7773800492286682\n",
      "Loss: 0.4485858976840973 -0.7061401009559631\n",
      "Policy Reward: tensor(1.0984, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.42', '0.48', '0.39', '0.33', '0.18', '0.12', '0.06', '0.04', '0.03', '0.02', '0.01', '0.01', '0.02', '0.09', '0.30', '0.61', '0.44']\n",
      "Last Action:  tensor([0.4431, 0.7542, 0.4484, 0.3917, 0.3097, 0.8371, 0.7960, 0.2146, 0.9249,\n",
      "        0.2317], device='cuda:0')\n",
      "Loss: 0.41256183385849 -0.6320902705192566\n",
      "Loss: 0.44525429606437683 -1.2044072151184082\n",
      "Loss: 0.37664034962654114 -0.7256969809532166\n",
      "Loss: 0.3866141438484192 -0.7864850163459778\n",
      "Loss: 0.41784828901290894 -1.0550034046173096\n",
      "Loss: 0.39769622683525085 -0.889055609703064\n",
      "Loss: 0.4202868938446045 -0.9572094678878784\n",
      "Policy Reward: tensor(1.1888, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.33', '0.53', '0.34', '0.28', '0.12', '0.05', '0.02', '0.01', '0.01', '0.01', '0.01', '0.01', '0.03', '0.12', '0.51', '0.51', '0.68']\n",
      "Last Action:  tensor([0.6835, 0.0930, 0.8905, 0.1590, 0.8983, 0.0998, 0.1086, 0.3376, 0.6218,\n",
      "        0.3116], device='cuda:0')\n",
      "Bigstep:  69\n",
      "Loss: 0.33971473574638367 -0.341353178024292\n",
      "Loss: 0.40652167797088623 -0.7114642262458801\n",
      "Loss: 0.45172497630119324 -0.938971757888794\n",
      "Loss: 0.28710877895355225 -0.4729383587837219\n",
      "Loss: 0.3471565842628479 -0.6910257935523987\n",
      "Loss: 0.37918752431869507 -1.1410925388336182\n",
      "Loss: 0.4204082190990448 -0.8649688363075256\n",
      "Policy Reward: tensor(1.0343, device='cuda:0')\n",
      "Trajectory:  ['0.56', '0.42', '0.82', '0.29', '0.03', '0.05', '0.11', '0.19', '0.34', '0.30', '0.14', '0.13', '0.18', '0.30', '0.36', '0.23', '0.10', '0.15', '0.21']\n",
      "Last Action:  tensor([0.2139, 0.4705, 0.4409, 0.2290, 0.1325, 0.3081, 0.3171, 0.4479, 0.6049,\n",
      "        0.4658], device='cuda:0')\n",
      "Loss: 0.3756937086582184 -0.6531331539154053\n",
      "Loss: 0.3471750319004059 -0.48983895778656006\n",
      "Loss: 0.35480648279190063 -0.6177126169204712\n",
      "Loss: 0.37865546345710754 -0.749544084072113\n",
      "Loss: 0.39660030603408813 -0.6407535672187805\n",
      "Loss: 0.3613334000110626 -0.9638165235519409\n",
      "Loss: 0.41581541299819946 -0.7062546610832214\n",
      "Policy Reward: tensor(1.1009, device='cuda:0')\n",
      "Trajectory:  ['0.40', '1.00', '0.62', '0.02', '0.09', '0.02', '0.02', '0.01', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.02', '0.14', '0.57', '0.48', '0.44']\n",
      "Last Action:  tensor([0.4431, 0.5788, 0.5368, 0.7324, 0.4475, 0.3428, 0.5043, 0.3900, 0.2093,\n",
      "        0.4054], device='cuda:0')\n",
      "Loss: 0.38388851284980774 -0.6567150354385376\n",
      "Loss: 0.36995139718055725 -0.657335638999939\n",
      "Loss: 0.33111968636512756 -0.7718406319618225\n",
      "Loss: 0.36782798171043396 -0.8458424210548401\n",
      "Loss: 0.36031386256217957 -0.7770540714263916\n",
      "Loss: 0.392075777053833 -1.0982677936553955\n",
      "Loss: 0.3267655074596405 -0.8180151581764221\n",
      "Policy Reward: tensor(1.1788, device='cuda:0')\n",
      "Trajectory:  ['0.57', '1.00', '0.69', '0.05', '0.09', '0.03', '0.02', '0.01', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.04', '0.46', '0.57', '0.50', '0.74']\n",
      "Last Action:  tensor([0.7415, 0.9883, 0.4872, 0.6263, 0.5532, 0.4500, 0.7374, 0.5060, 0.6640,\n",
      "        0.7689], device='cuda:0')\n",
      "Loss: 0.4173150956630707 -0.7787675261497498\n",
      "Loss: 0.4045010209083557 -1.0050376653671265\n",
      "Loss: 0.365433931350708 -0.8774759769439697\n",
      "Loss: 0.45441070199012756 -0.9164375066757202\n",
      "Loss: 0.3169042766094208 -1.0540310144424438\n",
      "Loss: 0.3680357038974762 -0.6618070006370544\n",
      "Loss: 0.3376428484916687 -0.8083357810974121\n",
      "Policy Reward: tensor(1.0176, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.59', '0.06', '0.02', '0.01', '0.01', '0.00', '0.00', '0.01', '0.01', '0.00', '0.01', '0.01', '0.09', '0.66', '0.42', '0.42', '0.57']\n",
      "Last Action:  tensor([0.5695, 0.6921, 0.8617, 0.5022, 0.4834, 0.6465, 0.8280, 0.3055, 0.5065,\n",
      "        0.4921], device='cuda:0')\n",
      "Loss: 0.3464716672897339 -1.0471805334091187\n",
      "Loss: 0.40341541171073914 -0.933940589427948\n",
      "Loss: 0.3938198983669281 -0.942801833152771\n",
      "Loss: 0.42993420362472534 -0.8220943212509155\n",
      "Loss: 0.3876905143260956 -1.0362359285354614\n",
      "Loss: 0.33697131276130676 -0.580990731716156\n",
      "Loss: 0.43445536494255066 -1.1022288799285889\n",
      "Policy Reward: tensor(1.1021, device='cuda:0')\n",
      "Trajectory:  ['0.47', '1.00', '0.62', '0.17', '0.08', '0.04', '0.03', '0.02', '0.02', '0.02', '0.02', '0.02', '0.01', '0.02', '0.05', '0.34', '0.65', '0.57', '0.47']\n",
      "Last Action:  tensor([0.4746, 0.8751, 0.6974, 0.5188, 0.9116, 0.3372, 0.7244, 0.4725, 0.5039,\n",
      "        0.4985], device='cuda:0')\n",
      "Loss: 0.37196239829063416 -0.7593052983283997\n",
      "Loss: 0.4343129098415375 -1.371859073638916\n",
      "Loss: 0.3293241262435913 -0.8112276792526245\n",
      "Loss: 0.4327288568019867 -1.1468795537948608\n",
      "Loss: 0.38029181957244873 -1.0885858535766602\n",
      "Loss: 0.35161980986595154 -0.9033872485160828\n",
      "Loss: 0.349774032831192 -0.868545413017273\n",
      "Policy Reward: tensor(1.1296, device='cuda:0')\n",
      "Trajectory:  ['0.40', '1.00', '0.57', '0.02', '0.06', '0.12', '0.10', '0.09', '0.11', '0.14', '0.13', '0.11', '0.10', '0.12', '0.09', '0.13', '0.81', '0.97', '0.45']\n",
      "Last Action:  tensor([0.4535, 0.1547, 0.3476, 0.6261, 0.5343, 0.8152, 0.8428, 0.3360, 0.8671,\n",
      "        0.4760], device='cuda:0')\n",
      "Loss: 0.34916922450065613 -0.7060556411743164\n",
      "Loss: 0.3073458969593048 -0.4707055985927582\n",
      "Loss: 0.389589786529541 -1.0925569534301758\n",
      "Loss: 0.32802125811576843 -0.8136545419692993\n",
      "Loss: 0.36512207984924316 -1.0508843660354614\n",
      "Loss: 0.3446158468723297 -0.7127854228019714\n",
      "Loss: 0.3094472587108612 -0.7739894390106201\n",
      "Policy Reward: tensor(1.2367, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.44', '0.24', '0.04', '0.01', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.01', '0.01', '0.02', '0.03', '0.04', '0.07']\n",
      "Last Action:  tensor([0.0691, 0.8304, 0.3260, 0.8140, 0.6077, 0.3774, 0.8458, 0.9712, 0.4335,\n",
      "        0.3410], device='cuda:0')\n",
      "Loss: 0.3554528057575226 -0.9934840798377991\n",
      "Loss: 0.410543292760849 -0.9661335945129395\n",
      "Loss: 0.31148889660835266 -0.9490312337875366\n",
      "Loss: 0.40635180473327637 -0.963745653629303\n",
      "Loss: 0.4007568061351776 -1.2295273542404175\n",
      "Loss: 0.3891465663909912 -1.074453592300415\n",
      "Loss: 0.41000309586524963 -0.9641031622886658\n",
      "Policy Reward: tensor(1.0802, device='cuda:0')\n",
      "Trajectory:  ['0.56', '1.00', '0.64', '0.04', '0.04', '0.01', '0.01', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.01', '0.13', '0.84', '0.50', '0.53', '0.67']\n",
      "Last Action:  tensor([0.6659, 0.4575, 0.5507, 0.5411, 0.2625, 0.5515, 0.4178, 0.5856, 0.2383,\n",
      "        0.7694], device='cuda:0')\n",
      "Bigstep:  70\n",
      "Loss: 0.4147515296936035 -0.2866934835910797\n",
      "Loss: 0.3800273835659027 -0.1404983252286911\n",
      "Loss: 0.4258940517902374 0.0643032118678093\n",
      "Loss: 0.3494000732898712 0.12434325367212296\n",
      "Loss: 0.38215139508247375 -0.18897411227226257\n",
      "Loss: 0.347378671169281 -0.2791236639022827\n",
      "Loss: 0.3781857490539551 -0.3795464336872101\n",
      "Policy Reward: tensor(1.0673, device='cuda:0')\n",
      "Trajectory:  ['0.06', '1.00', '0.81', '0.14', '0.24', '0.05', '0.01', '0.01', '0.00', '0.01', '0.00', '0.00', '0.00', '0.01', '0.14', '0.72', '0.55', '0.43', '0.80']\n",
      "Last Action:  tensor([0.7984, 0.9068, 0.9349, 0.6790, 0.4308, 0.7059, 0.9476, 0.4061, 0.4212,\n",
      "        0.2429], device='cuda:0')\n",
      "Loss: 0.36111879348754883 -0.5094596147537231\n",
      "Loss: 0.366911917924881 -0.248648539185524\n",
      "Loss: 0.38679298758506775 -0.41581082344055176\n",
      "Loss: 0.3319905698299408 -0.16746601462364197\n",
      "Loss: 0.4167576730251312 -0.448519229888916\n",
      "Loss: 0.3823799788951874 -0.35500720143318176\n",
      "Loss: 0.4084611237049103 -0.49839043617248535\n",
      "Policy Reward: tensor(1.1917, device='cuda:0')\n",
      "Trajectory:  ['0.41', '1.00', '0.66', '0.18', '0.70', '0.61', '0.66', '0.54', '0.45', '0.36', '0.16', '0.02', '0.00', '0.00', '0.13', '0.92', '0.43', '0.67', '0.76']\n",
      "Last Action:  tensor([0.7613, 0.7855, 0.7255, 0.7129, 0.4555, 0.8045, 0.4514, 0.8597, 0.6829,\n",
      "        0.8141], device='cuda:0')\n",
      "Loss: 0.3308617174625397 -0.4334266781806946\n",
      "Loss: 0.36547645926475525 -0.6316457390785217\n",
      "Loss: 0.3268927037715912 -0.47671762108802795\n",
      "Loss: 0.34916451573371887 -0.49265673756599426\n",
      "Loss: 0.3918205797672272 -0.57382732629776\n",
      "Loss: 0.41404759883880615 -0.44594842195510864\n",
      "Loss: 0.3333950936794281 -0.39932167530059814\n",
      "Policy Reward: tensor(1.1514, device='cuda:0')\n",
      "Trajectory:  ['0.02', '1.00', '0.87', '0.49', '0.72', '0.67', '0.50', '0.37', '0.18', '0.06', '0.06', '0.04', '0.02', '0.04', '0.70', '0.96', '0.86', '0.79', '0.79']\n",
      "Last Action:  tensor([0.7938, 0.9705, 0.6986, 0.8202, 0.7917, 0.5412, 0.5126, 0.7213, 0.9943,\n",
      "        0.7042], device='cuda:0')\n",
      "Loss: 0.3428252041339874 -0.39213985204696655\n",
      "Loss: 0.4075738489627838 -0.5612915754318237\n",
      "Loss: 0.33710500597953796 -0.7604998350143433\n",
      "Loss: 0.3935404419898987 -0.6316321492195129\n",
      "Loss: 0.40157440304756165 -0.4926278293132782\n",
      "Loss: 0.4089227020740509 -0.6554632186889648\n",
      "Loss: 0.431274950504303 -0.7559914588928223\n",
      "Policy Reward: tensor(1.1846, device='cuda:0')\n",
      "Trajectory:  ['0.45', '1.00', '0.61', '0.56', '0.73', '0.69', '0.83', '0.75', '0.50', '0.26', '0.07', '0.02', '0.01', '0.01', '0.17', '0.98', '0.97', '0.41', '0.27']\n",
      "Last Action:  tensor([0.2701, 0.9928, 0.8244, 0.4056, 0.8528, 0.1431, 0.4794, 0.9706, 0.8194,\n",
      "        0.9897], device='cuda:0')\n",
      "Loss: 0.4058098793029785 -0.5549299120903015\n",
      "Loss: 0.31632012128829956 -0.2201157510280609\n",
      "Loss: 0.3633688986301422 -0.7404050827026367\n",
      "Loss: 0.405039519071579 -0.6367775797843933\n",
      "Loss: 0.40700143575668335 -0.6635903120040894\n",
      "Loss: 0.4054112434387207 -0.9274724125862122\n",
      "Loss: 0.3472006916999817 -0.6875381469726562\n",
      "Policy Reward: tensor(1.1436, device='cuda:0')\n",
      "Trajectory:  ['0.27', '0.78', '0.56', '0.54', '0.78', '0.62', '0.62', '0.42', '0.20', '0.10', '0.00', '0.00', '0.09', '0.94', '0.68', '0.49', '0.98', '0.55', '0.49']\n",
      "Last Action:  tensor([0.4949, 0.5798, 0.9543, 0.2411, 0.8183, 0.8227, 0.9940, 0.8093, 0.3090,\n",
      "        0.6238], device='cuda:0')\n",
      "Loss: 0.36773955821990967 -0.8274599313735962\n",
      "Loss: 0.30363336205482483 -0.3047531545162201\n",
      "Loss: 0.38054415583610535 -0.3210374116897583\n",
      "Loss: 0.28958722949028015 -0.6402183175086975\n",
      "Loss: 0.3685314953327179 -0.7731208801269531\n",
      "Loss: 0.38374894857406616 -0.5157829523086548\n",
      "Loss: 0.4344223737716675 -0.7402229309082031\n",
      "Policy Reward: tensor(1.1602, device='cuda:0')\n",
      "Trajectory:  ['0.19', '1.00', '0.82', '0.09', '0.90', '0.74', '0.70', '0.43', '0.17', '0.04', '0.01', '0.01', '0.02', '0.20', '0.70', '0.45', '0.64', '0.57', '0.44']\n",
      "Last Action:  tensor([0.4400, 0.9182, 0.8416, 0.9368, 0.4643, 0.9598, 0.2558, 0.6405, 0.6142,\n",
      "        0.5722], device='cuda:0')\n",
      "Loss: 0.35730254650115967 -0.7778527140617371\n",
      "Loss: 0.3943524658679962 -0.8038792014122009\n",
      "Loss: 0.38449203968048096 -0.5332290530204773\n",
      "Loss: 0.3562401831150055 -0.7355878353118896\n",
      "Loss: 0.3755931854248047 -0.6409292221069336\n",
      "Loss: 0.3628578782081604 -0.8369027972221375\n",
      "Loss: 0.41446590423583984 -0.9388515949249268\n",
      "Policy Reward: tensor(1.2773, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.82', '0.86', '0.80', '0.68', '0.53', '0.33', '0.12', '0.02', '0.01', '0.01', '0.01', '0.04', '0.24', '0.76', '0.48', '0.80', '0.62']\n",
      "Last Action:  tensor([0.6201, 0.9916, 0.2793, 0.4557, 0.3191, 0.5666, 0.5783, 0.6563, 0.6321,\n",
      "        0.5548], device='cuda:0')\n",
      "Loss: 0.36382395029067993 -0.6883481740951538\n",
      "Loss: 0.3313869833946228 -0.8131240010261536\n",
      "Loss: 0.3947649896144867 -0.8360547423362732\n",
      "Loss: 0.33053529262542725 -0.5879215598106384\n",
      "Loss: 0.3605307936668396 -0.3344869017601013\n",
      "Loss: 0.3903966248035431 -0.6666874885559082\n",
      "Loss: 0.41316699981689453 -0.819934070110321\n",
      "Policy Reward: tensor(1.2411, device='cuda:0')\n",
      "Trajectory:  ['0.51', '1.00', '0.62', '0.22', '0.91', '0.68', '0.81', '0.71', '0.44', '0.20', '0.22', '0.14', '0.02', '0.02', '0.90', '0.96', '0.65', '0.57', '0.69']\n",
      "Last Action:  tensor([0.6889, 0.6391, 0.9482, 0.5797, 0.4754, 0.7918, 0.7381, 0.8179, 0.6346,\n",
      "        0.9463], device='cuda:0')\n",
      "Bigstep:  71\n",
      "Loss: 0.49807244539260864 -0.34664031863212585\n",
      "Loss: 0.4173772931098938 -0.21580341458320618\n",
      "Loss: 0.42901650071144104 -0.5422857403755188\n",
      "Loss: 0.4287867248058319 -0.8275026082992554\n",
      "Loss: 0.4015037417411804 -0.775610625743866\n",
      "Loss: 0.44538211822509766 -0.7998321652412415\n",
      "Loss: 0.4076889455318451 -1.0197333097457886\n",
      "Policy Reward: tensor(1.1347, device='cuda:0')\n",
      "Trajectory:  ['0.52', '0.30', '0.90', '0.87', '0.77', '0.78', '0.72', '0.71', '0.66', '0.42', '0.20', '0.01', '0.01', '0.02', '0.80', '1.00', '0.89', '0.54', '0.91']\n",
      "Last Action:  tensor([0.9076, 0.8926, 0.7586, 0.8475, 0.6421, 0.9965, 0.7165, 0.7333, 0.7137,\n",
      "        0.9675], device='cuda:0')\n",
      "Loss: 0.4663964509963989 -0.848584771156311\n",
      "Loss: 0.4002454876899719 -0.6339867115020752\n",
      "Loss: 0.3895234167575836 -0.6735045909881592\n",
      "Loss: 0.31697264313697815 -0.5527089834213257\n",
      "Loss: 0.44864577054977417 -0.8440594673156738\n",
      "Loss: 0.48753175139427185 -1.0753860473632812\n",
      "Loss: 0.4013378620147705 -0.811352550983429\n",
      "Policy Reward: tensor(1.0754, device='cuda:0')\n",
      "Trajectory:  ['0.45', '1.00', '0.87', '0.93', '0.93', '0.96', '0.95', '0.83', '0.89', '0.78', '0.72', '0.37', '0.08', '0.01', '0.00', '0.01', '0.46', '0.99', '1.00']\n",
      "Last Action:  tensor([0.9974, 0.9659, 0.8098, 0.7954, 0.9600, 0.8150, 0.6385, 0.4182, 0.6819,\n",
      "        0.6931], device='cuda:0')\n",
      "Loss: 0.4105154573917389 -0.8438597917556763\n",
      "Loss: 0.38210177421569824 -0.9042240381240845\n",
      "Loss: 0.42001843452453613 -0.8618288040161133\n",
      "Loss: 0.31769827008247375 -0.8415374159812927\n",
      "Loss: 0.4035007357597351 -1.0255564451217651\n",
      "Loss: 0.4008037745952606 -1.0126889944076538\n",
      "Loss: 0.4074954688549042 -0.6876539587974548\n",
      "Policy Reward: tensor(1.1028, device='cuda:0')\n",
      "Trajectory:  ['0.03', '1.00', '0.98', '0.90', '0.88', '0.85', '0.74', '0.60', '0.39', '0.10', '0.01', '0.00', '0.00', '0.01', '0.37', '1.00', '0.99', '0.70', '0.44']\n",
      "Last Action:  tensor([0.4441, 0.7108, 0.4630, 0.9855, 0.8318, 0.9096, 0.8142, 0.8442, 0.6617,\n",
      "        0.7583], device='cuda:0')\n",
      "Loss: 0.4266839921474457 -0.9387903213500977\n",
      "Loss: 0.41078272461891174 -1.1718045473098755\n",
      "Loss: 0.41448819637298584 -1.073151707649231\n",
      "Loss: 0.41817036271095276 -0.5077525973320007\n",
      "Loss: 0.4881729185581207 -1.3479032516479492\n",
      "Loss: 0.37408751249313354 -0.7837610244750977\n",
      "Loss: 0.49671804904937744 -0.8003309965133667\n",
      "Policy Reward: tensor(1.0130, device='cuda:0')\n",
      "Trajectory:  ['0.46', '1.00', '0.91', '0.83', '0.97', '0.92', '0.88', '0.70', '0.22', '0.15', '0.03', '0.04', '0.30', '0.97', '0.74', '0.78', '0.93', '0.65', '0.92']\n",
      "Last Action:  tensor([0.9248, 0.7008, 0.6664, 0.6350, 0.8649, 0.8375, 0.5753, 0.4871, 0.5329,\n",
      "        0.9894], device='cuda:0')\n",
      "Loss: 0.37944671511650085 -0.8847000598907471\n",
      "Loss: 0.4100888669490814 -0.7816462516784668\n",
      "Loss: 0.3603883981704712 -0.7028217911720276\n",
      "Loss: 0.45325303077697754 -0.8796287178993225\n",
      "Loss: 0.37902551889419556 -0.8955727815628052\n",
      "Loss: 0.42801252007484436 -1.0796568393707275\n",
      "Loss: 0.4131593108177185 -0.9494574069976807\n",
      "Policy Reward: tensor(1.1534, device='cuda:0')\n",
      "Trajectory:  ['0.48', '1.00', '0.81', '0.96', '0.97', '0.94', '0.92', '0.83', '0.53', '0.30', '0.16', '0.04', '0.00', '0.05', '1.00', '0.99', '0.57', '0.75', '0.75']\n",
      "Last Action:  tensor([0.7455, 0.9261, 0.9741, 0.7297, 0.8374, 0.7998, 0.5566, 0.8552, 0.8196,\n",
      "        0.8518], device='cuda:0')\n",
      "Loss: 0.37597426772117615 -1.0702811479568481\n",
      "Loss: 0.48470357060432434 -1.024562954902649\n",
      "Loss: 0.3851892650127411 -0.8668560981750488\n",
      "Loss: 0.42314445972442627 -1.1459083557128906\n",
      "Loss: 0.34665364027023315 -0.9497191905975342\n",
      "Loss: 0.4171522557735443 -0.780365526676178\n",
      "Loss: 0.373961478471756 -0.7632587552070618\n",
      "Policy Reward: tensor(1.1396, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.93', '0.88', '0.80', '0.62', '0.46', '0.22', '0.03', '0.02', '0.01', '0.00', '0.01', '0.15', '0.99', '1.00', '0.64', '0.41', '0.54']\n",
      "Last Action:  tensor([0.5377, 0.8975, 0.7204, 0.9367, 0.8822, 0.5318, 0.6259, 0.6387, 0.9228,\n",
      "        0.9047], device='cuda:0')\n",
      "Loss: 0.39507925510406494 -0.8377301692962646\n",
      "Loss: 0.4059365689754486 -1.047047734260559\n",
      "Loss: 0.3850450813770294 -0.9472070932388306\n",
      "Loss: 0.39200446009635925 -0.7750165462493896\n",
      "Loss: 0.42182478308677673 -1.0777065753936768\n",
      "Loss: 0.4689101278781891 -0.985000729560852\n",
      "Loss: 0.43014827370643616 -1.0561697483062744\n",
      "Policy Reward: tensor(0.9989, device='cuda:0')\n",
      "Trajectory:  ['0.11', '1.00', '0.99', '0.92', '0.94', '0.77', '0.61', '0.42', '0.13', '0.02', '0.00', '0.01', '0.12', '0.96', '0.83', '0.79', '0.95', '0.88', '0.76']\n",
      "Last Action:  tensor([0.7591, 0.8772, 0.6390, 0.8330, 0.9672, 0.6345, 0.9379, 0.7908, 0.9847,\n",
      "        0.6452], device='cuda:0')\n",
      "Loss: 0.40719977021217346 -0.7926214933395386\n",
      "Loss: 0.4811239242553711 -1.1740200519561768\n",
      "Loss: 0.42885446548461914 -0.8197247982025146\n",
      "Loss: 0.3833717107772827 -0.7861958742141724\n",
      "Loss: 0.3084741532802582 -0.5469235777854919\n",
      "Loss: 0.3753471076488495 -0.9240126609802246\n",
      "Loss: 0.4307115077972412 -0.7555289268493652\n",
      "Policy Reward: tensor(1.1431, device='cuda:0')\n",
      "Trajectory:  ['0.48', '1.00', '0.93', '0.87', '0.94', '0.92', '0.86', '0.74', '0.53', '0.30', '0.12', '0.00', '0.00', '0.89', '0.99', '0.83', '0.95', '0.96', '0.94']\n",
      "Last Action:  tensor([0.9430, 0.9015, 0.8678, 0.5266, 0.9981, 0.9262, 0.9445, 0.5970, 0.8648,\n",
      "        0.7021], device='cuda:0')\n",
      "Bigstep:  72\n",
      "Loss: 0.5179916024208069 0.3019326627254486\n",
      "Loss: 0.4863329827785492 0.4058937430381775\n",
      "Loss: 0.3986411392688751 -0.437031090259552\n",
      "Loss: 0.5007843971252441 -1.026951551437378\n",
      "Loss: 0.4281191825866699 -1.0290135145187378\n",
      "Loss: 0.4639619290828705 -0.9874468445777893\n",
      "Loss: 0.35498854517936707 -0.9750719666481018\n",
      "Policy Reward: tensor(1.1766, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.80', '0.85', '0.81', '0.87', '0.88', '0.86', '0.83', '0.80', '0.75', '0.60', '0.28', '0.02', '0.00', '0.00', '0.00', '0.06', '0.91']\n",
      "Last Action:  tensor([0.9132, 0.3265, 0.2896, 0.5030, 0.2219, 0.8792, 0.4741, 0.5407, 0.5050,\n",
      "        0.1873], device='cuda:0')\n",
      "Loss: 0.40124714374542236 -0.8123096227645874\n",
      "Loss: 0.4648923873901367 -1.1468795537948608\n",
      "Loss: 0.4217093586921692 -0.8379989862442017\n",
      "Loss: 0.461186021566391 -1.1008937358856201\n",
      "Loss: 0.4329771101474762 -1.1977156400680542\n",
      "Loss: 0.5280531644821167 -1.449615240097046\n",
      "Loss: 0.43615856766700745 -1.2553589344024658\n",
      "Policy Reward: tensor(1.1680, device='cuda:0')\n",
      "Trajectory:  ['0.51', '1.00', '0.31', '0.67', '0.85', '0.81', '0.85', '0.68', '0.33', '0.10', '0.01', '0.00', '0.00', '0.00', '0.66', '0.97', '0.38', '0.69', '0.39']\n",
      "Last Action:  tensor([0.3936, 0.5015, 0.9123, 0.6473, 0.8344, 0.3072, 0.3247, 0.3213, 0.8895,\n",
      "        0.9068], device='cuda:0')\n",
      "Loss: 0.41905874013900757 -0.9315491318702698\n",
      "Loss: 0.4348266124725342 -1.2782411575317383\n",
      "Loss: 0.4408288598060608 -1.095637321472168\n",
      "Loss: 0.42301759123802185 -1.209428071975708\n",
      "Loss: 0.43897926807403564 -1.0229853391647339\n",
      "Loss: 0.44265902042388916 -1.2424395084381104\n",
      "Loss: 0.418535053730011 -1.1808760166168213\n",
      "Policy Reward: tensor(1.2913, device='cuda:0')\n",
      "Trajectory:  ['0.25', '1.00', '0.74', '0.13', '0.87', '0.86', '0.93', '0.83', '0.61', '0.32', '0.05', '0.00', '0.00', '0.00', '0.03', '0.25', '0.42', '0.25', '0.21']\n",
      "Last Action:  tensor([0.2076, 0.2763, 0.3410, 0.1587, 0.0907, 0.4238, 0.3837, 0.5047, 0.2460,\n",
      "        0.3584], device='cuda:0')\n",
      "Loss: 0.3876940608024597 -1.0237557888031006\n",
      "Loss: 0.4272969663143158 -0.9517036080360413\n",
      "Loss: 0.4682494103908539 -1.0240731239318848\n",
      "Loss: 0.41159382462501526 -1.1770648956298828\n",
      "Loss: 0.4902975559234619 -1.5109796524047852\n",
      "Loss: 0.41941526532173157 -1.1809886693954468\n",
      "Loss: 0.51444411277771 -1.2517285346984863\n",
      "Policy Reward: tensor(1.2874, device='cuda:0')\n",
      "Trajectory:  ['0.33', '1.00', '0.61', '0.14', '0.81', '0.87', '0.77', '0.69', '0.52', '0.17', '0.03', '0.00', '0.00', '0.00', '0.06', '0.92', '0.85', '0.23', '0.32']\n",
      "Last Action:  tensor([0.3185, 0.8459, 0.2785, 0.9124, 0.6566, 0.7048, 0.9163, 0.1793, 0.8440,\n",
      "        0.6498], device='cuda:0')\n",
      "Loss: 0.45682066679000854 -1.134078025817871\n",
      "Loss: 0.39483216404914856 -1.2860496044158936\n",
      "Loss: 0.48413771390914917 -1.2725540399551392\n",
      "Loss: 0.34222811460494995 -0.9193564653396606\n",
      "Loss: 0.3781922161579132 -1.0486352443695068\n",
      "Loss: 0.348072350025177 -0.8682591319084167\n",
      "Loss: 0.441241055727005 -1.369947910308838\n",
      "Policy Reward: tensor(1.2290, device='cuda:0')\n",
      "Trajectory:  ['0.05', '1.00', '0.49', '0.64', '0.83', '0.62', '0.40', '0.26', '0.08', '0.03', '0.01', '0.00', '0.00', '0.00', '0.02', '0.73', '0.94', '0.28', '0.18']\n",
      "Last Action:  tensor([0.1838, 0.5392, 0.3644, 0.8957, 0.3338, 0.6704, 0.5333, 0.9092, 0.6154,\n",
      "        0.8033], device='cuda:0')\n",
      "Loss: 0.49143779277801514 -1.2671175003051758\n",
      "Loss: 0.346749484539032 -1.005317211151123\n",
      "Loss: 0.48242974281311035 -1.2027984857559204\n",
      "Loss: 0.6134684085845947 -1.6759302616119385\n",
      "Loss: 0.47526973485946655 -1.2853710651397705\n",
      "Loss: 0.4433455169200897 -1.220792293548584\n",
      "Loss: 0.4181652069091797 -1.0164971351623535\n",
      "Policy Reward: tensor(1.2205, device='cuda:0')\n",
      "Trajectory:  ['0.44', '1.00', '0.45', '0.41', '0.94', '0.84', '0.91', '0.79', '0.57', '0.22', '0.03', '0.00', '0.00', '0.00', '0.11', '0.97', '0.91', '0.41', '0.65']\n",
      "Last Action:  tensor([0.6517, 0.0825, 0.9065, 0.2170, 0.8248, 0.1747, 0.1775, 0.1312, 0.9280,\n",
      "        0.4796], device='cuda:0')\n",
      "Loss: 0.44008931517601013 -1.239763855934143\n",
      "Loss: 0.3886124789714813 -1.2310830354690552\n",
      "Loss: 0.43851515650749207 -1.4929463863372803\n",
      "Loss: 0.45768770575523376 -1.1659457683563232\n",
      "Loss: 0.44522640109062195 -1.1992402076721191\n",
      "Loss: 0.33446913957595825 -1.090046763420105\n",
      "Loss: 0.3227728009223938 -0.8067658543586731\n",
      "Policy Reward: tensor(1.1656, device='cuda:0')\n",
      "Trajectory:  ['0.30', '0.49', '0.29', '0.31', '0.63', '0.95', '0.93', '0.92', '0.73', '0.25', '0.02', '0.00', '0.00', '0.00', '0.37', '0.97', '0.44', '0.22', '0.21']\n",
      "Last Action:  tensor([0.2089, 0.8135, 0.6503, 0.7592, 0.8636, 0.1744, 0.7992, 0.8503, 0.2975,\n",
      "        0.5204], device='cuda:0')\n",
      "Loss: 0.4042209982872009 -1.3736560344696045\n",
      "Loss: 0.40807658433914185 -1.4200762510299683\n",
      "Loss: 0.33825916051864624 -1.029524564743042\n",
      "Loss: 0.5067833065986633 -1.5227818489074707\n",
      "Loss: 0.4161277115345001 -1.0240195989608765\n",
      "Loss: 0.3691044747829437 -1.0597586631774902\n",
      "Loss: 0.4118031859397888 -1.0408306121826172\n",
      "Policy Reward: tensor(1.1890, device='cuda:0')\n",
      "Trajectory:  ['0.39', '1.00', '0.45', '0.16', '0.94', '0.75', '0.76', '0.47', '0.15', '0.01', '0.00', '0.00', '0.00', '0.00', '0.12', '0.88', '0.67', '0.12', '0.51']\n",
      "Last Action:  tensor([0.5053, 0.3459, 0.8957, 0.4575, 0.8462, 0.7284, 0.3965, 0.1367, 0.7784,\n",
      "        0.3384], device='cuda:0')\n",
      "Bigstep:  73\n",
      "Loss: 0.5216361284255981 0.19850070774555206\n",
      "Loss: 0.48415958881378174 -0.12280416488647461\n",
      "Loss: 0.4581897258758545 -0.27568310499191284\n",
      "Loss: 0.5036409497261047 -0.16510502994060516\n",
      "Loss: 0.5354775190353394 -0.48102688789367676\n",
      "Loss: 0.4639098644256592 -0.09252128005027771\n",
      "Loss: 0.48468294739723206 -0.3944690227508545\n",
      "Policy Reward: tensor(1.1288, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.41', '0.73', '0.83', '0.68', '0.43', '0.38', '0.28', '0.09', '0.01', '0.00', '0.00', '0.00', '0.00', '0.00', '0.01', '0.30', '0.87']\n",
      "Last Action:  tensor([0.8696, 0.5178, 0.0961, 0.0300, 0.7634, 0.1071, 0.0296, 0.0744, 0.0166,\n",
      "        0.7945], device='cuda:0')\n",
      "Loss: 0.45153623819351196 -0.24688252806663513\n",
      "Loss: 0.5547743439674377 -0.5359876155853271\n",
      "Loss: 0.5487220287322998 -0.6070225834846497\n",
      "Loss: 0.5347023010253906 -0.4924929738044739\n",
      "Loss: 0.5182893872261047 -0.7180572748184204\n",
      "Loss: 0.42395707964897156 -0.3457637131214142\n",
      "Loss: 0.5051800608634949 -0.6911592483520508\n",
      "Policy Reward: tensor(1.2440, device='cuda:0')\n",
      "Trajectory:  ['0.03', '1.00', '0.63', '0.54', '0.74', '0.90', '0.77', '0.77', '0.78', '0.51', '0.05', '0.00', '0.00', '0.00', '0.00', '0.00', '0.10', '0.78', '0.45']\n",
      "Last Action:  tensor([0.4504, 0.8330, 0.3133, 0.0204, 0.1937, 0.0544, 0.0667, 0.0336, 0.0601,\n",
      "        0.0344], device='cuda:0')\n",
      "Loss: 0.45916104316711426 -0.556456446647644\n",
      "Loss: 0.5306850075721741 -0.3841968774795532\n",
      "Loss: 0.4535069763660431 -0.4072265923023224\n",
      "Loss: 0.4588385224342346 -0.53618323802948\n",
      "Loss: 0.46744516491889954 -0.37795764207839966\n",
      "Loss: 0.518997848033905 -0.5110755562782288\n",
      "Loss: 0.39777132868766785 -0.05919726565480232\n",
      "Policy Reward: tensor(1.2438, device='cuda:0')\n",
      "Trajectory:  ['0.47', '0.89', '0.11', '0.31', '0.87', '0.81', '0.78', '0.63', '0.27', '0.02', '0.00', '0.00', '0.00', '0.00', '0.00', '0.07', '0.68', '0.51', '0.03']\n",
      "Last Action:  tensor([0.0312, 0.2183, 0.0745, 0.6686, 0.2697, 0.1029, 0.0205, 0.0313, 0.1623,\n",
      "        0.1691], device='cuda:0')\n",
      "Loss: 0.540708065032959 -0.8026509881019592\n",
      "Loss: 0.4791854918003082 -0.7491656541824341\n",
      "Loss: 0.521397590637207 -0.5788183212280273\n",
      "Loss: 0.5703981518745422 -0.6172736287117004\n",
      "Loss: 0.46395885944366455 -0.31199607253074646\n",
      "Loss: 0.4658890664577484 -0.40233927965164185\n",
      "Loss: 0.4188360869884491 -0.11573471873998642\n",
      "Policy Reward: tensor(1.1535, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.62', '0.82', '0.82', '0.51', '0.32', '0.20', '0.03', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.01', '0.05', '0.12']\n",
      "Last Action:  tensor([0.1188, 0.0230, 0.2673, 0.0834, 0.0752, 0.2840, 0.0247, 0.4518, 0.2401,\n",
      "        0.1708], device='cuda:0')\n",
      "Loss: 0.5382203459739685 -0.6286861300468445\n",
      "Loss: 0.5322293043136597 -0.33020859956741333\n",
      "Loss: 0.4776049852371216 -0.09873206168413162\n",
      "Loss: 0.4601054787635803 -0.39887577295303345\n",
      "Loss: 0.5048741102218628 -0.9738311767578125\n",
      "Loss: 0.47042161226272583 -0.4151381850242615\n",
      "Loss: 0.5021624565124512 -0.5275305509567261\n",
      "Policy Reward: tensor(1.1257, device='cuda:0')\n",
      "Trajectory:  ['0.14', '1.00', '0.58', '0.19', '0.87', '0.73', '0.57', '0.31', '0.04', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.03', '0.32', '0.42', '0.14']\n",
      "Last Action:  tensor([0.1387, 0.1054, 0.4577, 0.0965, 0.0252, 0.1144, 0.7433, 0.0152, 0.0296,\n",
      "        0.1115], device='cuda:0')\n",
      "Loss: 0.4214940369129181 -0.02266571670770645\n",
      "Loss: 0.5259711146354675 -0.8285679817199707\n",
      "Loss: 0.46524450182914734 -0.21324113011360168\n",
      "Loss: 0.513974130153656 -0.5521302819252014\n",
      "Loss: 0.5485267043113708 -0.7432574033737183\n",
      "Loss: 0.502671480178833 -0.636171281337738\n",
      "Loss: 0.5549381375312805 -0.4084152579307556\n",
      "Policy Reward: tensor(1.1816, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.84', '0.81', '0.84', '0.80', '0.69', '0.59', '0.48', '0.20', '0.01', '0.00', '0.00', '0.00', '0.00', '0.00', '0.01', '0.30', '0.72']\n",
      "Last Action:  tensor([0.7168, 0.0189, 0.0271, 0.5474, 0.0450, 0.0236, 0.0424, 0.3580, 0.2068,\n",
      "        0.0253], device='cuda:0')\n",
      "Loss: 0.51969975233078 -0.5069552063941956\n",
      "Loss: 0.5617728233337402 -0.5180071592330933\n",
      "Loss: 0.4678732752799988 -0.4305979013442993\n",
      "Loss: 0.4366183876991272 -0.19488495588302612\n",
      "Loss: 0.4322703182697296 -0.4525551199913025\n",
      "Loss: 0.4083055257797241 -0.19015976786613464\n",
      "Loss: 0.555659294128418 -0.7175566554069519\n",
      "Policy Reward: tensor(1.2787, device='cuda:0')\n",
      "Trajectory:  ['0.15', '1.00', '0.50', '0.07', '0.86', '0.70', '0.58', '0.23', '0.01', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.09', '0.50', '0.66', '0.05']\n",
      "Last Action:  tensor([0.0458, 0.2707, 0.1730, 0.0388, 0.4079, 0.1002, 0.2997, 0.0767, 0.1282,\n",
      "        0.0379], device='cuda:0')\n",
      "Loss: 0.5626047253608704 -0.7676080465316772\n",
      "Loss: 0.5163553357124329 -0.6932073831558228\n",
      "Loss: 0.4982929527759552 -0.4054262042045593\n",
      "Loss: 0.40585798025131226 -0.3615093231201172\n",
      "Loss: 0.43369653820991516 -0.6095724105834961\n",
      "Loss: 0.5851214528083801 -0.982138454914093\n",
      "Loss: 0.5275195837020874 -0.6661627292633057\n",
      "Policy Reward: tensor(1.2569, device='cuda:0')\n",
      "Trajectory:  ['0.05', '1.00', '0.52', '0.10', '0.85', '0.82', '0.68', '0.38', '0.04', '0.00', '0.00', '0.00', '0.00', '0.00', '0.00', '0.06', '0.59', '0.47', '0.03']\n",
      "Last Action:  tensor([0.0301, 0.2293, 0.2990, 0.0258, 0.0442, 0.1288, 0.1174, 0.0570, 0.2362,\n",
      "        0.3187], device='cuda:0')\n",
      "Bigstep:  74\n",
      "Loss: 0.6053205728530884 -0.5263789296150208\n",
      "Loss: 0.4805300235748291 -0.13108699023723602\n",
      "Loss: 0.490153431892395 0.35486090183258057\n",
      "Loss: 0.48306939005851746 -0.4518216550350189\n",
      "Loss: 0.4523017704486847 -0.7952932715415955\n",
      "Loss: 0.3922630548477173 -0.5502215623855591\n",
      "Loss: 0.3846535086631775 -0.5242652893066406\n",
      "Policy Reward: tensor(1.1342, device='cuda:0')\n",
      "Trajectory:  ['0.04', '1.00', '0.62', '0.63', '0.71', '0.75', '0.66', '0.61', '0.62', '0.57', '0.28', '0.01', '0.00', '0.00', '0.00', '0.03', '0.86', '0.93', '0.16']\n",
      "Last Action:  tensor([0.1621, 0.0763, 0.2581, 0.0805, 0.0707, 0.4843, 0.0252, 0.3005, 0.0357,\n",
      "        0.6486], device='cuda:0')\n",
      "Loss: 0.4558994174003601 -0.582955539226532\n",
      "Loss: 0.4459993839263916 -0.31020215153694153\n",
      "Loss: 0.4468783438205719 -0.6341097950935364\n",
      "Loss: 0.40096455812454224 -0.7316058278083801\n",
      "Loss: 0.449817419052124 -0.8700350522994995\n",
      "Loss: 0.45757243037223816 -0.7429044246673584\n",
      "Loss: 0.4147806167602539 -0.7441898584365845\n",
      "Policy Reward: tensor(1.1058, device='cuda:0')\n",
      "Trajectory:  ['0.02', '1.00', '0.52', '0.71', '0.85', '0.57', '0.40', '0.29', '0.07', '0.01', '0.00', '0.00', '0.00', '0.00', '0.45', '0.99', '0.56', '0.08', '0.13']\n",
      "Last Action:  tensor([0.1345, 0.1581, 0.3892, 0.2465, 0.6934, 0.1520, 0.1987, 0.6749, 0.3417,\n",
      "        0.1752], device='cuda:0')\n",
      "Loss: 0.46513620018959045 -0.7534701228141785\n",
      "Loss: 0.4417053461074829 -0.9221599698066711\n",
      "Loss: 0.3715273141860962 -0.6631712913513184\n",
      "Loss: 0.3644896149635315 -0.42285239696502686\n",
      "Loss: 0.47964102029800415 -0.6150830388069153\n",
      "Loss: 0.4577561318874359 -1.0931572914123535\n",
      "Loss: 0.41479405760765076 -0.7914373874664307\n",
      "Policy Reward: tensor(1.0074, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.41', '0.72', '0.85', '0.61', '0.33', '0.26', '0.20', '0.09', '0.01', '0.00', '0.00', '0.00', '0.07', '0.92', '0.66', '0.22', '0.45']\n",
      "Last Action:  tensor([0.4500, 0.1457, 0.7436, 0.4727, 0.2846, 0.0799, 0.2286, 0.2724, 0.2445,\n",
      "        0.2054], device='cuda:0')\n",
      "Loss: 0.5742143392562866 -1.315299391746521\n",
      "Loss: 0.4013376832008362 -1.0829845666885376\n",
      "Loss: 0.5250400304794312 -1.1264472007751465\n",
      "Loss: 0.5128499269485474 -0.8218355178833008\n",
      "Loss: 0.45221570134162903 -0.8276436924934387\n",
      "Loss: 0.48967012763023376 -1.060075283050537\n",
      "Loss: 0.4710417091846466 -1.1600711345672607\n",
      "Policy Reward: tensor(1.2020, device='cuda:0')\n",
      "Trajectory:  ['0.04', '1.00', '0.50', '0.67', '0.83', '0.51', '0.36', '0.32', '0.26', '0.15', '0.04', '0.01', '0.00', '0.01', '0.52', '1.00', '0.79', '0.11', '0.11']\n",
      "Last Action:  tensor([0.1062, 0.4067, 0.6282, 0.2111, 0.0687, 0.2277, 0.2019, 0.4400, 0.0909,\n",
      "        0.5255], device='cuda:0')\n",
      "Loss: 0.548775315284729 -1.1246988773345947\n",
      "Loss: 0.4670961797237396 -0.8744075894355774\n",
      "Loss: 0.44952619075775146 -0.8654900193214417\n",
      "Loss: 0.5046199560165405 -1.334630012512207\n",
      "Loss: 0.45772501826286316 -0.8981873393058777\n",
      "Loss: 0.3844348192214966 -0.7824543118476868\n",
      "Loss: 0.4731312394142151 -1.191689372062683\n",
      "Policy Reward: tensor(1.1548, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.65', '0.85', '0.84', '0.52', '0.37', '0.39', '0.44', '0.41', '0.21', '0.09', '0.02', '0.02', '0.10', '0.83', '0.96', '0.51', '0.86']\n",
      "Last Action:  tensor([0.8615, 0.6261, 0.5748, 0.0958, 0.8813, 0.5283, 0.7553, 0.4218, 0.4339,\n",
      "        0.8039], device='cuda:0')\n",
      "Loss: 0.45557472109794617 -0.7750956416130066\n",
      "Loss: 0.49290260672569275 -0.9867644906044006\n",
      "Loss: 0.44595083594322205 -0.8662161827087402\n",
      "Loss: 0.47757643461227417 -1.1223301887512207\n",
      "Loss: 0.5114622116088867 -1.4205631017684937\n",
      "Loss: 0.41959619522094727 -0.9770846366882324\n",
      "Loss: 0.5080084204673767 -1.0818382501602173\n",
      "Policy Reward: tensor(1.0778, device='cuda:0')\n",
      "Trajectory:  ['0.74', '0.23', '0.22', '0.48', '0.76', '0.72', '0.83', '0.72', '0.58', '0.60', '0.60', '0.47', '0.42', '0.24', '0.09', '0.61', '1.00', '0.89', '0.47']\n",
      "Last Action:  tensor([0.4685, 0.2470, 0.8454, 0.6279, 0.8408, 0.7806, 0.4075, 0.8495, 0.0977,\n",
      "        0.8459], device='cuda:0')\n",
      "Loss: 0.4623183608055115 -0.855404257774353\n",
      "Loss: 0.46048468351364136 -1.1941795349121094\n",
      "Loss: 0.43755191564559937 -0.7024377584457397\n",
      "Loss: 0.47409787774086 -1.2599388360977173\n",
      "Loss: 0.43447792530059814 -1.0931346416473389\n",
      "Loss: 0.49943241477012634 -1.2622417211532593\n",
      "Loss: 0.43997856974601746 -1.0520321130752563\n",
      "Policy Reward: tensor(1.1305, device='cuda:0')\n",
      "Trajectory:  ['0.76', '0.16', '0.39', '0.71', '0.63', '0.70', '0.82', '0.75', '0.66', '0.66', '0.64', '0.56', '0.52', '0.33', '0.18', '0.79', '1.00', '0.67', '0.31']\n",
      "Last Action:  tensor([0.3147, 0.5685, 0.1782, 0.6215, 0.1934, 0.5886, 0.3687, 0.6814, 0.8487,\n",
      "        0.2003], device='cuda:0')\n",
      "Loss: 0.5942130088806152 -1.139884114265442\n",
      "Loss: 0.4137246608734131 -0.9550727605819702\n",
      "Loss: 0.4232921004295349 -0.8902713060379028\n",
      "Loss: 0.47110095620155334 -0.8384225964546204\n",
      "Loss: 0.4711674451828003 -1.219712734222412\n",
      "Loss: 0.43232661485671997 -0.9405269026756287\n",
      "Loss: 0.45864155888557434 -1.0330637693405151\n",
      "Policy Reward: tensor(0.9846, device='cuda:0')\n",
      "Trajectory:  ['0.80', '0.53', '0.04', '0.14', '0.89', '0.51', '0.67', '0.48', '0.56', '0.51', '0.42', '0.48', '0.49', '0.26', '0.71', '0.98', '0.83', '0.36', '0.51']\n",
      "Last Action:  tensor([0.5096, 0.5937, 0.8029, 0.4347, 0.5568, 0.6869, 0.8063, 0.7829, 0.4788,\n",
      "        0.5602], device='cuda:0')\n",
      "Bigstep:  75\n",
      "Loss: 0.42034560441970825 -0.2938469350337982\n",
      "Loss: 0.43709665536880493 -0.4436512589454651\n",
      "Loss: 0.409851610660553 -0.5411272644996643\n",
      "Loss: 0.39814600348472595 -0.9871683716773987\n",
      "Loss: 0.4427386522293091 -1.070960283279419\n",
      "Loss: 0.45695024728775024 -1.3065030574798584\n",
      "Loss: 0.3628785312175751 -0.8771149516105652\n",
      "Policy Reward: tensor(1.1450, device='cuda:0')\n",
      "Trajectory:  ['0.63', '0.19', '0.03', '0.29', '0.97', '0.67', '0.84', '0.59', '0.51', '0.54', '0.49', '0.56', '0.91', '0.98', '0.93', '0.97', '0.97', '0.89', '0.66']\n",
      "Last Action:  tensor([0.6552, 0.8395, 0.6870, 0.9569, 0.8275, 0.9399, 0.8837, 0.9244, 0.9966,\n",
      "        0.9598], device='cuda:0')\n",
      "Loss: 0.37931475043296814 -1.1505861282348633\n",
      "Loss: 0.4582395851612091 -1.2379306554794312\n",
      "Loss: 0.40878206491470337 -1.2615021467208862\n",
      "Loss: 0.4408992528915405 -1.4286144971847534\n",
      "Loss: 0.3648366332054138 -1.2180007696151733\n",
      "Loss: 0.46453505754470825 -1.4232977628707886\n",
      "Loss: 0.34906214475631714 -0.9909490346908569\n",
      "Policy Reward: tensor(1.1408, device='cuda:0')\n",
      "Trajectory:  ['0.35', '1.00', '0.28', '0.05', '0.92', '0.73', '0.59', '0.34', '0.22', '0.19', '0.21', '0.39', '0.78', '0.99', '0.99', '1.00', '1.00', '0.98', '0.89']\n",
      "Last Action:  tensor([0.8854, 0.9637, 0.9836, 0.8003, 0.4350, 0.6237, 0.9220, 0.9319, 0.4695,\n",
      "        0.3935], device='cuda:0')\n",
      "Loss: 0.43478986620903015 -1.410690426826477\n",
      "Loss: 0.4574836492538452 -1.5148452520370483\n",
      "Loss: 0.35876670479774475 -0.8911026120185852\n",
      "Loss: 0.49371638894081116 -1.5597827434539795\n",
      "Loss: 0.40407946705818176 -0.9937101006507874\n",
      "Loss: 0.40919145941734314 -1.4269860982894897\n",
      "Loss: 0.42296135425567627 -1.268080234527588\n",
      "Policy Reward: tensor(1.1968, device='cuda:0')\n",
      "Trajectory:  ['0.48', '1.00', '0.07', '0.06', '0.80', '0.70', '0.69', '0.47', '0.31', '0.24', '0.17', '0.24', '0.59', '0.98', '0.99', '1.00', '0.99', '0.96', '0.75']\n",
      "Last Action:  tensor([0.7496, 0.9893, 0.5150, 0.5859, 0.4051, 0.8567, 0.2990, 0.8410, 0.9522,\n",
      "        0.8290], device='cuda:0')\n",
      "Loss: 0.4745233952999115 -1.2077709436416626\n",
      "Loss: 0.4230344295501709 -1.455113410949707\n",
      "Loss: 0.46655964851379395 -1.286992073059082\n",
      "Loss: 0.446241170167923 -1.494350790977478\n",
      "Loss: 0.3984794616699219 -1.216118574142456\n",
      "Loss: 0.4123302400112152 -1.4253743886947632\n",
      "Loss: 0.4280623495578766 -1.2218623161315918\n",
      "Policy Reward: tensor(1.1326, device='cuda:0')\n",
      "Trajectory:  ['0.80', '0.68', '0.05', '0.22', '0.91', '0.73', '0.65', '0.47', '0.44', '0.51', '0.53', '0.45', '0.60', '0.74', '0.99', '0.84', '0.92', '0.86', '0.50']\n",
      "Last Action:  tensor([0.5007, 0.4470, 0.6743, 0.9855, 0.9047, 0.7451, 0.7786, 0.6050, 0.9645,\n",
      "        0.9508], device='cuda:0')\n",
      "Loss: 0.43525180220603943 -1.346938967704773\n",
      "Loss: 0.41912642121315 -1.418371558189392\n",
      "Loss: 0.4938400089740753 -1.6588674783706665\n",
      "Loss: 0.44479039311408997 -1.1566516160964966\n",
      "Loss: 0.3459121584892273 -0.9931930899620056\n",
      "Loss: 0.41448381543159485 -1.4196131229400635\n",
      "Loss: 0.3822793960571289 -1.242697834968567\n",
      "Policy Reward: tensor(1.1645, device='cuda:0')\n",
      "Trajectory:  ['0.41', '0.99', '0.03', '0.24', '0.93', '0.70', '0.64', '0.38', '0.33', '0.35', '0.39', '0.62', '0.89', '0.93', '0.93', '0.98', '0.96', '0.72', '0.40']\n",
      "Last Action:  tensor([0.3998, 0.5734, 0.5201, 0.9801, 0.7751, 0.6259, 0.5280, 0.5371, 0.7056,\n",
      "        0.6371], device='cuda:0')\n",
      "Loss: 0.4773549735546112 -1.5966556072235107\n",
      "Loss: 0.3564441502094269 -1.269163727760315\n",
      "Loss: 0.3935646116733551 -1.416312575340271\n",
      "Loss: 0.46865323185920715 -1.5991134643554688\n",
      "Loss: 0.40669524669647217 -1.3918309211730957\n",
      "Loss: 0.3940471112728119 -1.1731417179107666\n",
      "Loss: 0.4390101134777069 -1.566557765007019\n",
      "Policy Reward: tensor(1.1229, device='cuda:0')\n",
      "Trajectory:  ['0.68', '0.29', '0.12', '0.76', '0.83', '0.66', '0.63', '0.42', '0.55', '0.57', '0.55', '0.52', '0.67', '0.81', '0.99', '0.90', '0.91', '0.92', '0.61']\n",
      "Last Action:  tensor([0.6054, 0.4619, 0.9885, 0.8652, 0.9448, 0.3398, 0.9398, 0.4772, 0.8147,\n",
      "        0.5427], device='cuda:0')\n",
      "Loss: 0.46225741505622864 -1.5984821319580078\n",
      "Loss: 0.3939729928970337 -1.3069090843200684\n",
      "Loss: 0.41419121623039246 -1.4763559103012085\n",
      "Loss: 0.42965081334114075 -1.6188074350357056\n",
      "Loss: 0.41919010877609253 -1.1917604207992554\n",
      "Loss: 0.40637674927711487 -0.9883689880371094\n",
      "Loss: 0.38744187355041504 -1.2697198390960693\n",
      "Policy Reward: tensor(1.1002, device='cuda:0')\n",
      "Trajectory:  ['0.78', '0.55', '0.40', '0.41', '0.73', '0.70', '0.71', '0.75', '0.78', '0.82', '0.84', '0.81', '0.70', '0.67', '0.72', '0.70', '0.79', '0.85', '0.88']\n",
      "Last Action:  tensor([0.8841, 0.7188, 0.8656, 0.6367, 0.6609, 0.8208, 0.5326, 0.9043, 0.9783,\n",
      "        0.8464], device='cuda:0')\n",
      "Loss: 0.4189242422580719 -1.3501225709915161\n",
      "Loss: 0.3687264025211334 -1.166952133178711\n",
      "Loss: 0.4614953398704529 -1.695905327796936\n",
      "Loss: 0.4138892889022827 -1.1527115106582642\n",
      "Loss: 0.3703121840953827 -1.2533613443374634\n",
      "Loss: 0.4479929208755493 -1.38163423538208\n",
      "Loss: 0.3907472491264343 -1.201857089996338\n",
      "Policy Reward: tensor(1.0731, device='cuda:0')\n",
      "Trajectory:  ['0.01', '0.99', '0.60', '0.65', '0.61', '0.40', '0.32', '0.23', '0.19', '0.18', '0.20', '0.35', '0.78', '0.99', '0.99', '1.00', '0.99', '0.97', '0.77']\n",
      "Last Action:  tensor([0.7695, 0.7309, 0.9133, 0.5628, 0.9693, 0.9201, 0.4923, 0.6332, 0.9774,\n",
      "        0.8956], device='cuda:0')\n",
      "Bigstep:  76\n",
      "Loss: 0.46857935190200806 -1.194774866104126\n",
      "Loss: 0.3568055033683777 -0.8884199261665344\n",
      "Loss: 0.35493889451026917 -0.9619808793067932\n",
      "Loss: 0.32168257236480713 -0.7803041338920593\n",
      "Loss: 0.4008500874042511 -0.845320463180542\n",
      "Loss: 0.38527533411979675 -1.1499468088150024\n",
      "Loss: 0.3539561629295349 -1.1131643056869507\n",
      "Policy Reward: tensor(1.2185, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.71', '0.81', '0.59', '0.25', '0.13', '0.07', '0.03', '0.03', '0.09', '0.30', '0.79', '1.00', '1.00', '1.00', '1.00', '1.00', '0.95']\n",
      "Last Action:  tensor([0.9535, 0.9854, 0.9966, 0.9639, 0.8799, 0.6853, 0.9442, 0.8807, 0.8976,\n",
      "        0.8235], device='cuda:0')\n",
      "Loss: 0.4351286292076111 -1.1523665189743042\n",
      "Loss: 0.3022465407848358 -0.8021795153617859\n",
      "Loss: 0.397087961435318 -1.439867377281189\n",
      "Loss: 0.3505997359752655 -1.0883300304412842\n",
      "Loss: 0.34859499335289 -1.0843867063522339\n",
      "Loss: 0.3860127925872803 -1.254753589630127\n",
      "Loss: 0.4031275808811188 -1.398776650428772\n",
      "Policy Reward: tensor(1.1881, device='cuda:0')\n",
      "Trajectory:  ['0.53', '0.99', '0.04', '0.28', '0.83', '0.47', '0.29', '0.09', '0.04', '0.02', '0.03', '0.14', '0.79', '1.00', '0.99', '0.99', '1.00', '1.00', '0.99']\n",
      "Last Action:  tensor([0.9867, 0.9913, 0.5057, 0.9664, 0.9221, 0.6801, 0.7778, 0.9501, 0.9057,\n",
      "        0.4203], device='cuda:0')\n",
      "Loss: 0.35305607318878174 -1.22081458568573\n",
      "Loss: 0.43465301394462585 -1.2937284708023071\n",
      "Loss: 0.436418354511261 -1.1522873640060425\n",
      "Loss: 0.37595292925834656 -0.9724686145782471\n",
      "Loss: 0.3224010765552521 -0.9294131994247437\n",
      "Loss: 0.3992306888103485 -1.1539584398269653\n",
      "Loss: 0.3804849088191986 -1.3817039728164673\n",
      "Policy Reward: tensor(1.1576, device='cuda:0')\n",
      "Trajectory:  ['0.30', '1.00', '0.10', '0.07', '0.81', '0.64', '0.33', '0.12', '0.16', '0.25', '0.35', '0.60', '0.97', '0.99', '0.99', '0.98', '0.99', '0.98', '0.87']\n",
      "Last Action:  tensor([0.8744, 0.9461, 0.9916, 0.9975, 0.3821, 0.9389, 0.9838, 0.4733, 0.9205,\n",
      "        0.9889], device='cuda:0')\n",
      "Loss: 0.4308857321739197 -1.2744048833847046\n",
      "Loss: 0.2984209358692169 -1.0174713134765625\n",
      "Loss: 0.30626001954078674 -0.9457668662071228\n",
      "Loss: 0.3284868001937866 -0.8652629852294922\n",
      "Loss: 0.4530407190322876 -1.3476428985595703\n",
      "Loss: 0.34044885635375977 -1.1604408025741577\n",
      "Loss: 0.3743176758289337 -1.1285091638565063\n",
      "Policy Reward: tensor(1.1309, device='cuda:0')\n",
      "Trajectory:  ['0.53', '0.97', '0.03', '0.16', '0.73', '0.50', '0.45', '0.16', '0.07', '0.03', '0.03', '0.10', '0.69', '1.00', '0.99', '1.00', '1.00', '1.00', '0.97']\n",
      "Last Action:  tensor([0.9678, 0.6889, 0.9992, 0.9436, 0.9962, 0.9861, 0.9992, 0.9569, 0.9067,\n",
      "        0.9744], device='cuda:0')\n",
      "Loss: 0.36479172110557556 -1.0663176774978638\n",
      "Loss: 0.34948453307151794 -1.0902493000030518\n",
      "Loss: 0.3126276731491089 -0.8477481007575989\n",
      "Loss: 0.3410875201225281 -1.1663542985916138\n",
      "Loss: 0.3534991145133972 -1.2680723667144775\n",
      "Loss: 0.355095237493515 -0.9151908159255981\n",
      "Loss: 0.47430840134620667 -1.4184823036193848\n",
      "Policy Reward: tensor(1.1288, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.41', '0.75', '0.66', '0.17', '0.09', '0.06', '0.03', '0.05', '0.19', '0.79', '0.99', '0.99', '1.00', '1.00', '1.00', '0.92', '0.45']\n",
      "Last Action:  tensor([0.4515, 0.9990, 0.9978, 0.9916, 0.8238, 0.9645, 0.9498, 0.9397, 0.7375,\n",
      "        0.9588], device='cuda:0')\n",
      "Loss: 0.39866873621940613 -1.309353232383728\n",
      "Loss: 0.35611411929130554 -1.1483654975891113\n",
      "Loss: 0.4131074845790863 -1.047702431678772\n",
      "Loss: 0.36961209774017334 -0.9789207577705383\n",
      "Loss: 0.36227235198020935 -1.1419618129730225\n",
      "Loss: 0.3220057487487793 -1.213084101676941\n",
      "Loss: 0.39984676241874695 -1.4265944957733154\n",
      "Policy Reward: tensor(1.1648, device='cuda:0')\n",
      "Trajectory:  ['0.46', '1.00', '0.23', '0.14', '0.86', '0.42', '0.18', '0.08', '0.06', '0.09', '0.24', '0.85', '0.99', '1.00', '1.00', '1.00', '1.00', '1.00', '0.98']\n",
      "Last Action:  tensor([0.9827, 0.8230, 0.9767, 0.9929, 0.6100, 0.7859, 0.9424, 0.9819, 0.9988,\n",
      "        0.9992], device='cuda:0')\n",
      "Loss: 0.426482617855072 -1.2585453987121582\n",
      "Loss: 0.34791627526283264 -1.362293004989624\n",
      "Loss: 0.33046072721481323 -1.0257794857025146\n",
      "Loss: 0.37981927394866943 -1.6408183574676514\n",
      "Loss: 0.3449648320674896 -1.4944955110549927\n",
      "Loss: 0.3832972049713135 -1.1014877557754517\n",
      "Loss: 0.43179622292518616 -1.6345833539962769\n",
      "Policy Reward: tensor(1.1139, device='cuda:0')\n",
      "Trajectory:  ['0.45', '0.72', '0.03', '0.40', '0.86', '0.55', '0.42', '0.36', '0.43', '0.54', '0.51', '0.52', '0.95', '0.99', '0.98', '0.92', '0.97', '0.97', '0.61']\n",
      "Last Action:  tensor([0.6056, 0.9993, 0.7983, 0.9577, 0.9956, 0.6273, 0.9983, 0.9343, 0.7476,\n",
      "        0.9986], device='cuda:0')\n",
      "Loss: 0.33890584111213684 -1.2562943696975708\n",
      "Loss: 0.3604051470756531 -1.097330927848816\n",
      "Loss: 0.4362548887729645 -1.4911707639694214\n",
      "Loss: 0.3593307137489319 -0.9163877367973328\n",
      "Loss: 0.3555788993835449 -1.2793693542480469\n",
      "Loss: 0.43523475527763367 -1.5420730113983154\n",
      "Loss: 0.3382372260093689 -0.974926233291626\n",
      "Policy Reward: tensor(1.2489, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.61', '0.78', '0.67', '0.14', '0.05', '0.04', '0.02', '0.07', '0.23', '0.72', '1.00', '1.00', '1.00', '1.00', '1.00', '0.99', '0.82']\n",
      "Last Action:  tensor([0.8204, 0.5362, 0.9905, 0.9498, 0.8168, 0.9591, 0.8868, 0.9777, 0.9910,\n",
      "        0.9693], device='cuda:0')\n",
      "Bigstep:  77\n",
      "Loss: 0.4044775366783142 -0.47097739577293396\n",
      "Loss: 0.32446810603141785 -0.02860286645591259\n",
      "Loss: 0.30093950033187866 -0.15592217445373535\n",
      "Loss: 0.4165967106819153 -1.0064470767974854\n",
      "Loss: 0.3624206483364105 -0.3938792645931244\n",
      "Loss: 0.3711158335208893 -0.8072948455810547\n",
      "Loss: 0.40648749470710754 -0.6770853996276855\n",
      "Policy Reward: tensor(1.1519, device='cuda:0')\n",
      "Trajectory:  ['0.49', '1.00', '0.06', '0.19', '0.98', '0.50', '0.18', '0.04', '0.01', '0.02', '0.07', '0.43', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9985, 0.9985, 0.9894, 0.9994, 0.7969, 0.9683, 0.9981, 0.9987, 0.9992,\n",
      "        0.9996], device='cuda:0')\n",
      "Loss: 0.4242934584617615 -0.6702074408531189\n",
      "Loss: 0.36630699038505554 -0.8105112314224243\n",
      "Loss: 0.4616931676864624 -0.9298415780067444\n",
      "Loss: 0.3244902491569519 -0.7108731269836426\n",
      "Loss: 0.44441697001457214 -1.1038464307785034\n",
      "Loss: 0.4295578598976135 -1.3311080932617188\n",
      "Loss: 0.28631263971328735 -0.3659745454788208\n",
      "Policy Reward: tensor(1.1873, device='cuda:0')\n",
      "Trajectory:  ['0.55', '0.96', '0.03', '0.23', '0.89', '0.38', '0.18', '0.02', '0.00', '0.00', '0.01', '0.13', '0.91', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9959, 0.9586, 0.9999, 0.9719, 0.6170, 0.9743, 0.9957, 0.9969, 0.8215,\n",
      "        0.9895], device='cuda:0')\n",
      "Loss: 0.29402363300323486 -0.6273871064186096\n",
      "Loss: 0.3821864426136017 -0.7801145911216736\n",
      "Loss: 0.35150018334388733 -0.5316510200500488\n",
      "Loss: 0.37685534358024597 -0.8082363605499268\n",
      "Loss: 0.394552618265152 -0.9301788210868835\n",
      "Loss: 0.3361663520336151 -0.7424064874649048\n",
      "Loss: 0.40763700008392334 -0.7887582778930664\n",
      "Policy Reward: tensor(1.0845, device='cuda:0')\n",
      "Trajectory:  ['0.85', '0.57', '0.07', '0.03', '0.48', '0.88', '0.40', '0.06', '0.09', '0.34', '0.46', '0.33', '0.85', '0.99', '0.99', '0.99', '1.00', '1.00', '0.97']\n",
      "Last Action:  tensor([0.9734, 0.9994, 0.8667, 0.9996, 0.9799, 0.9977, 0.9939, 0.9996, 0.8048,\n",
      "        0.6567], device='cuda:0')\n",
      "Loss: 0.3477783501148224 -0.9416321516036987\n",
      "Loss: 0.3247458338737488 -0.5580508708953857\n",
      "Loss: 0.3799903392791748 -0.662461519241333\n",
      "Loss: 0.43589845299720764 -0.9112977385520935\n",
      "Loss: 0.38796767592430115 -0.8009489178657532\n",
      "Loss: 0.3166324198246002 -0.41332632303237915\n",
      "Loss: 0.4064624607563019 -0.6299155354499817\n",
      "Policy Reward: tensor(1.0271, device='cuda:0')\n",
      "Trajectory:  ['0.53', '0.93', '0.04', '0.29', '0.96', '0.41', '0.12', '0.01', '0.00', '0.00', '0.02', '0.22', '0.97', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9986, 0.9812, 0.9971, 0.9110, 0.9988, 0.9950, 0.9983, 0.9441, 0.9931,\n",
      "        0.9994], device='cuda:0')\n",
      "Loss: 0.40621915459632874 -1.0617114305496216\n",
      "Loss: 0.4237712621688843 -0.9732333421707153\n",
      "Loss: 0.3699037432670593 -0.7387336492538452\n",
      "Loss: 0.402118980884552 -0.950590193271637\n",
      "Loss: 0.3980100452899933 -1.0816733837127686\n",
      "Loss: 0.4039171040058136 -1.1458734273910522\n",
      "Loss: 0.37072083353996277 -0.6208506226539612\n",
      "Policy Reward: tensor(1.2082, device='cuda:0')\n",
      "Trajectory:  ['0.93', '0.74', '0.12', '0.59', '0.96', '0.50', '0.13', '0.01', '0.00', '0.01', '0.05', '0.27', '0.98', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9962, 0.9235, 0.9909, 0.9888, 0.9927, 0.8175, 0.9956, 0.9901, 0.9947,\n",
      "        0.9271], device='cuda:0')\n",
      "Loss: 0.38607603311538696 -1.0146080255508423\n",
      "Loss: 0.30927813053131104 -0.7095332741737366\n",
      "Loss: 0.4876493811607361 -0.8461066484451294\n",
      "Loss: 0.42029356956481934 -0.8974754214286804\n",
      "Loss: 0.37091341614723206 -1.038341760635376\n",
      "Loss: 0.3380163908004761 -0.7583577632904053\n",
      "Loss: 0.3388504385948181 -0.7706238627433777\n",
      "Policy Reward: tensor(1.1931, device='cuda:0')\n",
      "Trajectory:  ['0.15', '1.00', '0.34', '0.13', '0.67', '0.59', '0.78', '0.82', '0.77', '0.72', '0.76', '0.83', '0.79', '0.75', '0.79', '0.90', '0.77', '0.73', '0.84']\n",
      "Last Action:  tensor([0.8399, 0.9931, 0.9965, 0.9960, 0.9917, 0.9879, 0.8482, 0.9484, 0.9704,\n",
      "        0.9272], device='cuda:0')\n",
      "Loss: 0.3148547410964966 -0.931230902671814\n",
      "Loss: 0.41507235169410706 -1.1050570011138916\n",
      "Loss: 0.3360344469547272 -0.7083254456520081\n",
      "Loss: 0.4028780460357666 -1.0273789167404175\n",
      "Loss: 0.43173202872276306 -0.8755515217781067\n",
      "Loss: 0.3231758773326874 -0.518523633480072\n",
      "Loss: 0.3242669403553009 -0.5338447093963623\n",
      "Policy Reward: tensor(1.0248, device='cuda:0')\n",
      "Trajectory:  ['0.58', '0.97', '0.04', '0.23', '0.94', '0.39', '0.16', '0.01', '0.00', '0.00', '0.02', '0.21', '0.91', '1.00', '1.00', '1.00', '1.00', '1.00', '0.98']\n",
      "Last Action:  tensor([0.9801, 0.9962, 0.8702, 0.9980, 0.9969, 0.9996, 0.9983, 0.9546, 0.9983,\n",
      "        0.9864], device='cuda:0')\n",
      "Loss: 0.3871415853500366 -1.0792427062988281\n",
      "Loss: 0.3978574872016907 -0.9835511445999146\n",
      "Loss: 0.3572827875614166 -0.5792414546012878\n",
      "Loss: 0.41312316060066223 -0.8101493716239929\n",
      "Loss: 0.41333243250846863 -1.1288871765136719\n",
      "Loss: 0.3236529529094696 -0.7411813139915466\n",
      "Loss: 0.32550081610679626 -0.714806318283081\n",
      "Policy Reward: tensor(1.2065, device='cuda:0')\n",
      "Trajectory:  ['0.17', '1.00', '0.90', '0.35', '0.71', '0.22', '0.01', '0.01', '0.04', '0.13', '0.20', '0.82', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '0.99']\n",
      "Last Action:  tensor([0.9933, 0.9986, 0.9994, 0.9940, 0.9531, 0.9837, 0.9912, 0.9129, 0.9994,\n",
      "        0.9845], device='cuda:0')\n",
      "Bigstep:  78\n",
      "Loss: 0.34280985593795776 -0.13106533885002136\n",
      "Loss: 0.3981979489326477 -0.6674339175224304\n",
      "Loss: 0.355689138174057 -0.3503127694129944\n",
      "Loss: 0.35524529218673706 -0.5169299840927124\n",
      "Loss: 0.35003918409347534 -0.3952854871749878\n",
      "Loss: 0.3879547417163849 -0.3139135241508484\n",
      "Loss: 0.39064013957977295 -0.6890059113502502\n",
      "Policy Reward: tensor(1.1411, device='cuda:0')\n",
      "Trajectory:  ['0.03', '1.00', '0.84', '0.76', '0.29', '0.01', '0.00', '0.00', '0.00', '0.01', '0.04', '0.18', '0.88', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9993, 0.9992, 0.9947, 0.9318, 0.9418, 0.9866, 0.9987, 0.9667, 0.9848,\n",
      "        0.9977], device='cuda:0')\n",
      "Loss: 0.44270196557044983 -0.40458911657333374\n",
      "Loss: 0.33030733466148376 -0.32371625304222107\n",
      "Loss: 0.3669472932815552 -0.5963531732559204\n",
      "Loss: 0.4172651767730713 -0.363882452249527\n",
      "Loss: 0.33826351165771484 -0.24584396183490753\n",
      "Loss: 0.4507179856300354 -0.8799412250518799\n",
      "Loss: 0.3439079225063324 -0.6248002648353577\n",
      "Policy Reward: tensor(1.0901, device='cuda:0')\n",
      "Trajectory:  ['0.92', '0.57', '0.14', '0.71', '0.95', '0.18', '0.01', '0.00', '0.00', '0.01', '0.04', '0.13', '0.29', '0.91', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9998, 0.9997, 0.9910, 0.9545, 0.9472, 0.9483, 0.9942, 0.9841, 0.9762,\n",
      "        0.9991], device='cuda:0')\n",
      "Loss: 0.33170032501220703 -0.3232336938381195\n",
      "Loss: 0.4279511272907257 -0.6543469429016113\n",
      "Loss: 0.4312487542629242 -0.5350009799003601\n",
      "Loss: 0.38434672355651855 -0.6248645782470703\n",
      "Loss: 0.40375879406929016 -0.6447481513023376\n",
      "Loss: 0.3819792568683624 -0.4406965970993042\n",
      "Loss: 0.388904869556427 -0.6388269662857056\n",
      "Policy Reward: tensor(1.0393, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.87', '0.62', '0.08', '0.00', '0.00', '0.00', '0.00', '0.03', '0.21', '0.30', '0.95', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9997, 0.9966, 0.9970, 0.9691, 0.7145, 0.8295, 0.9105, 0.9932, 0.9993,\n",
      "        0.9997], device='cuda:0')\n",
      "Loss: 0.304717481136322 -0.03695613890886307\n",
      "Loss: 0.37721002101898193 -0.40337586402893066\n",
      "Loss: 0.35681813955307007 -0.3492983281612396\n",
      "Loss: 0.3608393371105194 -0.6653212904930115\n",
      "Loss: 0.41387835144996643 -0.5662354230880737\n",
      "Loss: 0.360365629196167 -0.5671162605285645\n",
      "Loss: 0.3631022572517395 -0.37642303109169006\n",
      "Policy Reward: tensor(1.1980, device='cuda:0')\n",
      "Trajectory:  ['0.38', '1.00', '0.19', '0.08', '0.87', '0.11', '0.00', '0.00', '0.00', '0.01', '0.07', '0.51', '0.99', '1.00', '1.00', '1.00', '1.00', '1.00', '0.99']\n",
      "Last Action:  tensor([0.9931, 0.9978, 0.5862, 0.9181, 0.9846, 0.9755, 0.9884, 0.9925, 0.9891,\n",
      "        0.9938], device='cuda:0')\n",
      "Loss: 0.41222625970840454 -0.4387513995170593\n",
      "Loss: 0.39505743980407715 -0.6211899518966675\n",
      "Loss: 0.34884193539619446 -0.4822114408016205\n",
      "Loss: 0.36021891236305237 -0.5936242938041687\n",
      "Loss: 0.4078218638896942 -0.7084087133407593\n",
      "Loss: 0.32200828194618225 -0.28773021697998047\n",
      "Loss: 0.40871021151542664 -0.5795867443084717\n",
      "Policy Reward: tensor(1.1618, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.71', '0.64', '0.55', '0.14', '0.01', '0.00', '0.00', '0.00', '0.02', '0.08', '0.22', '0.77', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9989, 0.9981, 0.9797, 0.9964, 0.9990, 0.9881, 0.4832, 0.5517, 0.9987,\n",
      "        0.9948], device='cuda:0')\n",
      "Loss: 0.4013616442680359 -0.69678795337677\n",
      "Loss: 0.37323322892189026 -0.4171828627586365\n",
      "Loss: 0.35314494371414185 -0.28554365038871765\n",
      "Loss: 0.38743993639945984 -0.579261064529419\n",
      "Loss: 0.36932578682899475 -0.5061233639717102\n",
      "Loss: 0.4659262001514435 -0.7703002095222473\n",
      "Loss: 0.4540741443634033 -0.6047372817993164\n",
      "Policy Reward: tensor(1.2320, device='cuda:0')\n",
      "Trajectory:  ['0.43', '1.00', '0.02', '0.06', '0.96', '0.30', '0.01', '0.01', '0.04', '0.27', '0.26', '0.40', '0.98', '1.00', '1.00', '0.99', '1.00', '0.99', '0.94']\n",
      "Last Action:  tensor([0.9391, 0.9995, 0.9981, 0.9969, 0.9995, 0.9353, 0.8800, 0.9406, 0.9873,\n",
      "        0.9889], device='cuda:0')\n",
      "Loss: 0.39054638147354126 -0.44135984778404236\n",
      "Loss: 0.36119258403778076 -0.7126337885856628\n",
      "Loss: 0.3860306143760681 -0.529179036617279\n",
      "Loss: 0.3461209237575531 -0.44118478894233704\n",
      "Loss: 0.37704333662986755 -0.48483774065971375\n",
      "Loss: 0.31439489126205444 -0.2541017532348633\n",
      "Loss: 0.4218897521495819 -0.4646020233631134\n",
      "Policy Reward: tensor(1.0897, device='cuda:0')\n",
      "Trajectory:  ['0.88', '0.76', '0.03', '0.30', '0.98', '0.42', '0.01', '0.00', '0.00', '0.00', '0.02', '0.26', '0.98', '1.00', '1.00', '1.00', '1.00', '1.00', '0.99']\n",
      "Last Action:  tensor([0.9934, 0.9993, 0.9890, 0.9974, 0.9995, 0.8193, 0.8957, 0.9990, 0.8745,\n",
      "        0.9869], device='cuda:0')\n",
      "Loss: 0.4664900004863739 -0.9328215718269348\n",
      "Loss: 0.3689027428627014 -0.5942198634147644\n",
      "Loss: 0.3028832674026489 -0.2770231366157532\n",
      "Loss: 0.3705693483352661 -0.7114643454551697\n",
      "Loss: 0.3317357897758484 -0.1640463024377823\n",
      "Loss: 0.42399659752845764 -0.7910197973251343\n",
      "Loss: 0.39620211720466614 -0.6973724365234375\n",
      "Policy Reward: tensor(1.1469, device='cuda:0')\n",
      "Trajectory:  ['0.44', '1.00', '0.06', '0.19', '0.85', '0.12', '0.00', '0.00', '0.00', '0.00', '0.07', '0.32', '0.98', '1.00', '1.00', '1.00', '1.00', '1.00', '0.99']\n",
      "Last Action:  tensor([0.9885, 0.9996, 0.9984, 0.9993, 0.9985, 0.9838, 0.9995, 0.9944, 0.9997,\n",
      "        0.9957], device='cuda:0')\n",
      "Bigstep:  79\n",
      "Loss: 0.3596230149269104 -0.19852282106876373\n",
      "Loss: 0.37386834621429443 0.26487818360328674\n",
      "Loss: 0.3161320984363556 -0.023596910759806633\n",
      "Loss: 0.3574514091014862 -0.23815423250198364\n",
      "Loss: 0.36358702182769775 -0.2672642171382904\n",
      "Loss: 0.38753464818000793 -0.48027393221855164\n",
      "Loss: 0.4000012278556824 -0.3475249409675598\n",
      "Policy Reward: tensor(1.1626, device='cuda:0')\n",
      "Trajectory:  ['0.96', '0.86', '0.28', '0.28', '0.99', '0.83', '0.24', '0.00', '0.00', '0.00', '0.03', '0.18', '0.49', '0.98', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9958, 0.9946, 0.9983, 0.9869, 0.9840, 0.9994, 0.9997, 0.9998, 0.9854,\n",
      "        0.9959], device='cuda:0')\n",
      "Loss: 0.3316621780395508 -0.034546028822660446\n",
      "Loss: 0.32320794463157654 -0.035070501267910004\n",
      "Loss: 0.402351438999176 -0.6336420178413391\n",
      "Loss: 0.37948232889175415 -0.20063865184783936\n",
      "Loss: 0.31645652651786804 -0.23811085522174835\n",
      "Loss: 0.4044932723045349 -0.68916916847229\n",
      "Loss: 0.30880099534988403 -0.4023285210132599\n",
      "Policy Reward: tensor(1.1419, device='cuda:0')\n",
      "Trajectory:  ['0.39', '1.00', '0.15', '0.14', '0.92', '0.76', '0.26', '0.01', '0.00', '0.01', '0.09', '0.39', '0.89', '1.00', '1.00', '1.00', '1.00', '1.00', '0.99']\n",
      "Last Action:  tensor([0.9874, 0.9868, 0.9992, 0.9969, 0.9813, 0.9593, 0.9997, 0.9623, 0.9585,\n",
      "        0.8967], device='cuda:0')\n",
      "Loss: 0.4174445867538452 -0.8601019978523254\n",
      "Loss: 0.36492154002189636 -0.8769662976264954\n",
      "Loss: 0.39273056387901306 -0.6799419522285461\n",
      "Loss: 0.37508681416511536 -0.3372373878955841\n",
      "Loss: 0.37420541048049927 -0.6392369270324707\n",
      "Loss: 0.418619304895401 -0.7647939920425415\n",
      "Loss: 0.4111546277999878 -0.7462986707687378\n",
      "Policy Reward: tensor(1.1392, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.49', '0.90', '0.93', '0.82', '0.30', '0.05', '0.02', '0.05', '0.22', '0.81', '0.90', '0.99', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9991, 0.9958, 0.9980, 0.9999, 0.9949, 0.9998, 0.6210, 0.9581, 0.9755,\n",
      "        0.9413], device='cuda:0')\n",
      "Loss: 0.33255496621131897 -0.43150657415390015\n",
      "Loss: 0.4060608148574829 -0.677120566368103\n",
      "Loss: 0.34328630566596985 -0.831741988658905\n",
      "Loss: 0.33568814396858215 -0.46979326009750366\n",
      "Loss: 0.34422990679740906 -0.8231477737426758\n",
      "Loss: 0.3968859016895294 -0.49425238370895386\n",
      "Loss: 0.34289103746414185 -0.7569565176963806\n",
      "Policy Reward: tensor(1.0319, device='cuda:0')\n",
      "Trajectory:  ['0.54', '0.51', '0.02', '0.26', '1.00', '0.95', '0.75', '0.18', '0.03', '0.07', '0.32', '0.78', '1.00', '1.00', '1.00', '1.00', '1.00', '0.97', '0.63']\n",
      "Last Action:  tensor([0.6261, 0.9990, 0.9939, 0.9985, 0.9998, 1.0000, 0.9900, 0.9984, 0.9988,\n",
      "        0.9716], device='cuda:0')\n",
      "Loss: 0.3620862662792206 -0.9285798072814941\n",
      "Loss: 0.3417785167694092 -0.8099344968795776\n",
      "Loss: 0.3506677746772766 -0.8550676107406616\n",
      "Loss: 0.35929083824157715 -0.9795268177986145\n",
      "Loss: 0.35025885701179504 -0.8645733594894409\n",
      "Loss: 0.35765883326530457 -0.4940667152404785\n",
      "Loss: 0.33258911967277527 -0.2465129792690277\n",
      "Policy Reward: tensor(1.1808, device='cuda:0')\n",
      "Trajectory:  ['0.26', '1.00', '0.48', '0.02', '0.96', '0.80', '0.35', '0.04', '0.01', '0.05', '0.43', '0.99', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '0.97']\n",
      "Last Action:  tensor([0.9651, 0.9996, 0.9621, 0.9955, 0.9958, 0.9570, 0.9979, 0.9993, 0.9613,\n",
      "        0.9839], device='cuda:0')\n",
      "Loss: 0.3463629186153412 -0.7698244452476501\n",
      "Loss: 0.3733479380607605 -0.7967333793640137\n",
      "Loss: 0.38969823718070984 -0.677710235118866\n",
      "Loss: 0.384922593832016 -0.8853058815002441\n",
      "Loss: 0.37449783086776733 -0.9331228733062744\n",
      "Loss: 0.39646559953689575 -0.954397976398468\n",
      "Loss: 0.287219762802124 -0.3007213771343231\n",
      "Policy Reward: tensor(1.0612, device='cuda:0')\n",
      "Trajectory:  ['0.37', '0.73', '0.06', '0.25', '1.00', '0.98', '0.80', '0.49', '0.12', '0.06', '0.15', '0.38', '0.74', '1.00', '1.00', '1.00', '1.00', '1.00', '0.99']\n",
      "Last Action:  tensor([0.9891, 0.9985, 0.9693, 0.9978, 0.9987, 0.9981, 0.8123, 0.9827, 0.9997,\n",
      "        0.9994], device='cuda:0')\n",
      "Loss: 0.3391425907611847 -0.31858327984809875\n",
      "Loss: 0.3759647011756897 -0.9576488733291626\n",
      "Loss: 0.34925416111946106 -0.702126681804657\n",
      "Loss: 0.3353061378002167 -0.24122896790504456\n",
      "Loss: 0.30703306198120117 -0.4477144777774811\n",
      "Loss: 0.36542245745658875 -1.0590368509292603\n",
      "Loss: 0.3513660430908203 -0.577613890171051\n",
      "Policy Reward: tensor(1.1717, device='cuda:0')\n",
      "Trajectory:  ['0.57', '0.98', '0.01', '0.29', '0.99', '0.86', '0.84', '0.38', '0.08', '0.03', '0.12', '0.83', '0.99', '1.00', '1.00', '1.00', '1.00', '1.00', '0.98']\n",
      "Last Action:  tensor([0.9818, 0.9993, 0.9882, 0.9500, 0.9954, 0.9996, 0.9985, 0.9982, 0.9812,\n",
      "        0.9811], device='cuda:0')\n",
      "Loss: 0.3818003237247467 -0.9618133306503296\n",
      "Loss: 0.3924471139907837 -0.7178172469139099\n",
      "Loss: 0.45264381170272827 -1.1533284187316895\n",
      "Loss: 0.39061275124549866 -0.9620838165283203\n",
      "Loss: 0.3557356595993042 -0.5923426747322083\n",
      "Loss: 0.3525361120700836 -0.6640438437461853\n",
      "Loss: 0.323183536529541 -0.42872369289398193\n",
      "Policy Reward: tensor(1.1101, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.90', '0.67', '0.97', '0.89', '0.63', '0.20', '0.02', '0.12', '0.23', '0.65', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '0.97']\n",
      "Last Action:  tensor([0.9750, 0.9695, 0.9434, 0.9482, 0.9972, 0.9995, 0.7293, 0.9987, 0.9313,\n",
      "        0.9987], device='cuda:0')\n",
      "Bigstep:  80\n",
      "Loss: 0.4019138514995575 0.1898827850818634\n",
      "Loss: 0.41624295711517334 -0.03367386758327484\n",
      "Loss: 0.3969583511352539 -0.2589162290096283\n",
      "Loss: 0.3234344720840454 -0.08994217962026596\n",
      "Loss: 0.39098432660102844 -0.5042029023170471\n",
      "Loss: 0.2690257728099823 -0.16374574601650238\n",
      "Loss: 0.34058883786201477 -0.20385418832302094\n",
      "Policy Reward: tensor(1.2999, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.88', '0.44', '0.67', '0.63', '0.30', '0.15', '0.02', '0.01', '0.02', '0.04', '0.11', '0.33', '0.87', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9956, 0.9865, 0.9972, 0.9975, 0.9990, 0.9878, 0.9991, 0.8678, 0.9641,\n",
      "        0.9987], device='cuda:0')\n",
      "Loss: 0.4316314160823822 -0.45131444931030273\n",
      "Loss: 0.3804340064525604 -0.5183894038200378\n",
      "Loss: 0.35821473598480225 -0.30791687965393066\n",
      "Loss: 0.3227735459804535 -0.4702259302139282\n",
      "Loss: 0.43061691522598267 -0.5583454966545105\n",
      "Loss: 0.3973727226257324 -0.31720414757728577\n",
      "Loss: 0.31282901763916016 -0.4646158814430237\n",
      "Policy Reward: tensor(1.1280, device='cuda:0')\n",
      "Trajectory:  ['0.94', '0.73', '0.25', '0.05', '0.12', '0.90', '0.36', '0.44', '0.52', '0.32', '0.37', '0.56', '0.51', '0.46', '0.80', '0.99', '0.96', '0.88', '0.73']\n",
      "Last Action:  tensor([0.7287, 0.9996, 0.9906, 0.8626, 0.8011, 0.9985, 0.9997, 0.9968, 0.9858,\n",
      "        0.9993], device='cuda:0')\n",
      "Loss: 0.35847553610801697 -0.1074787825345993\n",
      "Loss: 0.28555530309677124 -0.2895238399505615\n",
      "Loss: 0.43453437089920044 -0.9030529856681824\n",
      "Loss: 0.3785354793071747 -0.564326286315918\n",
      "Loss: 0.3371818959712982 -0.7523769736289978\n",
      "Loss: 0.3483949601650238 -0.40178996324539185\n",
      "Loss: 0.369811475276947 -0.2741181552410126\n",
      "Policy Reward: tensor(1.0926, device='cuda:0')\n",
      "Trajectory:  ['0.56', '0.98', '0.05', '0.03', '0.48', '0.57', '0.41', '0.18', '0.15', '0.24', '0.19', '0.29', '0.26', '0.61', '1.00', '1.00', '1.00', '1.00', '0.99']\n",
      "Last Action:  tensor([0.9940, 0.9994, 0.9454, 0.9951, 0.9993, 0.9970, 0.9928, 0.9998, 0.9987,\n",
      "        0.9996], device='cuda:0')\n",
      "Loss: 0.33116352558135986 -0.39746183156967163\n",
      "Loss: 0.39607495069503784 -0.6888898611068726\n",
      "Loss: 0.3033643662929535 -0.27703142166137695\n",
      "Loss: 0.39237773418426514 -0.6006529331207275\n",
      "Loss: 0.34196823835372925 -0.4161766469478607\n",
      "Loss: 0.44158482551574707 -0.5945466756820679\n",
      "Loss: 0.3683922588825226 -0.36882442235946655\n",
      "Policy Reward: tensor(1.0710, device='cuda:0')\n",
      "Trajectory:  ['0.62', '0.91', '0.04', '0.04', '0.51', '0.42', '0.36', '0.07', '0.06', '0.15', '0.19', '0.20', '0.27', '0.88', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9974, 0.9963, 0.9935, 0.9995, 0.9993, 0.8607, 0.9270, 0.9979, 0.9996,\n",
      "        0.9991], device='cuda:0')\n",
      "Loss: 0.34064000844955444 -0.4944106340408325\n",
      "Loss: 0.3237534761428833 -0.5505270957946777\n",
      "Loss: 0.3819614052772522 -0.5537533760070801\n",
      "Loss: 0.3258556127548218 -0.5275713801383972\n",
      "Loss: 0.39073050022125244 -0.33181363344192505\n",
      "Loss: 0.34701216220855713 -0.4906507730484009\n",
      "Loss: 0.4058316648006439 -0.44406455755233765\n",
      "Policy Reward: tensor(1.1930, device='cuda:0')\n",
      "Trajectory:  ['0.25', '0.97', '0.12', '0.01', '0.61', '0.29', '0.23', '0.11', '0.03', '0.04', '0.09', '0.19', '0.63', '0.97', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9989, 0.9945, 0.9634, 0.9422, 0.9997, 0.9996, 0.9993, 0.9994, 0.9964,\n",
      "        0.9980], device='cuda:0')\n",
      "Loss: 0.45802363753318787 -0.745026707649231\n",
      "Loss: 0.31996992230415344 -0.7144591212272644\n",
      "Loss: 0.3338738679885864 -0.40624451637268066\n",
      "Loss: 0.3517971932888031 -0.2919072210788727\n",
      "Loss: 0.4151022434234619 -0.9326083660125732\n",
      "Loss: 0.4081854224205017 -0.8781833052635193\n",
      "Loss: 0.3257485032081604 -0.6057547926902771\n",
      "Policy Reward: tensor(1.0582, device='cuda:0')\n",
      "Trajectory:  ['0.11', '0.17', '0.05', '0.03', '0.06', '0.11', '0.19', '0.51', '0.66', '0.75', '0.89', '0.78', '0.62', '0.62', '0.74', '0.83', '0.58', '0.42', '0.66']\n",
      "Last Action:  tensor([0.6604, 0.9996, 0.9892, 0.9997, 0.9999, 0.9991, 0.9902, 0.9997, 0.9890,\n",
      "        0.8419], device='cuda:0')\n",
      "Loss: 0.39044317603111267 -0.3566008508205414\n",
      "Loss: 0.3637130558490753 -0.36699700355529785\n",
      "Loss: 0.3920223116874695 -0.5644921064376831\n",
      "Loss: 0.3329985439777374 -0.38767778873443604\n",
      "Loss: 0.40754541754722595 -0.7526065707206726\n",
      "Loss: 0.3665185868740082 -0.5618590116500854\n",
      "Loss: 0.2851906418800354 -0.22741514444351196\n",
      "Policy Reward: tensor(1.0342, device='cuda:0')\n",
      "Trajectory:  ['0.14', '1.00', '0.14', '0.00', '0.40', '0.34', '0.09', '0.02', '0.01', '0.02', '0.14', '0.33', '0.58', '0.96', '0.99', '1.00', '1.00', '1.00', '0.99']\n",
      "Last Action:  tensor([0.9948, 0.9996, 0.9909, 0.9997, 0.9960, 0.9856, 0.9992, 0.9949, 0.9997,\n",
      "        0.9983], device='cuda:0')\n",
      "Loss: 0.42031458020210266 -0.5114931464195251\n",
      "Loss: 0.3259137272834778 -0.4276021122932434\n",
      "Loss: 0.37253043055534363 -0.5205636620521545\n",
      "Loss: 0.3917584717273712 -0.6347116231918335\n",
      "Loss: 0.35517245531082153 -0.41259706020355225\n",
      "Loss: 0.35182639956474304 -0.46625158190727234\n",
      "Loss: 0.37569501996040344 -0.24568000435829163\n",
      "Policy Reward: tensor(1.0473, device='cuda:0')\n",
      "Trajectory:  ['0.85', '0.99', '0.32', '0.01', '0.20', '0.32', '0.32', '0.07', '0.05', '0.08', '0.15', '0.23', '0.26', '0.29', '0.91', '0.99', '0.99', '0.98', '0.98']\n",
      "Last Action:  tensor([0.9782, 0.9993, 0.9997, 0.7860, 0.9995, 0.3874, 0.9997, 0.9971, 0.9992,\n",
      "        0.9984], device='cuda:0')\n",
      "Bigstep:  81\n",
      "Loss: 0.36845943331718445 0.5831887125968933\n",
      "Loss: 0.33165282011032104 0.660720944404602\n",
      "Loss: 0.3270703852176666 0.3927464485168457\n",
      "Loss: 0.3925493359565735 0.08684177696704865\n",
      "Loss: 0.2890629172325134 0.05862388014793396\n",
      "Loss: 0.4047989845275879 0.105105921626091\n",
      "Loss: 0.39337533712387085 0.10100650787353516\n",
      "Policy Reward: tensor(1.2645, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.65', '0.55', '0.71', '0.53', '0.11', '0.04', '0.02', '0.05', '0.29', '0.55', '0.77', '0.80', '0.99', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9997, 0.9995, 0.9893, 0.9965, 0.4597, 0.2731, 0.9994, 0.9939, 0.9980,\n",
      "        0.6966], device='cuda:0')\n",
      "Loss: 0.3734838366508484 -0.4115602374076843\n",
      "Loss: 0.3854439854621887 -0.16835415363311768\n",
      "Loss: 0.3895125091075897 0.02350783720612526\n",
      "Loss: 0.39933469891548157 -0.07326532900333405\n",
      "Loss: 0.3476980924606323 0.019140910357236862\n",
      "Loss: 0.35988491773605347 -0.06645170599222183\n",
      "Loss: 0.393777996301651 -0.2392038106918335\n",
      "Policy Reward: tensor(1.1225, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.32', '0.56', '0.71', '0.65', '0.29', '0.04', '0.03', '0.03', '0.14', '0.50', '0.61', '0.88', '0.98', '1.00', '1.00', '1.00', '0.99']\n",
      "Last Action:  tensor([0.9929, 0.1383, 0.5276, 0.9872, 0.7404, 0.8236, 0.1405, 0.9992, 0.8564,\n",
      "        0.5016], device='cuda:0')\n",
      "Loss: 0.40463197231292725 -0.04404968023300171\n",
      "Loss: 0.3263532221317291 -0.2390938699245453\n",
      "Loss: 0.30762162804603577 -0.1369207501411438\n",
      "Loss: 0.4103890657424927 -0.12428582459688187\n",
      "Loss: 0.3515113592147827 -0.16963213682174683\n",
      "Loss: 0.4188125729560852 -0.2593792974948883\n",
      "Loss: 0.3533254861831665 -0.16781555116176605\n",
      "Policy Reward: tensor(1.2362, device='cuda:0')\n",
      "Trajectory:  ['0.62', '1.00', '0.08', '0.01', '0.09', '0.22', '0.46', '0.16', '0.04', '0.01', '0.03', '0.23', '0.66', '0.87', '0.99', '1.00', '1.00', '0.82', '0.43']\n",
      "Last Action:  tensor([0.4310, 0.9832, 0.3936, 0.5069, 0.8409, 0.8353, 0.3219, 0.1393, 0.2250,\n",
      "        0.5668], device='cuda:0')\n",
      "Loss: 0.38074618577957153 -0.21250122785568237\n",
      "Loss: 0.4042189121246338 -0.299916535615921\n",
      "Loss: 0.2985887825489044 -0.2833670377731323\n",
      "Loss: 0.36812642216682434 -0.29123568534851074\n",
      "Loss: 0.36822956800460815 -0.26323720812797546\n",
      "Loss: 0.33911922574043274 -0.05389221012592316\n",
      "Loss: 0.3726215958595276 -0.05013561248779297\n",
      "Policy Reward: tensor(1.2006, device='cuda:0')\n",
      "Trajectory:  ['0.10', '1.00', '0.66', '0.00', '0.35', '0.74', '0.23', '0.04', '0.03', '0.09', '0.21', '0.30', '0.90', '1.00', '1.00', '1.00', '0.79', '0.21', '0.17']\n",
      "Last Action:  tensor([0.1695, 0.1307, 0.1111, 0.0700, 0.4573, 0.0359, 0.4805, 0.6478, 0.2183,\n",
      "        0.0831], device='cuda:0')\n",
      "Loss: 0.4463379681110382 -0.4109300673007965\n",
      "Loss: 0.36093857884407043 -0.5575928688049316\n",
      "Loss: 0.2656959891319275 -0.23920170962810516\n",
      "Loss: 0.3873440623283386 -0.4287802577018738\n",
      "Loss: 0.3556441366672516 -0.14444097876548767\n",
      "Loss: 0.4033369719982147 -0.20672227442264557\n",
      "Loss: 0.29615819454193115 -0.23823601007461548\n",
      "Policy Reward: tensor(1.2089, device='cuda:0')\n",
      "Trajectory:  ['0.96', '0.80', '0.30', '0.03', '0.16', '0.32', '0.52', '0.19', '0.06', '0.02', '0.06', '0.34', '0.78', '0.95', '0.99', '1.00', '0.84', '0.66', '0.66']\n",
      "Last Action:  tensor([0.6567, 0.5644, 0.1709, 0.7998, 0.7969, 0.0663, 0.0851, 0.0981, 0.9134,\n",
      "        0.2414], device='cuda:0')\n",
      "Loss: 0.32917118072509766 -0.2038859874010086\n",
      "Loss: 0.36244499683380127 -0.19498232007026672\n",
      "Loss: 0.3695767819881439 -0.020836496725678444\n",
      "Loss: 0.37013235688209534 -0.18775475025177002\n",
      "Loss: 0.3024991750717163 -0.15662188827991486\n",
      "Loss: 0.3074687123298645 -0.21534600853919983\n",
      "Loss: 0.3538743853569031 -0.0454602986574173\n",
      "Policy Reward: tensor(1.1768, device='cuda:0')\n",
      "Trajectory:  ['0.94', '0.76', '0.28', '0.04', '0.38', '0.25', '0.55', '0.19', '0.05', '0.07', '0.13', '0.17', '0.39', '0.94', '1.00', '1.00', '0.99', '0.94', '0.70']\n",
      "Last Action:  tensor([0.6968, 0.3908, 0.9449, 0.5741, 0.7465, 0.8678, 0.9715, 0.8642, 0.3705,\n",
      "        0.4423], device='cuda:0')\n",
      "Loss: 0.37636250257492065 -0.34735241532325745\n",
      "Loss: 0.37027406692504883 -0.5208925008773804\n",
      "Loss: 0.35984352231025696 -0.12643031775951385\n",
      "Loss: 0.36642569303512573 -0.09368810057640076\n",
      "Loss: 0.3741208016872406 -0.318959504365921\n",
      "Loss: 0.34558916091918945 0.04939621686935425\n",
      "Loss: 0.34132981300354004 0.06678789108991623\n",
      "Policy Reward: tensor(1.2005, device='cuda:0')\n",
      "Trajectory:  ['0.40', '1.00', '0.08', '0.00', '0.33', '0.56', '0.36', '0.11', '0.03', '0.03', '0.17', '0.59', '0.87', '0.99', '1.00', '0.99', '0.98', '0.98', '0.91']\n",
      "Last Action:  tensor([0.9150, 0.4645, 0.0624, 0.6768, 0.3685, 0.0927, 0.4711, 0.5043, 0.1561,\n",
      "        0.4660], device='cuda:0')\n",
      "Loss: 0.3425593674182892 0.12326585501432419\n",
      "Loss: 0.3010924458503723 0.1365828812122345\n",
      "Loss: 0.34203121066093445 -0.2554025650024414\n",
      "Loss: 0.37389275431632996 -0.577458381652832\n",
      "Loss: 0.37297534942626953 -0.11143849045038223\n",
      "Loss: 0.43358322978019714 -0.4409141540527344\n",
      "Loss: 0.3405331075191498 -0.4455999433994293\n",
      "Policy Reward: tensor(1.3044, device='cuda:0')\n",
      "Trajectory:  ['0.97', '0.81', '0.48', '0.04', '0.02', '0.40', '0.43', '0.31', '0.18', '0.16', '0.10', '0.09', '0.19', '0.67', '0.98', '0.99', '0.98', '0.41', '0.62']\n",
      "Last Action:  tensor([0.6156, 0.8621, 0.5637, 0.0592, 0.1321, 0.3508, 0.5466, 0.8135, 0.2121,\n",
      "        0.5446], device='cuda:0')\n",
      "Bigstep:  82\n",
      "Loss: 0.4355981647968292 0.48035210371017456\n",
      "Loss: 0.4130091667175293 0.18222445249557495\n",
      "Loss: 0.43069300055503845 0.47268155217170715\n",
      "Loss: 0.44574078917503357 -0.1537596881389618\n",
      "Loss: 0.36814048886299133 -0.02893095463514328\n",
      "Loss: 0.43370357155799866 -0.4727870523929596\n",
      "Loss: 0.43012863397598267 0.319635272026062\n",
      "Policy Reward: tensor(1.2071, device='cuda:0')\n",
      "Trajectory:  ['0.60', '0.98', '0.22', '0.02', '0.67', '0.62', '0.41', '0.18', '0.04', '0.04', '0.31', '0.75', '0.99', '1.00', '1.00', '1.00', '1.00', '0.98', '0.92']\n",
      "Last Action:  tensor([0.9175, 0.8531, 0.9485, 0.6781, 0.7465, 0.9594, 0.7697, 0.6146, 0.5866,\n",
      "        0.6548], device='cuda:0')\n",
      "Loss: 0.4165836274623871 -0.25380611419677734\n",
      "Loss: 0.42597341537475586 -0.05138628929853439\n",
      "Loss: 0.37722721695899963 0.09708459675312042\n",
      "Loss: 0.4387294352054596 -0.39745062589645386\n",
      "Loss: 0.40801694989204407 -0.3667939305305481\n",
      "Loss: 0.39983677864074707 -0.11371531337499619\n",
      "Loss: 0.3652549386024475 0.1387961506843567\n",
      "Policy Reward: tensor(1.1262, device='cuda:0')\n",
      "Trajectory:  ['0.31', '1.00', '0.70', '0.00', '0.25', '0.82', '0.40', '0.09', '0.03', '0.05', '0.26', '0.62', '0.97', '1.00', '1.00', '0.99', '0.99', '0.98', '0.90']\n",
      "Last Action:  tensor([0.8965, 0.9375, 0.6606, 0.7065, 0.7471, 0.7877, 0.9912, 0.8892, 0.6055,\n",
      "        0.6258], device='cuda:0')\n",
      "Loss: 0.4107811450958252 0.11234293133020401\n",
      "Loss: 0.37107139825820923 0.23521113395690918\n",
      "Loss: 0.45258232951164246 -0.12739728391170502\n",
      "Loss: 0.32871517539024353 0.010555434972047806\n",
      "Loss: 0.4256390631198883 -0.297090619802475\n",
      "Loss: 0.4881986081600189 -0.5721688270568848\n",
      "Loss: 0.34614887833595276 0.13734431564807892\n",
      "Policy Reward: tensor(1.1055, device='cuda:0')\n",
      "Trajectory:  ['0.55', '0.53', '0.20', '0.03', '0.17', '0.77', '0.46', '0.39', '0.44', '0.41', '0.32', '0.57', '0.95', '1.00', '1.00', '0.96', '0.37', '0.57', '0.64']\n",
      "Last Action:  tensor([0.6376, 0.7180, 0.5604, 0.6910, 0.9790, 0.8709, 0.7156, 0.5579, 0.9233,\n",
      "        0.9014], device='cuda:0')\n",
      "Loss: 0.42495205998420715 -0.11056362092494965\n",
      "Loss: 0.42374950647354126 -0.18234071135520935\n",
      "Loss: 0.32324764132499695 -0.16493670642375946\n",
      "Loss: 0.330343097448349 0.386574387550354\n",
      "Loss: 0.3926347494125366 0.0365428663790226\n",
      "Loss: 0.3634333908557892 -0.08960671722888947\n",
      "Loss: 0.45706307888031006 -0.36329224705696106\n",
      "Policy Reward: tensor(1.1864, device='cuda:0')\n",
      "Trajectory:  ['0.11', '1.00', '0.74', '0.19', '0.73', '0.77', '0.33', '0.04', '0.02', '0.07', '0.52', '0.77', '0.96', '1.00', '0.99', '0.82', '0.58', '0.49', '0.35']\n",
      "Last Action:  tensor([0.3496, 0.7399, 0.5698, 0.4482, 0.6711, 0.7371, 0.8299, 0.9211, 0.6959,\n",
      "        0.7032], device='cuda:0')\n",
      "Loss: 0.4458696246147156 -0.19089072942733765\n",
      "Loss: 0.4751162528991699 -0.39530643820762634\n",
      "Loss: 0.4420415759086609 -0.14049001038074493\n",
      "Loss: 0.3811917304992676 -0.12978020310401917\n",
      "Loss: 0.35585057735443115 -0.12471073865890503\n",
      "Loss: 0.48689985275268555 -0.0860375165939331\n",
      "Loss: 0.4403626024723053 -0.3269762098789215\n",
      "Policy Reward: tensor(1.1149, device='cuda:0')\n",
      "Trajectory:  ['0.04', '1.00', '0.88', '0.68', '0.76', '0.59', '0.11', '0.07', '0.23', '0.21', '0.17', '0.30', '0.75', '0.99', '1.00', '1.00', '1.00', '1.00', '0.93']\n",
      "Last Action:  tensor([0.9304, 0.7665, 0.7566, 0.9151, 0.8304, 0.8960, 0.7224, 0.1948, 0.7934,\n",
      "        0.9041], device='cuda:0')\n",
      "Loss: 0.40238407254219055 -0.2186128795146942\n",
      "Loss: 0.4321795701980591 -0.37954139709472656\n",
      "Loss: 0.4201957881450653 -0.455183207988739\n",
      "Loss: 0.4506321847438812 -0.2505286633968353\n",
      "Loss: 0.34888648986816406 0.36284688115119934\n",
      "Loss: 0.3563807010650635 -0.18101923167705536\n",
      "Loss: 0.4177789092063904 -0.12345535308122635\n",
      "Policy Reward: tensor(1.1407, device='cuda:0')\n",
      "Trajectory:  ['0.96', '0.89', '0.75', '0.52', '0.21', '0.39', '0.54', '0.33', '0.36', '0.52', '0.60', '0.49', '0.64', '0.98', '1.00', '1.00', '1.00', '0.98', '0.96']\n",
      "Last Action:  tensor([0.9569, 0.8456, 0.7254, 0.7732, 0.7083, 0.9513, 0.2469, 0.9944, 0.4449,\n",
      "        0.8486], device='cuda:0')\n",
      "Loss: 0.46176472306251526 -0.5885197520256042\n",
      "Loss: 0.45901909470558167 -0.30843180418014526\n",
      "Loss: 0.39110666513442993 0.04323664680123329\n",
      "Loss: 0.36469635367393494 0.1388235092163086\n",
      "Loss: 0.4635447561740875 -0.5027623176574707\n",
      "Loss: 0.42034661769866943 -0.5694606900215149\n",
      "Loss: 0.43652844429016113 -0.28628405928611755\n",
      "Policy Reward: tensor(1.1769, device='cuda:0')\n",
      "Trajectory:  ['0.69', '1.00', '0.90', '0.23', '0.55', '0.71', '0.33', '0.03', '0.02', '0.10', '0.40', '0.62', '0.96', '1.00', '1.00', '1.00', '1.00', '0.98', '0.71']\n",
      "Last Action:  tensor([0.7085, 0.6452, 0.3547, 0.4117, 0.9572, 0.5783, 0.6969, 0.8172, 0.7025,\n",
      "        0.6483], device='cuda:0')\n",
      "Loss: 0.42481446266174316 -0.3537609577178955\n",
      "Loss: 0.3482591509819031 -0.20911334455013275\n",
      "Loss: 0.407638281583786 -0.4979657232761383\n",
      "Loss: 0.37644514441490173 -0.22795960307121277\n",
      "Loss: 0.3548325002193451 -0.13083010911941528\n",
      "Loss: 0.39999422430992126 -0.4008365273475647\n",
      "Loss: 0.3415137827396393 -0.11446376889944077\n",
      "Policy Reward: tensor(1.1236, device='cuda:0')\n",
      "Trajectory:  ['0.46', '1.00', '0.85', '0.19', '0.58', '0.76', '0.37', '0.03', '0.02', '0.04', '0.19', '0.60', '0.78', '0.99', '1.00', '0.99', '0.91', '0.62', '0.53']\n",
      "Last Action:  tensor([0.5344, 0.7064, 0.7851, 0.6642, 0.6958, 0.7054, 0.6024, 0.4045, 0.8913,\n",
      "        0.9318], device='cuda:0')\n",
      "Bigstep:  83\n",
      "Loss: 0.4122876226902008 0.4790836274623871\n",
      "Loss: 0.4121480882167816 0.23582887649536133\n",
      "Loss: 0.4250468313694 -0.03319581225514412\n",
      "Loss: 0.41025346517562866 -0.3105887770652771\n",
      "Loss: 0.39004456996917725 -0.211083322763443\n",
      "Loss: 0.4313738942146301 -0.5495005249977112\n",
      "Loss: 0.3362236022949219 -0.157208651304245\n",
      "Policy Reward: tensor(1.1776, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.43', '0.57', '0.68', '0.64', '0.36', '0.06', '0.01', '0.00', '0.02', '0.22', '0.57', '0.64', '0.83', '0.93', '0.54', '0.62', '0.47']\n",
      "Last Action:  tensor([0.4655, 0.6307, 0.8793, 0.9588, 0.6631, 0.1335, 0.7221, 0.9987, 0.6077,\n",
      "        0.5634], device='cuda:0')\n",
      "Loss: 0.44924935698509216 -0.6406620144844055\n",
      "Loss: 0.3636619746685028 -0.35799241065979004\n",
      "Loss: 0.39251837134361267 -0.3453734517097473\n",
      "Loss: 0.4424690008163452 -0.46939292550086975\n",
      "Loss: 0.3678816854953766 -0.23398782312870026\n",
      "Loss: 0.35208025574684143 -0.16493268311023712\n",
      "Loss: 0.41397690773010254 -0.2275698333978653\n",
      "Policy Reward: tensor(1.2316, device='cuda:0')\n",
      "Trajectory:  ['0.33', '0.99', '0.05', '0.00', '0.24', '0.21', '0.25', '0.26', '0.10', '0.02', '0.04', '0.25', '0.19', '0.36', '0.81', '0.80', '0.68', '0.55', '0.52']\n",
      "Last Action:  tensor([0.5174, 0.4745, 0.5305, 0.9128, 0.1335, 0.3176, 0.9173, 0.5499, 0.2812,\n",
      "        0.6506], device='cuda:0')\n",
      "Loss: 0.4026140868663788 -0.5707837343215942\n",
      "Loss: 0.41443902254104614 -0.6043087840080261\n",
      "Loss: 0.37335628271102905 -0.3643692135810852\n",
      "Loss: 0.3582344055175781 -0.49628394842147827\n",
      "Loss: 0.45714521408081055 -0.5570821762084961\n",
      "Loss: 0.3467240333557129 -0.3221887946128845\n",
      "Loss: 0.43196427822113037 -0.8076528310775757\n",
      "Policy Reward: tensor(1.1910, device='cuda:0')\n",
      "Trajectory:  ['0.02', '1.00', '0.53', '0.44', '0.72', '0.62', '0.37', '0.07', '0.01', '0.01', '0.04', '0.32', '0.54', '0.71', '0.89', '0.77', '0.58', '0.42', '0.40']\n",
      "Last Action:  tensor([0.3950, 0.7167, 0.3575, 0.1983, 0.4247, 0.6489, 0.1666, 0.8546, 0.6172,\n",
      "        0.4640], device='cuda:0')\n",
      "Loss: 0.42918312549591064 -0.4195118546485901\n",
      "Loss: 0.5043056011199951 -0.8686593770980835\n",
      "Loss: 0.3983268439769745 -0.584375262260437\n",
      "Loss: 0.3466280698776245 -0.4561980664730072\n",
      "Loss: 0.3708922564983368 -0.4319913983345032\n",
      "Loss: 0.3298148214817047 -0.532520592212677\n",
      "Loss: 0.3900344669818878 -0.27364298701286316\n",
      "Policy Reward: tensor(1.0771, device='cuda:0')\n",
      "Trajectory:  ['0.96', '0.88', '0.50', '0.16', '0.13', '0.38', '0.33', '0.17', '0.06', '0.23', '0.14', '0.24', '0.09', '0.66', '0.96', '1.00', '1.00', '1.00', '0.96']\n",
      "Last Action:  tensor([0.9613, 0.5812, 0.9272, 0.2540, 0.0609, 0.9816, 0.1249, 0.9018, 0.9279,\n",
      "        0.9142], device='cuda:0')\n",
      "Loss: 0.422442227602005 -0.6079018712043762\n",
      "Loss: 0.5005802512168884 -1.0019561052322388\n",
      "Loss: 0.4617099463939667 -0.7446529865264893\n",
      "Loss: 0.3850843608379364 -0.5530681014060974\n",
      "Loss: 0.3932592272758484 -0.7575933933258057\n",
      "Loss: 0.4180212616920471 -0.44436126947402954\n",
      "Loss: 0.38167881965637207 -0.5167920589447021\n",
      "Policy Reward: tensor(1.0734, device='cuda:0')\n",
      "Trajectory:  ['0.97', '0.88', '0.50', '0.12', '0.06', '0.29', '0.40', '0.64', '0.66', '0.78', '0.70', '0.66', '0.51', '0.48', '0.92', '1.00', '1.00', '1.00', '0.95']\n",
      "Last Action:  tensor([0.9524, 0.9084, 0.5163, 0.6300, 0.9613, 0.3037, 0.8305, 0.9787, 0.7957,\n",
      "        0.5379], device='cuda:0')\n",
      "Loss: 0.43998807668685913 -0.7151815295219421\n",
      "Loss: 0.4731236398220062 -0.8337748050689697\n",
      "Loss: 0.37034210562705994 -0.22562335431575775\n",
      "Loss: 0.36604443192481995 -0.5634262561798096\n",
      "Loss: 0.4247475862503052 -0.37716174125671387\n",
      "Loss: 0.42189091444015503 -0.8616697788238525\n",
      "Loss: 0.4743744730949402 -0.5553303956985474\n",
      "Policy Reward: tensor(1.0855, device='cuda:0')\n",
      "Trajectory:  ['0.20', '0.19', '0.01', '0.00', '0.35', '0.45', '0.38', '0.23', '0.29', '0.69', '0.30', '0.29', '0.58', '0.90', '0.97', '1.00', '0.94', '0.24', '0.26']\n",
      "Last Action:  tensor([0.2570, 0.9652, 0.8192, 0.9009, 0.7024, 0.9505, 0.1791, 0.5850, 0.9925,\n",
      "        0.9049], device='cuda:0')\n",
      "Loss: 0.3852803707122803 -0.46738168597221375\n",
      "Loss: 0.39440566301345825 -0.3841606676578522\n",
      "Loss: 0.4398139417171478 -0.4158829152584076\n",
      "Loss: 0.39883315563201904 -0.3885200321674347\n",
      "Loss: 0.435817688703537 -0.5823637247085571\n",
      "Loss: 0.4456961154937744 -0.8233466148376465\n",
      "Loss: 0.3927476704120636 -0.6625218987464905\n",
      "Policy Reward: tensor(1.1041, device='cuda:0')\n",
      "Trajectory:  ['0.26', '1.00', '0.01', '0.00', '0.21', '0.31', '0.24', '0.27', '0.12', '0.02', '0.00', '0.02', '0.11', '0.35', '0.72', '0.82', '0.74', '0.49', '0.45']\n",
      "Last Action:  tensor([0.4481, 0.6751, 0.6152, 0.5685, 0.6665, 0.7759, 0.8157, 0.7318, 0.6865,\n",
      "        0.4605], device='cuda:0')\n",
      "Loss: 0.45278677344322205 -0.6693977117538452\n",
      "Loss: 0.4633669853210449 -0.7116674780845642\n",
      "Loss: 0.4098658561706543 -0.6090002059936523\n",
      "Loss: 0.398546427488327 -0.5033709406852722\n",
      "Loss: 0.3473518490791321 -0.4428292512893677\n",
      "Loss: 0.44909676909446716 -0.4891286790370941\n",
      "Loss: 0.4129379689693451 -0.5718511343002319\n",
      "Policy Reward: tensor(1.1172, device='cuda:0')\n",
      "Trajectory:  ['0.28', '0.43', '0.03', '0.01', '0.27', '0.19', '0.41', '0.17', '0.10', '0.07', '0.07', '0.05', '0.11', '0.66', '0.98', '0.99', '0.96', '0.37', '0.63']\n",
      "Last Action:  tensor([0.6294, 0.4263, 0.1935, 0.3090, 0.2424, 0.2091, 0.3637, 0.6028, 0.5102,\n",
      "        0.1687], device='cuda:0')\n",
      "Bigstep:  84\n",
      "Loss: 0.3911629617214203 -0.0684770718216896\n",
      "Loss: 0.43092167377471924 0.2833288908004761\n",
      "Loss: 0.4259471297264099 -0.1932055950164795\n",
      "Loss: 0.4177686274051666 -0.3192594051361084\n",
      "Loss: 0.3849068880081177 -0.3496740758419037\n",
      "Loss: 0.36907950043678284 -0.04390446096658707\n",
      "Loss: 0.4682762324810028 -0.7301488518714905\n",
      "Policy Reward: tensor(1.2184, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.55', '0.70', '0.74', '0.69', '0.55', '0.22', '0.04', '0.01', '0.00', '0.00', '0.01', '0.03', '0.26', '0.69', '0.99', '0.95', '0.75']\n",
      "Last Action:  tensor([0.7473, 0.7601, 0.5097, 0.1953, 0.3186, 0.3264, 0.9063, 0.9869, 0.9817,\n",
      "        0.3900], device='cuda:0')\n",
      "Loss: 0.43339821696281433 -0.5602510571479797\n",
      "Loss: 0.38836541771888733 -0.5753136873245239\n",
      "Loss: 0.3560253381729126 -0.1424179971218109\n",
      "Loss: 0.4269241988658905 -0.6559197902679443\n",
      "Loss: 0.40795496106147766 -0.34886905550956726\n",
      "Loss: 0.44856733083724976 -0.5682016015052795\n",
      "Loss: 0.31727197766304016 -0.2860598564147949\n",
      "Policy Reward: tensor(1.1601, device='cuda:0')\n",
      "Trajectory:  ['0.79', '0.11', '0.70', '0.05', '0.53', '0.44', '0.55', '0.39', '0.04', '0.00', '0.00', '0.00', '0.00', '0.06', '0.34', '0.87', '0.85', '0.83', '0.53']\n",
      "Last Action:  tensor([0.5263, 0.5315, 0.8481, 0.2280, 0.5292, 0.0607, 0.5928, 0.1965, 0.2144,\n",
      "        0.8772], device='cuda:0')\n",
      "Loss: 0.38855424523353577 -0.3356156349182129\n",
      "Loss: 0.36599695682525635 -0.4432898163795471\n",
      "Loss: 0.40526890754699707 -0.5550485849380493\n",
      "Loss: 0.40989258885383606 -0.8634510636329651\n",
      "Loss: 0.43099966645240784 -0.31889545917510986\n",
      "Loss: 0.40241265296936035 -0.22597819566726685\n",
      "Loss: 0.4100707173347473 -0.564762532711029\n",
      "Policy Reward: tensor(1.1689, device='cuda:0')\n",
      "Trajectory:  ['0.98', '0.94', '0.77', '0.33', '0.10', '0.60', '0.29', '0.27', '0.04', '0.00', '0.00', '0.00', '0.05', '0.58', '1.00', '1.00', '0.99', '0.98', '0.89']\n",
      "Last Action:  tensor([0.8917, 0.4774, 0.2515, 0.9426, 0.2143, 0.1885, 0.5295, 0.0903, 0.1235,\n",
      "        0.3488], device='cuda:0')\n",
      "Loss: 0.38107991218566895 -0.4286598563194275\n",
      "Loss: 0.435701847076416 -0.3872881531715393\n",
      "Loss: 0.3843574523925781 -0.6223615407943726\n",
      "Loss: 0.38008251786231995 -0.2820250988006592\n",
      "Loss: 0.38730838894844055 -0.7498291730880737\n",
      "Loss: 0.3904457092285156 -0.6040014028549194\n",
      "Loss: 0.3692476451396942 -0.7300671935081482\n",
      "Policy Reward: tensor(1.1313, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.54', '0.81', '0.81', '0.62', '0.35', '0.04', '0.00', '0.00', '0.00', '0.04', '0.19', '0.56', '0.82', '0.84', '0.68', '0.38', '0.14']\n",
      "Last Action:  tensor([0.1423, 0.3070, 0.4611, 0.8272, 0.1164, 0.4016, 0.4624, 0.1104, 0.1477,\n",
      "        0.3946], device='cuda:0')\n",
      "Loss: 0.390653133392334 -0.40229806303977966\n",
      "Loss: 0.3897562026977539 -0.7020978927612305\n",
      "Loss: 0.2760382294654846 -0.3245295286178589\n",
      "Loss: 0.4403136372566223 -0.680400013923645\n",
      "Loss: 0.3652935028076172 -0.28891080617904663\n",
      "Loss: 0.47404488921165466 -0.5293200016021729\n",
      "Loss: 0.33390945196151733 -0.307009756565094\n",
      "Policy Reward: tensor(1.1558, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.41', '0.72', '0.75', '0.62', '0.37', '0.11', '0.01', '0.00', '0.00', '0.00', '0.03', '0.26', '0.60', '0.86', '0.65', '0.73', '0.37']\n",
      "Last Action:  tensor([0.3665, 0.3088, 0.1564, 0.3564, 0.3410, 0.5239, 0.7637, 0.2949, 0.2019,\n",
      "        0.3232], device='cuda:0')\n",
      "Loss: 0.34513649344444275 -0.5512457489967346\n",
      "Loss: 0.43323007225990295 -0.8491554260253906\n",
      "Loss: 0.46181541681289673 -0.7340993285179138\n",
      "Loss: 0.3331783413887024 -0.21658748388290405\n",
      "Loss: 0.37940096855163574 -0.374750554561615\n",
      "Loss: 0.36527279019355774 -0.2766735553741455\n",
      "Loss: 0.3231474459171295 -0.4302963316440582\n",
      "Policy Reward: tensor(1.2030, device='cuda:0')\n",
      "Trajectory:  ['0.44', '1.00', '0.65', '0.43', '0.62', '0.47', '0.27', '0.02', '0.00', '0.00', '0.00', '0.00', '0.02', '0.15', '0.68', '0.96', '0.87', '0.82', '0.57']\n",
      "Last Action:  tensor([0.5671, 0.6188, 0.5679, 0.4780, 0.4717, 0.1660, 0.3819, 0.9942, 0.4101,\n",
      "        0.4803], device='cuda:0')\n",
      "Loss: 0.46055540442466736 -0.6325342059135437\n",
      "Loss: 0.35090187191963196 -0.2533564567565918\n",
      "Loss: 0.37658044695854187 -0.44388455152511597\n",
      "Loss: 0.34356996417045593 -0.6174310445785522\n",
      "Loss: 0.37882423400878906 -0.4296242892742157\n",
      "Loss: 0.3982715308666229 -0.6262416243553162\n",
      "Loss: 0.46507495641708374 -0.5181235671043396\n",
      "Policy Reward: tensor(1.1797, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.32', '0.60', '0.83', '0.70', '0.38', '0.02', '0.00', '0.00', '0.00', '0.01', '0.20', '0.89', '0.84', '0.88', '0.49', '0.29', '0.10']\n",
      "Last Action:  tensor([0.1019, 0.8403, 0.5776, 0.2859, 0.4586, 0.4088, 0.3590, 0.5668, 0.3147,\n",
      "        0.0711], device='cuda:0')\n",
      "Loss: 0.3310861587524414 -0.3899027407169342\n",
      "Loss: 0.37679579854011536 -0.544338047504425\n",
      "Loss: 0.43214330077171326 -0.5135307312011719\n",
      "Loss: 0.48485130071640015 -0.9818761348724365\n",
      "Loss: 0.4144200086593628 -0.45143911242485046\n",
      "Loss: 0.34782642126083374 -0.5013817548751831\n",
      "Loss: 0.33963045477867126 -0.3375729024410248\n",
      "Policy Reward: tensor(1.1422, device='cuda:0')\n",
      "Trajectory:  ['0.14', '1.00', '0.69', '0.11', '0.82', '0.62', '0.38', '0.03', '0.00', '0.00', '0.00', '0.05', '0.51', '0.56', '0.90', '0.73', '0.51', '0.08', '0.10']\n",
      "Last Action:  tensor([0.0973, 0.2267, 0.5700, 0.3142, 0.4710, 0.2621, 0.2244, 0.7251, 0.2762,\n",
      "        0.3409], device='cuda:0')\n",
      "Bigstep:  85\n",
      "Loss: 0.4033542275428772 -0.10767686367034912\n",
      "Loss: 0.4159458577632904 -0.5663021802902222\n",
      "Loss: 0.3261259198188782 -0.2215636968612671\n",
      "Loss: 0.3271111249923706 0.1972242295742035\n",
      "Loss: 0.3445959687232971 -0.21570351719856262\n",
      "Loss: 0.4538661539554596 -0.7591843605041504\n",
      "Loss: 0.3614293038845062 -0.20280307531356812\n",
      "Policy Reward: tensor(1.1234, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.71', '0.81', '0.73', '0.65', '0.39', '0.04', '0.00', '0.00', '0.00', '0.00', '0.02', '0.12', '0.51', '0.96', '0.97', '0.84', '0.54']\n",
      "Last Action:  tensor([0.5402, 0.9874, 0.3576, 0.3403, 0.7584, 0.7467, 0.1245, 0.1943, 0.3417,\n",
      "        0.5364], device='cuda:0')\n",
      "Loss: 0.40320834517478943 -0.312837153673172\n",
      "Loss: 0.3685430586338043 -0.35315829515457153\n",
      "Loss: 0.36064064502716064 -0.4071616232395172\n",
      "Loss: 0.5015362501144409 -0.651283860206604\n",
      "Loss: 0.3661488890647888 -0.3582383990287781\n",
      "Loss: 0.4272584319114685 -0.5598745346069336\n",
      "Loss: 0.326810359954834 -0.538428008556366\n",
      "Policy Reward: tensor(1.2424, device='cuda:0')\n",
      "Trajectory:  ['0.98', '0.85', '0.11', '0.01', '0.61', '0.43', '0.68', '0.54', '0.39', '0.24', '0.20', '0.08', '0.02', '0.01', '0.12', '0.97', '1.00', '1.00', '0.86']\n",
      "Last Action:  tensor([0.8643, 0.1138, 0.3876, 0.8641, 0.3806, 0.9017, 0.9991, 0.5121, 0.2678,\n",
      "        0.0386], device='cuda:0')\n",
      "Loss: 0.45256003737449646 -0.5931388139724731\n",
      "Loss: 0.3786066472530365 -0.5331241488456726\n",
      "Loss: 0.37199145555496216 -0.4315500855445862\n",
      "Loss: 0.3687974214553833 -0.2470385581254959\n",
      "Loss: 0.4274437129497528 -0.3841002583503723\n",
      "Loss: 0.38653624057769775 -0.3610161542892456\n",
      "Loss: 0.4708019495010376 -0.728867769241333\n",
      "Policy Reward: tensor(1.2100, device='cuda:0')\n",
      "Trajectory:  ['0.48', '0.62', '0.01', '0.00', '0.23', '0.17', '0.30', '0.14', '0.01', '0.00', '0.00', '0.00', '0.04', '0.29', '0.37', '0.85', '0.64', '0.33', '0.11']\n",
      "Last Action:  tensor([0.1146, 0.5713, 0.2530, 0.1684, 0.8470, 0.0863, 0.3738, 0.4437, 0.7578,\n",
      "        0.9238], device='cuda:0')\n",
      "Loss: 0.4229861795902252 -0.5249319672584534\n",
      "Loss: 0.41782060265541077 -0.6421608924865723\n",
      "Loss: 0.3996880054473877 -0.5484061241149902\n",
      "Loss: 0.3890842795372009 -0.7500783205032349\n",
      "Loss: 0.3890237510204315 -0.20629513263702393\n",
      "Loss: 0.488595575094223 -0.6109310984611511\n",
      "Loss: 0.4096878468990326 -0.36912429332733154\n",
      "Policy Reward: tensor(1.1304, device='cuda:0')\n",
      "Trajectory:  ['0.05', '1.00', '0.67', '0.06', '0.30', '0.40', '0.07', '0.01', '0.01', '0.02', '0.03', '0.03', '0.07', '0.67', '1.00', '1.00', '0.99', '0.61', '0.20']\n",
      "Last Action:  tensor([0.2020, 0.9945, 0.5262, 0.3575, 0.1880, 0.2515, 0.5248, 0.6837, 0.2688,\n",
      "        0.1161], device='cuda:0')\n",
      "Loss: 0.36894044280052185 -0.5469821691513062\n",
      "Loss: 0.3776901960372925 -0.41225144267082214\n",
      "Loss: 0.33523011207580566 -0.4892679452896118\n",
      "Loss: 0.41708269715309143 -0.4575217068195343\n",
      "Loss: 0.3778754770755768 -0.7555317878723145\n",
      "Loss: 0.38885363936424255 -0.5494588613510132\n",
      "Loss: 0.40591832995414734 -0.6644489765167236\n",
      "Policy Reward: tensor(1.0398, device='cuda:0')\n",
      "Trajectory:  ['0.99', '0.95', '0.42', '0.01', '0.34', '0.45', '0.33', '0.26', '0.01', '0.00', '0.00', '0.01', '0.17', '0.84', '1.00', '0.97', '0.76', '0.21', '0.07']\n",
      "Last Action:  tensor([0.0712, 0.3733, 0.3144, 0.2524, 0.3685, 0.9469, 0.2435, 0.2791, 0.6535,\n",
      "        0.7623], device='cuda:0')\n",
      "Loss: 0.4039391875267029 -0.39818960428237915\n",
      "Loss: 0.36745527386665344 -0.202876478433609\n",
      "Loss: 0.4028148949146271 -0.6209192276000977\n",
      "Loss: 0.41389504075050354 -0.42451125383377075\n",
      "Loss: 0.4426150918006897 -0.6649050712585449\n",
      "Loss: 0.4025804102420807 -0.5971548557281494\n",
      "Loss: 0.36337924003601074 -0.6808682084083557\n",
      "Policy Reward: tensor(1.0720, device='cuda:0')\n",
      "Trajectory:  ['0.65', '0.03', '0.51', '0.02', '0.37', '0.45', '0.41', '0.23', '0.01', '0.00', '0.00', '0.00', '0.04', '0.47', '0.99', '0.94', '0.49', '0.36', '0.18']\n",
      "Last Action:  tensor([0.1761, 0.1720, 0.4252, 0.4678, 0.2038, 0.9329, 0.2429, 0.6183, 0.6077,\n",
      "        0.0592], device='cuda:0')\n",
      "Loss: 0.3566994071006775 -0.3353508710861206\n",
      "Loss: 0.3721816837787628 -0.5190812349319458\n",
      "Loss: 0.3955194354057312 -0.6015520691871643\n",
      "Loss: 0.43783122301101685 -0.4209159314632416\n",
      "Loss: 0.383372038602829 -0.41787058115005493\n",
      "Loss: 0.3727887272834778 -0.6566911935806274\n",
      "Loss: 0.41462230682373047 -0.41291606426239014\n",
      "Policy Reward: tensor(1.1269, device='cuda:0')\n",
      "Trajectory:  ['0.48', '1.00', '0.74', '0.01', '0.19', '0.42', '0.10', '0.01', '0.01', '0.01', '0.01', '0.01', '0.05', '0.89', '1.00', '1.00', '1.00', '0.98', '0.86']\n",
      "Last Action:  tensor([0.8579, 0.4136, 0.9848, 0.3070, 0.2543, 0.4151, 0.7689, 0.3390, 0.2900,\n",
      "        0.5456], device='cuda:0')\n",
      "Loss: 0.4066307842731476 -0.7388483881950378\n",
      "Loss: 0.4379369020462036 -0.369072288274765\n",
      "Loss: 0.33190926909446716 -0.28215909004211426\n",
      "Loss: 0.3579455614089966 -0.5752559304237366\n",
      "Loss: 0.35317251086235046 -0.29295462369918823\n",
      "Loss: 0.4339750409126282 -0.8321301341056824\n",
      "Loss: 0.3935939371585846 -0.4087733030319214\n",
      "Policy Reward: tensor(1.1376, device='cuda:0')\n",
      "Trajectory:  ['0.98', '0.72', '0.01', '0.01', '0.61', '0.31', '0.26', '0.25', '0.16', '0.26', '0.24', '0.60', '0.58', '0.03', '0.00', '0.01', '0.39', '0.98', '1.00']\n",
      "Last Action:  tensor([0.9998, 0.2260, 0.3344, 0.9936, 0.3061, 0.2606, 0.3340, 0.9531, 0.4194,\n",
      "        0.2611], device='cuda:0')\n",
      "Bigstep:  86\n",
      "Loss: 0.4276758134365082 -0.05968841165304184\n",
      "Loss: 0.3870072662830353 0.4754584729671478\n",
      "Loss: 0.4800490438938141 -0.6749191880226135\n",
      "Loss: 0.3684022128582001 0.20085613429546356\n",
      "Loss: 0.39339011907577515 0.02030152827501297\n",
      "Loss: 0.39581039547920227 -0.25056391954421997\n",
      "Loss: 0.47889214754104614 -0.2968427538871765\n",
      "Policy Reward: tensor(1.0907, device='cuda:0')\n",
      "Trajectory:  ['0.46', '0.32', '0.01', '0.00', '0.35', '0.49', '0.72', '0.78', '0.20', '0.13', '0.15', '0.09', '0.08', '0.96', '1.00', '0.94', '0.55', '0.31', '0.03']\n",
      "Last Action:  tensor([0.0252, 0.3229, 0.1295, 0.1324, 0.1247, 0.1846, 0.0177, 0.4136, 0.4192,\n",
      "        0.2378], device='cuda:0')\n",
      "Loss: 0.3550928831100464 -0.11792226135730743\n",
      "Loss: 0.38570794463157654 -0.45716047286987305\n",
      "Loss: 0.32360804080963135 -0.11813428997993469\n",
      "Loss: 0.3451462984085083 -0.36038169264793396\n",
      "Loss: 0.3587014079093933 0.20104479789733887\n",
      "Loss: 0.36554640531539917 -0.32917520403862\n",
      "Loss: 0.5234238505363464 -0.7391473650932312\n",
      "Policy Reward: tensor(1.2587, device='cuda:0')\n",
      "Trajectory:  ['0.17', '1.00', '0.38', '0.00', '0.45', '0.34', '0.30', '0.09', '0.00', '0.00', '0.00', '0.01', '0.06', '0.44', '0.94', '0.76', '0.62', '0.35', '0.42']\n",
      "Last Action:  tensor([0.4232, 0.0875, 0.3579, 0.2598, 0.3895, 0.0683, 0.3078, 0.4046, 0.9450,\n",
      "        0.3767], device='cuda:0')\n",
      "Loss: 0.429982453584671 -0.17985674738883972\n",
      "Loss: 0.4703516364097595 -0.5466015338897705\n",
      "Loss: 0.3380589485168457 -0.17674335837364197\n",
      "Loss: 0.37527021765708923 -0.4333834946155548\n",
      "Loss: 0.3900117874145508 -0.15535816550254822\n",
      "Loss: 0.3605988323688507 -0.1044156551361084\n",
      "Loss: 0.4178473651409149 -0.5747154355049133\n",
      "Policy Reward: tensor(1.1144, device='cuda:0')\n",
      "Trajectory:  ['0.44', '0.02', '0.66', '0.01', '0.45', '0.31', '0.45', '0.27', '0.06', '0.00', '0.00', '0.00', '0.02', '0.26', '0.90', '0.76', '0.77', '0.43', '0.31']\n",
      "Last Action:  tensor([0.3071, 0.0530, 0.9758, 0.0676, 0.9168, 0.2072, 0.9849, 0.3047, 0.2948,\n",
      "        0.1271], device='cuda:0')\n",
      "Loss: 0.4219740629196167 -0.7562633752822876\n",
      "Loss: 0.38690388202667236 0.022177323698997498\n",
      "Loss: 0.4872433543205261 -0.9024471044540405\n",
      "Loss: 0.36630523204803467 -0.3012934923171997\n",
      "Loss: 0.3832416236400604 -0.4207904636859894\n",
      "Loss: 0.39865630865097046 -0.28363683819770813\n",
      "Loss: 0.36581361293792725 0.055143147706985474\n",
      "Policy Reward: tensor(1.1275, device='cuda:0')\n",
      "Trajectory:  ['0.86', '0.66', '0.02', '0.01', '0.65', '0.31', '0.52', '0.35', '0.09', '0.00', '0.00', '0.00', '0.06', '0.66', '1.00', '0.96', '0.42', '0.13', '0.18']\n",
      "Last Action:  tensor([0.1770, 0.9600, 0.1178, 0.0700, 0.1637, 0.2333, 0.3303, 0.0564, 0.0678,\n",
      "        0.2435], device='cuda:0')\n",
      "Loss: 0.4115021824836731 -0.3539862036705017\n",
      "Loss: 0.3344622254371643 -0.259838342666626\n",
      "Loss: 0.44033902883529663 -0.4404577314853668\n",
      "Loss: 0.4795358180999756 -0.7122061252593994\n",
      "Loss: 0.35974952578544617 -0.46681609749794006\n",
      "Loss: 0.3443339169025421 -0.201941579580307\n",
      "Loss: 0.3228703737258911 0.00453547015786171\n",
      "Policy Reward: tensor(1.1571, device='cuda:0')\n",
      "Trajectory:  ['0.22', '0.26', '0.04', '0.02', '0.04', '0.12', '0.33', '0.83', '0.95', '0.62', '0.27', '0.15', '0.09', '0.11', '0.13', '0.17', '0.25', '0.44', '0.61']\n",
      "Last Action:  tensor([0.6137, 0.5604, 0.5135, 0.0807, 0.2347, 0.9423, 0.3634, 0.1796, 0.1267,\n",
      "        0.3491], device='cuda:0')\n",
      "Loss: 0.43221384286880493 -0.4503571391105652\n",
      "Loss: 0.4999604821205139 -0.7550971508026123\n",
      "Loss: 0.4051848351955414 -0.6700008511543274\n",
      "Loss: 0.39605677127838135 -0.15196484327316284\n",
      "Loss: 0.3259005844593048 -0.28131186962127686\n",
      "Loss: 0.3703159689903259 -0.19129733741283417\n",
      "Loss: 0.3363019824028015 -0.3352086842060089\n",
      "Policy Reward: tensor(1.2440, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.77', '0.63', '0.64', '0.74', '0.61', '0.57', '0.48', '0.16', '0.05', '0.02', '0.01', '0.01', '0.12', '0.92', '1.00', '0.95', '0.55']\n",
      "Last Action:  tensor([0.5463, 0.1310, 0.5498, 0.2832, 0.2316, 0.2302, 0.2364, 0.4304, 0.2417,\n",
      "        0.1633], device='cuda:0')\n",
      "Loss: 0.3980861008167267 -0.5459600687026978\n",
      "Loss: 0.3691021800041199 -0.12686565518379211\n",
      "Loss: 0.4220825731754303 -0.6799001693725586\n",
      "Loss: 0.40648940205574036 -0.7819308042526245\n",
      "Loss: 0.45770350098609924 -0.5191057920455933\n",
      "Loss: 0.3351190686225891 -0.0543086901307106\n",
      "Loss: 0.43641752004623413 -0.5751449465751648\n",
      "Policy Reward: tensor(1.1329, device='cuda:0')\n",
      "Trajectory:  ['0.31', '0.89', '0.00', '0.00', '0.26', '0.12', '0.31', '0.35', '0.21', '0.03', '0.00', '0.00', '0.03', '0.39', '0.96', '0.73', '0.55', '0.56', '0.32']\n",
      "Last Action:  tensor([0.3222, 0.2136, 0.1303, 0.1476, 0.2004, 0.0848, 0.3429, 0.2353, 0.1495,\n",
      "        0.1237], device='cuda:0')\n",
      "Loss: 0.34975796937942505 -0.2579396367073059\n",
      "Loss: 0.3841356635093689 -0.43559393286705017\n",
      "Loss: 0.41617366671562195 -0.45877203345298767\n",
      "Loss: 0.46354222297668457 -0.5527870655059814\n",
      "Loss: 0.3099544942378998 0.027423039078712463\n",
      "Loss: 0.3329105079174042 -0.6737781763076782\n",
      "Loss: 0.4051365852355957 -0.6395622491836548\n",
      "Policy Reward: tensor(1.0695, device='cuda:0')\n",
      "Trajectory:  ['0.85', '0.10', '0.80', '0.03', '0.45', '0.38', '0.46', '0.43', '0.20', '0.01', '0.00', '0.01', '0.31', '0.74', '1.00', '0.99', '0.39', '0.05', '0.17']\n",
      "Last Action:  tensor([0.1696, 0.2503, 0.0787, 0.6435, 0.2002, 0.3099, 0.2967, 0.9587, 0.2090,\n",
      "        0.7330], device='cuda:0')\n",
      "Bigstep:  87\n",
      "Loss: 0.41765084862709045 -0.2018299400806427\n",
      "Loss: 0.39267829060554504 0.11036360263824463\n",
      "Loss: 0.3810482323169708 0.13213923573493958\n",
      "Loss: 0.3920707702636719 -0.10574762523174286\n",
      "Loss: 0.37872058153152466 0.05480117350816727\n",
      "Loss: 0.34832414984703064 0.0976920872926712\n",
      "Loss: 0.4098510444164276 0.0446305051445961\n",
      "Policy Reward: tensor(1.1631, device='cuda:0')\n",
      "Trajectory:  ['0.73', '0.90', '0.05', '0.00', '0.23', '0.17', '0.41', '0.29', '0.10', '0.00', '0.00', '0.00', '0.04', '0.48', '1.00', '0.95', '0.15', '0.20', '0.38']\n",
      "Last Action:  tensor([0.3765, 0.1216, 0.2284, 0.4147, 0.2428, 0.0130, 0.9106, 0.2901, 0.2132,\n",
      "        0.1612], device='cuda:0')\n",
      "Loss: 0.35158029198646545 -0.21994549036026\n",
      "Loss: 0.3741781413555145 -0.24285437166690826\n",
      "Loss: 0.38590970635414124 -0.11020605266094208\n",
      "Loss: 0.33784928917884827 -0.01215783879160881\n",
      "Loss: 0.38725730776786804 -0.34104278683662415\n",
      "Loss: 0.3986179828643799 -0.544287919998169\n",
      "Loss: 0.3951182961463928 0.06619240343570709\n",
      "Policy Reward: tensor(1.2391, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.84', '0.70', '0.61', '0.55', '0.37', '0.09', '0.00', '0.00', '0.00', '0.01', '0.15', '0.90', '0.99', '0.82', '0.41', '0.33', '0.21']\n",
      "Last Action:  tensor([0.2075, 0.2073, 0.0757, 0.5689, 0.3263, 0.1902, 0.1502, 0.3167, 0.0206,\n",
      "        0.0708], device='cuda:0')\n",
      "Loss: 0.39894697070121765 -0.28999441862106323\n",
      "Loss: 0.3684554994106293 -0.23558618128299713\n",
      "Loss: 0.41864997148513794 -0.22878769040107727\n",
      "Loss: 0.44142356514930725 -0.8731014728546143\n",
      "Loss: 0.41837501525878906 -0.6211413741111755\n",
      "Loss: 0.39257729053497314 -0.3369637131690979\n",
      "Loss: 0.4422014653682709 -0.5825711488723755\n",
      "Policy Reward: tensor(1.1130, device='cuda:0')\n",
      "Trajectory:  ['0.87', '0.99', '0.53', '0.00', '0.06', '0.26', '0.34', '0.13', '0.04', '0.04', '0.09', '0.10', '0.03', '0.04', '0.17', '0.97', '1.00', '1.00', '0.42']\n",
      "Last Action:  tensor([0.4196, 0.1793, 0.4922, 0.4331, 0.3599, 0.3640, 0.0313, 0.0364, 0.9087,\n",
      "        0.2620], device='cuda:0')\n",
      "Loss: 0.36743631958961487 -0.19659627974033356\n",
      "Loss: 0.4010356664657593 -0.5772537589073181\n",
      "Loss: 0.48396730422973633 -0.46011728048324585\n",
      "Loss: 0.4759560227394104 -0.716290295124054\n",
      "Loss: 0.4235438406467438 -0.5420796871185303\n",
      "Loss: 0.41236743330955505 -0.6488549709320068\n",
      "Loss: 0.4088922441005707 -0.49349668622016907\n",
      "Policy Reward: tensor(1.1834, device='cuda:0')\n",
      "Trajectory:  ['0.07', '1.00', '0.83', '0.16', '0.38', '0.46', '0.35', '0.09', '0.01', '0.00', '0.00', '0.00', '0.09', '0.84', '1.00', '1.00', '0.38', '0.05', '0.28']\n",
      "Last Action:  tensor([0.2816, 0.4391, 0.2978, 0.4282, 0.2056, 0.1243, 0.0958, 0.2051, 0.3720,\n",
      "        0.0378], device='cuda:0')\n",
      "Loss: 0.40111082792282104 -0.3190867304801941\n",
      "Loss: 0.3900504410266876 -0.35471585392951965\n",
      "Loss: 0.36987119913101196 0.057785533368587494\n",
      "Loss: 0.4304606020450592 -0.3200351893901825\n",
      "Loss: 0.3416198492050171 -0.17021194100379944\n",
      "Loss: 0.37448275089263916 -0.246766597032547\n",
      "Loss: 0.44383183121681213 -0.5905794501304626\n",
      "Policy Reward: tensor(1.2504, device='cuda:0')\n",
      "Trajectory:  ['0.16', '1.00', '0.11', '0.00', '0.22', '0.27', '0.36', '0.17', '0.03', '0.00', '0.00', '0.00', '0.03', '0.48', '0.93', '0.69', '0.53', '0.31', '0.38']\n",
      "Last Action:  tensor([0.3768, 0.1733, 0.9625, 0.3650, 0.1985, 0.8719, 0.1223, 0.1540, 0.4021,\n",
      "        0.3124], device='cuda:0')\n",
      "Loss: 0.3402293026447296 -0.11644028127193451\n",
      "Loss: 0.33562758564949036 -0.05336173623800278\n",
      "Loss: 0.3284679353237152 -0.3716699779033661\n",
      "Loss: 0.3663170337677002 -0.2402806580066681\n",
      "Loss: 0.36638012528419495 -0.5279543995857239\n",
      "Loss: 0.3637138307094574 -0.2814328670501709\n",
      "Loss: 0.31088677048683167 0.07456693053245544\n",
      "Policy Reward: tensor(1.0450, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.78', '0.57', '0.55', '0.59', '0.39', '0.04', '0.00', '0.00', '0.00', '0.01', '0.30', '0.97', '1.00', '0.65', '0.19', '0.38', '0.27']\n",
      "Last Action:  tensor([0.2744, 0.5385, 0.3604, 0.4909, 0.5427, 0.7196, 0.2326, 0.2372, 0.9742,\n",
      "        0.4284], device='cuda:0')\n",
      "Loss: 0.40958669781684875 -0.5996763110160828\n",
      "Loss: 0.3738848567008972 -0.3216919004917145\n",
      "Loss: 0.386589914560318 -0.19552329182624817\n",
      "Loss: 0.33004021644592285 -0.35941076278686523\n",
      "Loss: 0.44842344522476196 -0.7565146684646606\n",
      "Loss: 0.3645564019680023 -0.356788694858551\n",
      "Loss: 0.4666605591773987 -0.5416271090507507\n",
      "Policy Reward: tensor(1.0723, device='cuda:0')\n",
      "Trajectory:  ['0.06', '1.00', '0.69', '0.04', '0.56', '0.49', '0.39', '0.09', '0.00', '0.00', '0.00', '0.00', '0.10', '0.88', '0.89', '0.68', '0.22', '0.16', '0.16']\n",
      "Last Action:  tensor([0.1592, 0.2048, 0.3029, 0.4332, 0.9239, 0.1420, 0.2321, 0.1470, 0.4072,\n",
      "        0.8394], device='cuda:0')\n",
      "Loss: 0.4422285854816437 -0.4644969403743744\n",
      "Loss: 0.36983075737953186 -0.29053840041160583\n",
      "Loss: 0.38102903962135315 -0.36641740798950195\n",
      "Loss: 0.29774680733680725 -0.04078983515501022\n",
      "Loss: 0.5331218242645264 -0.8601524829864502\n",
      "Loss: 0.42526480555534363 -0.5694800019264221\n",
      "Loss: 0.382542222738266 -0.843296229839325\n",
      "Policy Reward: tensor(1.1424, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.50', '0.65', '0.55', '0.43', '0.30', '0.12', '0.01', '0.00', '0.01', '0.03', '0.11', '0.45', '0.76', '0.83', '0.57', '0.29', '0.13']\n",
      "Last Action:  tensor([0.1278, 0.4498, 0.1725, 0.3276, 0.4357, 0.1993, 0.3436, 0.0414, 0.2137,\n",
      "        0.3775], device='cuda:0')\n",
      "Bigstep:  88\n",
      "Loss: 0.39839714765548706 -0.12648355960845947\n",
      "Loss: 0.41865378618240356 0.13113059103488922\n",
      "Loss: 0.39903566241264343 -0.07908272743225098\n",
      "Loss: 0.3984651267528534 -0.06758368760347366\n",
      "Loss: 0.3442680239677429 -0.17793872952461243\n",
      "Loss: 0.41732364892959595 -0.4311143457889557\n",
      "Loss: 0.4339821934700012 -0.5701818466186523\n",
      "Policy Reward: tensor(1.2067, device='cuda:0')\n",
      "Trajectory:  ['0.11', '0.88', '0.20', '0.01', '0.57', '0.28', '0.55', '0.05', '0.00', '0.00', '0.00', '0.01', '0.02', '0.13', '0.83', '1.00', '1.00', '0.52', '0.10']\n",
      "Last Action:  tensor([0.1038, 0.2549, 0.2440, 0.3247, 0.2333, 0.2088, 0.0970, 0.0196, 0.0389,\n",
      "        0.4112], device='cuda:0')\n",
      "Loss: 0.38142043352127075 -0.24308082461357117\n",
      "Loss: 0.4054163694381714 -0.24599269032478333\n",
      "Loss: 0.3897280693054199 -0.3935157358646393\n",
      "Loss: 0.39246952533721924 -0.37282276153564453\n",
      "Loss: 0.46175602078437805 -0.5089941024780273\n",
      "Loss: 0.4532335698604584 -0.45014461874961853\n",
      "Loss: 0.41546332836151123 -0.5595019459724426\n",
      "Policy Reward: tensor(1.2406, device='cuda:0')\n",
      "Trajectory:  ['0.29', '0.14', '0.59', '0.42', '0.50', '0.45', '0.44', '0.05', '0.00', '0.00', '0.00', '0.00', '0.04', '0.61', '0.99', '0.92', '0.48', '0.19', '0.54']\n",
      "Last Action:  tensor([0.5378, 0.4873, 0.1509, 0.2895, 0.2741, 0.3225, 0.4571, 0.9705, 0.5221,\n",
      "        0.2919], device='cuda:0')\n",
      "Loss: 0.394059956073761 -0.5760390758514404\n",
      "Loss: 0.3493032157421112 -0.1434158980846405\n",
      "Loss: 0.42688271403312683 -0.3162018358707428\n",
      "Loss: 0.43953937292099 -0.6078232526779175\n",
      "Loss: 0.36617040634155273 -0.5588722229003906\n",
      "Loss: 0.36870160698890686 -0.3156477212905884\n",
      "Loss: 0.45101410150527954 -0.17252908647060394\n",
      "Policy Reward: tensor(1.2712, device='cuda:0')\n",
      "Trajectory:  ['0.11', '0.08', '0.01', '0.02', '0.69', '0.40', '0.40', '0.02', '0.00', '0.00', '0.00', '0.00', '0.20', '0.96', '1.00', '1.00', '0.37', '0.10', '0.42']\n",
      "Last Action:  tensor([0.4167, 0.3468, 0.2487, 0.9945, 0.9698, 0.9920, 0.8010, 0.5737, 0.3570,\n",
      "        0.2447], device='cuda:0')\n",
      "Loss: 0.49812477827072144 -0.7736154198646545\n",
      "Loss: 0.3835390508174896 -0.4553815722465515\n",
      "Loss: 0.3523746728897095 -0.34010404348373413\n",
      "Loss: 0.3997989892959595 -0.20944131910800934\n",
      "Loss: 0.41441887617111206 -0.4561716318130493\n",
      "Loss: 0.34128788113594055 -0.28855013847351074\n",
      "Loss: 0.38060206174850464 -0.4527456760406494\n",
      "Policy Reward: tensor(1.0632, device='cuda:0')\n",
      "Trajectory:  ['0.97', '0.31', '0.41', '0.07', '0.82', '0.52', '0.66', '0.46', '0.09', '0.05', '0.07', '0.06', '0.03', '0.03', '0.57', '1.00', '1.00', '1.00', '0.92']\n",
      "Last Action:  tensor([0.9211, 0.9998, 0.5055, 0.2062, 0.1036, 0.7271, 0.3008, 0.0542, 0.4101,\n",
      "        0.9385], device='cuda:0')\n",
      "Loss: 0.5441024899482727 -0.5340974926948547\n",
      "Loss: 0.3086332082748413 -0.290658175945282\n",
      "Loss: 0.3160848915576935 -0.03599134087562561\n",
      "Loss: 0.42577555775642395 -0.4743425250053406\n",
      "Loss: 0.4891899824142456 -0.6195989847183228\n",
      "Loss: 0.39393293857574463 -0.41548171639442444\n",
      "Loss: 0.35720211267471313 -0.4416724443435669\n",
      "Policy Reward: tensor(1.2308, device='cuda:0')\n",
      "Trajectory:  ['0.08', '0.25', '0.07', '0.29', '0.64', '0.40', '0.46', '0.01', '0.00', '0.00', '0.00', '0.05', '0.63', '0.97', '1.00', '0.65', '0.17', '0.58', '0.23']\n",
      "Last Action:  tensor([0.2317, 0.0849, 0.3774, 0.3076, 0.7682, 0.2092, 0.4641, 0.4779, 0.9278,\n",
      "        0.4807], device='cuda:0')\n",
      "Loss: 0.3653624355792999 -0.45626723766326904\n",
      "Loss: 0.4030989110469818 -0.2551366984844208\n",
      "Loss: 0.4361954927444458 -0.8071786165237427\n",
      "Loss: 0.37693753838539124 -0.41071751713752747\n",
      "Loss: 0.35566824674606323 -0.27695879340171814\n",
      "Loss: 0.3934098184108734 -0.2990391254425049\n",
      "Loss: 0.39925724267959595 -0.3582841753959656\n",
      "Policy Reward: tensor(1.1570, device='cuda:0')\n",
      "Trajectory:  ['0.40', '0.99', '0.34', '0.00', '0.32', '0.44', '0.36', '0.06', '0.00', '0.00', '0.00', '0.00', '0.01', '0.25', '0.80', '0.99', '0.82', '0.32', '0.32']\n",
      "Last Action:  tensor([0.3192, 0.4033, 0.9885, 0.1596, 0.7758, 0.2007, 0.0544, 0.9489, 0.0997,\n",
      "        0.1123], device='cuda:0')\n",
      "Loss: 0.40614908933639526 -0.12500473856925964\n",
      "Loss: 0.39628100395202637 -0.581597626209259\n",
      "Loss: 0.35601821541786194 -0.4160553216934204\n",
      "Loss: 0.3929126262664795 -0.3186087906360626\n",
      "Loss: 0.3695535361766815 -0.11049249768257141\n",
      "Loss: 0.386411190032959 -0.5839840173721313\n",
      "Loss: 0.331645131111145 -0.48586949706077576\n",
      "Policy Reward: tensor(1.2017, device='cuda:0')\n",
      "Trajectory:  ['0.08', '0.99', '0.32', '0.01', '0.42', '0.33', '0.47', '0.07', '0.00', '0.00', '0.00', '0.00', '0.01', '0.23', '0.92', '0.86', '0.68', '0.45', '0.28']\n",
      "Last Action:  tensor([0.2807, 0.8681, 0.3216, 0.1179, 0.8203, 0.4423, 0.4509, 0.3107, 0.4422,\n",
      "        0.3235], device='cuda:0')\n",
      "Loss: 0.45056337118148804 -0.6592816710472107\n",
      "Loss: 0.35287049412727356 -0.47076502442359924\n",
      "Loss: 0.40350306034088135 -0.4527246356010437\n",
      "Loss: 0.44020310044288635 -0.6705070734024048\n",
      "Loss: 0.40585628151893616 -0.5661983489990234\n",
      "Loss: 0.368385910987854 -0.3726690411567688\n",
      "Loss: 0.48494330048561096 -0.9866960644721985\n",
      "Policy Reward: tensor(1.1237, device='cuda:0')\n",
      "Trajectory:  ['0.41', '0.41', '0.61', '0.12', '0.59', '0.36', '0.56', '0.04', '0.00', '0.00', '0.00', '0.00', '0.04', '0.59', '0.87', '0.96', '0.65', '0.12', '0.32']\n",
      "Last Action:  tensor([0.3182, 0.3277, 0.4663, 0.8552, 0.0442, 0.2917, 0.3175, 0.9663, 0.2715,\n",
      "        0.5558], device='cuda:0')\n",
      "Bigstep:  89\n",
      "Loss: 0.511297881603241 -0.6245059370994568\n",
      "Loss: 0.45778945088386536 -0.2122260183095932\n",
      "Loss: 0.378619521856308 -0.21586880087852478\n",
      "Loss: 0.34685108065605164 0.08686457574367523\n",
      "Loss: 0.41005605459213257 -0.442882776260376\n",
      "Loss: 0.4057329297065735 0.13838988542556763\n",
      "Loss: 0.4026050567626953 -0.11635521054267883\n",
      "Policy Reward: tensor(1.2076, device='cuda:0')\n",
      "Trajectory:  ['0.09', '0.99', '0.35', '0.01', '0.44', '0.27', '0.31', '0.03', '0.00', '0.00', '0.00', '0.00', '0.03', '0.47', '0.84', '0.69', '0.53', '0.19', '0.30']\n",
      "Last Action:  tensor([0.3015, 0.4181, 0.1976, 0.5085, 0.4085, 0.7742, 0.2266, 0.1233, 0.1173,\n",
      "        0.2152], device='cuda:0')\n",
      "Loss: 0.4756533205509186 -0.5027922987937927\n",
      "Loss: 0.44464802742004395 -0.43154284358024597\n",
      "Loss: 0.4446888566017151 -0.831177830696106\n",
      "Loss: 0.4056940972805023 -0.3112165331840515\n",
      "Loss: 0.34978166222572327 0.07061643153429031\n",
      "Loss: 0.4434939920902252 -0.35338452458381653\n",
      "Loss: 0.37430888414382935 -0.35892826318740845\n",
      "Policy Reward: tensor(1.0237, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.51', '0.72', '0.54', '0.41', '0.24', '0.05', '0.00', '0.00', '0.00', '0.00', '0.02', '0.28', '0.83', '0.71', '0.48', '0.25', '0.33']\n",
      "Last Action:  tensor([0.3347, 0.0767, 0.0839, 0.2254, 0.3898, 0.2916, 0.5169, 0.1892, 0.0855,\n",
      "        0.1261], device='cuda:0')\n",
      "Loss: 0.42841774225234985 -0.17823368310928345\n",
      "Loss: 0.42953431606292725 -0.396470844745636\n",
      "Loss: 0.4055872857570648 -0.4712313115596771\n",
      "Loss: 0.4089667499065399 -0.6337938904762268\n",
      "Loss: 0.39253148436546326 -0.42908209562301636\n",
      "Loss: 0.41094106435775757 -0.16881000995635986\n",
      "Loss: 0.3492056429386139 -0.08577860891819\n",
      "Policy Reward: tensor(1.1640, device='cuda:0')\n",
      "Trajectory:  ['0.07', '0.94', '0.37', '0.00', '0.46', '0.24', '0.38', '0.02', '0.00', '0.00', '0.00', '0.00', '0.01', '0.32', '0.74', '0.49', '0.53', '0.35', '0.07']\n",
      "Last Action:  tensor([0.0656, 0.2463, 0.4058, 0.2360, 0.3163, 0.4415, 0.3150, 0.0955, 0.5245,\n",
      "        0.2137], device='cuda:0')\n",
      "Loss: 0.35983917117118835 -0.17516687512397766\n",
      "Loss: 0.43941596150398254 -0.5044979453086853\n",
      "Loss: 0.3737187683582306 -0.5069807171821594\n",
      "Loss: 0.452994167804718 -0.41523879766464233\n",
      "Loss: 0.3580406606197357 0.008258789777755737\n",
      "Loss: 0.4307684004306793 -0.6725797057151794\n",
      "Loss: 0.40479597449302673 -0.4870792031288147\n",
      "Policy Reward: tensor(1.1182, device='cuda:0')\n",
      "Trajectory:  ['0.02', '1.00', '0.73', '0.48', '0.46', '0.47', '0.19', '0.00', '0.00', '0.00', '0.00', '0.00', '0.02', '0.22', '0.32', '0.28', '0.41', '0.12', '0.26']\n",
      "Last Action:  tensor([0.2565, 0.4210, 0.5616, 0.3459, 0.1899, 0.1395, 0.4165, 0.0604, 0.1699,\n",
      "        0.1100], device='cuda:0')\n",
      "Loss: 0.36418819427490234 -0.4992373287677765\n",
      "Loss: 0.42071533203125 -0.7863399982452393\n",
      "Loss: 0.5412317514419556 -0.7389400601387024\n",
      "Loss: 0.4507577419281006 -0.5726468563079834\n",
      "Loss: 0.37506189942359924 -0.03549818694591522\n",
      "Loss: 0.4358389675617218 -0.4543996751308441\n",
      "Loss: 0.37752625346183777 -0.465255469083786\n",
      "Policy Reward: tensor(1.0069, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.82', '0.64', '0.42', '0.38', '0.12', '0.00', '0.00', '0.00', '0.00', '0.00', '0.01', '0.19', '0.68', '0.62', '0.52', '0.50', '0.33']\n",
      "Last Action:  tensor([0.3260, 0.2748, 0.3132, 0.3568, 0.8143, 0.1465, 0.1773, 0.3366, 0.0751,\n",
      "        0.2137], device='cuda:0')\n",
      "Loss: 0.3634493052959442 -0.27186086773872375\n",
      "Loss: 0.43634045124053955 -0.19634240865707397\n",
      "Loss: 0.45810064673423767 -0.7208670377731323\n",
      "Loss: 0.3451250493526459 -0.3747600317001343\n",
      "Loss: 0.3784634470939636 -0.488574355840683\n",
      "Loss: 0.37304988503456116 -0.49195653200149536\n",
      "Loss: 0.4003607928752899 -0.4838571846485138\n",
      "Policy Reward: tensor(1.2973, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.60', '0.68', '0.52', '0.44', '0.25', '0.01', '0.00', '0.00', '0.00', '0.01', '0.12', '0.60', '0.78', '0.71', '0.54', '0.39', '0.16']\n",
      "Last Action:  tensor([0.1581, 0.3922, 0.0722, 0.0427, 0.4062, 0.2200, 0.2044, 0.2293, 0.0647,\n",
      "        0.3458], device='cuda:0')\n",
      "Loss: 0.37477919459342957 -0.27439358830451965\n",
      "Loss: 0.4146488904953003 -0.6339917182922363\n",
      "Loss: 0.34989070892333984 0.06466023623943329\n",
      "Loss: 0.3675288259983063 -0.19584305584430695\n",
      "Loss: 0.4196402132511139 -0.6878973245620728\n",
      "Loss: 0.4639405608177185 -0.5559386014938354\n",
      "Loss: 0.36942771077156067 -0.15235589444637299\n",
      "Policy Reward: tensor(1.1094, device='cuda:0')\n",
      "Trajectory:  ['0.07', '1.00', '0.55', '0.01', '0.43', '0.37', '0.27', '0.01', '0.00', '0.00', '0.00', '0.00', '0.08', '0.66', '0.88', '0.58', '0.50', '0.33', '0.19']\n",
      "Last Action:  tensor([0.1865, 0.4050, 0.3584, 0.3100, 0.7749, 0.3453, 0.2094, 0.1354, 0.2192,\n",
      "        0.3177], device='cuda:0')\n",
      "Loss: 0.36804166436195374 -0.26303067803382874\n",
      "Loss: 0.3607334494590759 -0.4737548232078552\n",
      "Loss: 0.3701920211315155 -0.5092902183532715\n",
      "Loss: 0.40945982933044434 -0.4705334007740021\n",
      "Loss: 0.4073289930820465 -0.39432471990585327\n",
      "Loss: 0.4150315225124359 -0.6931414604187012\n",
      "Loss: 0.3873063027858734 -0.3659564256668091\n",
      "Policy Reward: tensor(1.1343, device='cuda:0')\n",
      "Trajectory:  ['0.95', '0.18', '0.32', '0.12', '0.64', '0.42', '0.39', '0.02', '0.00', '0.00', '0.00', '0.00', '0.01', '0.11', '0.64', '0.79', '0.75', '0.42', '0.36']\n",
      "Last Action:  tensor([0.3631, 0.5351, 0.1242, 0.2748, 0.0877, 0.3586, 0.0925, 0.3147, 0.2772,\n",
      "        0.5268], device='cuda:0')\n",
      "Bigstep:  90\n",
      "Loss: 0.4838157594203949 -0.4330269992351532\n",
      "Loss: 0.4333672523498535 -0.23798348009586334\n",
      "Loss: 0.40588587522506714 -0.338158518075943\n",
      "Loss: 0.4944530129432678 -0.7690814733505249\n",
      "Loss: 0.3728087842464447 -0.07506565749645233\n",
      "Loss: 0.3814243972301483 -0.5078083276748657\n",
      "Loss: 0.33953508734703064 -0.00815272331237793\n",
      "Policy Reward: tensor(1.1172, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.48', '0.65', '0.32', '0.23', '0.05', '0.00', '0.00', '0.00', '0.00', '0.01', '0.08', '0.45', '0.85', '0.41', '0.77', '0.38', '0.13']\n",
      "Last Action:  tensor([0.1294, 0.3057, 0.9688, 0.1771, 0.5363, 0.1100, 0.5763, 0.4411, 0.2093,\n",
      "        0.5780], device='cuda:0')\n",
      "Loss: 0.3180902302265167 0.022113077342510223\n",
      "Loss: 0.36181238293647766 -0.09468364715576172\n",
      "Loss: 0.4435327351093292 -0.43196260929107666\n",
      "Loss: 0.3259226679801941 -0.27358153462409973\n",
      "Loss: 0.39578649401664734 -0.10503645241260529\n",
      "Loss: 0.3993183672428131 -0.18391035497188568\n",
      "Loss: 0.39712485671043396 -0.3721359372138977\n",
      "Policy Reward: tensor(1.1374, device='cuda:0')\n",
      "Trajectory:  ['0.14', '1.00', '0.61', '0.02', '0.37', '0.10', '0.06', '0.00', '0.00', '0.00', '0.00', '0.00', '0.01', '0.07', '0.36', '0.38', '0.36', '0.68', '0.90']\n",
      "Last Action:  tensor([0.8980, 0.3670, 0.1026, 0.4114, 0.5208, 0.1552, 0.4124, 0.2157, 0.6147,\n",
      "        0.6534], device='cuda:0')\n",
      "Loss: 0.4352445900440216 -0.5902165174484253\n",
      "Loss: 0.3909112811088562 -0.5579500794410706\n",
      "Loss: 0.38361096382141113 -0.5395762324333191\n",
      "Loss: 0.3279721140861511 -0.04472984001040459\n",
      "Loss: 0.42349809408187866 -0.6410415172576904\n",
      "Loss: 0.3284112811088562 -0.24983473122119904\n",
      "Loss: 0.3979267179965973 -0.30658167600631714\n",
      "Policy Reward: tensor(1.2110, device='cuda:0')\n",
      "Trajectory:  ['0.92', '0.15', '0.41', '0.26', '0.46', '0.36', '0.20', '0.01', '0.00', '0.00', '0.00', '0.00', '0.02', '0.15', '0.57', '0.85', '0.82', '0.72', '0.50']\n",
      "Last Action:  tensor([0.4957, 0.3705, 0.0584, 0.4505, 0.5113, 0.4501, 0.9564, 0.1143, 0.1791,\n",
      "        0.0818], device='cuda:0')\n",
      "Loss: 0.4015319347381592 -0.559137761592865\n",
      "Loss: 0.4578932821750641 -0.78011554479599\n",
      "Loss: 0.45430126786231995 -0.9030698537826538\n",
      "Loss: 0.3272065818309784 -0.2795780897140503\n",
      "Loss: 0.3732735514640808 -0.361081063747406\n",
      "Loss: 0.43172985315322876 -0.46912187337875366\n",
      "Loss: 0.35751914978027344 -0.43778014183044434\n",
      "Policy Reward: tensor(1.2299, device='cuda:0')\n",
      "Trajectory:  ['0.14', '0.11', '0.02', '0.05', '0.75', '0.35', '0.11', '0.00', '0.00', '0.00', '0.00', '0.00', '0.11', '0.64', '0.83', '0.57', '0.32', '0.20', '0.43']\n",
      "Last Action:  tensor([0.4333, 0.8351, 0.4874, 0.5699, 0.9989, 0.2843, 0.3597, 0.8721, 0.3240,\n",
      "        0.5633], device='cuda:0')\n",
      "Loss: 0.4237121343612671 -0.5311898589134216\n",
      "Loss: 0.35496726632118225 -0.306313157081604\n",
      "Loss: 0.48133334517478943 -0.4672982394695282\n",
      "Loss: 0.4109237492084503 -0.6861734986305237\n",
      "Loss: 0.4014437794685364 -0.45758116245269775\n",
      "Loss: 0.3980749845504761 -0.10528180003166199\n",
      "Loss: 0.46798524260520935 -0.5927325487136841\n",
      "Policy Reward: tensor(1.2459, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.63', '0.69', '0.42', '0.30', '0.10', '0.00', '0.00', '0.00', '0.00', '0.01', '0.17', '0.68', '0.71', '0.61', '0.47', '0.24', '0.24']\n",
      "Last Action:  tensor([0.2439, 0.3204, 0.4211, 0.3690, 0.2504, 0.4304, 0.4089, 0.2445, 0.4552,\n",
      "        0.2719], device='cuda:0')\n",
      "Loss: 0.33637627959251404 -0.1661801040172577\n",
      "Loss: 0.3631657660007477 -0.5150838494300842\n",
      "Loss: 0.370800644159317 -0.48700520396232605\n",
      "Loss: 0.42349863052368164 -0.4642714858055115\n",
      "Loss: 0.4152600169181824 -0.7918509840965271\n",
      "Loss: 0.3491493761539459 -0.18904125690460205\n",
      "Loss: 0.34752345085144043 -0.5371503233909607\n",
      "Policy Reward: tensor(1.2346, device='cuda:0')\n",
      "Trajectory:  ['0.24', '0.92', '0.40', '0.00', '0.46', '0.23', '0.08', '0.00', '0.00', '0.01', '0.03', '0.09', '0.12', '0.12', '0.45', '0.98', '1.00', '0.80', '0.57']\n",
      "Last Action:  tensor([0.5729, 0.4649, 0.9610, 0.2913, 0.2342, 0.5077, 0.3578, 0.4602, 0.2439,\n",
      "        0.2557], device='cuda:0')\n",
      "Loss: 0.36454206705093384 -0.2888428270816803\n",
      "Loss: 0.3338092565536499 -0.1482255756855011\n",
      "Loss: 0.35747724771499634 -0.37435394525527954\n",
      "Loss: 0.36755964159965515 -0.41707247495651245\n",
      "Loss: 0.3643611967563629 -0.33455321192741394\n",
      "Loss: 0.41668248176574707 -0.33416712284088135\n",
      "Loss: 0.40227198600769043 -0.47221654653549194\n",
      "Policy Reward: tensor(1.1271, device='cuda:0')\n",
      "Trajectory:  ['0.98', '0.22', '0.04', '0.02', '0.28', '0.31', '0.27', '0.11', '0.17', '0.21', '0.25', '0.30', '0.47', '0.59', '0.49', '0.43', '0.62', '0.80', '0.48']\n",
      "Last Action:  tensor([0.4799, 0.3816, 0.8327, 0.2410, 0.1293, 0.2727, 0.2957, 0.0543, 0.8731,\n",
      "        0.4022], device='cuda:0')\n",
      "Loss: 0.36285966634750366 -0.5621396899223328\n",
      "Loss: 0.3454087972640991 -0.7522754073143005\n",
      "Loss: 0.44629326462745667 -0.3578014373779297\n",
      "Loss: 0.359639048576355 -0.18225282430648804\n",
      "Loss: 0.47153177857398987 -0.7619166374206543\n",
      "Loss: 0.3230743408203125 -0.28474920988082886\n",
      "Loss: 0.3742690086364746 -0.3392786681652069\n",
      "Policy Reward: tensor(1.1750, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.53', '0.73', '0.32', '0.18', '0.01', '0.00', '0.00', '0.00', '0.00', '0.00', '0.03', '0.21', '0.67', '0.77', '0.67', '0.67', '0.49']\n",
      "Last Action:  tensor([0.4915, 0.2254, 0.2842, 0.0683, 0.7950, 0.2789, 0.2775, 0.3572, 0.1541,\n",
      "        0.0974], device='cuda:0')\n",
      "Bigstep:  91\n",
      "Loss: 0.3725408613681793 0.11595175415277481\n",
      "Loss: 0.49343183636665344 -0.35000699758529663\n",
      "Loss: 0.44111576676368713 -0.09835097193717957\n",
      "Loss: 0.41265806555747986 -0.3073611855506897\n",
      "Loss: 0.36642369627952576 -0.304667592048645\n",
      "Loss: 0.4409327208995819 -0.5200074911117554\n",
      "Loss: 0.4080659747123718 -0.3849843144416809\n",
      "Policy Reward: tensor(1.1997, device='cuda:0')\n",
      "Trajectory:  ['0.06', '1.00', '0.54', '0.70', '0.59', '0.54', '0.22', '0.01', '0.00', '0.00', '0.00', '0.00', '0.01', '0.13', '0.59', '0.84', '0.89', '0.78', '0.71']\n",
      "Last Action:  tensor([0.7062, 0.5114, 0.7511, 0.6931, 0.5737, 0.9985, 0.4645, 0.3066, 0.5562,\n",
      "        0.7768], device='cuda:0')\n",
      "Loss: 0.37305545806884766 -0.006197720766067505\n",
      "Loss: 0.38043326139450073 -0.14390920102596283\n",
      "Loss: 0.4205819070339203 -0.6157174706459045\n",
      "Loss: 0.34887969493865967 -0.267860472202301\n",
      "Loss: 0.4003995358943939 -0.45639756321907043\n",
      "Loss: 0.4138184189796448 -0.3519141972064972\n",
      "Loss: 0.3822985887527466 -0.5603313446044922\n",
      "Policy Reward: tensor(1.0770, device='cuda:0')\n",
      "Trajectory:  ['0.22', '0.11', '0.04', '0.07', '0.61', '0.32', '0.31', '0.01', '0.00', '0.00', '0.00', '0.02', '0.32', '0.76', '0.95', '0.87', '0.74', '0.50', '0.50']\n",
      "Last Action:  tensor([0.4966, 0.5819, 0.9861, 0.7665, 0.1478, 0.8552, 0.4467, 0.3259, 0.3900,\n",
      "        0.8363], device='cuda:0')\n",
      "Loss: 0.4120996594429016 -0.5063475370407104\n",
      "Loss: 0.3582354187965393 -0.46491575241088867\n",
      "Loss: 0.3639522194862366 -0.5371770262718201\n",
      "Loss: 0.49290409684181213 -0.8307849168777466\n",
      "Loss: 0.417050302028656 -0.511111855506897\n",
      "Loss: 0.31104421615600586 -0.14585992693901062\n",
      "Loss: 0.38491326570510864 -0.37136757373809814\n",
      "Policy Reward: tensor(1.0817, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.33', '0.68', '0.55', '0.38', '0.29', '0.02', '0.00', '0.00', '0.00', '0.01', '0.14', '0.51', '0.86', '0.90', '0.83', '0.71', '0.56']\n",
      "Last Action:  tensor([0.5608, 0.5987, 0.5545, 0.5715, 0.5981, 0.5670, 0.7120, 0.3780, 0.5070,\n",
      "        0.4442], device='cuda:0')\n",
      "Loss: 0.4406944215297699 -0.7826943397521973\n",
      "Loss: 0.44836166501045227 -0.4221540093421936\n",
      "Loss: 0.4191107749938965 -0.4495989680290222\n",
      "Loss: 0.4452569782733917 -0.4364594519138336\n",
      "Loss: 0.4154992401599884 -0.4500289857387543\n",
      "Loss: 0.4397861063480377 -0.7955087423324585\n",
      "Loss: 0.3242824375629425 -0.10202130675315857\n",
      "Policy Reward: tensor(1.1564, device='cuda:0')\n",
      "Trajectory:  ['0.08', '1.00', '0.91', '0.30', '0.47', '0.31', '0.18', '0.02', '0.00', '0.00', '0.00', '0.00', '0.07', '0.57', '0.89', '0.88', '0.88', '0.88', '0.85']\n",
      "Last Action:  tensor([0.8477, 0.9858, 0.5732, 0.9307, 0.5078, 0.5016, 0.6530, 0.5450, 0.9866,\n",
      "        0.2814], device='cuda:0')\n",
      "Loss: 0.3631189167499542 -0.49331921339035034\n",
      "Loss: 0.3556930124759674 -0.40324917435646057\n",
      "Loss: 0.40210387110710144 -0.46083998680114746\n",
      "Loss: 0.3636119067668915 -0.18236517906188965\n",
      "Loss: 0.4115372598171234 -0.5143201351165771\n",
      "Loss: 0.3421204090118408 -0.47962915897369385\n",
      "Loss: 0.40212398767471313 -0.32683366537094116\n",
      "Policy Reward: tensor(1.1753, device='cuda:0')\n",
      "Trajectory:  ['0.06', '1.00', '0.85', '0.08', '0.41', '0.47', '0.45', '0.17', '0.00', '0.00', '0.00', '0.07', '0.64', '0.88', '0.81', '0.78', '0.68', '0.62', '0.56']\n",
      "Last Action:  tensor([0.5647, 0.3966, 0.5185, 0.4364, 0.5981, 0.5423, 0.3029, 0.7351, 0.5211,\n",
      "        0.3816], device='cuda:0')\n",
      "Loss: 0.41781678795814514 -0.4321478009223938\n",
      "Loss: 0.441217839717865 -0.42640477418899536\n",
      "Loss: 0.2661852538585663 0.09296082705259323\n",
      "Loss: 0.377194344997406 -0.334207147359848\n",
      "Loss: 0.36468684673309326 -0.056744225323200226\n",
      "Loss: 0.4110552966594696 -0.7304028272628784\n",
      "Loss: 0.41177675127983093 -0.4107750654220581\n",
      "Policy Reward: tensor(1.1574, device='cuda:0')\n",
      "Trajectory:  ['0.16', '1.00', '0.92', '0.74', '0.50', '0.59', '0.16', '0.01', '0.00', '0.00', '0.00', '0.04', '0.61', '1.00', '0.83', '0.98', '0.97', '0.97', '0.95']\n",
      "Last Action:  tensor([0.9523, 0.6745, 0.6029, 0.6891, 0.7151, 0.6552, 0.8228, 0.8319, 0.5178,\n",
      "        0.6626], device='cuda:0')\n",
      "Loss: 0.39004993438720703 -0.34177401661872864\n",
      "Loss: 0.30374428629875183 -0.37885791063308716\n",
      "Loss: 0.49314361810684204 -0.3330041766166687\n",
      "Loss: 0.3750738501548767 -0.27900147438049316\n",
      "Loss: 0.32871928811073303 -0.11941130459308624\n",
      "Loss: 0.4199208617210388 -0.11950960755348206\n",
      "Loss: 0.364967405796051 -0.23963198065757751\n",
      "Policy Reward: tensor(1.3097, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.37', '0.74', '0.61', '0.45', '0.29', '0.03', '0.01', '0.00', '0.00', '0.01', '0.06', '0.49', '0.99', '0.95', '0.84', '0.79', '0.63']\n",
      "Last Action:  tensor([0.6282, 0.5641, 0.6681, 0.4386, 0.6898, 0.7789, 0.9909, 0.9310, 0.7393,\n",
      "        0.6056], device='cuda:0')\n",
      "Loss: 0.41437971591949463 -0.2528471052646637\n",
      "Loss: 0.45962435007095337 -0.5626847147941589\n",
      "Loss: 0.41312721371650696 -0.4738024175167084\n",
      "Loss: 0.42187079787254333 -0.5409581661224365\n",
      "Loss: 0.4215768873691559 -0.6293740272521973\n",
      "Loss: 0.49859294295310974 -0.7089340090751648\n",
      "Loss: 0.37999358773231506 -0.4336097240447998\n",
      "Policy Reward: tensor(1.2030, device='cuda:0')\n",
      "Trajectory:  ['0.91', '0.20', '0.75', '0.06', '0.60', '0.47', '0.52', '0.24', '0.01', '0.00', '0.00', '0.01', '0.21', '0.81', '0.93', '0.88', '0.83', '0.70', '0.61']\n",
      "Last Action:  tensor([0.6076, 0.9778, 0.5665, 0.4320, 0.4898, 0.9962, 0.9900, 0.5919, 0.4878,\n",
      "        0.6750], device='cuda:0')\n",
      "Bigstep:  92\n",
      "Loss: 0.46878236532211304 -0.44117090106010437\n",
      "Loss: 0.395378977060318 0.13847194612026215\n",
      "Loss: 0.4177141785621643 0.08602787554264069\n",
      "Loss: 0.41490960121154785 -0.21747276186943054\n",
      "Loss: 0.37421664595603943 -0.07280591130256653\n",
      "Loss: 0.43377041816711426 -0.34133026003837585\n",
      "Loss: 0.3972185254096985 -0.03485428914427757\n",
      "Policy Reward: tensor(1.1733, device='cuda:0')\n",
      "Trajectory:  ['0.41', '0.95', '0.33', '0.00', '0.31', '0.24', '0.31', '0.14', '0.01', '0.00', '0.00', '0.01', '0.06', '0.15', '0.29', '0.48', '0.60', '0.40', '0.34']\n",
      "Last Action:  tensor([0.3378, 0.7713, 0.1019, 0.6803, 0.7650, 0.1052, 0.1170, 0.1667, 0.1703,\n",
      "        0.3494], device='cuda:0')\n",
      "Loss: 0.4482554495334625 -0.28469738364219666\n",
      "Loss: 0.35344794392585754 -0.2896565794944763\n",
      "Loss: 0.37864232063293457 -0.14524100720882416\n",
      "Loss: 0.4627581536769867 -0.7779675722122192\n",
      "Loss: 0.4739275574684143 -0.5763616561889648\n",
      "Loss: 0.41135403513908386 -0.3207021951675415\n",
      "Loss: 0.46704962849617004 -0.326660692691803\n",
      "Policy Reward: tensor(1.1914, device='cuda:0')\n",
      "Trajectory:  ['0.97', '0.31', '0.65', '0.16', '0.26', '0.38', '0.14', '0.05', '0.05', '0.09', '0.15', '0.32', '0.22', '0.09', '0.02', '0.19', '0.99', '1.00', '0.33']\n",
      "Last Action:  tensor([0.3345, 0.9514, 0.8917, 0.0771, 0.2436, 0.1717, 0.0201, 0.0962, 0.4012,\n",
      "        0.8688], device='cuda:0')\n",
      "Loss: 0.36664190888404846 -0.27264684438705444\n",
      "Loss: 0.3582262098789215 -0.16179193556308746\n",
      "Loss: 0.41837170720100403 -0.5898531675338745\n",
      "Loss: 0.3922646641731262 -0.5843556523323059\n",
      "Loss: 0.39831438660621643 -0.1924578845500946\n",
      "Loss: 0.32014307379722595 -0.10538139194250107\n",
      "Loss: 0.3722979724407196 -0.35891106724739075\n",
      "Policy Reward: tensor(1.1874, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.32', '0.44', '0.50', '0.33', '0.23', '0.16', '0.08', '0.02', '0.01', '0.01', '0.04', '0.08', '0.13', '0.25', '0.40', '0.55', '0.29']\n",
      "Last Action:  tensor([0.2931, 0.9766, 0.0844, 0.2508, 0.1839, 0.0155, 0.2406, 0.1152, 0.1885,\n",
      "        0.3177], device='cuda:0')\n",
      "Loss: 0.4279731512069702 -0.614784300327301\n",
      "Loss: 0.43715062737464905 -0.5840241312980652\n",
      "Loss: 0.36785849928855896 0.02810811437666416\n",
      "Loss: 0.35780879855155945 -0.5045883059501648\n",
      "Loss: 0.4011359214782715 -0.454020231962204\n",
      "Loss: 0.42781686782836914 -0.5285552740097046\n",
      "Loss: 0.4323504865169525 -0.12003222107887268\n",
      "Policy Reward: tensor(1.0768, device='cuda:0')\n",
      "Trajectory:  ['0.06', '1.00', '0.62', '0.01', '0.52', '0.29', '0.40', '0.17', '0.01', '0.00', '0.00', '0.01', '0.05', '0.12', '0.24', '0.37', '0.45', '0.43', '0.19']\n",
      "Last Action:  tensor([0.1909, 0.4895, 0.9587, 0.2015, 0.0553, 0.5307, 0.0380, 0.9932, 0.0746,\n",
      "        0.9534], device='cuda:0')\n",
      "Loss: 0.40173113346099854 -0.39916208386421204\n",
      "Loss: 0.3974316716194153 -0.3494220972061157\n",
      "Loss: 0.35115402936935425 -0.1164342612028122\n",
      "Loss: 0.3688853979110718 -0.25734713673591614\n",
      "Loss: 0.47335579991340637 -0.5389062166213989\n",
      "Loss: 0.41054534912109375 -0.18525376915931702\n",
      "Loss: 0.41007062792778015 -0.7407373785972595\n",
      "Policy Reward: tensor(1.2548, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.90', '0.76', '0.42', '0.27', '0.20', '0.02', '0.01', '0.01', '0.01', '0.01', '0.01', '0.06', '0.62', '1.00', '0.93', '0.98', '0.99']\n",
      "Last Action:  tensor([0.9901, 0.1032, 0.4055, 0.1825, 0.0258, 0.4158, 0.2015, 0.6378, 0.2016,\n",
      "        0.1507], device='cuda:0')\n",
      "Loss: 0.4048222005367279 -0.5111376047134399\n",
      "Loss: 0.3825066089630127 -0.36199429631233215\n",
      "Loss: 0.40740591287612915 -0.15727682411670685\n",
      "Loss: 0.3939463496208191 -0.39894020557403564\n",
      "Loss: 0.4107193946838379 -0.37608736753463745\n",
      "Loss: 0.37320390343666077 -0.4077710211277008\n",
      "Loss: 0.3982318341732025 -0.3736313283443451\n",
      "Policy Reward: tensor(1.1558, device='cuda:0')\n",
      "Trajectory:  ['0.03', '1.00', '0.58', '0.01', '0.49', '0.31', '0.40', '0.18', '0.01', '0.00', '0.00', '0.00', '0.00', '0.04', '0.17', '0.43', '0.51', '0.60', '0.55']\n",
      "Last Action:  tensor([0.5495, 0.1354, 0.2467, 0.9752, 0.9226, 0.3706, 0.4541, 0.2180, 0.1622,\n",
      "        0.0723], device='cuda:0')\n",
      "Loss: 0.44220492243766785 -0.6792675256729126\n",
      "Loss: 0.3432084619998932 -0.22317767143249512\n",
      "Loss: 0.3559480905532837 0.0519556887447834\n",
      "Loss: 0.3743046522140503 -0.2419244349002838\n",
      "Loss: 0.3900493085384369 -0.5731000304222107\n",
      "Loss: 0.3498627543449402 -0.5046242475509644\n",
      "Loss: 0.3649682402610779 -0.08098229765892029\n",
      "Policy Reward: tensor(1.0740, device='cuda:0')\n",
      "Trajectory:  ['0.28', '1.00', '0.69', '0.01', '0.33', '0.38', '0.30', '0.09', '0.00', '0.00', '0.00', '0.00', '0.01', '0.22', '0.57', '0.57', '0.46', '0.34', '0.08']\n",
      "Last Action:  tensor([0.0760, 0.1023, 0.1182, 0.1221, 0.1271, 0.1677, 0.4597, 0.0980, 0.7712,\n",
      "        0.3987], device='cuda:0')\n",
      "Loss: 0.37015897035598755 -0.6151031851768494\n",
      "Loss: 0.3065031170845032 -0.1452125608921051\n",
      "Loss: 0.4731385409832001 -0.3808310627937317\n",
      "Loss: 0.4140130579471588 -0.5517544150352478\n",
      "Loss: 0.4551602303981781 -0.5726457834243774\n",
      "Loss: 0.4594394862651825 -0.649574875831604\n",
      "Loss: 0.435690701007843 -0.4429100453853607\n",
      "Policy Reward: tensor(1.0829, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.48', '0.69', '0.46', '0.38', '0.30', '0.10', '0.01', '0.00', '0.00', '0.00', '0.00', '0.00', '0.04', '0.19', '0.52', '0.52', '0.70']\n",
      "Last Action:  tensor([0.7042, 0.9469, 0.0724, 0.2019, 0.3908, 0.9470, 0.1173, 0.2463, 0.1461,\n",
      "        0.0255], device='cuda:0')\n",
      "Bigstep:  93\n",
      "Loss: 0.39781832695007324 0.1670059710741043\n",
      "Loss: 0.3935967981815338 -0.23669041693210602\n",
      "Loss: 0.374654084444046 -0.08352477848529816\n",
      "Loss: 0.3703770637512207 -0.07806140929460526\n",
      "Loss: 0.4082793593406677 -0.2860901653766632\n",
      "Loss: 0.4678811728954315 -0.5696624517440796\n",
      "Loss: 0.37753602862358093 -0.4883654713630676\n",
      "Policy Reward: tensor(1.0086, device='cuda:0')\n",
      "Trajectory:  ['0.09', '1.00', '0.47', '0.00', '0.36', '0.27', '0.32', '0.21', '0.02', '0.00', '0.00', '0.01', '0.09', '0.15', '0.09', '0.04', '0.04', '0.12', '0.22']\n",
      "Last Action:  tensor([0.2167, 0.1646, 0.1175, 0.1895, 0.1215, 0.0998, 0.4586, 0.1193, 0.1783,\n",
      "        0.4528], device='cuda:0')\n",
      "Loss: 0.3330501317977905 -0.14759734272956848\n",
      "Loss: 0.34980058670043945 -0.32914677262306213\n",
      "Loss: 0.38315433263778687 -0.4844764471054077\n",
      "Loss: 0.4039453864097595 -0.13055828213691711\n",
      "Loss: 0.3397063910961151 -0.04855690896511078\n",
      "Loss: 0.30725088715553284 -0.04876002296805382\n",
      "Loss: 0.3687894344329834 -0.47596627473831177\n",
      "Policy Reward: tensor(1.1154, device='cuda:0')\n",
      "Trajectory:  ['0.11', '1.00', '0.55', '0.00', '0.38', '0.33', '0.40', '0.11', '0.00', '0.00', '0.01', '0.31', '0.44', '0.04', '0.02', '0.05', '0.09', '0.13', '0.06']\n",
      "Last Action:  tensor([0.0649, 0.0589, 0.3185, 0.2030, 0.3230, 0.4320, 0.9644, 0.2378, 0.9160,\n",
      "        0.1284], device='cuda:0')\n",
      "Loss: 0.3491643965244293 -0.253207266330719\n",
      "Loss: 0.3343770205974579 -0.15110477805137634\n",
      "Loss: 0.3379386365413666 -0.07324941456317902\n",
      "Loss: 0.3164956867694855 0.087317556142807\n",
      "Loss: 0.39033418893814087 -0.46026062965393066\n",
      "Loss: 0.4517304599285126 -0.7050630450248718\n",
      "Loss: 0.43877485394477844 -0.6997236609458923\n",
      "Policy Reward: tensor(1.1054, device='cuda:0')\n",
      "Trajectory:  ['0.72', '0.25', '0.74', '0.20', '0.56', '0.43', '0.48', '0.10', '0.00', '0.00', '0.03', '0.48', '0.61', '0.32', '0.09', '0.11', '0.18', '0.22', '0.23']\n",
      "Last Action:  tensor([0.2277, 0.0813, 0.6734, 0.3645, 0.4220, 0.7202, 0.3062, 0.8881, 0.0174,\n",
      "        0.0832], device='cuda:0')\n",
      "Loss: 0.40610620379447937 -0.37708112597465515\n",
      "Loss: 0.3609251081943512 -0.17721420526504517\n",
      "Loss: 0.34466031193733215 -0.42848387360572815\n",
      "Loss: 0.38468414545059204 -0.11597531288862228\n",
      "Loss: 0.3299626111984253 -0.10506711900234222\n",
      "Loss: 0.37186330556869507 -0.2627806067466736\n",
      "Loss: 0.3849600553512573 -0.4807834029197693\n",
      "Policy Reward: tensor(1.1685, device='cuda:0')\n",
      "Trajectory:  ['0.64', '0.98', '0.35', '0.00', '0.31', '0.41', '0.34', '0.05', '0.01', '0.02', '0.04', '0.04', '0.03', '0.10', '0.85', '0.72', '0.50', '0.35', '0.25']\n",
      "Last Action:  tensor([0.2507, 0.1126, 0.1702, 0.7282, 0.1427, 0.3446, 0.0779, 0.9955, 0.1922,\n",
      "        0.1356], device='cuda:0')\n",
      "Loss: 0.44892939925193787 -0.5505719184875488\n",
      "Loss: 0.47502484917640686 -0.7843316197395325\n",
      "Loss: 0.3830866813659668 -0.12468518316745758\n",
      "Loss: 0.3595830500125885 -0.48075348138809204\n",
      "Loss: 0.38552820682525635 -0.14144951105117798\n",
      "Loss: 0.39380088448524475 -0.6452504396438599\n",
      "Loss: 0.3820379376411438 -0.07588782906532288\n",
      "Policy Reward: tensor(1.0827, device='cuda:0')\n",
      "Trajectory:  ['0.68', '0.98', '0.89', '0.27', '0.39', '0.45', '0.39', '0.11', '0.00', '0.00', '0.01', '0.15', '0.65', '0.25', '0.33', '0.02', '0.01', '0.03', '0.14']\n",
      "Last Action:  tensor([0.1356, 0.1331, 0.8848, 0.8871, 0.1356, 0.2767, 0.1529, 0.0990, 0.0748,\n",
      "        0.1749], device='cuda:0')\n",
      "Loss: 0.38006722927093506 0.013670869171619415\n",
      "Loss: 0.31308549642562866 -0.14483153820037842\n",
      "Loss: 0.44415706396102905 -0.7265203595161438\n",
      "Loss: 0.35570216178894043 -0.32253438234329224\n",
      "Loss: 0.358491986989975 -0.4010586440563202\n",
      "Loss: 0.3304699957370758 -0.2824975252151489\n",
      "Loss: 0.4526109993457794 -0.5914371609687805\n",
      "Policy Reward: tensor(1.1849, device='cuda:0')\n",
      "Trajectory:  ['0.98', '0.80', '0.28', '0.02', '0.34', '0.41', '0.32', '0.19', '0.01', '0.01', '0.10', '0.65', '0.52', '0.57', '0.74', '0.46', '0.50', '0.75', '0.46']\n",
      "Last Action:  tensor([0.4573, 0.8209, 0.3360, 0.2613, 0.1089, 0.2533, 0.2519, 0.1142, 0.3854,\n",
      "        0.1822], device='cuda:0')\n",
      "Loss: 0.33573004603385925 -0.3905749022960663\n",
      "Loss: 0.4006529152393341 -0.13545909523963928\n",
      "Loss: 0.419487863779068 -0.5281134843826294\n",
      "Loss: 0.36017951369285583 -0.09124268591403961\n",
      "Loss: 0.32798102498054504 -0.3846890926361084\n",
      "Loss: 0.3743988871574402 -0.20072518289089203\n",
      "Loss: 0.32069897651672363 -0.23628731071949005\n",
      "Policy Reward: tensor(1.1431, device='cuda:0')\n",
      "Trajectory:  ['0.02', '1.00', '0.87', '0.56', '0.63', '0.59', '0.34', '0.03', '0.00', '0.01', '0.13', '0.70', '0.69', '0.43', '0.25', '0.04', '0.05', '0.17', '0.29']\n",
      "Last Action:  tensor([0.2877, 0.9937, 0.3287, 0.1410, 0.1989, 0.3179, 0.2004, 0.1801, 0.1104,\n",
      "        0.4943], device='cuda:0')\n",
      "Loss: 0.29511117935180664 -0.12691554427146912\n",
      "Loss: 0.39878952503204346 -0.37541401386260986\n",
      "Loss: 0.36884093284606934 -0.4365561902523041\n",
      "Loss: 0.36949992179870605 -0.5609555840492249\n",
      "Loss: 0.4410037398338318 -0.7082071304321289\n",
      "Loss: 0.378368079662323 -0.39977654814720154\n",
      "Loss: 0.3255799412727356 -0.12483420222997665\n",
      "Policy Reward: tensor(1.2418, device='cuda:0')\n",
      "Trajectory:  ['0.01', '1.00', '0.77', '0.01', '0.39', '0.32', '0.45', '0.11', '0.02', '0.07', '0.45', '0.75', '0.34', '0.29', '0.03', '0.04', '0.11', '0.22', '0.19']\n",
      "Last Action:  tensor([0.1883, 0.8597, 0.2509, 0.1303, 0.1552, 0.2087, 0.1949, 0.1442, 0.1575,\n",
      "        0.2391], device='cuda:0')\n",
      "Bigstep:  94\n",
      "Loss: 0.3870323896408081 -0.09530895948410034\n",
      "Loss: 0.3770311176776886 -0.051463812589645386\n",
      "Loss: 0.3796355724334717 -0.14190837740898132\n",
      "Loss: 0.42951881885528564 -0.1057397723197937\n",
      "Loss: 0.3264276683330536 -0.0539521686732769\n",
      "Loss: 0.46804070472717285 -0.3679927885532379\n",
      "Loss: 0.37575048208236694 -0.3132229447364807\n",
      "Policy Reward: tensor(1.1458, device='cuda:0')\n",
      "Trajectory:  ['0.04', '1.00', '0.40', '0.00', '0.22', '0.15', '0.27', '0.11', '0.06', '0.15', '0.56', '0.58', '0.37', '0.04', '0.00', '0.01', '0.06', '0.11', '0.16']\n",
      "Last Action:  tensor([0.1585, 0.8073, 0.2068, 0.1573, 0.1923, 0.0914, 0.3891, 0.2519, 0.2380,\n",
      "        0.2166], device='cuda:0')\n",
      "Loss: 0.4236608147621155 -0.47074663639068604\n",
      "Loss: 0.4391287863254547 -0.28661584854125977\n",
      "Loss: 0.3710773289203644 -0.09093210101127625\n",
      "Loss: 0.34188053011894226 -0.2741462290287018\n",
      "Loss: 0.34776437282562256 -0.0895804688334465\n",
      "Loss: 0.350359171628952 -0.2768067717552185\n",
      "Loss: 0.4474408030509949 -0.41185200214385986\n",
      "Policy Reward: tensor(1.2549, device='cuda:0')\n",
      "Trajectory:  ['0.02', '1.00', '0.71', '0.69', '0.55', '0.50', '0.45', '0.34', '0.11', '0.24', '0.37', '0.80', '0.21', '0.04', '0.00', '0.00', '0.05', '0.09', '0.08']\n",
      "Last Action:  tensor([0.0765, 0.0879, 0.2618, 0.1981, 0.0247, 0.0317, 0.0414, 0.1245, 0.1155,\n",
      "        0.6875], device='cuda:0')\n",
      "Loss: 0.42029133439064026 -0.6155316233634949\n",
      "Loss: 0.3301429748535156 -0.01265249028801918\n",
      "Loss: 0.34115222096443176 -0.019503869116306305\n",
      "Loss: 0.3494187295436859 -0.08557799458503723\n",
      "Loss: 0.36271950602531433 -0.45206108689308167\n",
      "Loss: 0.3659532964229584 -0.5055547952651978\n",
      "Loss: 0.4214910566806793 -0.4183367192745209\n",
      "Policy Reward: tensor(1.2093, device='cuda:0')\n",
      "Trajectory:  ['0.08', '1.00', '0.44', '0.00', '0.22', '0.13', '0.24', '0.22', '0.07', '0.12', '0.34', '0.61', '0.40', '0.02', '0.00', '0.01', '0.02', '0.04', '0.06']\n",
      "Last Action:  tensor([0.0586, 0.1629, 0.2703, 0.2985, 0.3882, 0.0610, 0.8539, 0.0108, 0.0407,\n",
      "        0.0394], device='cuda:0')\n",
      "Loss: 0.3760647773742676 -0.1447790116071701\n",
      "Loss: 0.3474317193031311 -0.24179087579250336\n",
      "Loss: 0.3420557975769043 -0.26988184452056885\n",
      "Loss: 0.424683541059494 -0.363081157207489\n",
      "Loss: 0.3847462236881256 -0.36754465103149414\n",
      "Loss: 0.4512680172920227 -0.4747287333011627\n",
      "Loss: 0.34328287839889526 -0.27968713641166687\n",
      "Policy Reward: tensor(1.1276, device='cuda:0')\n",
      "Trajectory:  ['0.98', '0.33', '0.56', '0.01', '0.21', '0.19', '0.30', '0.19', '0.02', '0.02', '0.17', '0.31', '0.71', '0.58', '0.08', '0.02', '0.00', '0.01', '0.02']\n",
      "Last Action:  tensor([0.0227, 0.0432, 0.2954, 0.0882, 0.0677, 0.1039, 0.1998, 0.9423, 0.9999,\n",
      "        0.0170], device='cuda:0')\n",
      "Loss: 0.38863328099250793 -0.384876012802124\n",
      "Loss: 0.4059182107448578 -0.29303938150405884\n",
      "Loss: 0.3284943997859955 -0.3186374306678772\n",
      "Loss: 0.32351917028427124 -0.1752428114414215\n",
      "Loss: 0.38063928484916687 -0.44731780886650085\n",
      "Loss: 0.3761403560638428 -0.10711310803890228\n",
      "Loss: 0.3318479061126709 -0.2759198546409607\n",
      "Policy Reward: tensor(1.2196, device='cuda:0')\n",
      "Trajectory:  ['0.02', '1.00', '0.52', '0.03', '0.21', '0.29', '0.13', '0.01', '0.01', '0.03', '0.08', '0.32', '0.65', '0.38', '0.02', '0.01', '0.04', '0.13', '0.10']\n",
      "Last Action:  tensor([0.0976, 0.0356, 0.0423, 0.1885, 0.1915, 0.0615, 0.0344, 0.0424, 0.0320,\n",
      "        0.0760], device='cuda:0')\n",
      "Loss: 0.3726733922958374 -0.35794782638549805\n",
      "Loss: 0.40660008788108826 -0.6358991265296936\n",
      "Loss: 0.363545298576355 -0.26656967401504517\n",
      "Loss: 0.39617541432380676 -0.3323315382003784\n",
      "Loss: 0.4014219343662262 -0.4506993293762207\n",
      "Loss: 0.389125257730484 -0.20833924412727356\n",
      "Loss: 0.38228461146354675 -0.6058996915817261\n",
      "Policy Reward: tensor(1.1574, device='cuda:0')\n",
      "Trajectory:  ['0.09', '1.00', '0.45', '0.00', '0.32', '0.16', '0.44', '0.07', '0.01', '0.02', '0.23', '0.43', '0.60', '0.13', '0.01', '0.00', '0.00', '0.01', '0.02']\n",
      "Last Action:  tensor([0.0193, 0.0254, 0.9948, 0.4413, 0.0124, 0.1820, 0.1876, 0.0347, 0.0192,\n",
      "        0.1697], device='cuda:0')\n",
      "Loss: 0.42507052421569824 -0.3936658799648285\n",
      "Loss: 0.37599506974220276 -0.09797879308462143\n",
      "Loss: 0.3351871073246002 -0.2555048167705536\n",
      "Loss: 0.4419025778770447 -0.563300609588623\n",
      "Loss: 0.442152738571167 -0.6283488869667053\n",
      "Loss: 0.380258172750473 -0.5051289796829224\n",
      "Loss: 0.35453343391418457 -0.30317047238349915\n",
      "Policy Reward: tensor(1.1252, device='cuda:0')\n",
      "Trajectory:  ['0.93', '0.32', '0.37', '0.01', '0.28', '0.12', '0.37', '0.20', '0.16', '0.24', '0.50', '0.68', '0.23', '0.03', '0.01', '0.01', '0.02', '0.03', '0.04']\n",
      "Last Action:  tensor([0.0359, 0.0629, 0.0239, 0.1835, 0.2970, 0.0169, 0.1386, 0.2124, 0.2179,\n",
      "        0.0672], device='cuda:0')\n",
      "Loss: 0.3823484480381012 -0.7830166220664978\n",
      "Loss: 0.3309285044670105 -0.2297617346048355\n",
      "Loss: 0.3945700228214264 -0.4142613708972931\n",
      "Loss: 0.4200808107852936 -0.1854291558265686\n",
      "Loss: 0.39736613631248474 -0.7455978393554688\n",
      "Loss: 0.4269493520259857 -0.6681046485900879\n",
      "Loss: 0.3890480399131775 -0.4649082124233246\n",
      "Policy Reward: tensor(1.1993, device='cuda:0')\n",
      "Trajectory:  ['0.09', '1.00', '0.36', '0.00', '0.26', '0.13', '0.33', '0.11', '0.07', '0.20', '0.51', '0.36', '0.56', '0.36', '0.11', '0.01', '0.01', '0.01', '0.02']\n",
      "Last Action:  tensor([0.0207, 0.0224, 0.2303, 0.0245, 0.0659, 0.0137, 0.0502, 0.1397, 0.6986,\n",
      "        0.1190], device='cuda:0')\n",
      "Bigstep:  95\n",
      "Loss: 0.3536216616630554 0.16732367873191833\n",
      "Loss: 0.3788283169269562 -0.37264764308929443\n",
      "Loss: 0.4230378270149231 -0.5230116844177246\n",
      "Loss: 0.36559125781059265 -0.2975596785545349\n",
      "Loss: 0.3514350652694702 -0.2931176424026489\n",
      "Loss: 0.45891687273979187 -0.7253978848457336\n",
      "Loss: 0.43736010789871216 -0.5914611220359802\n",
      "Policy Reward: tensor(1.2318, device='cuda:0')\n",
      "Trajectory:  ['0.12', '1.00', '0.92', '0.69', '0.56', '0.56', '0.34', '0.08', '0.09', '0.43', '0.93', '0.96', '0.86', '0.73', '0.31', '0.13', '0.11', '0.18', '0.20']\n",
      "Last Action:  tensor([0.2008, 0.9989, 0.9490, 0.6381, 0.1524, 0.9993, 0.2938, 0.2607, 0.9983,\n",
      "        0.1831], device='cuda:0')\n",
      "Loss: 0.37035924196243286 -0.20422449707984924\n",
      "Loss: 0.4229224920272827 -0.605434238910675\n",
      "Loss: 0.3644316792488098 -0.34017306566238403\n",
      "Loss: 0.39186134934425354 -0.3820309638977051\n",
      "Loss: 0.3938348591327667 -0.5317126512527466\n",
      "Loss: 0.401515930891037 -0.45597562193870544\n",
      "Loss: 0.3861372470855713 -0.4113490581512451\n",
      "Policy Reward: tensor(1.1913, device='cuda:0')\n",
      "Trajectory:  ['0.05', '0.27', '0.09', '0.17', '0.71', '0.62', '0.29', '0.05', '0.03', '0.05', '0.11', '0.35', '0.99', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9998, 0.1234, 0.1156, 1.0000, 0.5296, 0.2145, 0.1749, 0.9999, 0.2077,\n",
      "        0.0356], device='cuda:0')\n",
      "Loss: 0.38126131892204285 -0.7855545878410339\n",
      "Loss: 0.44589072465896606 -0.6519683003425598\n",
      "Loss: 0.403837651014328 -0.5331279039382935\n",
      "Loss: 0.3489418923854828 0.23026195168495178\n",
      "Loss: 0.37096431851387024 -0.465830534696579\n",
      "Loss: 0.38793864846229553 -0.4985809326171875\n",
      "Loss: 0.4186372756958008 -0.6185849905014038\n",
      "Policy Reward: tensor(1.0522, device='cuda:0')\n",
      "Trajectory:  ['0.98', '0.25', '0.34', '0.01', '0.63', '0.52', '0.36', '0.20', '0.04', '0.06', '0.09', '0.23', '0.93', '0.89', '0.52', '0.43', '0.26', '0.28', '0.17']\n",
      "Last Action:  tensor([0.1651, 0.4000, 0.9988, 0.1627, 0.1683, 0.2433, 0.1001, 0.5300, 0.2040,\n",
      "        0.1695], device='cuda:0')\n",
      "Loss: 0.3486437499523163 -0.3180808424949646\n",
      "Loss: 0.33514437079429626 -0.3649033308029175\n",
      "Loss: 0.4026630222797394 -0.7869587540626526\n",
      "Loss: 0.37190350890159607 -0.5453088283538818\n",
      "Loss: 0.3876323997974396 -0.5067999958992004\n",
      "Loss: 0.37359198927879333 -0.47590118646621704\n",
      "Loss: 0.38365501165390015 -0.3778388500213623\n",
      "Policy Reward: tensor(1.1520, device='cuda:0')\n",
      "Trajectory:  ['0.98', '0.55', '0.33', '0.03', '0.62', '0.51', '0.37', '0.23', '0.10', '0.14', '0.29', '0.62', '0.96', '0.92', '0.55', '0.42', '0.61', '0.18', '0.19']\n",
      "Last Action:  tensor([0.1909, 0.9849, 0.2325, 0.1308, 0.4083, 0.9990, 0.8517, 0.1351, 0.1472,\n",
      "        0.1901], device='cuda:0')\n",
      "Loss: 0.4859282374382019 -0.8245113492012024\n",
      "Loss: 0.3686979413032532 -0.4596661925315857\n",
      "Loss: 0.40507152676582336 -0.3057193160057068\n",
      "Loss: 0.41178637742996216 -0.6388224959373474\n",
      "Loss: 0.3423749506473541 -0.4077150225639343\n",
      "Loss: 0.3924695551395416 -0.6128978729248047\n",
      "Loss: 0.3934991955757141 -0.35526520013809204\n",
      "Policy Reward: tensor(1.1699, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.78', '0.68', '0.47', '0.39', '0.34', '0.38', '0.39', '0.37', '0.33', '0.47', '0.97', '1.00', '1.00', '1.00', '0.90', '0.66', '0.25']\n",
      "Last Action:  tensor([0.2487, 0.1968, 0.1092, 0.6294, 0.1016, 0.9989, 0.6901, 0.9991, 0.1517,\n",
      "        0.8168], device='cuda:0')\n",
      "Loss: 0.3840070068836212 -0.8089910745620728\n",
      "Loss: 0.3859592378139496 -0.3460507392883301\n",
      "Loss: 0.3495836853981018 -0.2421424388885498\n",
      "Loss: 0.36409759521484375 -0.37725627422332764\n",
      "Loss: 0.41770580410957336 -0.8592639565467834\n",
      "Loss: 0.40485796332359314 -0.485984206199646\n",
      "Loss: 0.3351981043815613 -0.3835507333278656\n",
      "Policy Reward: tensor(1.2135, device='cuda:0')\n",
      "Trajectory:  ['0.99', '0.24', '0.78', '0.14', '0.66', '0.66', '0.62', '0.73', '0.70', '0.52', '0.34', '0.17', '0.55', '0.99', '1.00', '0.93', '0.63', '0.57', '0.89']\n",
      "Last Action:  tensor([0.8939, 0.1259, 0.9807, 0.1562, 0.1736, 0.1987, 0.9995, 0.9993, 0.4164,\n",
      "        0.9716], device='cuda:0')\n",
      "Loss: 0.4792461097240448 -0.6406440734863281\n",
      "Loss: 0.4441346526145935 -0.6939263939857483\n",
      "Loss: 0.4416155517101288 -0.8245145082473755\n",
      "Loss: 0.4667017161846161 -0.6910603046417236\n",
      "Loss: 0.3679691255092621 -0.5101852416992188\n",
      "Loss: 0.41535478830337524 -0.4870133399963379\n",
      "Loss: 0.4091779291629791 -0.5879759192466736\n",
      "Policy Reward: tensor(1.1456, device='cuda:0')\n",
      "Trajectory:  ['0.96', '0.23', '0.19', '0.02', '0.56', '0.64', '0.50', '0.25', '0.16', '0.13', '0.08', '0.10', '0.83', '1.00', '1.00', '0.78', '0.50', '0.56', '0.60']\n",
      "Last Action:  tensor([0.6031, 0.2825, 0.2689, 0.3675, 0.0720, 0.8127, 0.3873, 0.3960, 0.3135,\n",
      "        0.9507], device='cuda:0')\n",
      "Loss: 0.36173930764198303 -0.8400993347167969\n",
      "Loss: 0.39753326773643494 -0.6181557774543762\n",
      "Loss: 0.3578409254550934 -0.23126021027565002\n",
      "Loss: 0.3759266138076782 -0.5563823580741882\n",
      "Loss: 0.3320363759994507 -0.13602900505065918\n",
      "Loss: 0.3916129469871521 -0.6509724855422974\n",
      "Loss: 0.38032934069633484 -0.47414183616638184\n",
      "Policy Reward: tensor(1.1808, device='cuda:0')\n",
      "Trajectory:  ['0.05', '1.00', '0.49', '0.01', '0.56', '0.46', '0.30', '0.31', '0.31', '0.33', '0.56', '0.85', '0.75', '0.40', '0.42', '0.31', '0.13', '0.06', '0.06']\n",
      "Last Action:  tensor([0.0619, 0.1908, 0.2648, 0.9992, 0.2359, 0.5675, 0.3391, 0.9893, 0.0946,\n",
      "        0.0919], device='cuda:0')\n",
      "Bigstep:  96\n",
      "Loss: 0.37091153860092163 0.0028325840830802917\n",
      "Loss: 0.4062884747982025 0.015816427767276764\n",
      "Loss: 0.39873650670051575 -0.022756023332476616\n",
      "Loss: 0.366309255361557 -0.32367485761642456\n",
      "Loss: 0.42046359181404114 -0.12947234511375427\n",
      "Loss: 0.3597799241542816 -0.5490509271621704\n",
      "Loss: 0.3685421645641327 -0.06297861039638519\n",
      "Policy Reward: tensor(1.1098, device='cuda:0')\n",
      "Trajectory:  ['0.83', '0.84', '0.62', '0.65', '0.71', '0.52', '0.29', '0.17', '0.39', '0.68', '0.99', '1.00', '1.00', '1.00', '0.99', '0.83', '0.97', '0.99', '0.99']\n",
      "Last Action:  tensor([0.9942, 0.6887, 0.8764, 0.4099, 0.4579, 0.7986, 0.3507, 0.2917, 0.8505,\n",
      "        0.5946], device='cuda:0')\n",
      "Loss: 0.3512665033340454 -0.22067728638648987\n",
      "Loss: 0.4176129996776581 -0.23949016630649567\n",
      "Loss: 0.41956597566604614 -0.0778299868106842\n",
      "Loss: 0.4226412773132324 -0.8140987157821655\n",
      "Loss: 0.4363223612308502 -0.8777013421058655\n",
      "Loss: 0.31545498967170715 -0.025447573512792587\n",
      "Loss: 0.3532141149044037 -0.492366760969162\n",
      "Policy Reward: tensor(1.1981, device='cuda:0')\n",
      "Trajectory:  ['0.05', '0.48', '0.15', '0.20', '0.66', '0.43', '0.13', '0.08', '0.13', '0.31', '0.80', '0.95', '0.90', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9996, 1.0000, 0.4202, 0.9996, 0.8610, 0.8491, 0.3131, 0.3108, 0.6503,\n",
      "        0.7349], device='cuda:0')\n",
      "Loss: 0.3605799973011017 -0.33067160844802856\n",
      "Loss: 0.3127927780151367 0.03999977558851242\n",
      "Loss: 0.39759427309036255 -0.4579888582229614\n",
      "Loss: 0.3499624729156494 -0.2241075485944748\n",
      "Loss: 0.3734046220779419 -0.30028530955314636\n",
      "Loss: 0.39142468571662903 -0.5119777321815491\n",
      "Loss: 0.3367185890674591 -0.38089051842689514\n",
      "Policy Reward: tensor(1.2052, device='cuda:0')\n",
      "Trajectory:  ['0.04', '1.00', '0.79', '0.51', '0.53', '0.46', '0.34', '0.17', '0.19', '0.46', '0.75', '0.83', '0.99', '0.99', '0.94', '0.83', '0.74', '0.82', '0.89']\n",
      "Last Action:  tensor([0.8923, 0.6978, 0.5674, 0.3522, 0.1804, 0.4531, 0.9989, 0.4722, 0.9545,\n",
      "        0.9236], device='cuda:0')\n",
      "Loss: 0.4319722652435303 -0.6108289361000061\n",
      "Loss: 0.383016973733902 -0.6800609827041626\n",
      "Loss: 0.35157689452171326 -0.2548767626285553\n",
      "Loss: 0.4137636125087738 -0.24718959629535675\n",
      "Loss: 0.39181292057037354 -0.46388792991638184\n",
      "Loss: 0.32316866517066956 -0.3751332461833954\n",
      "Loss: 0.2908545136451721 -0.04990791156888008\n",
      "Policy Reward: tensor(1.1164, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.90', '0.71', '0.52', '0.47', '0.40', '0.27', '0.37', '0.68', '0.96', '0.95', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9996, 0.1992, 0.8954, 0.3871, 0.3973, 0.8973, 0.3741, 0.3984, 0.3124,\n",
      "        0.5849], device='cuda:0')\n",
      "Loss: 0.3014116585254669 -0.233774334192276\n",
      "Loss: 0.37353596091270447 -0.25666722655296326\n",
      "Loss: 0.3978891372680664 -0.5925551652908325\n",
      "Loss: 0.4053375720977783 -0.7528629899024963\n",
      "Loss: 0.2999047040939331 -0.12882086634635925\n",
      "Loss: 0.3409688174724579 -0.2322748452425003\n",
      "Loss: 0.34417563676834106 -0.38524776697158813\n",
      "Policy Reward: tensor(1.1843, device='cuda:0')\n",
      "Trajectory:  ['0.07', '1.00', '0.74', '0.01', '0.58', '0.51', '0.29', '0.18', '0.21', '0.43', '0.77', '0.96', '0.95', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9994, 0.1975, 0.3389, 0.9393, 0.4307, 0.5324, 0.9997, 0.3078, 0.5499,\n",
      "        0.7762], device='cuda:0')\n",
      "Loss: 0.36846932768821716 -0.12266985327005386\n",
      "Loss: 0.41274845600128174 -0.5926249027252197\n",
      "Loss: 0.33532240986824036 -0.12808288633823395\n",
      "Loss: 0.407513290643692 -0.4525092840194702\n",
      "Loss: 0.33573681116104126 -0.44574832916259766\n",
      "Loss: 0.3567168116569519 -0.20921590924263\n",
      "Loss: 0.3657751679420471 -0.5750374794006348\n",
      "Policy Reward: tensor(1.0997, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.47', '0.52', '0.48', '0.30', '0.31', '0.35', '0.38', '0.57', '0.56', '0.72', '0.95', '0.93', '0.85', '0.71', '0.38', '0.30', '0.22']\n",
      "Last Action:  tensor([0.2196, 0.2815, 0.5001, 0.2169, 0.6066, 0.9940, 0.3101, 0.8124, 0.4905,\n",
      "        0.5620], device='cuda:0')\n",
      "Loss: 0.38759249448776245 -0.41423287987709045\n",
      "Loss: 0.3485548496246338 -0.3077632188796997\n",
      "Loss: 0.3316059410572052 -0.12995539605617523\n",
      "Loss: 0.4134678542613983 -0.6370360255241394\n",
      "Loss: 0.3174985945224762 -0.534160852432251\n",
      "Loss: 0.40501347184181213 -0.426580548286438\n",
      "Loss: 0.41493523120880127 -0.6925582885742188\n",
      "Policy Reward: tensor(1.1752, device='cuda:0')\n",
      "Trajectory:  ['0.85', '0.94', '0.28', '0.00', '0.56', '0.37', '0.26', '0.21', '0.14', '0.24', '0.50', '0.78', '0.99', '0.99', '0.90', '0.79', '0.71', '0.65', '0.51']\n",
      "Last Action:  tensor([0.5089, 0.3174, 0.7357, 0.8540, 0.2368, 0.4727, 0.4979, 0.5489, 0.9291,\n",
      "        0.6317], device='cuda:0')\n",
      "Loss: 0.34984293580055237 -0.34936976432800293\n",
      "Loss: 0.4273238778114319 -0.6001612544059753\n",
      "Loss: 0.34684833884239197 -0.5535122752189636\n",
      "Loss: 0.42175987362861633 -0.7529556751251221\n",
      "Loss: 0.3772420585155487 -0.6201140880584717\n",
      "Loss: 0.3912316560745239 -0.7446548342704773\n",
      "Loss: 0.2837451696395874 -0.12695810198783875\n",
      "Policy Reward: tensor(1.2793, device='cuda:0')\n",
      "Trajectory:  ['0.22', '1.00', '0.59', '0.12', '0.69', '0.33', '0.12', '0.05', '0.19', '0.47', '0.82', '0.99', '0.98', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9994, 0.6840, 0.1769, 0.7123, 0.6921, 0.7413, 0.7203, 0.9952, 0.3967,\n",
      "        0.2185], device='cuda:0')\n",
      "Bigstep:  97\n",
      "Loss: 0.34987086057662964 0.31059712171554565\n",
      "Loss: 0.3636857867240906 -0.24207571148872375\n",
      "Loss: 0.4018327593803406 -0.1751737892627716\n",
      "Loss: 0.3624737560749054 -0.3152512311935425\n",
      "Loss: 0.3206489086151123 0.10232318192720413\n",
      "Loss: 0.32789748907089233 0.15927113592624664\n",
      "Loss: 0.36343875527381897 -0.2018987387418747\n",
      "Policy Reward: tensor(1.2033, device='cuda:0')\n",
      "Trajectory:  ['0.19', '0.97', '0.75', '0.06', '0.80', '0.61', '0.53', '0.35', '0.25', '0.36', '0.95', '1.00', '1.00', '1.00', '0.99', '0.96', '0.89', '0.73', '0.88']\n",
      "Last Action:  tensor([0.8783, 0.9520, 0.8920, 0.7596, 0.7965, 0.7467, 0.7766, 0.9994, 0.7491,\n",
      "        0.9965], device='cuda:0')\n",
      "Loss: 0.3688491880893707 -0.40345141291618347\n",
      "Loss: 0.41505905985832214 -0.38735249638557434\n",
      "Loss: 0.3504580557346344 -0.04970359429717064\n",
      "Loss: 0.35952335596084595 -0.13487115502357483\n",
      "Loss: 0.26804879307746887 0.17843009531497955\n",
      "Loss: 0.31684213876724243 -0.1792500764131546\n",
      "Loss: 0.3548600673675537 -0.30138930678367615\n",
      "Policy Reward: tensor(1.1917, device='cuda:0')\n",
      "Trajectory:  ['0.06', '1.00', '0.76', '0.77', '0.70', '0.66', '0.53', '0.21', '0.07', '0.30', '0.76', '0.92', '1.00', '1.00', '1.00', '1.00', '0.99', '0.85', '0.64']\n",
      "Last Action:  tensor([0.6373, 0.7023, 0.9998, 0.9611, 0.7930, 0.7161, 0.7178, 0.9728, 0.5995,\n",
      "        0.8945], device='cuda:0')\n",
      "Loss: 0.33895328640937805 -0.22174072265625\n",
      "Loss: 0.3643766939640045 -0.40441736578941345\n",
      "Loss: 0.284909188747406 0.3979942202568054\n",
      "Loss: 0.4148835837841034 -0.5178584456443787\n",
      "Loss: 0.32240030169487 -0.22451362013816833\n",
      "Loss: 0.36015447974205017 -0.24980594217777252\n",
      "Loss: 0.3540765047073364 -0.2848273515701294\n",
      "Policy Reward: tensor(1.1293, device='cuda:0')\n",
      "Trajectory:  ['0.98', '0.57', '0.51', '0.08', '0.67', '0.58', '0.47', '0.68', '0.71', '0.74', '0.86', '0.98', '1.00', '1.00', '1.00', '0.98', '0.93', '0.83', '0.80']\n",
      "Last Action:  tensor([0.8019, 0.7723, 0.7892, 0.8029, 0.8479, 0.9943, 0.7645, 0.9542, 0.6959,\n",
      "        0.6466], device='cuda:0')\n",
      "Loss: 0.2768774628639221 -0.17842093110084534\n",
      "Loss: 0.32802993059158325 -0.30984559655189514\n",
      "Loss: 0.38088878989219666 -0.4263113737106323\n",
      "Loss: 0.36625632643699646 -0.2719897925853729\n",
      "Loss: 0.41040468215942383 -0.40850406885147095\n",
      "Loss: 0.313576340675354 -0.19801121950149536\n",
      "Loss: 0.3278235197067261 -0.1560865342617035\n",
      "Policy Reward: tensor(1.2157, device='cuda:0')\n",
      "Trajectory:  ['0.06', '1.00', '0.51', '0.00', '0.52', '0.29', '0.40', '0.55', '0.65', '0.73', '0.79', '0.84', '0.98', '1.00', '1.00', '0.99', '0.98', '0.83', '0.68']\n",
      "Last Action:  tensor([0.6755, 0.7233, 0.6730, 0.9979, 0.6972, 0.5824, 0.6919, 0.7169, 0.9985,\n",
      "        0.7497], device='cuda:0')\n",
      "Loss: 0.30142244696617126 -0.30447328090667725\n",
      "Loss: 0.314922958612442 0.026482105255126953\n",
      "Loss: 0.32184088230133057 -0.14925162494182587\n",
      "Loss: 0.3066999614238739 -0.19507068395614624\n",
      "Loss: 0.37812983989715576 -0.21398478746414185\n",
      "Loss: 0.2930926978588104 -0.36416515707969666\n",
      "Loss: 0.40066009759902954 -0.19375064969062805\n",
      "Policy Reward: tensor(1.1392, device='cuda:0')\n",
      "Trajectory:  ['0.99', '0.96', '0.98', '0.99', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9972, 0.7071, 0.7544, 0.7602, 0.6764, 0.7517, 0.6801, 0.6978, 0.9054,\n",
      "        0.7510], device='cuda:0')\n",
      "Loss: 0.3599121570587158 -0.36224260926246643\n",
      "Loss: 0.38257384300231934 -0.485935777425766\n",
      "Loss: 0.3802531659603119 -0.5493717789649963\n",
      "Loss: 0.3262971341609955 -0.4464464485645294\n",
      "Loss: 0.33163368701934814 -0.07461965084075928\n",
      "Loss: 0.4256678819656372 -0.5475574731826782\n",
      "Loss: 0.376100093126297 -0.5630252361297607\n",
      "Policy Reward: tensor(0.9581, device='cuda:0')\n",
      "Trajectory:  ['0.14', '1.00', '0.58', '0.00', '0.61', '0.35', '0.31', '0.45', '0.48', '0.54', '0.66', '0.89', '1.00', '1.00', '1.00', '0.99', '0.94', '0.85', '0.76']\n",
      "Last Action:  tensor([0.7610, 0.8759, 0.7757, 0.7462, 0.9763, 0.8045, 0.9999, 0.7291, 0.7445,\n",
      "        0.8234], device='cuda:0')\n",
      "Loss: 0.31742554903030396 -0.1911136656999588\n",
      "Loss: 0.4060891270637512 -0.4901163876056671\n",
      "Loss: 0.36672163009643555 -0.17175382375717163\n",
      "Loss: 0.35341545939445496 -0.22846414148807526\n",
      "Loss: 0.33520540595054626 -0.26227256655693054\n",
      "Loss: 0.36142653226852417 -0.3733440041542053\n",
      "Loss: 0.38384541869163513 -0.24729491770267487\n",
      "Policy Reward: tensor(1.1413, device='cuda:0')\n",
      "Trajectory:  ['0.27', '1.00', '0.67', '0.00', '0.67', '0.44', '0.48', '0.71', '0.72', '0.61', '0.75', '0.97', '1.00', '1.00', '1.00', '0.99', '0.96', '0.83', '0.76']\n",
      "Last Action:  tensor([0.7553, 0.7695, 0.7280, 0.9910, 0.7369, 0.8080, 0.9967, 0.7760, 0.7922,\n",
      "        0.7151], device='cuda:0')\n",
      "Loss: 0.28533828258514404 -0.28826817870140076\n",
      "Loss: 0.33820220828056335 -0.11536642909049988\n",
      "Loss: 0.3174422085285187 -0.2570967376232147\n",
      "Loss: 0.3885444104671478 -0.6313392519950867\n",
      "Loss: 0.406624972820282 -0.4290122091770172\n",
      "Loss: 0.3408221900463104 -0.23452243208885193\n",
      "Loss: 0.3654777407646179 -0.39012038707733154\n",
      "Policy Reward: tensor(1.0861, device='cuda:0')\n",
      "Trajectory:  ['0.99', '0.67', '0.80', '0.64', '0.84', '0.88', '0.69', '0.63', '0.24', '0.07', '0.07', '0.18', '0.62', '1.00', '1.00', '1.00', '1.00', '0.92', '0.62']\n",
      "Last Action:  tensor([0.6221, 0.8993, 0.8401, 0.8290, 0.7682, 0.9993, 0.9996, 0.7797, 0.8210,\n",
      "        0.8068], device='cuda:0')\n",
      "Bigstep:  98\n",
      "Loss: 0.3541213274002075 0.3195600211620331\n",
      "Loss: 0.35804885625839233 0.4021137058734894\n",
      "Loss: 0.3176218867301941 -0.2201698273420334\n",
      "Loss: 0.32266783714294434 0.14588184654712677\n",
      "Loss: 0.3977012634277344 -0.25712138414382935\n",
      "Loss: 0.33697617053985596 -0.027945637702941895\n",
      "Loss: 0.3650723993778229 -0.17100776731967926\n",
      "Policy Reward: tensor(1.1234, device='cuda:0')\n",
      "Trajectory:  ['0.25', '1.00', '0.80', '0.05', '0.48', '0.34', '0.41', '0.78', '0.98', '0.99', '0.99', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9994, 0.9987, 0.9992, 0.9986, 0.9740, 0.9894, 0.9975, 0.9988, 0.9717,\n",
      "        0.9991], device='cuda:0')\n",
      "Loss: 0.3865290582180023 -0.5002968907356262\n",
      "Loss: 0.3409775495529175 0.024692727252840996\n",
      "Loss: 0.3259907066822052 0.17224180698394775\n",
      "Loss: 0.3468227982521057 0.27575406432151794\n",
      "Loss: 0.36355412006378174 0.22715239226818085\n",
      "Loss: 0.341974675655365 0.00872285757213831\n",
      "Loss: 0.46797290444374084 -0.4326363801956177\n",
      "Policy Reward: tensor(1.1114, device='cuda:0')\n",
      "Trajectory:  ['0.16', '1.00', '0.78', '0.57', '0.55', '0.67', '0.89', '0.98', '0.98', '0.99', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '0.99']\n",
      "Last Action:  tensor([0.9944, 0.9908, 0.9958, 0.9887, 0.9959, 0.9925, 0.9989, 0.8860, 0.9941,\n",
      "        0.9923], device='cuda:0')\n",
      "Loss: 0.3173638582229614 0.036974452435970306\n",
      "Loss: 0.31208735704421997 0.12197047472000122\n",
      "Loss: 0.3965305685997009 -0.1873013973236084\n",
      "Loss: 0.3936828672885895 -0.19543848931789398\n",
      "Loss: 0.37626251578330994 -0.41600075364112854\n",
      "Loss: 0.43624642491340637 0.09243136644363403\n",
      "Loss: 0.4617081582546234 -0.37783634662628174\n",
      "Policy Reward: tensor(1.1689, device='cuda:0')\n",
      "Trajectory:  ['0.14', '1.00', '0.79', '0.00', '0.48', '0.27', '0.53', '0.77', '0.75', '0.63', '0.77', '0.99', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '0.97']\n",
      "Last Action:  tensor([0.9678, 0.9436, 0.9989, 0.9946, 0.9920, 0.9997, 0.8464, 0.9421, 0.9934,\n",
      "        0.9461], device='cuda:0')\n",
      "Loss: 0.34953105449676514 -0.47956180572509766\n",
      "Loss: 0.3163353502750397 0.04663164168596268\n",
      "Loss: 0.39991506934165955 -0.15276660025119781\n",
      "Loss: 0.39039644598960876 -0.3836306929588318\n",
      "Loss: 0.3323284387588501 -0.21538032591342926\n",
      "Loss: 0.38040217757225037 -0.09529547393321991\n",
      "Loss: 0.39524030685424805 -0.20541256666183472\n",
      "Policy Reward: tensor(1.2111, device='cuda:0')\n",
      "Trajectory:  ['0.99', '0.70', '0.72', '0.97', '1.00', '1.00', '0.99', '0.98', '0.99', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '0.99', '0.97']\n",
      "Last Action:  tensor([0.9674, 0.7708, 0.9825, 0.9338, 0.9930, 0.9995, 0.9999, 0.9919, 0.9942,\n",
      "        0.9823], device='cuda:0')\n",
      "Loss: 0.4242895841598511 -0.5680903196334839\n",
      "Loss: 0.38329198956489563 -0.25553613901138306\n",
      "Loss: 0.45355555415153503 -0.286051869392395\n",
      "Loss: 0.3709014058113098 -0.5031722187995911\n",
      "Loss: 0.2860696613788605 0.19297657907009125\n",
      "Loss: 0.31332525610923767 -0.2076433151960373\n",
      "Loss: 0.3293284773826599 -0.03576468676328659\n",
      "Policy Reward: tensor(1.1679, device='cuda:0')\n",
      "Trajectory:  ['0.19', '1.00', '0.91', '0.00', '0.48', '0.45', '0.60', '0.83', '0.92', '0.98', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9965, 0.9957, 0.7905, 0.9913, 0.9919, 0.9952, 0.9998, 0.9943, 0.9956,\n",
      "        0.9975], device='cuda:0')\n",
      "Loss: 0.33402130007743835 0.03511877357959747\n",
      "Loss: 0.31853780150413513 -0.18975907564163208\n",
      "Loss: 0.36301931738853455 -0.28505080938339233\n",
      "Loss: 0.3366240859031677 -0.14767801761627197\n",
      "Loss: 0.35937824845314026 -0.23379069566726685\n",
      "Loss: 0.34198319911956787 0.025171278044581413\n",
      "Loss: 0.3432444632053375 0.1078648716211319\n",
      "Policy Reward: tensor(1.1191, device='cuda:0')\n",
      "Trajectory:  ['0.05', '1.00', '0.86', '0.64', '0.50', '0.70', '0.90', '0.94', '0.67', '0.59', '0.93', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '0.94']\n",
      "Last Action:  tensor([0.9357, 0.9744, 0.9999, 0.9912, 0.9940, 0.9963, 0.9986, 0.9949, 0.9961,\n",
      "        0.9968], device='cuda:0')\n",
      "Loss: 0.361457884311676 -0.5018324255943298\n",
      "Loss: 0.3404664099216461 -0.14840096235275269\n",
      "Loss: 0.3895385265350342 -0.34550565481185913\n",
      "Loss: 0.41126173734664917 0.043352145701646805\n",
      "Loss: 0.3349136710166931 -0.17287421226501465\n",
      "Loss: 0.4287300109863281 -0.23884697258472443\n",
      "Loss: 0.3550410866737366 -0.3518396019935608\n",
      "Policy Reward: tensor(1.0826, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.92', '0.68', '0.48', '0.69', '0.65', '0.46', '0.74', '0.99', '0.98', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9999, 0.9986, 0.9998, 0.9597, 0.9961, 0.9627, 0.9969, 0.9170, 0.9885,\n",
      "        0.9995], device='cuda:0')\n",
      "Loss: 0.3700530529022217 -0.05909426137804985\n",
      "Loss: 0.3096563518047333 0.016286004334688187\n",
      "Loss: 0.30621156096458435 0.08547989279031754\n",
      "Loss: 0.35584303736686707 -0.1829288750886917\n",
      "Loss: 0.4253136217594147 -0.42484167218208313\n",
      "Loss: 0.3009049892425537 -0.04413524270057678\n",
      "Loss: 0.5135383605957031 -0.8444997072219849\n",
      "Policy Reward: tensor(1.1165, device='cuda:0')\n",
      "Trajectory:  ['0.13', '1.00', '0.82', '0.01', '0.48', '0.37', '0.49', '0.85', '0.97', '0.99', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9984, 0.9990, 0.9977, 0.9375, 0.9976, 0.9989, 0.9977, 0.9938, 1.0000,\n",
      "        0.9819], device='cuda:0')\n",
      "Bigstep:  99\n",
      "Loss: 0.47628411650657654 -0.03532753139734268\n",
      "Loss: 0.3393303453922272 0.3634682893753052\n",
      "Loss: 0.4431593716144562 -0.09960944950580597\n",
      "Loss: 0.37990322709083557 -0.2760060429573059\n",
      "Loss: 0.37629932165145874 0.17627224326133728\n",
      "Loss: 0.4041151702404022 -0.3038926124572754\n",
      "Loss: 0.3325245678424835 -0.00513835996389389\n",
      "Policy Reward: tensor(1.0114, device='cuda:0')\n",
      "Trajectory:  ['0.03', '1.00', '0.70', '0.74', '0.77', '0.90', '0.99', '0.95', '0.69', '0.74', '0.94', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '0.95']\n",
      "Last Action:  tensor([0.9476, 0.9562, 0.9567, 0.9677, 0.9991, 0.7731, 0.8801, 0.9999, 0.9304,\n",
      "        0.9263], device='cuda:0')\n",
      "Loss: 0.29279667139053345 0.19785960018634796\n",
      "Loss: 0.3187013566493988 0.007690045982599258\n",
      "Loss: 0.47046077251434326 -0.1720718890428543\n",
      "Loss: 0.4353097081184387 -0.11167129874229431\n",
      "Loss: 0.39538276195526123 -0.19771906733512878\n",
      "Loss: 0.29301750659942627 0.09133987128734589\n",
      "Loss: 0.3112643361091614 9.066984057426453e-05\n",
      "Policy Reward: tensor(1.1271, device='cuda:0')\n",
      "Trajectory:  ['0.99', '0.40', '0.72', '0.37', '0.86', '0.68', '0.52', '0.62', '0.77', '0.66', '0.58', '0.60', '0.96', '1.00', '1.00', '1.00', '1.00', '0.88', '0.67']\n",
      "Last Action:  tensor([0.6691, 0.8941, 0.9269, 0.6678, 0.7822, 0.9406, 0.9635, 0.8690, 0.8231,\n",
      "        0.8883], device='cuda:0')\n",
      "Loss: 0.44036731123924255 -0.5060150623321533\n",
      "Loss: 0.36846137046813965 0.0783676952123642\n",
      "Loss: 0.36549699306488037 -0.17453494668006897\n",
      "Loss: 0.4451669454574585 -0.28982868790626526\n",
      "Loss: 0.3907366693019867 -0.3476555049419403\n",
      "Loss: 0.39956724643707275 -0.19271036982536316\n",
      "Loss: 0.4128079414367676 -0.08948591351509094\n",
      "Policy Reward: tensor(1.2659, device='cuda:0')\n",
      "Trajectory:  ['0.14', '1.00', '0.64', '0.26', '0.73', '0.27', '0.08', '0.09', '0.08', '0.06', '0.21', '0.85', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00']\n",
      "Last Action:  tensor([0.9995, 0.9594, 0.9148, 0.9681, 0.9537, 0.9713, 0.9593, 0.9143, 0.9996,\n",
      "        0.9918], device='cuda:0')\n",
      "Loss: 0.3208465874195099 0.25061121582984924\n",
      "Loss: 0.3099610507488251 0.08025038242340088\n",
      "Loss: 0.36261823773384094 -0.20463049411773682\n",
      "Loss: 0.3681146800518036 -0.038264643400907516\n",
      "Loss: 0.3864005506038666 -0.2645266354084015\n",
      "Loss: 0.2622104287147522 0.14513960480690002\n",
      "Loss: 0.3103710412979126 0.13807106018066406\n",
      "Policy Reward: tensor(1.1056, device='cuda:0')\n",
      "Trajectory:  ['0.09', '1.00', '0.52', '0.01', '0.42', '0.21', '0.03', '0.04', '0.10', '0.10', '0.12', '0.77', '1.00', '1.00', '1.00', '0.99', '0.74', '0.55', '0.72']\n",
      "Last Action:  tensor([0.7217, 0.7908, 0.9784, 0.9994, 0.9994, 0.8308, 0.8260, 0.7992, 0.8249,\n",
      "        0.8993], device='cuda:0')\n",
      "Loss: 0.36216872930526733 0.20422866940498352\n",
      "Loss: 0.3475257158279419 -0.37143266201019287\n",
      "Loss: 0.32748833298683167 0.05007778853178024\n",
      "Loss: 0.4240858554840088 -0.4344702959060669\n",
      "Loss: 0.29727762937545776 0.19642028212547302\n",
      "Loss: 0.3854232430458069 -0.2801717519760132\n",
      "Loss: 0.34708526730537415 -0.1665557622909546\n",
      "Policy Reward: tensor(1.0718, device='cuda:0')\n",
      "Trajectory:  ['0.00', '1.00', '0.81', '0.67', '0.57', '0.53', '0.48', '0.16', '0.05', '0.15', '0.43', '0.79', '0.92', '0.88', '0.76', '0.75', '0.78', '0.79', '0.76']\n",
      "Last Action:  tensor([0.7558, 0.9630, 0.6469, 0.7513, 0.8679, 0.8262, 0.3730, 0.8743, 0.5737,\n",
      "        0.8798], device='cuda:0')\n",
      "Loss: 0.39361730217933655 -0.4029091000556946\n",
      "Loss: 0.35669827461242676 -0.301361620426178\n",
      "Loss: 0.36780133843421936 -0.3175275921821594\n",
      "Loss: 0.3071909248828888 0.0386904738843441\n",
      "Loss: 0.436957448720932 -0.4521554708480835\n",
      "Loss: 0.41533663868904114 -0.438045471906662\n",
      "Loss: 0.3927631378173828 -0.32336530089378357\n",
      "Policy Reward: tensor(1.1655, device='cuda:0')\n",
      "Trajectory:  ['0.98', '0.13', '0.54', '0.03', '0.56', '0.30', '0.21', '0.28', '0.26', '0.38', '0.41', '0.59', '0.85', '0.83', '0.48', '0.60', '0.22', '0.29', '0.36']\n",
      "Last Action:  tensor([0.3576, 0.9182, 0.2929, 0.0556, 0.4136, 0.4125, 0.1562, 0.9992, 0.2475,\n",
      "        0.9114], device='cuda:0')\n",
      "Loss: 0.3947821855545044 -0.13100430369377136\n",
      "Loss: 0.3332838714122772 -0.14330153167247772\n",
      "Loss: 0.33508652448654175 -0.18077628314495087\n",
      "Loss: 0.3915889859199524 -0.6362992525100708\n",
      "Loss: 0.42350566387176514 -0.632634699344635\n",
      "Loss: 0.34540465474128723 0.002860371023416519\n",
      "Loss: 0.41068604588508606 -0.32184258103370667\n",
      "Policy Reward: tensor(1.1295, device='cuda:0')\n",
      "Trajectory:  ['0.06', '1.00', '0.74', '0.66', '0.65', '0.52', '0.54', '0.51', '0.55', '0.57', '0.61', '0.79', '0.84', '0.64', '0.41', '0.37', '0.41', '0.46', '0.41']\n",
      "Last Action:  tensor([0.4069, 0.2047, 0.7706, 0.1696, 0.5481, 0.9962, 0.6447, 0.2428, 0.4740,\n",
      "        0.7873], device='cuda:0')\n",
      "Loss: 0.35640671849250793 -0.29391464591026306\n",
      "Loss: 0.3228464126586914 -0.1997634917497635\n",
      "Loss: 0.3733060359954834 -0.3286283016204834\n",
      "Loss: 0.4141572117805481 -0.6674041748046875\n",
      "Loss: 0.3652280271053314 -0.22314010560512543\n",
      "Loss: 0.35157305002212524 -0.3300458490848541\n",
      "Loss: 0.4187803268432617 -0.6417602300643921\n",
      "Policy Reward: tensor(1.1336, device='cuda:0')\n",
      "Trajectory:  ['0.25', '1.00', '0.75', '0.37', '0.67', '0.38', '0.37', '0.35', '0.45', '0.50', '0.55', '0.83', '0.81', '0.46', '0.25', '0.19', '0.15', '0.19', '0.14']\n",
      "Last Action:  tensor([0.1425, 0.9042, 0.9997, 0.0673, 0.8488, 0.2919, 0.9548, 0.2414, 0.8006,\n",
      "        0.2300], device='cuda:0')\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#10,15,15,32\n",
    "train(100, 8, 64, 256, 20, model, 0.05, 0.95, opt, 'cuda')\n",
    "#None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#torch.save(model, 'hposimple3')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Policy Reward: tensor(1.3462, device='cuda:0')\n",
      "Trajectory:  ['0.13', '1.00', '0.56', '0.02', '0.40', '0.26', '0.29', '0.38', '0.44', '0.56', '0.57', '0.67', '0.78', '0.50', '0.25', '0.10', '0.11', '0.14', '0.15']\n",
      "Last Action:  tensor([0.1494, 0.5015, 0.9240, 0.9600, 0.6349, 0.5174, 0.1337, 0.3088, 0.2662,\n",
      "        0.2339], device='cuda:0')\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "validate(1, 10, 20, model, 'cuda', render=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Policy Reward: tensor(1.1745, device='cuda:0')\n",
      "Trajectory:  ['0.05', '1.00', '0.72', '0.61', '0.61', '0.45', '0.50', '0.49', '0.55', '0.58', '0.57', '0.77', '0.83', '0.59', '0.40', '0.22', '0.19', '0.22', '0.20']\n",
      "Last Action:  tensor([0.2039, 0.7268, 0.6978, 0.9998, 0.3892, 0.4775, 0.5315, 0.2118, 0.8875,\n",
      "        0.3627], device='cuda:0')\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "validate(1, 10, 20, model, 'cuda', render=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "from scipy.stats import norm, multivariate_normal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "x = np.linspace(0, 1, 100)\n",
    "x1 = np.linspace(-5, 0, 100)\n",
    "x2 = np.linspace(0, 5, 100)\n",
    "\n",
    "K = norm.pdf(10*np.abs(np.subtract(*np.meshgrid(x, x))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "y = multivariate_normal.rvs(np.zeros(100, dtype=np.float), K, size=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x7f3ca7a1a320>]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 57
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, y[0])\n",
    "plt.plot(x, y[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[2, 3]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "\n",
    "[1,2,3][1:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-920542d2f85d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mK\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/scipy/stats/_multivariate.py\u001b[0m in \u001b[0;36mrvs\u001b[0;34m(self, mean, cov, size, random_state)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \"\"\"\n\u001b[0;32m--> 657\u001b[0;31m         \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/scipy/stats/_multivariate.py\u001b[0m in \u001b[0;36m_process_parameters\u001b[0;34m(self, dim, mean, cov)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             raise ValueError(\"Array 'mean' must be a vector of length %d.\" %\n\u001b[0;32m--> 407\u001b[0;31m                              dim)\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcov\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Array 'mean' must be a vector of length 30."
     ],
     "ename": "ValueError",
     "evalue": "Array 'mean' must be a vector of length 30.",
     "output_type": "error"
    }
   ],
   "source": [
    "K = torch.empty((3,10,10))\n",
    "for i in range(3):\n",
    "    K[i] = torch.eye(10) * (i+1)**2\n",
    "mean = torch.ones((3,10)) * torch.tensor([-1,1,10]).view(-1, 1)\n",
    "dist = torch.distributions.multivariate_normal.MultivariateNormal(mean, K)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "s = dist.sample()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(11.2609)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 42
    }
   ],
   "source": [
    "((s[2]-10)**2).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0.5000, -0.4685])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    }
   ],
   "source": [
    "\n",
    "\n",
    "env = GPEnv()\n",
    "env.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Action:  tensor([[0.5000]])\n",
      "y:  [[-0.46851146]]\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "(tensor([ 0.5000, -0.4685]), 3.5108876300649072e-06, False, {})"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 14
    }
   ],
   "source": [
    "env.step(torch.tensor([[0.5]], dtype=torch.float))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}